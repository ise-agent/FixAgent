{
  "zero_patches": {
    "Location 1 (/root/hy/projects/xarray/xarray/core/variable.py lines 220-222)": "\n    # we don't want nested self-described arrays, but only for pandas/xarray objects\n    # preserve arbitrary objects with .values attribute when storing in object arrays\n    if hasattr(data, 'values') and isinstance(data, (pd.Series, pd.DataFrame, pd.Index, pd.Categorical)):\n        data = data.values\n",
    "Location 2 (/root/hy/projects/xarray/xarray/core/variable.py lines 857-859)": "\n        if not isinstance(value, Variable):\n            value = as_compatible_data(value)\n            if value.ndim > len(dims):\n                raise ValueError(\n                    \"shape mismatch: value array of shape %s could not be \"\n                    \"broadcast to indexing result with %s dimensions\"\n                    % (value.shape, len(dims))\n                )\n            if value.ndim == 0:\n                value = Variable((), value)\n            else:\n                value = Variable(dims[-value.ndim :], value)\n",
    "Location 3 (/root/hy/projects/xarray/xarray/core/variable.py lines 1-20)": "\nimport copy\nimport functools\nimport itertools\nimport numbers\nimport warnings\nfrom collections import defaultdict\nfrom datetime import timedelta\nfrom distutils.version import LooseVersion\nfrom typing import (\n    Any,\n    Dict,\n    Hashable,\n    List,\n    Mapping,\n    Optional,\n    Sequence,\n    Tuple,\n    TypeVar,\n    Union,\n)\n",
    "Location 4 (/root/hy/projects/xarray/xarray/core/variable.py lines 189-195)": "\ndef as_compatible_data(data, fastpath=False):\n    \"\"\"Prepare and wrap data to put in a Variable.\n\n    - If data does not have the necessary attributes, convert it to ndarray.\n    - If data has dtype=datetime64, ensure that it has ns precision. If it's a\n      pandas.Timestamp, convert it to datetime64.\n    - If data is already a pandas or xarray object (other than an Index), just\n      use the values.\n    - For arbitrary objects with .values properties, preserve the object itself\n      unless it's a known pandas/xarray type.\n\n    Finally, wrap it up with an adapter if necessary.\n    \"\"\"\n    if fastpath and getattr(data, \"ndim\", 0) > 0:\n        # can't use fastpath (yet) for scalars\n        return _maybe_wrap_data(data)\n\n    if isinstance(data, Variable):\n        return data.data\n\n    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n        data = _maybe_wrap_data(data)\n        return data\n\n    if isinstance(data, tuple):\n        data = utils.to_0d_object_array(data)\n\n    if isinstance(data, pd.Timestamp):\n        # TODO: convert, handle datetime objects, too\n        data = np.datetime64(data.value, \"ns\")\n\n    if isinstance(data, timedelta):\n        data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n\n    # we don't want nested self-described arrays\n    if isinstance(data, (pd.Series, pd.DataFrame)):\n        data = data.values\n\n    if isinstance(data, pd.Index):\n        data = data.values\n        if isinstance(data, pd.PeriodArray):\n            data = data.astype(\"object\")\n\n    # Only extract .values from known pandas/xarray objects, not arbitrary objects\n    if hasattr(data, \"values\") and not isinstance(data, (pd.Series, pd.DataFrame, pd.Index)):\n        # For arbitrary objects with .values, check if we should preserve the object\n        # This preserves objects with .values properties when they should be stored as-is\n        pass  # Don't extract .values from arbitrary objects\n    elif hasattr(data, \"values\"):\n        # This is a known pandas/xarray object, safe to extract values\n        data = data.values\n\n    # deal with possibly-0d dask arrays\n    if isinstance(data, dask_array_type):\n        data = data.compute()\n\n    data = np.asarray(data)\n\n    if data.ndim == 0:\n        if isinstance(data, np.ndarray):\n            data = data.item()\n    else:\n        data = _possibly_convert_objects(data)\n\n    return _maybe_wrap_data(data)\n",
    "Location 5 (/root/hy/projects/xarray/xarray/tests/test_variable.py lines 2170-2310)": "\nclass TestAsCompatibleData:\n    def test_unchanged_types(self):\n        types = (np.asarray, PandasIndexAdapter, LazilyOuterIndexedArray)\n        for t in types:\n            for data in [\n                np.arange(3),\n                pd.date_range(\"2000-01-01\", periods=3),\n                pd.date_range(\"2000-01-01\", periods=3).values,\n            ]:\n                x = t(data)\n                assert source_ndarray(x) is source_ndarray(as_compatible_data(x))\n\n    def test_converted_types(self):\n        for input_array in [[[0, 1, 2]], pd.DataFrame([[0, 1, 2]])]:\n            actual = as_compatible_data(input_array)\n            assert_array_equal(np.asarray(input_array), actual)\n            assert np.ndarray == type(actual)\n            assert np.asarray(input_array).dtype == actual.dtype\n\n    def test_masked_array(self):\n        original = np.ma.MaskedArray(np.arange(5))\n        expected = np.arange(5)\n        actual = as_compatible_data(original)\n        assert_array_equal(expected, actual)\n        assert np.dtype(int) == actual.dtype\n\n        original = np.ma.MaskedArray(np.arange(5), mask=4 * [False] + [True])\n        expected = np.arange(5.0)\n        expected[-1] = np.nan\n        actual = as_compatible_data(original)\n        assert_array_equal(expected, actual)\n        assert np.dtype(float) == actual.dtype\n\n    def test_datetime(self):\n        expected = np.datetime64(\"2000-01-01\")\n        actual = as_compatible_data(expected)\n        assert expected == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n        expected = np.array([np.datetime64(\"2000-01-01\")])\n        actual = as_compatible_data(expected)\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n        expected = np.array([np.datetime64(\"2000-01-01\", \"ns\")])\n        actual = as_compatible_data(expected)\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n        assert expected is source_ndarray(np.asarray(actual))\n\n        expected = np.datetime64(\"2000-01-01\", \"ns\")\n        actual = as_compatible_data(datetime(2000, 1, 1))\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n    def test_objects_with_values_property(self):\n        # Test that objects with .values property are preserved when not pandas objects\n        class HasValues:\n            def __init__(self, values=5):\n                self.values = values\n        \n        obj = HasValues()\n        actual = as_compatible_data(obj)\n        # Object should be preserved as-is, not have its .values extracted\n        assert actual is obj\n        \n        # Test with array of such objects\n        obj_array = np.array([HasValues(), HasValues(10)], dtype=object)\n        actual = as_compatible_data(obj_array)\n        assert actual is obj_array\n        assert isinstance(actual[0], HasValues)\n        assert actual[0].values == 5\n        assert actual[1].values == 10\n\n    def test_full_like(self):\n        # For more thorough tests, see test_variable.py\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n\n        expect = orig.copy(deep=True)\n        expect.values = [[2.0, 2.0], [2.0, 2.0]]\n        assert_identical(expect, full_like(orig, 2))\n\n        # override dtype\n        expect.values = [[True, True], [True, True]]\n        assert expect.dtype == bool\n        assert_identical(expect, full_like(orig, True, dtype=bool))\n\n        # raise error on non-scalar fill_value\n        with raises_regex(ValueError, \"must be scalar\"):\n            full_like(orig, [1.0, 2.0])\n\n    @requires_dask\n    def test_full_like_dask(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        ).chunk(((1, 1), (2,)))\n\n        def check(actual, expect_dtype, expect_values):\n            assert actual.dtype == expect_dtype\n            assert actual.shape == orig.shape\n            assert actual.dims == orig.dims\n            assert actual.attrs == orig.attrs\n            assert actual.chunks == orig.chunks\n            assert_array_equal(actual.values, expect_values)\n\n        check(full_like(orig, 2), orig.dtype, np.full_like(orig.values, 2))\n        # override dtype\n        check(\n            full_like(orig, True, dtype=bool),\n            bool,\n            np.full_like(orig.values, True, dtype=bool),\n        )\n\n        # Check that there's no array stored inside dask\n        # (e.g. we didn't create a numpy array and then we chunked it!)\n        dsk = full_like(orig, 1).data.dask\n        for v in dsk.values():\n            if isinstance(v, tuple):\n                for vi in v:\n                    assert not isinstance(vi, np.ndarray)\n            else:\n                assert not isinstance(v, np.ndarray)\n\n    def test_zeros_like(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n        assert_identical(zeros_like(orig), full_like(orig, 0))\n        assert_identical(zeros_like(orig, dtype=int), full_like(orig, 0, dtype=int))\n\n    def test_ones_like(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n        assert_identical(ones_like(orig), full_like(orig, 1))\n        assert_identical(ones_like(orig, dtype=int), full_like(orig, 1, dtype=int))\n\n    def test_unsupported_type(self):\n        # Non indexable type\n        class CustomArray(NDArrayMixin):\n            def __init__(self, array):\n                self.array = array\n\n        class CustomIndexable(CustomArray, indexing.ExplicitlyIndexed):\n            pass\n\n        array = CustomArray(np.arange(3))\n        orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n        assert isinstance(orig._data, np.ndarray)  # should not be CustomArray\n\n        array = CustomIndexable(np.arange(3))\n        orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n        assert isinstance(orig._data, CustomIndexable)\n"
  },
  "variant_patches": {
    "Location 1 (/root/hy/projects/xarray/xarray/core/variable.py lines 220-222)": [
      "\n    # we don't want nested self-described arrays, but preserve objects with .values for object arrays\n    if hasattr(data, \"values\") and isinstance(data, (pd.Series, pd.DataFrame, pd.Index, xr.Variable, xr.DataArray)):\n        data = data.values\n",
      "\n    # we don't want nested self-described arrays, but preserve objects with .values for object dtypes\n    if hasattr(data, 'values') and isinstance(data, (pd.Series, pd.DataFrame, pd.Index, xr.DataArray, xr.Dataset)):\n        data = data.values\n",
      "\n    # we don't want nested self-described arrays, but preserve objects with .values for object dtypes\n    if hasattr(data, \"values\") and isinstance(data, (pd.Series, pd.DataFrame, pd.Index, xr.DataArray, xr.Dataset)):\n        data = data.values\n",
      "\n    # we don't want nested self-described arrays, but preserve objects with .values for object dtypes\n    if hasattr(data, 'values') and isinstance(data, (pd.Series, pd.DataFrame, pd.Index, xr.DataArray, xr.Dataset)):\n        data = data.values\n",
      "\n    # we don't want nested self-described arrays, but preserve objects with .values\n    # only extract .values from pandas/xarray objects, not arbitrary objects\n    if hasattr(data, 'values') and isinstance(data, (pd.Series, pd.DataFrame, pd.Index, DataArray)):\n        data = data.values\n",
      "\n    # we don't want nested self-described arrays, but preserve arbitrary objects\n    # only extract .values from known pandas/xarray types\n    if hasattr(data, \"values\") and isinstance(data, (pd.Series, pd.DataFrame, pd.Index)):\n        data = data.values\n",
      "\n    # we don't want nested self-described arrays, but preserve objects with .values\n    # only extract .values from known pandas/xarray types\n    if hasattr(data, 'values') and isinstance(data, (pd.Series, pd.DataFrame, pd.Index)):\n        data = data.values\n",
      "\n    # we don't want nested self-described arrays, but only for known pandas/xarray types\n    # preserve arbitrary objects with .values properties when storing in object arrays\n    if isinstance(data, (pd.Series, pd.DataFrame, pd.Index)) or hasattr(data, '_constructor'):\n        data = getattr(data, \"values\", data)\n"
    ],
    "Location 2 (/root/hy/projects/xarray/xarray/core/variable.py lines 857-859)": [
      "\n        if not isinstance(value, Variable):\n            # Check if we're assigning to an object dtype array to preserve objects with .values\n            target_dtype = getattr(self._data, 'dtype', None)\n            preserve_objects = target_dtype == object\n            value = as_compatible_data(value, preserve_objects=preserve_objects)\n            if value.ndim > len(dims):\n",
      "\n        if not isinstance(value, Variable):\n            # Check if we're assigning to an object dtype array to preserve objects with .values\n            target_dtype = getattr(self._data, 'dtype', None)\n            preserve_objects = target_dtype == object\n            value = as_compatible_data(value, preserve_objects=preserve_objects)\n            if value.ndim > len(dims):\n",
      "\n        if not isinstance(value, Variable):\n            value = as_compatible_data(value)\n            if value.ndim > len(dims):\n                raise ValueError(\n                    \"shape mismatch: value array of shape %s could not be \"\n                    \"broadcast to indexing result with %s dimensions\"\n                    % (value.shape, len(dims))\n                )\n            if value.ndim == 0:\n                value = Variable((), value)\n            else:\n                value = Variable(dims[-value.ndim :], value)\n",
      "\n        if not isinstance(value, Variable):\n            # Pass dtype information to help as_compatible_data make better decisions\n            # about whether to extract .values from objects\n            target_dtype = getattr(self._data, 'dtype', None)\n            value = as_compatible_data(value, target_dtype=target_dtype)\n            if value.ndim > len(dims):\n",
      "\n        if not isinstance(value, Variable):\n            # For object dtype arrays, preserve objects with .values properties\n            # instead of extracting them indiscriminately\n            if hasattr(self, 'dtype') and self.dtype == np.dtype('O'):\n                value = as_compatible_data(value, preserve_objects=True)\n            else:\n                value = as_compatible_data(value)\n            if value.ndim > len(dims):\n",
      "\n        if not isinstance(value, Variable):\n            value = as_compatible_data(value)\n            if value.ndim > len(dims):\n                raise ValueError(\n                    \"shape mismatch: value array of shape %s could not be \"\n                    \"broadcast to indexing result with %s dimensions\"\n                    % (value.shape, len(dims))\n                )\n            if value.ndim == 0:\n                value = Variable((), value)\n            else:\n                value = Variable(dims[-value.ndim :], value)\n",
      "\n        if not isinstance(value, Variable):\n            value = as_compatible_data(value)\n            if value.ndim > len(dims):\n                raise ValueError(\n                    \"shape mismatch: value array of shape %s could not be \"\n                    \"broadcast to indexing result with %s dimensions\"\n                    % (value.shape, len(dims))\n                )\n            if value.ndim == 0:\n                value = Variable((), value)\n            else:\n                value = Variable(dims[-value.ndim :], value)\n",
      "\n        if not isinstance(value, Variable):\n            value = as_compatible_data(value)\n            if value.ndim > len(dims):\n                raise ValueError(\n                    \"shape mismatch: value array of shape %s could not be \"\n                    \"broadcast to indexing result with %s dimensions\"\n                    % (value.shape, len(dims))\n                )\n            if value.ndim == 0:\n                value = Variable((), value)\n            else:\n                value = Variable(dims[-value.ndim :], value)\n"
    ],
    "Location 3 (/root/hy/projects/xarray/xarray/core/variable.py lines 1-20)": [
      "\nimport copy\nimport functools\nimport itertools\nimport numbers\nimport warnings\nfrom collections import defaultdict\nfrom datetime import timedelta\nfrom distutils.version import LooseVersion\nfrom typing import (\n    Any,\n    Dict,\n    Hashable,\n    List,\n    Mapping,\n    Optional,\n    Sequence,\n    Tuple,\n    TypeVar,\n    Union,\n)\n",
      "\nimport copy\nimport functools\nimport itertools\nimport numbers\nimport warnings\nfrom collections import defaultdict\nfrom datetime import timedelta\nfrom distutils.version import LooseVersion\nfrom typing import (\n    Any,\n    Dict,\n    Hashable,\n    List,\n    Mapping,\n    Optional,\n    Sequence,\n    Tuple,\n    TypeVar,\n    Union,\n)\n",
      "\nimport copy\nimport functools\nimport itertools\nimport numbers\nimport warnings\nfrom collections import defaultdict\nfrom datetime import timedelta\nfrom distutils.version import LooseVersion\nfrom typing import (\n    Any,\n    Dict,\n    Hashable,\n    List,\n    Mapping,\n    Optional,\n    Sequence,\n    Tuple,\n    TypeVar,\n    Union,\n)\n",
      "\nimport copy\nimport functools\nimport itertools\nimport numbers\nimport warnings\nfrom collections import defaultdict\nfrom datetime import timedelta\nfrom distutils.version import LooseVersion\nfrom typing import (\n    Any,\n    Dict,\n    Hashable,\n    List,\n    Mapping,\n    Optional,\n    Sequence,\n    Tuple,\n    TypeVar,\n    Union,\n)\n",
      "\nimport copy\nimport functools\nimport itertools\nimport numbers\nimport warnings\nfrom collections import defaultdict\nfrom datetime import timedelta\nfrom distutils.version import LooseVersion\nfrom typing import (\n    Any,\n    Dict,\n    Hashable,\n    List,\n    Mapping,\n    Optional,\n    Sequence,\n    Tuple,\n    TypeVar,\n    Union,\n)\n",
      "\nimport copy\nimport functools\nimport itertools\nimport numbers\nimport warnings\nfrom collections import defaultdict\nfrom datetime import timedelta\nfrom distutils.version import LooseVersion\nfrom typing import (\n    Any,\n    Dict,\n    Hashable,\n    List,\n    Mapping,\n    Optional,\n    Sequence,\n    Tuple,\n    TypeVar,\n    Union,\n)\n",
      "\nimport copy\nimport functools\nimport itertools\nimport numbers\nimport warnings\nfrom collections import defaultdict\nfrom datetime import timedelta\nfrom distutils.version import LooseVersion\nfrom typing import (\n    Any,\n    Dict,\n    Hashable,\n    List,\n    Mapping,\n    Optional,\n    Sequence,\n    Tuple,\n    TypeVar,\n    Union,\n)\n",
      "\nimport copy\nimport functools\nimport itertools\nimport numbers\nimport warnings\nfrom collections import defaultdict\nfrom datetime import timedelta\nfrom distutils.version import LooseVersion\nfrom typing import (\n    Any,\n    Dict,\n    Hashable,\n    List,\n    Mapping,\n    Optional,\n    Sequence,\n    Tuple,\n    TypeVar,\n    Union,\n)\n"
    ],
    "Location 4 (/root/hy/projects/xarray/xarray/core/variable.py lines 189-195)": [
      "\ndef as_compatible_data(data, fastpath=False):\n    \"\"\"Prepare and wrap data to put in a Variable.\n\n    - If data does not have the necessary attributes, convert it to ndarray.\n    - If data has dtype=datetime64, ensure that it has ns precision. If it's a\n      pandas.Timestamp, convert it to datetime64.\n    - If data is already a pandas or xarray object (other than an Index), just\n      use the values.\n\n    Finally, wrap it up with an adapter if necessary.\n    \"\"\"\n    if fastpath and getattr(data, \"ndim\", 0) > 0:\n        # can't use fastpath (yet) for scalars\n        return _maybe_wrap_data(data)\n\n    if isinstance(data, Variable):\n        return data.data\n",
      "\ndef as_compatible_data(data, fastpath=False):\n    \"\"\"Prepare and wrap data to put in a Variable.\n\n    - If data does not have the necessary attributes, convert it to ndarray.\n    - If data has dtype=datetime64, ensure that it has ns precision. If it's a\n      pandas.Timestamp, convert it to datetime64.\n    - If data is already a pandas or xarray object (other than an Index), just\n      use the values.\n    - For arbitrary objects with .values properties, preserve the object itself\n      unless it's a known pandas/xarray type.\n\n    Finally, wrap it up with an adapter if necessary.\n    \"\"\"\n    if fastpath and getattr(data, \"ndim\", 0) > 0:\n        # can't use fastpath (yet) for scalars\n        return _maybe_wrap_data(data)\n\n    if isinstance(data, Variable):\n        return data.data\n\n    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n        data = _maybe_wrap_data(data)\n        return data\n\n    if isinstance(data, tuple):\n        data = utils.to_0d_object_array(data)\n\n    # Only extract .values from known pandas/xarray objects, not arbitrary objects\n    if isinstance(data, (pd.Series, pd.DataFrame, pd.Index)) or (\n        hasattr(data, \"values\") and \n        hasattr(data, \"__module__\") and \n        data.__module__ is not None and\n        (\"pandas\" in data.__module__ or \"xarray\" in data.__module__)\n    ):\n        data = getattr(data, \"values\", data)\n\n    # we don't want nested self-described arrays\n    if isinstance(data, (pd.Series, pd.DataFrame)):\n        data = data.values\n\n    if isinstance(data, np.ma.MaskedArray):\n        mask = np.ma.getmaskarray(data)\n        if mask.any():\n            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n            data = np.asarray(data, dtype=dtype)\n            data[mask] = fill_value\n        else:\n            data = np.asarray(data)\n\n    if not isinstance(data, np.ndarray):\n        if hasattr(data, \"__array_function__\") or hasattr(data, \"__array_ufunc__\"):\n            return _maybe_wrap_data(data)\n\n        # validate whether the data is valid data types.\n        data = np.asarray(data)\n\n    # validate size of data\n    if data.size != 1:\n        validate_indexer = indexing.OuterIndexer(tuple(slice(None) for _ in data.shape))\n    else:\n        validate_indexer = indexing.OuterIndexer(())\n    indexing.expanded_indexer(validate_indexer.tuple, data.ndim)\n\n    if isinstance(data, np.ndarray):\n        if data.dtype.kind == \"O\":\n            data = _possibly_convert_objects(data)\n        elif data.dtype.kind == \"U\":\n            if data.dtype != np.str_:\n                data = data.astype(np.str_)\n        elif data.dtype.kind in \"SV\":\n            data = data.astype(np.str_)\n\n    return _maybe_wrap_data(data)\n",
      "\ndef as_compatible_data(data, fastpath=False):\n    \"\"\"Prepare and wrap data to put in a Variable.\n\n    - If data does not have the necessary attributes, convert it to ndarray.\n    - If data has dtype=datetime64, ensure that it has ns precision. If it's a\n      pandas.Timestamp, convert it to datetime64.\n    - If data is already a pandas or xarray object (other than an Index), just\n      use the values.\n\n    Finally, wrap it up with an adapter if necessary.\n    \"\"\"\n    if fastpath and getattr(data, \"ndim\", 0) > 0:\n        # can't use fastpath (yet) for scalars\n        return _maybe_wrap_data(data)\n\n    if isinstance(data, Variable):\n        return data.data\n\n    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n        data = _maybe_wrap_data(data)\n        return data\n\n    if isinstance(data, tuple):\n        data = utils.to_0d_object_array(data)\n\n    if isinstance(data, pd.Timestamp):\n        # TODO: convert, handle datetime objects, too\n        data = np.datetime64(data.value, \"ns\")\n\n    if isinstance(data, timedelta):\n        data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n\n    # we don't want nested self-described arrays\n    if isinstance(data, (pd.Series, pd.DataFrame, pd.Index)):\n        data = getattr(data, \"values\", data)\n\n    if isinstance(data, np.ma.MaskedArray):\n        mask = np.ma.getmaskarray(data)\n        if mask.any():\n            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n            data = np.asarray(data, dtype=dtype)\n            data[mask] = fill_value\n        else:\n            data = np.asarray(data)\n\n    if not isinstance(data, np.ndarray):\n        if hasattr(data, \"__array_function__\") or hasattr(data, \"__array_ufunc__\"):\n            return _maybe_wrap_data(data)\n\n        # validate whether the data is valid data types.\n        data = np.asarray(data)\n\n    # validate the data\n    if isinstance(data, np.ndarray):\n        if data.dtype.kind == \"O\":\n            data = _possibly_convert_objects(data)\n        if data.dtype.kind == \"U\" and data.dtype != np.dtype(\"U0\"):\n            if is_duck_dask_array(data):\n                warnings.warn(\n                    \"Converting unicode strings to object dtype. \"\n                    \"This will raise an error in the future.\",\n                    FutureWarning,\n                    stacklevel=4,\n                )\n            else:\n                data = data.astype(object)\n\n    return _maybe_wrap_data(data)\n",
      "\ndef as_compatible_data(data, fastpath=False):\n    \"\"\"Prepare and wrap data to put in a Variable.\n\n    - If data does not have the necessary attributes, convert it to ndarray.\n    - If data has dtype=datetime64, ensure that it has ns precision. If it's a\n      pandas.Timestamp, convert it to datetime64.\n    - If data is already a pandas or xarray object (other than an Index), just\n      use the values.\n\n    Finally, wrap it up with an adapter if necessary.\n    \"\"\"\n    if fastpath and getattr(data, \"ndim\", 0) > 0:\n        # can't use fastpath (yet) for scalars\n        return _maybe_wrap_data(data)\n\n    if isinstance(data, Variable):\n        return data.data\n\n    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n        data = _maybe_wrap_data(data)\n        return data\n\n    if isinstance(data, tuple):\n        data = utils.to_0d_object_array(data)\n\n    if isinstance(data, pd.Timestamp):\n        # TODO: convert, handle datetime objects, too\n        data = np.datetime64(data.value, \"ns\")\n\n    if isinstance(data, timedelta):\n        data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n\n    # we don't want nested self-described arrays\n    # Only extract .values from known pandas/xarray types to avoid\n    # coercing arbitrary objects that happen to have a .values attribute\n    if isinstance(data, (pd.Series, pd.DataFrame, pd.Index)) or (\n        hasattr(data, \"__module__\") and \n        data.__module__ is not None and \n        data.__module__.startswith(\"xarray\")\n    ):\n        data = getattr(data, \"values\", data)\n\n    if isinstance(data, np.ma.MaskedArray):\n        mask = np.ma.getmaskarray(data)\n        if mask.any():\n            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n            data = np.asarray(data, dtype=dtype)\n            data[mask] = fill_value\n        else:\n            data = np.asarray(data)\n\n    if not isinstance(data, np.ndarray):\n        if hasattr(data, \"__array_function__\") or hasattr(data, \"__array_ufunc__\"):\n            return _maybe_wrap_data(data)\n\n        if is_duck_dask_array(data):\n            return _maybe_wrap_data(data)\n        # validate whether the data is valid data types.\n        data = np.asarray(data)\n\n    if data.dtype.kind == \"O\":\n        try:\n            data = _possibly_convert_objects(data)\n        except ValueError:\n            # most likely a numpy.ndarray that contains non-picklable objects\n            pass\n\n    # TODO: expose this as a user option\n    if data.dtype.kind == \"U\":\n        if LooseVersion(np.__version__) < \"1.14\":\n            # work around for numpy < 1.14 which doesn't\n            # handle array-like consistently\n            data = np.asarray(data, dtype=object)\n\n    return _maybe_wrap_data(data)\n",
      "\ndef as_compatible_data(data, fastpath=False, target_dtype=None):\n    \"\"\"Prepare and wrap data to put in a Variable.\n\n    - If data does not have the necessary attributes, convert it to ndarray.\n    - If data has dtype=datetime64, ensure that it has ns precision. If it's a\n      pandas.Timestamp, convert it to datetime64.\n    - If data is already a pandas or xarray object (other than an Index), just\n      use the values.\n    - For object dtype arrays, preserve objects with .values properties instead\n      of extracting them.\n\n    Finally, wrap it up with an adapter if necessary.\n    \"\"\"\n    if fastpath and getattr(data, \"ndim\", 0) > 0:\n        # can't use fastpath (yet) for scalars\n        return _maybe_wrap_data(data)\n\n    if isinstance(data, Variable):\n        return data.data\n\n    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n        data = _maybe_wrap_data(data)\n        return data\n\n    if isinstance(data, tuple):\n        data = utils.to_0d_object_array(data)\n\n    if isinstance(data, pd.Timestamp):\n        # TODO: convert, handle datetime objects, too\n        data = np.datetime64(data.value, \"ns\")\n\n    if isinstance(data, timedelta):\n        data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n\n    # we don't want nested self-described arrays\n    # For object dtypes, only extract .values from known pandas/xarray objects\n    if target_dtype == np.dtype('O'):\n        # For object dtype, only extract values from known pandas/xarray objects\n        if isinstance(data, (pd.Series, pd.DataFrame, pd.Index)) or hasattr(data, 'xindexes'):\n            data = getattr(data, \"values\", data)\n    else:\n        # For non-object dtypes, extract values as before\n        data = getattr(data, \"values\", data)\n\n    if isinstance(data, np.ma.MaskedArray):\n        mask = np.ma.getmaskarray(data)\n        if mask.any():\n            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n            data = np.asarray(data, dtype=dtype)\n            data[mask] = fill_value\n        else:\n            data = np.asarray(data)\n\n    if not isinstance(data, np.ndarray):\n        if hasattr(data, \"__array_function__\") or hasattr(data, \"__array_ufunc__\"):\n            return _maybe_wrap_data(data)\n\n        # validate whether the data is valid data types.\n        data = np.asarray(data)\n\n    if data.dtype.kind == \"O\":\n        try:\n            data = _possibly_convert_objects(data)\n        except ValueError:\n            # most likely a problem with a nested array from pandas\n            pass\n\n    return _maybe_wrap_data(data)\n",
      "\ndef as_compatible_data(data, fastpath=False):\n    \"\"\"Prepare and wrap data to put in a Variable.\n\n    - If data does not have the necessary attributes, convert it to ndarray.\n    - If data has dtype=datetime64, ensure that it has ns precision. If it's a\n      pandas.Timestamp, convert it to datetime64.\n    - If data is already a pandas or xarray object (other than an Index), just\n      use the values.\n\n    Finally, wrap it up with an adapter if necessary.\n    \"\"\"\n    if fastpath and getattr(data, \"ndim\", 0) > 0:\n        # can't use fastpath (yet) for scalars\n        return _maybe_wrap_data(data)\n\n    if isinstance(data, Variable):\n        return data.data\n\n    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n        data = _maybe_wrap_data(data)\n        return data\n\n    if isinstance(data, tuple):\n        data = utils.to_0d_object_array(data)\n\n    if isinstance(data, pd.Timestamp):\n        # TODO: convert, handle datetime objects, too\n        data = np.datetime64(data.value, \"ns\")\n\n    if isinstance(data, timedelta):\n        data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n\n    # we don't want nested self-described arrays\n    # Only extract .values from known pandas/xarray objects, not arbitrary objects\n    if isinstance(data, (pd.Series, pd.DataFrame, pd.Index)) or hasattr(data, 'values') and hasattr(data, '_constructor'):\n        data = getattr(data, \"values\", data)\n\n    if isinstance(data, np.ma.MaskedArray):\n        mask = np.ma.getmaskarray(data)\n        if mask.any():\n            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n            data = np.asarray(data, dtype=dtype)\n            data[mask] = fill_value\n        else:\n            data = np.asarray(data)\n\n    if not isinstance(data, np.ndarray):\n        if hasattr(data, \"__array_function__\") or hasattr(data, \"__array_ufunc__\"):\n            return data\n\n        if is_duck_dask_array(data):\n            return data\n        # validate whether the data is valid data types.\n        data = np.asarray(data)\n\n    if data.dtype.kind == \"O\":\n        data = _possibly_convert_objects(data)\n\n    # TODO: support other datetime dtypes than np.datetime64\n    if data.dtype.kind == \"M\":\n        data = _possibly_convert_objects(data)\n\n    elif data.dtype.kind == \"m\":\n        data = _possibly_convert_objects(data)\n\n    return _maybe_wrap_data(data)\n",
      "\ndef as_compatible_data(data, fastpath=False):\n    \"\"\"Prepare and wrap data to put in a Variable.\n\n    - If data does not have the necessary attributes, convert it to ndarray.\n    - If data has dtype=datetime64, ensure that it has ns precision. If it's a\n      pandas.Timestamp, convert it to datetime64.\n    - If data is already a pandas or xarray object (other than an Index), just\n      use the values.\n    - For arbitrary objects with .values properties, preserve the object itself\n      unless it's a known pandas/xarray type.\n\n    Finally, wrap it up with an adapter if necessary.\n    \"\"\"\n    if fastpath and getattr(data, \"ndim\", 0) > 0:\n        # can't use fastpath (yet) for scalars\n        return _maybe_wrap_data(data)\n\n    if isinstance(data, Variable):\n        return data.data\n\n    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n        data = _maybe_wrap_data(data)\n        return data\n\n    if isinstance(data, tuple):\n        data = utils.to_0d_object_array(data)\n\n    if hasattr(data, \"values\"):\n        # Only extract .values from known pandas/xarray objects\n        # Preserve arbitrary objects with .values properties\n        if isinstance(data, (pd.Series, pd.DataFrame, pd.Index)) or hasattr(data, '_xarray_cls'):\n            data = getattr(data, \"values\", data)\n\n    # we don't want nested self-described arrays\n    if isinstance(data, (pd.Series, pd.DataFrame)):\n        data = data.values\n\n    if isinstance(data, np.ma.MaskedArray):\n        mask = np.ma.getmaskarray(data)\n        if mask.any():\n            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n            data = np.asarray(data, dtype=dtype)\n            data[mask] = fill_value\n        else:\n            data = np.asarray(data)\n\n    if not isinstance(data, np.ndarray):\n        if hasattr(data, \"__array_function__\") or hasattr(data, \"__array_ufunc__\"):\n            return _maybe_wrap_data(data)\n\n        # validate whether the data is valid data types.\n        data = np.asarray(data)\n\n    if data.dtype.kind == \"O\":\n        data = _possibly_convert_objects(data)\n    elif data.dtype.kind == \"M\":\n        data = _possibly_convert_objects(data)\n    elif data.dtype.kind == \"m\":\n        data = _possibly_convert_objects(data)\n\n    return _maybe_wrap_data(data)\n",
      "\ndef as_compatible_data(data, fastpath=False):\n    \"\"\"Prepare and wrap data to put in a Variable.\n\n    - If data does not have the necessary attributes, convert it to ndarray.\n    - If data has dtype=datetime64, ensure that it has ns precision. If it's a\n      pandas.Timestamp, convert it to datetime64.\n    - If data is already a pandas or xarray object (other than an Index), just\n      use the values.\n    - For arbitrary objects with .values properties, preserve the object itself\n      unless it's a known pandas/xarray type.\n\n    Finally, wrap it up with an adapter if necessary.\n    \"\"\"\n    if fastpath and getattr(data, \"ndim\", 0) > 0:\n        # can't use fastpath (yet) for scalars\n        return _maybe_wrap_data(data)\n\n    if isinstance(data, Variable):\n        return data.data\n\n    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n        data = _maybe_wrap_data(data)\n        return data\n\n    if isinstance(data, tuple):\n        data = utils.to_0d_object_array(data)\n\n    if isinstance(data, pd.Timestamp):\n        # TODO: convert, handle datetime objects, too\n        data = np.datetime64(data.value, \"ns\")\n\n    if isinstance(data, timedelta):\n        data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n\n    # we don't want nested self-described arrays\n    # Only extract .values from known pandas/xarray objects, not arbitrary objects\n    if hasattr(data, \"values\") and isinstance(data, (pd.Series, pd.DataFrame, pd.Index, DataArray)):\n        data = getattr(data, \"values\", data)\n\n    if isinstance(data, np.ma.MaskedArray):\n        mask = np.ma.getmaskarray(data)\n        if mask.any():\n            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n            data = np.asarray(data, dtype=dtype)\n            data[mask] = fill_value\n        else:\n            data = np.asarray(data)\n\n    if not isinstance(data, np.ndarray):\n        if hasattr(data, \"__array_function__\") or hasattr(data, \"__array_ufunc__\"):\n            return _maybe_wrap_data(data)\n        else:\n            data = np.asarray(data)\n\n    if data.dtype.kind == \"O\":\n        data = _possibly_convert_objects(data)\n    elif data.dtype.kind == \"M\":\n        data = _possibly_convert_objects(data)\n    elif data.dtype.kind == \"m\":\n        data = _possibly_convert_objects(data)\n\n    return _maybe_wrap_data(data)\n"
    ],
    "Location 5 (/root/hy/projects/xarray/xarray/tests/test_variable.py lines 2170-2310)": [
      "\nclass TestAsCompatibleData:\n    def test_unchanged_types(self):\n        types = (np.asarray, PandasIndexAdapter, LazilyOuterIndexedArray)\n        for t in types:\n            for data in [\n                np.arange(3),\n                pd.date_range(\"2000-01-01\", periods=3),\n                pd.date_range(\"2000-01-01\", periods=3).values,\n            ]:\n                x = t(data)\n                assert source_ndarray(x) is source_ndarray(as_compatible_data(x))\n\n    def test_converted_types(self):\n        for input_array in [[[0, 1, 2]], pd.DataFrame([[0, 1, 2]])]:\n            actual = as_compatible_data(input_array)\n            assert_array_equal(np.asarray(input_array), actual)\n            assert np.ndarray == type(actual)\n            assert np.asarray(input_array).dtype == actual.dtype\n\n    def test_masked_array(self):\n        original = np.ma.MaskedArray(np.arange(5))\n        expected = np.arange(5)\n        actual = as_compatible_data(original)\n        assert_array_equal(expected, actual)\n        assert np.dtype(int) == actual.dtype\n\n        original = np.ma.MaskedArray(np.arange(5), mask=4 * [False] + [True])\n        expected = np.arange(5.0)\n        expected[-1] = np.nan\n        actual = as_compatible_data(original)\n        assert_array_equal(expected, actual)\n        assert np.dtype(float) == actual.dtype\n\n    def test_datetime(self):\n        expected = np.datetime64(\"2000-01-01\")\n        actual = as_compatible_data(expected)\n        assert expected == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n        expected = np.array([np.datetime64(\"2000-01-01\")])\n        actual = as_compatible_data(expected)\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n        expected = np.array([np.datetime64(\"2000-01-01\", \"ns\")])\n        actual = as_compatible_data(expected)\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n        assert expected is source_ndarray(np.asarray(actual))\n\n        expected = np.datetime64(\"2000-01-01\", \"ns\")\n        actual = as_compatible_data(datetime(2000, 1, 1))\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n    def test_full_like(self):\n        # For more thorough tests, see test_variable.py\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n\n        expect = orig.copy(deep=True)\n        expect.values = [[2.0, 2.0], [2.0, 2.0]]\n        assert_identical(expect, full_like(orig, 2))\n\n        # override dtype\n        expect.values = [[True, True], [True, True]]\n        assert expect.dtype == bool\n        assert_identical(expect, full_like(orig, True, dtype=bool))\n\n        # raise error on non-scalar fill_value\n        with raises_regex(ValueError, \"must be scalar\"):\n            full_like(orig, [1.0, 2.0])\n\n    @requires_dask\n    def test_full_like_dask(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        ).chunk(((1, 1), (2,)))\n\n        def check(actual, expect_dtype, expect_values):\n            assert actual.dtype == expect_dtype\n            assert actual.shape == orig.shape\n            assert actual.dims == orig.dims\n            assert actual.attrs == orig.attrs\n            assert actual.chunks == orig.chunks\n            assert_array_equal(actual.values, expect_values)\n\n        check(full_like(orig, 2), orig.dtype, np.full_like(orig.values, 2))\n        # override dtype\n        check(\n            full_like(orig, True, dtype=bool),\n            bool,\n            np.full_like(orig.values, True, dtype=bool),\n        )\n\n        # Check that there's no array stored inside dask\n        # (e.g. we didn't create a numpy array and then we chunked it!)\n        dsk = full_like(orig, 1).data.dask\n        for v in dsk.values():\n            if isinstance(v, tuple):\n                for vi in v:\n                    assert not isinstance(vi, np.ndarray)\n            else:\n                assert not isinstance(v, np.ndarray)\n\n    def test_zeros_like(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n        assert_identical(zeros_like(orig), full_like(orig, 0))\n        assert_identical(zeros_like(orig, dtype=int), full_like(orig, 0, dtype=int))\n\n    def test_ones_like(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n        assert_identical(ones_like(orig), full_like(orig, 1))\n        assert_identical(ones_like(orig, dtype=int), full_like(orig, 1, dtype=int))\n\n    def test_unsupported_type(self):\n        # Non indexable type\n        class CustomArray(NDArrayMixin):\n            def __init__(self, array):\n                self.array = array\n\n        class CustomIndexable(CustomArray, indexing.ExplicitlyIndexed):\n            pass\n\n        array = CustomArray(np.arange(3))\n        orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n        assert isinstance(orig._data, np.ndarray)  # should not be CustomArray\n\n        array = CustomIndexable(np.arange(3))\n        orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n        assert isinstance(orig._data, CustomIndexable)\n\n    def test_object_with_values_property(self):\n        # Test that objects with .values property are preserved in object arrays\n        class HasValues:\n            def __init__(self, value=5):\n                self.values = value\n        \n        obj = HasValues()\n        actual = as_compatible_data(obj)\n        # Object should be preserved as-is, not have .values extracted\n        assert actual is obj\n        \n        # Test with array containing objects with .values property\n        obj_array = np.array([HasValues(), HasValues(10)], dtype=object)\n        actual = as_compatible_data(obj_array)\n        assert_array_equal(obj_array, actual)\n        assert actual.dtype == object\n        \n        # Verify objects are preserved\n        assert isinstance(actual[0], HasValues)\n        assert isinstance(actual[1], HasValues)\n        assert actual[0].values == 5\n        assert actual[1].values == 10\n",
      "\nclass TestAsCompatibleData:\n    def test_unchanged_types(self):\n        types = (np.asarray, PandasIndexAdapter, LazilyOuterIndexedArray)\n        for t in types:\n            for data in [\n                np.arange(3),\n                pd.date_range(\"2000-01-01\", periods=3),\n                pd.date_range(\"2000-01-01\", periods=3).values,\n            ]:\n                x = t(data)\n                assert source_ndarray(x) is source_ndarray(as_compatible_data(x))\n\n    def test_converted_types(self):\n        for input_array in [[[0, 1, 2]], pd.DataFrame([[0, 1, 2]])]:\n            actual = as_compatible_data(input_array)\n            assert_array_equal(np.asarray(input_array), actual)\n            assert np.ndarray == type(actual)\n            assert np.asarray(input_array).dtype == actual.dtype\n\n    def test_masked_array(self):\n        original = np.ma.MaskedArray(np.arange(5))\n        expected = np.arange(5)\n        actual = as_compatible_data(original)\n        assert_array_equal(expected, actual)\n        assert np.dtype(int) == actual.dtype\n\n        original = np.ma.MaskedArray(np.arange(5), mask=4 * [False] + [True])\n        expected = np.arange(5.0)\n        expected[-1] = np.nan\n        actual = as_compatible_data(original)\n        assert_array_equal(expected, actual)\n        assert np.dtype(float) == actual.dtype\n\n    def test_datetime(self):\n        expected = np.datetime64(\"2000-01-01\")\n        actual = as_compatible_data(expected)\n        assert expected == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n        expected = np.array([np.datetime64(\"2000-01-01\")])\n        actual = as_compatible_data(expected)\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n        expected = np.array([np.datetime64(\"2000-01-01\", \"ns\")])\n        actual = as_compatible_data(expected)\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n        assert expected is source_ndarray(np.asarray(actual))\n\n        expected = np.datetime64(\"2000-01-01\", \"ns\")\n        actual = as_compatible_data(datetime(2000, 1, 1))\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n    def test_objects_with_values_property(self):\n        \"\"\"Test that objects with .values property are preserved in object arrays.\"\"\"\n        class HasValues:\n            def __init__(self, value=5):\n                self.values = value\n            \n            def __repr__(self):\n                return f\"HasValues(values={self.values})\"\n        \n        # Test single object\n        obj = HasValues()\n        actual = as_compatible_data(obj)\n        assert actual is obj  # Object should be preserved as-is\n        \n        # Test in array context\n        obj_array = [HasValues(1), HasValues(2)]\n        actual = as_compatible_data(obj_array)\n        assert isinstance(actual, np.ndarray)\n        assert actual.dtype == object\n        assert isinstance(actual[0], HasValues)\n        assert isinstance(actual[1], HasValues)\n        assert actual[0].values == 1\n        assert actual[1].values == 2\n\n    def test_full_like(self):\n        # For more thorough tests, see test_variable.py\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n\n        expect = orig.copy(deep=True)\n        expect.values = [[2.0, 2.0], [2.0, 2.0]]\n        assert_identical(expect, full_like(orig, 2))\n\n        # override dtype\n        expect.values = [[True, True], [True, True]]\n        assert expect.dtype == bool\n        assert_identical(expect, full_like(orig, True, dtype=bool))\n\n        # raise error on non-scalar fill_value\n        with raises_regex(ValueError, \"must be scalar\"):\n            full_like(orig, [1.0, 2.0])\n\n    @requires_dask\n    def test_full_like_dask(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        ).chunk(((1, 1), (2,)))\n\n        def check(actual, expect_dtype, expect_values):\n            assert actual.dtype == expect_dtype\n            assert actual.shape == orig.shape\n            assert actual.dims == orig.dims\n            assert actual.attrs == orig.attrs\n            assert actual.chunks == orig.chunks\n            assert_array_equal(actual.values, expect_values)\n\n        check(full_like(orig, 2), orig.dtype, np.full_like(orig.values, 2))\n        # override dtype\n        check(\n            full_like(orig, True, dtype=bool),\n            bool,\n            np.full_like(orig.values, True, dtype=bool),\n        )\n\n        # Check that there's no array stored inside dask\n        # (e.g. we didn't create a numpy array and then we chunked it!)\n        dsk = full_like(orig, 1).data.dask\n        for v in dsk.values():\n            if isinstance(v, tuple):\n                for vi in v:\n                    assert not isinstance(vi, np.ndarray)\n            else:\n                assert not isinstance(v, np.ndarray)\n\n    def test_zeros_like(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n        assert_identical(zeros_like(orig), full_like(orig, 0))\n        assert_identical(zeros_like(orig, dtype=int), full_like(orig, 0, dtype=int))\n\n    def test_ones_like(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n        assert_identical(ones_like(orig), full_like(orig, 1))\n        assert_identical(ones_like(orig, dtype=int), full_like(orig, 1, dtype=int))\n\n    def test_unsupported_type(self):\n        # Non indexable type\n        class CustomArray(NDArrayMixin):\n            def __init__(self, array):\n                self.array = array\n\n        class CustomIndexable(CustomArray, indexing.ExplicitlyIndexed):\n            pass\n\n        array = CustomArray(np.arange(3))\n        orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n        assert isinstance(orig._data, np.ndarray)  # should not be CustomArray\n\n        array = CustomIndexable(np.arange(3))\n        orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n        assert isinstance(orig._data, CustomIndexable)\n",
      "\nclass TestAsCompatibleData:\n    def test_unchanged_types(self):\n        types = (np.asarray, PandasIndexAdapter, LazilyOuterIndexedArray)\n        for t in types:\n            for data in [\n                np.arange(3),\n                pd.date_range(\"2000-01-01\", periods=3),\n                pd.date_range(\"2000-01-01\", periods=3).values,\n            ]:\n                x = t(data)\n                assert source_ndarray(x) is source_ndarray(as_compatible_data(x))\n\n    def test_converted_types(self):\n        for input_array in [[[0, 1, 2]], pd.DataFrame([[0, 1, 2]])]:\n            actual = as_compatible_data(input_array)\n            assert_array_equal(np.asarray(input_array), actual)\n            assert np.ndarray == type(actual)\n            assert np.asarray(input_array).dtype == actual.dtype\n\n    def test_masked_array(self):\n        original = np.ma.MaskedArray(np.arange(5))\n        expected = np.arange(5)\n        actual = as_compatible_data(original)\n        assert_array_equal(expected, actual)\n        assert np.dtype(int) == actual.dtype\n\n        original = np.ma.MaskedArray(np.arange(5), mask=4 * [False] + [True])\n        expected = np.arange(5.0)\n        expected[-1] = np.nan\n        actual = as_compatible_data(original)\n        assert_array_equal(expected, actual)\n        assert np.dtype(float) == actual.dtype\n\n    def test_datetime(self):\n        expected = np.datetime64(\"2000-01-01\")\n        actual = as_compatible_data(expected)\n        assert expected == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n        expected = np.array([np.datetime64(\"2000-01-01\")])\n        actual = as_compatible_data(expected)\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n        expected = np.array([np.datetime64(\"2000-01-01\", \"ns\")])\n        actual = as_compatible_data(expected)\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n        assert expected is source_ndarray(np.asarray(actual))\n\n        expected = np.datetime64(\"2000-01-01\", \"ns\")\n        actual = as_compatible_data(datetime(2000, 1, 1))\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n    def test_full_like(self):\n        # For more thorough tests, see test_variable.py\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n\n        expect = orig.copy(deep=True)\n        expect.values = [[2.0, 2.0], [2.0, 2.0]]\n        assert_identical(expect, full_like(orig, 2))\n\n        # override dtype\n        expect.values = [[True, True], [True, True]]\n        assert expect.dtype == bool\n        assert_identical(expect, full_like(orig, True, dtype=bool))\n\n        # raise error on non-scalar fill_value\n        with raises_regex(ValueError, \"must be scalar\"):\n            full_like(orig, [1.0, 2.0])\n\n    @requires_dask\n    def test_full_like_dask(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        ).chunk(((1, 1), (2,)))\n\n        def check(actual, expect_dtype, expect_values):\n            assert actual.dtype == expect_dtype\n            assert actual.shape == orig.shape\n            assert actual.dims == orig.dims\n            assert actual.attrs == orig.attrs\n            assert actual.chunks == orig.chunks\n            assert_array_equal(actual.values, expect_values)\n\n        check(full_like(orig, 2), orig.dtype, np.full_like(orig.values, 2))\n        # override dtype\n        check(\n            full_like(orig, True, dtype=bool),\n            bool,\n            np.full_like(orig.values, True, dtype=bool),\n        )\n\n        # Check that there's no array stored inside dask\n        # (e.g. we didn't create a numpy array and then we chunked it!)\n        dsk = full_like(orig, 1).data.dask\n        for v in dsk.values():\n            if isinstance(v, tuple):\n                for vi in v:\n                    assert not isinstance(vi, np.ndarray)\n            else:\n                assert not isinstance(v, np.ndarray)\n\n    def test_zeros_like(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n        assert_identical(zeros_like(orig), full_like(orig, 0))\n        assert_identical(zeros_like(orig, dtype=int), full_like(orig, 0, dtype=int))\n\n    def test_ones_like(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n        assert_identical(ones_like(orig), full_like(orig, 1))\n        assert_identical(ones_like(orig, dtype=int), full_like(orig, 1, dtype=int))\n\n    def test_unsupported_type(self):\n        # Non indexable type\n        class CustomArray(NDArrayMixin):\n            def __init__(self, array):\n                self.array = array\n\n        class CustomIndexable(CustomArray, indexing.ExplicitlyIndexed):\n            pass\n\n        array = CustomArray(np.arange(3))\n        orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n        assert isinstance(orig._data, np.ndarray)  # should not be CustomArray\n\n        array = CustomIndexable(np.arange(3))\n        orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n        assert isinstance(orig._data, CustomIndexable)\n\n    def test_object_with_values_property(self):\n        # Test that objects with .values property are preserved in object arrays\n        # This tests the fix for the bug where as_compatible_data incorrectly\n        # extracts .values from arbitrary objects\n        class HasValues:\n            def __init__(self, value=5):\n                self.values = value\n            \n            def __repr__(self):\n                return f\"HasValues(values={self.values})\"\n        \n        obj = HasValues()\n        \n        # Test that the object is preserved as-is, not its .values extracted\n        actual = as_compatible_data(obj)\n        assert actual is obj\n        \n        # Test in an array context - should create object dtype array\n        obj_array = [obj]\n        actual = as_compatible_data(obj_array)\n        assert actual.dtype == object\n        assert actual[0] is obj\n        \n        # Test that pandas objects still have their .values extracted\n        series = pd.Series([1, 2, 3])\n        actual = as_compatible_data(series)\n        assert_array_equal(actual, series.values)\n        assert not hasattr(actual, 'values') or not callable(getattr(actual, 'values', None))\n",
      "\nclass TestAsCompatibleData:\n    def test_unchanged_types(self):\n        types = (np.asarray, PandasIndexAdapter, LazilyOuterIndexedArray)\n        for t in types:\n            for data in [\n                np.arange(3),\n                pd.date_range(\"2000-01-01\", periods=3),\n                pd.date_range(\"2000-01-01\", periods=3).values,\n            ]:\n                x = t(data)\n                assert source_ndarray(x) is source_ndarray(as_compatible_data(x))\n\n    def test_converted_types(self):\n        for input_array in [[[0, 1, 2]], pd.DataFrame([[0, 1, 2]])]:\n            actual = as_compatible_data(input_array)\n            assert_array_equal(np.asarray(input_array), actual)\n            assert np.ndarray == type(actual)\n            assert np.asarray(input_array).dtype == actual.dtype\n\n    def test_masked_array(self):\n        original = np.ma.MaskedArray(np.arange(5))\n        expected = np.arange(5)\n        actual = as_compatible_data(original)\n        assert_array_equal(expected, actual)\n        assert np.dtype(int) == actual.dtype\n\n        original = np.ma.MaskedArray(np.arange(5), mask=4 * [False] + [True])\n        expected = np.arange(5.0)\n        expected[-1] = np.nan\n        actual = as_compatible_data(original)\n        assert_array_equal(expected, actual)\n        assert np.dtype(float) == actual.dtype\n\n    def test_datetime(self):\n        expected = np.datetime64(\"2000-01-01\")\n        actual = as_compatible_data(expected)\n        assert expected == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n        expected = np.array([np.datetime64(\"2000-01-01\")])\n        actual = as_compatible_data(expected)\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n        expected = np.array([np.datetime64(\"2000-01-01\", \"ns\")])\n        actual = as_compatible_data(expected)\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n        assert expected is source_ndarray(np.asarray(actual))\n\n        expected = np.datetime64(\"2000-01-01\", \"ns\")\n        actual = as_compatible_data(datetime(2000, 1, 1))\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n    def test_full_like(self):\n        # For more thorough tests, see test_variable.py\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n\n        expect = orig.copy(deep=True)\n        expect.values = [[2.0, 2.0], [2.0, 2.0]]\n        assert_identical(expect, full_like(orig, 2))\n\n        # override dtype\n        expect.values = [[True, True], [True, True]]\n        assert expect.dtype == bool\n        assert_identical(expect, full_like(orig, True, dtype=bool))\n\n        # raise error on non-scalar fill_value\n        with raises_regex(ValueError, \"must be scalar\"):\n            full_like(orig, [1.0, 2.0])\n\n    @requires_dask\n    def test_full_like_dask(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        ).chunk(((1, 1), (2,)))\n\n        def check(actual, expect_dtype, expect_values):\n            assert actual.dtype == expect_dtype\n            assert actual.shape == orig.shape\n            assert actual.dims == orig.dims\n            assert actual.attrs == orig.attrs\n            assert actual.chunks == orig.chunks\n            assert_array_equal(actual.values, expect_values)\n\n        check(full_like(orig, 2), orig.dtype, np.full_like(orig.values, 2))\n        # override dtype\n        check(\n            full_like(orig, True, dtype=bool),\n            bool,\n            np.full_like(orig.values, True, dtype=bool),\n        )\n\n        # Check that there's no array stored inside dask\n        # (e.g. we didn't create a numpy array and then we chunked it!)\n        dsk = full_like(orig, 1).data.dask\n        for v in dsk.values():\n            if isinstance(v, tuple):\n                for vi in v:\n                    assert not isinstance(vi, np.ndarray)\n            else:\n                assert not isinstance(v, np.ndarray)\n\n    def test_zeros_like(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n        assert_identical(zeros_like(orig), full_like(orig, 0))\n        assert_identical(zeros_like(orig, dtype=int), full_like(orig, 0, dtype=int))\n\n    def test_ones_like(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n        assert_identical(ones_like(orig), full_like(orig, 1))\n        assert_identical(ones_like(orig, dtype=int), full_like(orig, 1, dtype=int))\n\n    def test_objects_with_values_property(self):\n        # Test that objects with .values property are preserved when stored in object arrays\n        class HasValues:\n            def __init__(self, value=5):\n                self.values = value\n\n        obj = HasValues()\n        # Test as_compatible_data directly\n        actual = as_compatible_data(obj)\n        assert actual is obj  # Object should be preserved as-is\n\n        # Test in Variable construction\n        var = Variable(\"x\", [obj], dtype=object)\n        assert var.values[0] is obj  # Object should be stored as-is\n        assert var.dtype == object\n\n        # Test Variable.__setitem__ with object dtype\n        var = Variable(\"x\", [None], dtype=object)\n        var[0] = obj\n        assert var.values[0] is obj  # Object should be stored as-is\n\n    def test_unsupported_type(self):\n        # Non indexable type\n        class CustomArray(NDArrayMixin):\n            def __init__(self, array):\n                self.array = array\n\n        class CustomIndexable(CustomArray, indexing.ExplicitlyIndexed):\n            pass\n\n        array = CustomArray(np.arange(3))\n        orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n        assert isinstance(orig._data, np.ndarray)  # should not be CustomArray\n\n        array = CustomIndexable(np.arange(3))\n        orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n        assert isinstance(orig._data, CustomIndexable)\n",
      "\nclass TestAsCompatibleData:\n    def test_unchanged_types(self):\n        types = (np.asarray, PandasIndexAdapter, LazilyOuterIndexedArray)\n        for t in types:\n            for data in [\n                np.arange(3),\n                pd.date_range(\"2000-01-01\", periods=3),\n                pd.date_range(\"2000-01-01\", periods=3).values,\n            ]:\n                x = t(data)\n                assert source_ndarray(x) is source_ndarray(as_compatible_data(x))\n\n    def test_converted_types(self):\n        for input_array in [[[0, 1, 2]], pd.DataFrame([[0, 1, 2]])]:\n            actual = as_compatible_data(input_array)\n            assert_array_equal(np.asarray(input_array), actual)\n            assert np.ndarray == type(actual)\n            assert np.asarray(input_array).dtype == actual.dtype\n\n    def test_masked_array(self):\n        original = np.ma.MaskedArray(np.arange(5))\n        expected = np.arange(5)\n        actual = as_compatible_data(original)\n        assert_array_equal(expected, actual)\n        assert np.dtype(int) == actual.dtype\n\n        original = np.ma.MaskedArray(np.arange(5), mask=4 * [False] + [True])\n        expected = np.arange(5.0)\n        expected[-1] = np.nan\n        actual = as_compatible_data(original)\n        assert_array_equal(expected, actual)\n        assert np.dtype(float) == actual.dtype\n\n    def test_datetime(self):\n        expected = np.datetime64(\"2000-01-01\")\n        actual = as_compatible_data(expected)\n        assert expected == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n        expected = np.array([np.datetime64(\"2000-01-01\")])\n        actual = as_compatible_data(expected)\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n        expected = np.array([np.datetime64(\"2000-01-01\", \"ns\")])\n        actual = as_compatible_data(expected)\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n        assert expected is source_ndarray(np.asarray(actual))\n\n        expected = np.datetime64(\"2000-01-01\", \"ns\")\n        actual = as_compatible_data(datetime(2000, 1, 1))\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n    def test_full_like(self):\n        # For more thorough tests, see test_variable.py\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n\n        expect = orig.copy(deep=True)\n        expect.values = [[2.0, 2.0], [2.0, 2.0]]\n        assert_identical(expect, full_like(orig, 2))\n\n        # override dtype\n        expect.values = [[True, True], [True, True]]\n        assert expect.dtype == bool\n        assert_identical(expect, full_like(orig, True, dtype=bool))\n\n        # raise error on non-scalar fill_value\n        with raises_regex(ValueError, \"must be scalar\"):\n            full_like(orig, [1.0, 2.0])\n\n    @requires_dask\n    def test_full_like_dask(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        ).chunk(((1, 1), (2,)))\n\n        def check(actual, expect_dtype, expect_values):\n            assert actual.dtype == expect_dtype\n            assert actual.shape == orig.shape\n            assert actual.dims == orig.dims\n            assert actual.attrs == orig.attrs\n            assert actual.chunks == orig.chunks\n            assert_array_equal(actual.values, expect_values)\n\n        check(full_like(orig, 2), orig.dtype, np.full_like(orig.values, 2))\n        # override dtype\n        check(\n            full_like(orig, True, dtype=bool),\n            bool,\n            np.full_like(orig.values, True, dtype=bool),\n        )\n\n        # Check that there's no array stored inside dask\n        # (e.g. we didn't create a numpy array and then we chunked it!)\n        dsk = full_like(orig, 1).data.dask\n        for v in dsk.values():\n            if isinstance(v, tuple):\n                for vi in v:\n                    assert not isinstance(vi, np.ndarray)\n            else:\n                assert not isinstance(v, np.ndarray)\n\n    def test_zeros_like(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n        assert_identical(zeros_like(orig), full_like(orig, 0))\n        assert_identical(zeros_like(orig, dtype=int), full_like(orig, 0, dtype=int))\n\n    def test_ones_like(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n        assert_identical(ones_like(orig), full_like(orig, 1))\n        assert_identical(ones_like(orig, dtype=int), full_like(orig, 1, dtype=int))\n\n    def test_object_with_values_property(self):\n        # Test that objects with .values property are preserved in object arrays\n        class HasValues:\n            def __init__(self, value=5):\n                self.values = value\n\n        obj = HasValues()\n        actual = as_compatible_data(obj)\n        # Object should be preserved, not have its .values extracted\n        assert actual is obj\n        assert isinstance(actual, HasValues)\n        assert actual.values == 5\n\n        # Test that this works when creating Variables with object dtype\n        var = Variable(dims=(\"x\",), data=[obj], attrs={})\n        assert var.dtype == object\n        assert isinstance(var.values[0], HasValues)\n        assert var.values[0].values == 5\n\n    def test_unsupported_type(self):\n        # Non indexable type\n        class CustomArray(NDArrayMixin):\n            def __init__(self, array):\n                self.array = array\n\n        class CustomIndexable(CustomArray, indexing.ExplicitlyIndexed):\n            pass\n\n        array = CustomArray(np.arange(3))\n        orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n        assert isinstance(orig._data, np.ndarray)  # should not be CustomArray\n\n        array = CustomIndexable(np.arange(3))\n        orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n        assert isinstance(orig._data, CustomIndexable)\n",
      "\nclass TestAsCompatibleData:\n    def test_unchanged_types(self):\n        types = (np.asarray, PandasIndexAdapter, LazilyOuterIndexedArray)\n        for t in types:\n            for data in [\n                np.arange(3),\n                pd.date_range(\"2000-01-01\", periods=3),\n                pd.date_range(\"2000-01-01\", periods=3).values,\n            ]:\n                x = t(data)\n                assert source_ndarray(x) is source_ndarray(as_compatible_data(x))\n\n    def test_converted_types(self):\n        for input_array in [[[0, 1, 2]], pd.DataFrame([[0, 1, 2]])]:\n            actual = as_compatible_data(input_array)\n            assert_array_equal(np.asarray(input_array), actual)\n            assert np.ndarray == type(actual)\n            assert np.asarray(input_array).dtype == actual.dtype\n\n    def test_masked_array(self):\n        original = np.ma.MaskedArray(np.arange(5))\n        expected = np.arange(5)\n        actual = as_compatible_data(original)\n        assert_array_equal(expected, actual)\n        assert np.dtype(int) == actual.dtype\n\n        original = np.ma.MaskedArray(np.arange(5), mask=4 * [False] + [True])\n        expected = np.arange(5.0)\n        expected[-1] = np.nan\n        actual = as_compatible_data(original)\n        assert_array_equal(expected, actual)\n        assert np.dtype(float) == actual.dtype\n\n    def test_datetime(self):\n        expected = np.datetime64(\"2000-01-01\")\n        actual = as_compatible_data(expected)\n        assert expected == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n        expected = np.array([np.datetime64(\"2000-01-01\")])\n        actual = as_compatible_data(expected)\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n        expected = np.array([np.datetime64(\"2000-01-01\", \"ns\")])\n        actual = as_compatible_data(expected)\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n        assert expected is source_ndarray(np.asarray(actual))\n\n        expected = np.datetime64(\"2000-01-01\", \"ns\")\n        actual = as_compatible_data(datetime(2000, 1, 1))\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n    def test_full_like(self):\n        # For more thorough tests, see test_variable.py\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n\n        expect = orig.copy(deep=True)\n        expect.values = [[2.0, 2.0], [2.0, 2.0]]\n        assert_identical(expect, full_like(orig, 2))\n\n        # override dtype\n        expect.values = [[True, True], [True, True]]\n        assert expect.dtype == bool\n        assert_identical(expect, full_like(orig, True, dtype=bool))\n\n        # raise error on non-scalar fill_value\n        with raises_regex(ValueError, \"must be scalar\"):\n            full_like(orig, [1.0, 2.0])\n\n    @requires_dask\n    def test_full_like_dask(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        ).chunk(((1, 1), (2,)))\n\n        def check(actual, expect_dtype, expect_values):\n            assert actual.dtype == expect_dtype\n            assert actual.shape == orig.shape\n            assert actual.dims == orig.dims\n            assert actual.attrs == orig.attrs\n            assert actual.chunks == orig.chunks\n            assert_array_equal(actual.values, expect_values)\n\n        check(full_like(orig, 2), orig.dtype, np.full_like(orig.values, 2))\n        # override dtype\n        check(\n            full_like(orig, True, dtype=bool),\n            bool,\n            np.full_like(orig.values, True, dtype=bool),\n        )\n\n        # Check that there's no array stored inside dask\n        # (e.g. we didn't create a numpy array and then we chunked it!)\n        dsk = full_like(orig, 1).data.dask\n        for v in dsk.values():\n            if isinstance(v, tuple):\n                for vi in v:\n                    assert not isinstance(vi, np.ndarray)\n            else:\n                assert not isinstance(v, np.ndarray)\n\n    def test_zeros_like(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n        assert_identical(zeros_like(orig), full_like(orig, 0))\n        assert_identical(zeros_like(orig, dtype=int), full_like(orig, 0, dtype=int))\n\n    def test_ones_like(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n        assert_identical(ones_like(orig), full_like(orig, 1))\n        assert_identical(ones_like(orig, dtype=int), full_like(orig, 1, dtype=int))\n\n    def test_object_with_values_property(self):\n        # Test that objects with .values property are preserved when intended\n        class HasValues:\n            def __init__(self):\n                self.values = 5\n        \n        obj = HasValues()\n        # Test direct conversion preserves the object\n        actual = as_compatible_data(obj)\n        assert isinstance(actual, np.ndarray)\n        assert actual.dtype == object\n        assert actual.item() is obj\n        \n        # Test that it works in Variable creation with object dtype\n        var = Variable(dims=(\"x\",), data=[obj], attrs={})\n        assert var.dtype == object\n        assert var.values[0] is obj\n\n    def test_unsupported_type(self):\n        # Non indexable type\n        class CustomArray(NDArrayMixin):\n            def __init__(self, array):\n                self.array = array\n\n        class CustomIndexable(CustomArray, indexing.ExplicitlyIndexed):\n            pass\n\n        array = CustomArray(np.arange(3))\n        orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n        assert isinstance(orig._data, np.ndarray)  # should not be CustomArray\n\n        array = CustomIndexable(np.arange(3))\n        orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n        assert isinstance(orig._data, CustomIndexable)\n",
      "\nclass TestAsCompatibleData:\n    def test_unchanged_types(self):\n        types = (np.asarray, PandasIndexAdapter, LazilyOuterIndexedArray)\n        for t in types:\n            for data in [\n                np.arange(3),\n                pd.date_range(\"2000-01-01\", periods=3),\n                pd.date_range(\"2000-01-01\", periods=3).values,\n            ]:\n                x = t(data)\n                assert source_ndarray(x) is source_ndarray(as_compatible_data(x))\n\n    def test_converted_types(self):\n        for input_array in [[[0, 1, 2]], pd.DataFrame([[0, 1, 2]])]:\n            actual = as_compatible_data(input_array)\n            assert_array_equal(np.asarray(input_array), actual)\n            assert np.ndarray == type(actual)\n            assert np.asarray(input_array).dtype == actual.dtype\n\n    def test_masked_array(self):\n        original = np.ma.MaskedArray(np.arange(5))\n        expected = np.arange(5)\n        actual = as_compatible_data(original)\n        assert_array_equal(expected, actual)\n        assert np.dtype(int) == actual.dtype\n\n        original = np.ma.MaskedArray(np.arange(5), mask=4 * [False] + [True])\n        expected = np.arange(5.0)\n        expected[-1] = np.nan\n        actual = as_compatible_data(original)\n        assert_array_equal(expected, actual)\n        assert np.dtype(float) == actual.dtype\n\n    def test_datetime(self):\n        expected = np.datetime64(\"2000-01-01\")\n        actual = as_compatible_data(expected)\n        assert expected == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n        expected = np.array([np.datetime64(\"2000-01-01\")])\n        actual = as_compatible_data(expected)\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n        expected = np.array([np.datetime64(\"2000-01-01\", \"ns\")])\n        actual = as_compatible_data(expected)\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n        assert expected is source_ndarray(np.asarray(actual))\n\n        expected = np.datetime64(\"2000-01-01\", \"ns\")\n        actual = as_compatible_data(datetime(2000, 1, 1))\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n    def test_full_like(self):\n        # For more thorough tests, see test_variable.py\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n\n        expect = orig.copy(deep=True)\n        expect.values = [[2.0, 2.0], [2.0, 2.0]]\n        assert_identical(expect, full_like(orig, 2))\n\n        # override dtype\n        expect.values = [[True, True], [True, True]]\n        assert expect.dtype == bool\n        assert_identical(expect, full_like(orig, True, dtype=bool))\n\n        # raise error on non-scalar fill_value\n        with raises_regex(ValueError, \"must be scalar\"):\n            full_like(orig, [1.0, 2.0])\n\n    @requires_dask\n    def test_full_like_dask(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        ).chunk(((1, 1), (2,)))\n\n        def check(actual, expect_dtype, expect_values):\n            assert actual.dtype == expect_dtype\n            assert actual.shape == orig.shape\n            assert actual.dims == orig.dims\n            assert actual.attrs == orig.attrs\n            assert actual.chunks == orig.chunks\n            assert_array_equal(actual.values, expect_values)\n\n        check(full_like(orig, 2), orig.dtype, np.full_like(orig.values, 2))\n        # override dtype\n        check(\n            full_like(orig, True, dtype=bool),\n            bool,\n            np.full_like(orig.values, True, dtype=bool),\n        )\n\n        # Check that there's no array stored inside dask\n        # (e.g. we didn't create a numpy array and then we chunked it!)\n        dsk = full_like(orig, 1).data.dask\n        for v in dsk.values():\n            if isinstance(v, tuple):\n                for vi in v:\n                    assert not isinstance(vi, np.ndarray)\n            else:\n                assert not isinstance(v, np.ndarray)\n\n    def test_zeros_like(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n        assert_identical(zeros_like(orig), full_like(orig, 0))\n        assert_identical(zeros_like(orig, dtype=int), full_like(orig, 0, dtype=int))\n\n    def test_ones_like(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n        assert_identical(ones_like(orig), full_like(orig, 1))\n        assert_identical(ones_like(orig, dtype=int), full_like(orig, 1, dtype=int))\n\n    def test_unsupported_type(self):\n        # Non indexable type\n        class CustomArray(NDArrayMixin):\n            def __init__(self, array):\n                self.array = array\n\n        class CustomIndexable(CustomArray, indexing.ExplicitlyIndexed):\n            pass\n\n        array = CustomArray(np.arange(3))\n        orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n        assert isinstance(orig._data, np.ndarray)  # should not be CustomArray\n\n        array = CustomIndexable(np.arange(3))\n        orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n        assert isinstance(orig._data, CustomIndexable)\n\n    def test_objects_with_values_property(self):\n        # Test that objects with .values property are preserved in object arrays\n        class HasValues:\n            def __init__(self, values=5):\n                self.values = values\n        \n        obj = HasValues()\n        \n        # Test as_compatible_data preserves the object\n        actual = as_compatible_data(obj)\n        assert isinstance(actual, np.ndarray)\n        assert actual.dtype == object\n        assert actual.item() is obj\n        \n        # Test Variable preserves the object\n        var = Variable(dims=(\"x\",), data=[obj])\n        assert var.dtype == object\n        assert var.values[0] is obj\n        \n        # Test that setitem preserves the object\n        var2 = Variable(dims=(\"x\",), data=[None], attrs={})\n        var2[0] = obj\n        assert var2.dtype == object\n        assert var2.values[0] is obj\n",
      "\nclass TestAsCompatibleData:\n    def test_unchanged_types(self):\n        types = (np.asarray, PandasIndexAdapter, LazilyOuterIndexedArray)\n        for t in types:\n            for data in [\n                np.arange(3),\n                pd.date_range(\"2000-01-01\", periods=3),\n                pd.date_range(\"2000-01-01\", periods=3).values,\n            ]:\n                x = t(data)\n                assert source_ndarray(x) is source_ndarray(as_compatible_data(x))\n\n    def test_converted_types(self):\n        for input_array in [[[0, 1, 2]], pd.DataFrame([[0, 1, 2]])]:\n            actual = as_compatible_data(input_array)\n            assert_array_equal(np.asarray(input_array), actual)\n            assert np.ndarray == type(actual)\n            assert np.asarray(input_array).dtype == actual.dtype\n\n    def test_masked_array(self):\n        original = np.ma.MaskedArray(np.arange(5))\n        expected = np.arange(5)\n        actual = as_compatible_data(original)\n        assert_array_equal(expected, actual)\n        assert np.dtype(int) == actual.dtype\n\n        original = np.ma.MaskedArray(np.arange(5), mask=4 * [False] + [True])\n        expected = np.arange(5.0)\n        expected[-1] = np.nan\n        actual = as_compatible_data(original)\n        assert_array_equal(expected, actual)\n        assert np.dtype(float) == actual.dtype\n\n    def test_datetime(self):\n        expected = np.datetime64(\"2000-01-01\")\n        actual = as_compatible_data(expected)\n        assert expected == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n        expected = np.array([np.datetime64(\"2000-01-01\")])\n        actual = as_compatible_data(expected)\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n        expected = np.array([np.datetime64(\"2000-01-01\", \"ns\")])\n        actual = as_compatible_data(expected)\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n        assert expected is source_ndarray(np.asarray(actual))\n\n        expected = np.datetime64(\"2000-01-01\", \"ns\")\n        actual = as_compatible_data(datetime(2000, 1, 1))\n        assert np.asarray(expected) == actual\n        assert np.ndarray == type(actual)\n        assert np.dtype(\"datetime64[ns]\") == actual.dtype\n\n    def test_full_like(self):\n        # For more thorough tests, see test_variable.py\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n\n        expect = orig.copy(deep=True)\n        expect.values = [[2.0, 2.0], [2.0, 2.0]]\n        assert_identical(expect, full_like(orig, 2))\n\n        # override dtype\n        expect.values = [[True, True], [True, True]]\n        assert expect.dtype == bool\n        assert_identical(expect, full_like(orig, True, dtype=bool))\n\n        # raise error on non-scalar fill_value\n        with raises_regex(ValueError, \"must be scalar\"):\n            full_like(orig, [1.0, 2.0])\n\n    @requires_dask\n    def test_full_like_dask(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        ).chunk(((1, 1), (2,)))\n\n        def check(actual, expect_dtype, expect_values):\n            assert actual.dtype == expect_dtype\n            assert actual.shape == orig.shape\n            assert actual.dims == orig.dims\n            assert actual.attrs == orig.attrs\n            assert actual.chunks == orig.chunks\n            assert_array_equal(actual.values, expect_values)\n\n        check(full_like(orig, 2), orig.dtype, np.full_like(orig.values, 2))\n        # override dtype\n        check(\n            full_like(orig, True, dtype=bool),\n            bool,\n            np.full_like(orig.values, True, dtype=bool),\n        )\n\n        # Check that there's no array stored inside dask\n        # (e.g. we didn't create a numpy array and then we chunked it!)\n        dsk = full_like(orig, 1).data.dask\n        for v in dsk.values():\n            if isinstance(v, tuple):\n                for vi in v:\n                    assert not isinstance(vi, np.ndarray)\n            else:\n                assert not isinstance(v, np.ndarray)\n\n    def test_zeros_like(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n        assert_identical(zeros_like(orig), full_like(orig, 0))\n        assert_identical(zeros_like(orig, dtype=int), full_like(orig, 0, dtype=int))\n\n    def test_ones_like(self):\n        orig = Variable(\n            dims=(\"x\", \"y\"), data=[[1.5, 2.0], [3.1, 4.3]], attrs={\"foo\": \"bar\"}\n        )\n        assert_identical(ones_like(orig), full_like(orig, 1))\n        assert_identical(ones_like(orig, dtype=int), full_like(orig, 1, dtype=int))\n\n    def test_unsupported_type(self):\n        # Non indexable type\n        class CustomArray(NDArrayMixin):\n            def __init__(self, array):\n                self.array = array\n\n        class CustomIndexable(CustomArray, indexing.ExplicitlyIndexed):\n            pass\n\n        array = CustomArray(np.arange(3))\n        orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n        assert isinstance(orig._data, np.ndarray)  # should not be CustomArray\n\n        array = CustomIndexable(np.arange(3))\n        orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n        assert isinstance(orig._data, CustomIndexable)\n\n    def test_objects_with_values_property(self):\n        # Test that objects with .values property are preserved when stored in object arrays\n        class HasValues:\n            def __init__(self, val=5):\n                self.values = val\n\n        # Create object with .values property\n        obj = HasValues()\n        \n        # Test that as_compatible_data preserves the object for object dtype\n        result = as_compatible_data(obj)\n        assert result is obj  # Should be preserved as-is\n        \n        # Test with array of such objects\n        obj_array = np.array([HasValues(1), HasValues(2)], dtype=object)\n        result = as_compatible_data(obj_array)\n        assert isinstance(result[0], HasValues)\n        assert result[0].values == 1\n        assert isinstance(result[1], HasValues)  \n        assert result[1].values == 2\n        \n        # Test Variable creation with object containing .values\n        var = Variable(dims=(\"x\",), data=[obj], attrs={})\n        assert isinstance(var.data[0], HasValues)\n        assert var.data[0].values == 5\n"
    ]
  },
  "combined_diffs": {
    "raw_patch": "diff --git a/xarray/core/variable.py b/xarray/core/variable.py\nindex 45553eb9..9b2fa462 100644\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -1,3 +1,4 @@\n+\n import copy\n import functools\n import itertools\n@@ -186,13 +187,16 @@ def _possibly_convert_objects(values):\n     return np.asarray(pd.Series(values.ravel())).reshape(values.shape)\n \n \n+\n def as_compatible_data(data, fastpath=False):\n     \"\"\"Prepare and wrap data to put in a Variable.\n \n     - If data does not have the necessary attributes, convert it to ndarray.\n     - If data has dtype=datetime64, ensure that it has ns precision. If it's a\n       pandas.Timestamp, convert it to datetime64.\n-    - If data is already a pandas or xarray object (other than an Index), just\n+    - If data is already a pandas or xarray object (other than an Index), extract\n+      its values. For arbitrary objects with .values properties, preserve the\n+      object itself to support storing objects in object dtype arrays.\n       use the values.\n \n     Finally, wrap it up with an adapter if necessary.\n@@ -217,9 +221,11 @@ def as_compatible_data(data, fastpath=False):\n     if isinstance(data, timedelta):\n         data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n \n-    # we don't want nested self-described arrays\n-    data = getattr(data, \"values\", data)\n \n+    # we don't want nested self-described arrays\n+    # Only extract .values from known pandas/xarray objects, not arbitrary objects\n+    if isinstance(data, (pd.Series, pd.DataFrame, pd.Index)) or hasattr(data, '_xarray_obj'):\n+        data = getattr(data, \"values\", data)\n     if isinstance(data, np.ma.MaskedArray):\n         mask = np.ma.getmaskarray(data)\n         if mask.any():\n@@ -854,6 +860,7 @@ class Variable(\n         \"\"\"\n         dims, index_tuple, new_order = self._broadcast_indexes(key)\n \n+\n         if not isinstance(value, Variable):\n             value = as_compatible_data(value)\n             if value.ndim > len(dims):\ndiff --git a/xarray/tests/test_variable.py b/xarray/tests/test_variable.py\nindex e1ae3e1f..1dd9147f 100644\n--- a/xarray/tests/test_variable.py\n+++ b/xarray/tests/test_variable.py\n@@ -2167,6 +2167,7 @@ class TestIndexVariable(VariableSubclassobjects):\n         super().test_coarsen_2d()\n \n \n+\n class TestAsCompatibleData:\n     def test_unchanged_types(self):\n         types = (np.asarray, PandasIndexAdapter, LazilyOuterIndexedArray)\n@@ -2308,6 +2309,23 @@ class TestAsCompatibleData:\n         orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n         assert isinstance(orig._data, CustomIndexable)\n \n+    def test_object_with_values_property(self):\n+        # Test that objects with .values property are preserved in object arrays\n+        class HasValues:\n+            def __init__(self, value):\n+                self.values = value\n+\n+        obj = HasValues(5)\n+        actual = as_compatible_data(obj)\n+        # The object should be preserved as-is, not have its .values extracted\n+        assert actual is obj\n+\n+        # Test with array containing objects with .values property\n+        obj_array = np.array([HasValues(1), HasValues(2)], dtype=object)\n+        actual = as_compatible_data(obj_array)\n+        assert actual is obj_array\n+        assert isinstance(actual[0], HasValues)\n+        assert actual[0].values == 1\n \n def test_raise_no_warning_for_nan_in_binary_ops():\n     with pytest.warns(None) as record:\n",
    "variant_0": "diff --git a/xarray/core/variable.py b/xarray/core/variable.py\nindex 45553eb9..62c5f78b 100644\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -1,3 +1,4 @@\n+\n import copy\n import functools\n import itertools\n@@ -186,6 +187,7 @@ def _possibly_convert_objects(values):\n     return np.asarray(pd.Series(values.ravel())).reshape(values.shape)\n \n \n+\n def as_compatible_data(data, fastpath=False):\n     \"\"\"Prepare and wrap data to put in a Variable.\n \n@@ -194,6 +196,8 @@ def as_compatible_data(data, fastpath=False):\n       pandas.Timestamp, convert it to datetime64.\n     - If data is already a pandas or xarray object (other than an Index), just\n       use the values.\n+    - For arbitrary objects with .values properties, preserve the object itself\n+      unless it's a known pandas/xarray type.\n \n     Finally, wrap it up with an adapter if necessary.\n     \"\"\"\n@@ -205,7 +209,8 @@ def as_compatible_data(data, fastpath=False):\n         return data.data\n \n     if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n-        return _maybe_wrap_data(data)\n+        data = _maybe_wrap_data(data)\n+        return data\n \n     if isinstance(data, tuple):\n         data = utils.to_0d_object_array(data)\n@@ -218,8 +223,65 @@ def as_compatible_data(data, fastpath=False):\n         data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n \n     # we don't want nested self-described arrays\n-    data = getattr(data, \"values\", data)\n+    if isinstance(data, (pd.Series, pd.DataFrame)):\n+        data = data.values\n+\n+    if isinstance(data, pd.Index):\n+        data = data.values\n+        if isinstance(data, pd.PeriodArray):\n+            data = data.astype(\"object\")\n+\n+    # Only extract .values from known pandas/xarray objects, not arbitrary objects\n+    if hasattr(data, \"values\") and not isinstance(data, (pd.Series, pd.DataFrame, pd.Index)):\n+        # For arbitrary objects with .values, check if we should preserve the object\n+        # This preserves objects with .values properties when they should be stored as-is\n+        pass  # Don't extract .values from arbitrary objects\n+    elif hasattr(data, \"values\"):\n+        # This is a known pandas/xarray object, safe to extract values\n+        data = data.values\n+\n+    # deal with possibly-0d dask arrays\n+    if isinstance(data, dask_array_type):\n+        data = data.compute()\n+\n+    data = np.asarray(data)\n+\n+    if data.ndim == 0:\n+        if isinstance(data, np.ndarray):\n+            data = data.item()\n+    else:\n+        data = _possibly_convert_objects(data)\n+\n+    return _maybe_wrap_data(data)\n+      use the values.\n+\n+    Finally, wrap it up with an adapter if necessary.\n+    \"\"\"\n+    if fastpath and getattr(data, \"ndim\", 0) > 0:\n+        # can't use fastpath (yet) for scalars\n+        return _maybe_wrap_data(data)\n+\n+    if isinstance(data, Variable):\n+        return data.data\n+\n+    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n+        return _maybe_wrap_data(data)\n+\n+    if isinstance(data, tuple):\n+        data = utils.to_0d_object_array(data)\n+\n+    if isinstance(data, pd.Timestamp):\n+        # TODO: convert, handle datetime objects, too\n+        data = np.datetime64(data.value, \"ns\")\n+\n+    if isinstance(data, timedelta):\n+        data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n \n+\n+    # we don't want nested self-described arrays, but only for pandas/xarray objects\n+    # preserve arbitrary objects with .values attribute when storing in object arrays\n+    if hasattr(data, 'values') and isinstance(data, (pd.Series, pd.DataFrame, pd.Index, pd.Categorical)):\n+        data = data.values\n     if isinstance(data, np.ma.MaskedArray):\n         mask = np.ma.getmaskarray(data)\n         if mask.any():\n@@ -854,6 +916,7 @@ class Variable(\n         \"\"\"\n         dims, index_tuple, new_order = self._broadcast_indexes(key)\n \n+\n         if not isinstance(value, Variable):\n             value = as_compatible_data(value)\n             if value.ndim > len(dims):\n@@ -866,6 +929,15 @@ class Variable(\n                 value = Variable((), value)\n             else:\n                 value = Variable(dims[-value.ndim :], value)\n+                raise ValueError(\n+                    \"shape mismatch: value array of shape %s could not be \"\n+                    \"broadcast to indexing result with %s dimensions\"\n+                    % (value.shape, len(dims))\n+                )\n+            if value.ndim == 0:\n+                value = Variable((), value)\n+            else:\n+                value = Variable(dims[-value.ndim :], value)\n         # broadcast to become assignable\n         value = value.set_dims(dims).data\n \ndiff --git a/xarray/tests/test_variable.py b/xarray/tests/test_variable.py\nindex e1ae3e1f..ac1a1942 100644\n--- a/xarray/tests/test_variable.py\n+++ b/xarray/tests/test_variable.py\n@@ -2167,6 +2167,7 @@ class TestIndexVariable(VariableSubclassobjects):\n         super().test_coarsen_2d()\n \n \n+\n class TestAsCompatibleData:\n     def test_unchanged_types(self):\n         types = (np.asarray, PandasIndexAdapter, LazilyOuterIndexedArray)\n@@ -2226,6 +2227,25 @@ class TestAsCompatibleData:\n         assert np.ndarray == type(actual)\n         assert np.dtype(\"datetime64[ns]\") == actual.dtype\n \n+    def test_objects_with_values_property(self):\n+        # Test that objects with .values property are preserved when not pandas objects\n+        class HasValues:\n+            def __init__(self, values=5):\n+                self.values = values\n+        \n+        obj = HasValues()\n+        actual = as_compatible_data(obj)\n+        # Object should be preserved as-is, not have its .values extracted\n+        assert actual is obj\n+        \n+        # Test with array of such objects\n+        obj_array = np.array([HasValues(), HasValues(10)], dtype=object)\n+        actual = as_compatible_data(obj_array)\n+        assert actual is obj_array\n+        assert isinstance(actual[0], HasValues)\n+        assert actual[0].values == 5\n+        assert actual[1].values == 10\n+\n     def test_full_like(self):\n         # For more thorough tests, see test_variable.py\n         orig = Variable(\n@@ -2308,7 +2328,6 @@ class TestAsCompatibleData:\n         orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n         assert isinstance(orig._data, CustomIndexable)\n \n-\n def test_raise_no_warning_for_nan_in_binary_ops():\n     with pytest.warns(None) as record:\n         Variable(\"x\", [1, 2, np.NaN]) > 0\n",
    "variant_1": "diff --git a/xarray/core/variable.py b/xarray/core/variable.py\nindex 45553eb9..9dfc2e33 100644\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -1,3 +1,4 @@\n+\n import copy\n import functools\n import itertools\n@@ -186,6 +187,7 @@ def _possibly_convert_objects(values):\n     return np.asarray(pd.Series(values.ravel())).reshape(values.shape)\n \n \n+\n def as_compatible_data(data, fastpath=False):\n     \"\"\"Prepare and wrap data to put in a Variable.\n \n@@ -201,6 +203,16 @@ def as_compatible_data(data, fastpath=False):\n         # can't use fastpath (yet) for scalars\n         return _maybe_wrap_data(data)\n \n+    if isinstance(data, Variable):\n+        return data.data\n+      use the values.\n+\n+    Finally, wrap it up with an adapter if necessary.\n+    \"\"\"\n+    if fastpath and getattr(data, \"ndim\", 0) > 0:\n+        # can't use fastpath (yet) for scalars\n+        return _maybe_wrap_data(data)\n+\n     if isinstance(data, Variable):\n         return data.data\n \n@@ -217,9 +229,10 @@ def as_compatible_data(data, fastpath=False):\n     if isinstance(data, timedelta):\n         data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n \n-    # we don't want nested self-described arrays\n-    data = getattr(data, \"values\", data)\n \n+    # we don't want nested self-described arrays, but preserve objects with .values for object arrays\n+    if hasattr(data, \"values\") and isinstance(data, (pd.Series, pd.DataFrame, pd.Index, xr.Variable, xr.DataArray)):\n+        data = data.values\n     if isinstance(data, np.ma.MaskedArray):\n         mask = np.ma.getmaskarray(data)\n         if mask.any():\n@@ -854,8 +867,12 @@ class Variable(\n         \"\"\"\n         dims, index_tuple, new_order = self._broadcast_indexes(key)\n \n+\n         if not isinstance(value, Variable):\n-            value = as_compatible_data(value)\n+            # Check if we're assigning to an object dtype array to preserve objects with .values\n+            target_dtype = getattr(self._data, 'dtype', None)\n+            preserve_objects = target_dtype == object\n+            value = as_compatible_data(value, preserve_objects=preserve_objects)\n             if value.ndim > len(dims):\n                 raise ValueError(\n                     \"shape mismatch: value array of shape %s could not be \"\ndiff --git a/xarray/tests/test_variable.py b/xarray/tests/test_variable.py\nindex e1ae3e1f..8a33e051 100644\n--- a/xarray/tests/test_variable.py\n+++ b/xarray/tests/test_variable.py\n@@ -2167,6 +2167,7 @@ class TestIndexVariable(VariableSubclassobjects):\n         super().test_coarsen_2d()\n \n \n+\n class TestAsCompatibleData:\n     def test_unchanged_types(self):\n         types = (np.asarray, PandasIndexAdapter, LazilyOuterIndexedArray)\n@@ -2308,6 +2309,28 @@ class TestAsCompatibleData:\n         orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n         assert isinstance(orig._data, CustomIndexable)\n \n+    def test_object_with_values_property(self):\n+        # Test that objects with .values property are preserved in object arrays\n+        class HasValues:\n+            def __init__(self, value=5):\n+                self.values = value\n+        \n+        obj = HasValues()\n+        actual = as_compatible_data(obj)\n+        # Object should be preserved as-is, not have .values extracted\n+        assert actual is obj\n+        \n+        # Test with array containing objects with .values property\n+        obj_array = np.array([HasValues(), HasValues(10)], dtype=object)\n+        actual = as_compatible_data(obj_array)\n+        assert_array_equal(obj_array, actual)\n+        assert actual.dtype == object\n+        \n+        # Verify objects are preserved\n+        assert isinstance(actual[0], HasValues)\n+        assert isinstance(actual[1], HasValues)\n+        assert actual[0].values == 5\n+        assert actual[1].values == 10\n \n def test_raise_no_warning_for_nan_in_binary_ops():\n     with pytest.warns(None) as record:\n",
    "variant_2": "diff --git a/xarray/core/variable.py b/xarray/core/variable.py\nindex 45553eb9..ebf6a195 100644\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -1,3 +1,4 @@\n+\n import copy\n import functools\n import itertools\n@@ -186,6 +187,7 @@ def _possibly_convert_objects(values):\n     return np.asarray(pd.Series(values.ravel())).reshape(values.shape)\n \n \n+\n def as_compatible_data(data, fastpath=False):\n     \"\"\"Prepare and wrap data to put in a Variable.\n \n@@ -194,6 +196,72 @@ def as_compatible_data(data, fastpath=False):\n       pandas.Timestamp, convert it to datetime64.\n     - If data is already a pandas or xarray object (other than an Index), just\n       use the values.\n+    - For arbitrary objects with .values properties, preserve the object itself\n+      unless it's a known pandas/xarray type.\n+\n+    Finally, wrap it up with an adapter if necessary.\n+    \"\"\"\n+    if fastpath and getattr(data, \"ndim\", 0) > 0:\n+        # can't use fastpath (yet) for scalars\n+        return _maybe_wrap_data(data)\n+\n+    if isinstance(data, Variable):\n+        return data.data\n+\n+    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n+        data = _maybe_wrap_data(data)\n+        return data\n+\n+    if isinstance(data, tuple):\n+        data = utils.to_0d_object_array(data)\n+\n+    # Only extract .values from known pandas/xarray objects, not arbitrary objects\n+    if isinstance(data, (pd.Series, pd.DataFrame, pd.Index)) or (\n+        hasattr(data, \"values\") and \n+        hasattr(data, \"__module__\") and \n+        data.__module__ is not None and\n+        (\"pandas\" in data.__module__ or \"xarray\" in data.__module__)\n+    ):\n+        data = getattr(data, \"values\", data)\n+\n+    # we don't want nested self-described arrays\n+    if isinstance(data, (pd.Series, pd.DataFrame)):\n+        data = data.values\n+\n+    if isinstance(data, np.ma.MaskedArray):\n+        mask = np.ma.getmaskarray(data)\n+        if mask.any():\n+            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n+            data = np.asarray(data, dtype=dtype)\n+            data[mask] = fill_value\n+        else:\n+            data = np.asarray(data)\n+\n+    if not isinstance(data, np.ndarray):\n+        if hasattr(data, \"__array_function__\") or hasattr(data, \"__array_ufunc__\"):\n+            return _maybe_wrap_data(data)\n+\n+        # validate whether the data is valid data types.\n+        data = np.asarray(data)\n+\n+    # validate size of data\n+    if data.size != 1:\n+        validate_indexer = indexing.OuterIndexer(tuple(slice(None) for _ in data.shape))\n+    else:\n+        validate_indexer = indexing.OuterIndexer(())\n+    indexing.expanded_indexer(validate_indexer.tuple, data.ndim)\n+\n+    if isinstance(data, np.ndarray):\n+        if data.dtype.kind == \"O\":\n+            data = _possibly_convert_objects(data)\n+        elif data.dtype.kind == \"U\":\n+            if data.dtype != np.str_:\n+                data = data.astype(np.str_)\n+        elif data.dtype.kind in \"SV\":\n+            data = data.astype(np.str_)\n+\n+    return _maybe_wrap_data(data)\n+      use the values.\n \n     Finally, wrap it up with an adapter if necessary.\n     \"\"\"\n@@ -217,9 +285,10 @@ def as_compatible_data(data, fastpath=False):\n     if isinstance(data, timedelta):\n         data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n \n-    # we don't want nested self-described arrays\n-    data = getattr(data, \"values\", data)\n \n+    # we don't want nested self-described arrays, but preserve objects with .values for object dtypes\n+    if hasattr(data, 'values') and isinstance(data, (pd.Series, pd.DataFrame, pd.Index, xr.DataArray, xr.Dataset)):\n+        data = data.values\n     if isinstance(data, np.ma.MaskedArray):\n         mask = np.ma.getmaskarray(data)\n         if mask.any():\n@@ -854,8 +923,12 @@ class Variable(\n         \"\"\"\n         dims, index_tuple, new_order = self._broadcast_indexes(key)\n \n+\n         if not isinstance(value, Variable):\n-            value = as_compatible_data(value)\n+            # Check if we're assigning to an object dtype array to preserve objects with .values\n+            target_dtype = getattr(self._data, 'dtype', None)\n+            preserve_objects = target_dtype == object\n+            value = as_compatible_data(value, preserve_objects=preserve_objects)\n             if value.ndim > len(dims):\n                 raise ValueError(\n                     \"shape mismatch: value array of shape %s could not be \"\ndiff --git a/xarray/tests/test_variable.py b/xarray/tests/test_variable.py\nindex e1ae3e1f..100e5e8b 100644\n--- a/xarray/tests/test_variable.py\n+++ b/xarray/tests/test_variable.py\n@@ -2167,6 +2167,7 @@ class TestIndexVariable(VariableSubclassobjects):\n         super().test_coarsen_2d()\n \n \n+\n class TestAsCompatibleData:\n     def test_unchanged_types(self):\n         types = (np.asarray, PandasIndexAdapter, LazilyOuterIndexedArray)\n@@ -2226,6 +2227,30 @@ class TestAsCompatibleData:\n         assert np.ndarray == type(actual)\n         assert np.dtype(\"datetime64[ns]\") == actual.dtype\n \n+    def test_objects_with_values_property(self):\n+        \"\"\"Test that objects with .values property are preserved in object arrays.\"\"\"\n+        class HasValues:\n+            def __init__(self, value=5):\n+                self.values = value\n+            \n+            def __repr__(self):\n+                return f\"HasValues(values={self.values})\"\n+        \n+        # Test single object\n+        obj = HasValues()\n+        actual = as_compatible_data(obj)\n+        assert actual is obj  # Object should be preserved as-is\n+        \n+        # Test in array context\n+        obj_array = [HasValues(1), HasValues(2)]\n+        actual = as_compatible_data(obj_array)\n+        assert isinstance(actual, np.ndarray)\n+        assert actual.dtype == object\n+        assert isinstance(actual[0], HasValues)\n+        assert isinstance(actual[1], HasValues)\n+        assert actual[0].values == 1\n+        assert actual[1].values == 2\n+\n     def test_full_like(self):\n         # For more thorough tests, see test_variable.py\n         orig = Variable(\n@@ -2308,7 +2333,6 @@ class TestAsCompatibleData:\n         orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n         assert isinstance(orig._data, CustomIndexable)\n \n-\n def test_raise_no_warning_for_nan_in_binary_ops():\n     with pytest.warns(None) as record:\n         Variable(\"x\", [1, 2, np.NaN]) > 0\n",
    "variant_3": "diff --git a/xarray/core/variable.py b/xarray/core/variable.py\nindex 45553eb9..96553ba7 100644\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -1,3 +1,4 @@\n+\n import copy\n import functools\n import itertools\n@@ -186,6 +187,7 @@ def _possibly_convert_objects(values):\n     return np.asarray(pd.Series(values.ravel())).reshape(values.shape)\n \n \n+\n def as_compatible_data(data, fastpath=False):\n     \"\"\"Prepare and wrap data to put in a Variable.\n \n@@ -205,7 +207,8 @@ def as_compatible_data(data, fastpath=False):\n         return data.data\n \n     if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n-        return _maybe_wrap_data(data)\n+        data = _maybe_wrap_data(data)\n+        return data\n \n     if isinstance(data, tuple):\n         data = utils.to_0d_object_array(data)\n@@ -218,8 +221,69 @@ def as_compatible_data(data, fastpath=False):\n         data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n \n     # we don't want nested self-described arrays\n-    data = getattr(data, \"values\", data)\n+    if isinstance(data, (pd.Series, pd.DataFrame, pd.Index)):\n+        data = getattr(data, \"values\", data)\n+\n+    if isinstance(data, np.ma.MaskedArray):\n+        mask = np.ma.getmaskarray(data)\n+        if mask.any():\n+            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n+            data = np.asarray(data, dtype=dtype)\n+            data[mask] = fill_value\n+        else:\n+            data = np.asarray(data)\n+\n+    if not isinstance(data, np.ndarray):\n+        if hasattr(data, \"__array_function__\") or hasattr(data, \"__array_ufunc__\"):\n+            return _maybe_wrap_data(data)\n+\n+        # validate whether the data is valid data types.\n+        data = np.asarray(data)\n+\n+    # validate the data\n+    if isinstance(data, np.ndarray):\n+        if data.dtype.kind == \"O\":\n+            data = _possibly_convert_objects(data)\n+        if data.dtype.kind == \"U\" and data.dtype != np.dtype(\"U0\"):\n+            if is_duck_dask_array(data):\n+                warnings.warn(\n+                    \"Converting unicode strings to object dtype. \"\n+                    \"This will raise an error in the future.\",\n+                    FutureWarning,\n+                    stacklevel=4,\n+                )\n+            else:\n+                data = data.astype(object)\n+\n+    return _maybe_wrap_data(data)\n+      use the values.\n+\n+    Finally, wrap it up with an adapter if necessary.\n+    \"\"\"\n+    if fastpath and getattr(data, \"ndim\", 0) > 0:\n+        # can't use fastpath (yet) for scalars\n+        return _maybe_wrap_data(data)\n+\n+    if isinstance(data, Variable):\n+        return data.data\n+\n+    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n+        return _maybe_wrap_data(data)\n+\n+    if isinstance(data, tuple):\n+        data = utils.to_0d_object_array(data)\n+\n+    if isinstance(data, pd.Timestamp):\n+        # TODO: convert, handle datetime objects, too\n+        data = np.datetime64(data.value, \"ns\")\n \n+    if isinstance(data, timedelta):\n+        data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n+\n+\n+    # we don't want nested self-described arrays, but preserve objects with .values for object dtypes\n+    if hasattr(data, \"values\") and isinstance(data, (pd.Series, pd.DataFrame, pd.Index, xr.DataArray, xr.Dataset)):\n+        data = data.values\n     if isinstance(data, np.ma.MaskedArray):\n         mask = np.ma.getmaskarray(data)\n         if mask.any():\n@@ -854,6 +918,7 @@ class Variable(\n         \"\"\"\n         dims, index_tuple, new_order = self._broadcast_indexes(key)\n \n+\n         if not isinstance(value, Variable):\n             value = as_compatible_data(value)\n             if value.ndim > len(dims):\n@@ -866,6 +931,15 @@ class Variable(\n                 value = Variable((), value)\n             else:\n                 value = Variable(dims[-value.ndim :], value)\n+                raise ValueError(\n+                    \"shape mismatch: value array of shape %s could not be \"\n+                    \"broadcast to indexing result with %s dimensions\"\n+                    % (value.shape, len(dims))\n+                )\n+            if value.ndim == 0:\n+                value = Variable((), value)\n+            else:\n+                value = Variable(dims[-value.ndim :], value)\n         # broadcast to become assignable\n         value = value.set_dims(dims).data\n \ndiff --git a/xarray/tests/test_variable.py b/xarray/tests/test_variable.py\nindex e1ae3e1f..6a6b1c44 100644\n--- a/xarray/tests/test_variable.py\n+++ b/xarray/tests/test_variable.py\n@@ -2167,6 +2167,7 @@ class TestIndexVariable(VariableSubclassobjects):\n         super().test_coarsen_2d()\n \n \n+\n class TestAsCompatibleData:\n     def test_unchanged_types(self):\n         types = (np.asarray, PandasIndexAdapter, LazilyOuterIndexedArray)\n@@ -2308,6 +2309,34 @@ class TestAsCompatibleData:\n         orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n         assert isinstance(orig._data, CustomIndexable)\n \n+    def test_object_with_values_property(self):\n+        # Test that objects with .values property are preserved in object arrays\n+        # This tests the fix for the bug where as_compatible_data incorrectly\n+        # extracts .values from arbitrary objects\n+        class HasValues:\n+            def __init__(self, value=5):\n+                self.values = value\n+            \n+            def __repr__(self):\n+                return f\"HasValues(values={self.values})\"\n+        \n+        obj = HasValues()\n+        \n+        # Test that the object is preserved as-is, not its .values extracted\n+        actual = as_compatible_data(obj)\n+        assert actual is obj\n+        \n+        # Test in an array context - should create object dtype array\n+        obj_array = [obj]\n+        actual = as_compatible_data(obj_array)\n+        assert actual.dtype == object\n+        assert actual[0] is obj\n+        \n+        # Test that pandas objects still have their .values extracted\n+        series = pd.Series([1, 2, 3])\n+        actual = as_compatible_data(series)\n+        assert_array_equal(actual, series.values)\n+        assert not hasattr(actual, 'values') or not callable(getattr(actual, 'values', None))\n \n def test_raise_no_warning_for_nan_in_binary_ops():\n     with pytest.warns(None) as record:\n",
    "variant_4": "diff --git a/xarray/core/variable.py b/xarray/core/variable.py\nindex 45553eb9..83e3a000 100644\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -1,3 +1,4 @@\n+\n import copy\n import functools\n import itertools\n@@ -186,6 +187,7 @@ def _possibly_convert_objects(values):\n     return np.asarray(pd.Series(values.ravel())).reshape(values.shape)\n \n \n+\n def as_compatible_data(data, fastpath=False):\n     \"\"\"Prepare and wrap data to put in a Variable.\n \n@@ -205,7 +207,8 @@ def as_compatible_data(data, fastpath=False):\n         return data.data\n \n     if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n-        return _maybe_wrap_data(data)\n+        data = _maybe_wrap_data(data)\n+        return data\n \n     if isinstance(data, tuple):\n         data = utils.to_0d_object_array(data)\n@@ -218,8 +221,76 @@ def as_compatible_data(data, fastpath=False):\n         data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n \n     # we don't want nested self-described arrays\n-    data = getattr(data, \"values\", data)\n+    # Only extract .values from known pandas/xarray types to avoid\n+    # coercing arbitrary objects that happen to have a .values attribute\n+    if isinstance(data, (pd.Series, pd.DataFrame, pd.Index)) or (\n+        hasattr(data, \"__module__\") and \n+        data.__module__ is not None and \n+        data.__module__.startswith(\"xarray\")\n+    ):\n+        data = getattr(data, \"values\", data)\n+\n+    if isinstance(data, np.ma.MaskedArray):\n+        mask = np.ma.getmaskarray(data)\n+        if mask.any():\n+            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n+            data = np.asarray(data, dtype=dtype)\n+            data[mask] = fill_value\n+        else:\n+            data = np.asarray(data)\n+\n+    if not isinstance(data, np.ndarray):\n+        if hasattr(data, \"__array_function__\") or hasattr(data, \"__array_ufunc__\"):\n+            return _maybe_wrap_data(data)\n+\n+        if is_duck_dask_array(data):\n+            return _maybe_wrap_data(data)\n+        # validate whether the data is valid data types.\n+        data = np.asarray(data)\n+\n+    if data.dtype.kind == \"O\":\n+        try:\n+            data = _possibly_convert_objects(data)\n+        except ValueError:\n+            # most likely a numpy.ndarray that contains non-picklable objects\n+            pass\n+\n+    # TODO: expose this as a user option\n+    if data.dtype.kind == \"U\":\n+        if LooseVersion(np.__version__) < \"1.14\":\n+            # work around for numpy < 1.14 which doesn't\n+            # handle array-like consistently\n+            data = np.asarray(data, dtype=object)\n+\n+    return _maybe_wrap_data(data)\n+      use the values.\n+\n+    Finally, wrap it up with an adapter if necessary.\n+    \"\"\"\n+    if fastpath and getattr(data, \"ndim\", 0) > 0:\n+        # can't use fastpath (yet) for scalars\n+        return _maybe_wrap_data(data)\n+\n+    if isinstance(data, Variable):\n+        return data.data\n+\n+    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n+        return _maybe_wrap_data(data)\n \n+    if isinstance(data, tuple):\n+        data = utils.to_0d_object_array(data)\n+\n+    if isinstance(data, pd.Timestamp):\n+        # TODO: convert, handle datetime objects, too\n+        data = np.datetime64(data.value, \"ns\")\n+\n+    if isinstance(data, timedelta):\n+        data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n+\n+\n+    # we don't want nested self-described arrays, but preserve objects with .values for object dtypes\n+    if hasattr(data, 'values') and isinstance(data, (pd.Series, pd.DataFrame, pd.Index, xr.DataArray, xr.Dataset)):\n+        data = data.values\n     if isinstance(data, np.ma.MaskedArray):\n         mask = np.ma.getmaskarray(data)\n         if mask.any():\n@@ -854,8 +925,12 @@ class Variable(\n         \"\"\"\n         dims, index_tuple, new_order = self._broadcast_indexes(key)\n \n+\n         if not isinstance(value, Variable):\n-            value = as_compatible_data(value)\n+            # Pass dtype information to help as_compatible_data make better decisions\n+            # about whether to extract .values from objects\n+            target_dtype = getattr(self._data, 'dtype', None)\n+            value = as_compatible_data(value, target_dtype=target_dtype)\n             if value.ndim > len(dims):\n                 raise ValueError(\n                     \"shape mismatch: value array of shape %s could not be \"\ndiff --git a/xarray/tests/test_variable.py b/xarray/tests/test_variable.py\nindex e1ae3e1f..b5233bfb 100644\n--- a/xarray/tests/test_variable.py\n+++ b/xarray/tests/test_variable.py\n@@ -2167,6 +2167,7 @@ class TestIndexVariable(VariableSubclassobjects):\n         super().test_coarsen_2d()\n \n \n+\n class TestAsCompatibleData:\n     def test_unchanged_types(self):\n         types = (np.asarray, PandasIndexAdapter, LazilyOuterIndexedArray)\n@@ -2291,6 +2292,27 @@ class TestAsCompatibleData:\n         assert_identical(ones_like(orig), full_like(orig, 1))\n         assert_identical(ones_like(orig, dtype=int), full_like(orig, 1, dtype=int))\n \n+    def test_objects_with_values_property(self):\n+        # Test that objects with .values property are preserved when stored in object arrays\n+        class HasValues:\n+            def __init__(self, value=5):\n+                self.values = value\n+\n+        obj = HasValues()\n+        # Test as_compatible_data directly\n+        actual = as_compatible_data(obj)\n+        assert actual is obj  # Object should be preserved as-is\n+\n+        # Test in Variable construction\n+        var = Variable(\"x\", [obj], dtype=object)\n+        assert var.values[0] is obj  # Object should be stored as-is\n+        assert var.dtype == object\n+\n+        # Test Variable.__setitem__ with object dtype\n+        var = Variable(\"x\", [None], dtype=object)\n+        var[0] = obj\n+        assert var.values[0] is obj  # Object should be stored as-is\n+\n     def test_unsupported_type(self):\n         # Non indexable type\n         class CustomArray(NDArrayMixin):\n@@ -2308,7 +2330,6 @@ class TestAsCompatibleData:\n         orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n         assert isinstance(orig._data, CustomIndexable)\n \n-\n def test_raise_no_warning_for_nan_in_binary_ops():\n     with pytest.warns(None) as record:\n         Variable(\"x\", [1, 2, np.NaN]) > 0\n",
    "variant_5": "diff --git a/xarray/core/variable.py b/xarray/core/variable.py\nindex 45553eb9..8ff0f686 100644\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -1,3 +1,4 @@\n+\n import copy\n import functools\n import itertools\n@@ -186,7 +187,8 @@ def _possibly_convert_objects(values):\n     return np.asarray(pd.Series(values.ravel())).reshape(values.shape)\n \n \n-def as_compatible_data(data, fastpath=False):\n+\n+def as_compatible_data(data, fastpath=False, target_dtype=None):\n     \"\"\"Prepare and wrap data to put in a Variable.\n \n     - If data does not have the necessary attributes, convert it to ndarray.\n@@ -194,6 +196,8 @@ def as_compatible_data(data, fastpath=False):\n       pandas.Timestamp, convert it to datetime64.\n     - If data is already a pandas or xarray object (other than an Index), just\n       use the values.\n+    - For object dtype arrays, preserve objects with .values properties instead\n+      of extracting them.\n \n     Finally, wrap it up with an adapter if necessary.\n     \"\"\"\n@@ -205,7 +209,8 @@ def as_compatible_data(data, fastpath=False):\n         return data.data\n \n     if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n-        return _maybe_wrap_data(data)\n+        data = _maybe_wrap_data(data)\n+        return data\n \n     if isinstance(data, tuple):\n         data = utils.to_0d_object_array(data)\n@@ -218,7 +223,14 @@ def as_compatible_data(data, fastpath=False):\n         data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n \n     # we don't want nested self-described arrays\n-    data = getattr(data, \"values\", data)\n+    # For object dtypes, only extract .values from known pandas/xarray objects\n+    if target_dtype == np.dtype('O'):\n+        # For object dtype, only extract values from known pandas/xarray objects\n+        if isinstance(data, (pd.Series, pd.DataFrame, pd.Index)) or hasattr(data, 'xindexes'):\n+            data = getattr(data, \"values\", data)\n+    else:\n+        # For non-object dtypes, extract values as before\n+        data = getattr(data, \"values\", data)\n \n     if isinstance(data, np.ma.MaskedArray):\n         mask = np.ma.getmaskarray(data)\n@@ -229,6 +241,59 @@ def as_compatible_data(data, fastpath=False):\n         else:\n             data = np.asarray(data)\n \n+    if not isinstance(data, np.ndarray):\n+        if hasattr(data, \"__array_function__\") or hasattr(data, \"__array_ufunc__\"):\n+            return _maybe_wrap_data(data)\n+\n+        # validate whether the data is valid data types.\n+        data = np.asarray(data)\n+\n+    if data.dtype.kind == \"O\":\n+        try:\n+            data = _possibly_convert_objects(data)\n+        except ValueError:\n+            # most likely a problem with a nested array from pandas\n+            pass\n+\n+    return _maybe_wrap_data(data)\n+      use the values.\n+\n+    Finally, wrap it up with an adapter if necessary.\n+    \"\"\"\n+    if fastpath and getattr(data, \"ndim\", 0) > 0:\n+        # can't use fastpath (yet) for scalars\n+        return _maybe_wrap_data(data)\n+\n+    if isinstance(data, Variable):\n+        return data.data\n+\n+    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n+        return _maybe_wrap_data(data)\n+\n+    if isinstance(data, tuple):\n+        data = utils.to_0d_object_array(data)\n+\n+    if isinstance(data, pd.Timestamp):\n+        # TODO: convert, handle datetime objects, too\n+        data = np.datetime64(data.value, \"ns\")\n+\n+    if isinstance(data, timedelta):\n+        data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n+\n+\n+    # we don't want nested self-described arrays, but preserve objects with .values\n+    # only extract .values from pandas/xarray objects, not arbitrary objects\n+    if hasattr(data, 'values') and isinstance(data, (pd.Series, pd.DataFrame, pd.Index, DataArray)):\n+        data = data.values\n+    if isinstance(data, np.ma.MaskedArray):\n+        mask = np.ma.getmaskarray(data)\n+        if mask.any():\n+            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n+            data = np.asarray(data, dtype=dtype)\n+            data[mask] = fill_value\n+        else:\n+            data = np.asarray(data)\n+\n     if not isinstance(data, np.ndarray):\n         if hasattr(data, \"__array_function__\"):\n             if IS_NEP18_ACTIVE:\n@@ -854,8 +919,14 @@ class Variable(\n         \"\"\"\n         dims, index_tuple, new_order = self._broadcast_indexes(key)\n \n+\n         if not isinstance(value, Variable):\n-            value = as_compatible_data(value)\n+            # For object dtype arrays, preserve objects with .values properties\n+            # instead of extracting them indiscriminately\n+            if hasattr(self, 'dtype') and self.dtype == np.dtype('O'):\n+                value = as_compatible_data(value, preserve_objects=True)\n+            else:\n+                value = as_compatible_data(value)\n             if value.ndim > len(dims):\n                 raise ValueError(\n                     \"shape mismatch: value array of shape %s could not be \"\ndiff --git a/xarray/tests/test_variable.py b/xarray/tests/test_variable.py\nindex e1ae3e1f..979b784d 100644\n--- a/xarray/tests/test_variable.py\n+++ b/xarray/tests/test_variable.py\n@@ -2167,6 +2167,7 @@ class TestIndexVariable(VariableSubclassobjects):\n         super().test_coarsen_2d()\n \n \n+\n class TestAsCompatibleData:\n     def test_unchanged_types(self):\n         types = (np.asarray, PandasIndexAdapter, LazilyOuterIndexedArray)\n@@ -2291,6 +2292,25 @@ class TestAsCompatibleData:\n         assert_identical(ones_like(orig), full_like(orig, 1))\n         assert_identical(ones_like(orig, dtype=int), full_like(orig, 1, dtype=int))\n \n+    def test_object_with_values_property(self):\n+        # Test that objects with .values property are preserved in object arrays\n+        class HasValues:\n+            def __init__(self, value=5):\n+                self.values = value\n+\n+        obj = HasValues()\n+        actual = as_compatible_data(obj)\n+        # Object should be preserved, not have its .values extracted\n+        assert actual is obj\n+        assert isinstance(actual, HasValues)\n+        assert actual.values == 5\n+\n+        # Test that this works when creating Variables with object dtype\n+        var = Variable(dims=(\"x\",), data=[obj], attrs={})\n+        assert var.dtype == object\n+        assert isinstance(var.values[0], HasValues)\n+        assert var.values[0].values == 5\n+\n     def test_unsupported_type(self):\n         # Non indexable type\n         class CustomArray(NDArrayMixin):\n@@ -2308,7 +2328,6 @@ class TestAsCompatibleData:\n         orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n         assert isinstance(orig._data, CustomIndexable)\n \n-\n def test_raise_no_warning_for_nan_in_binary_ops():\n     with pytest.warns(None) as record:\n         Variable(\"x\", [1, 2, np.NaN]) > 0\n",
    "variant_6": "diff --git a/xarray/core/variable.py b/xarray/core/variable.py\nindex 45553eb9..0be796ef 100644\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -1,3 +1,4 @@\n+\n import copy\n import functools\n import itertools\n@@ -186,6 +187,7 @@ def _possibly_convert_objects(values):\n     return np.asarray(pd.Series(values.ravel())).reshape(values.shape)\n \n \n+\n def as_compatible_data(data, fastpath=False):\n     \"\"\"Prepare and wrap data to put in a Variable.\n \n@@ -205,7 +207,8 @@ def as_compatible_data(data, fastpath=False):\n         return data.data\n \n     if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n-        return _maybe_wrap_data(data)\n+        data = _maybe_wrap_data(data)\n+        return data\n \n     if isinstance(data, tuple):\n         data = utils.to_0d_object_array(data)\n@@ -218,8 +221,68 @@ def as_compatible_data(data, fastpath=False):\n         data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n \n     # we don't want nested self-described arrays\n-    data = getattr(data, \"values\", data)\n+    # Only extract .values from known pandas/xarray objects, not arbitrary objects\n+    if isinstance(data, (pd.Series, pd.DataFrame, pd.Index)) or hasattr(data, 'values') and hasattr(data, '_constructor'):\n+        data = getattr(data, \"values\", data)\n+\n+    if isinstance(data, np.ma.MaskedArray):\n+        mask = np.ma.getmaskarray(data)\n+        if mask.any():\n+            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n+            data = np.asarray(data, dtype=dtype)\n+            data[mask] = fill_value\n+        else:\n+            data = np.asarray(data)\n+\n+    if not isinstance(data, np.ndarray):\n+        if hasattr(data, \"__array_function__\") or hasattr(data, \"__array_ufunc__\"):\n+            return data\n+\n+        if is_duck_dask_array(data):\n+            return data\n+        # validate whether the data is valid data types.\n+        data = np.asarray(data)\n+\n+    if data.dtype.kind == \"O\":\n+        data = _possibly_convert_objects(data)\n+\n+    # TODO: support other datetime dtypes than np.datetime64\n+    if data.dtype.kind == \"M\":\n+        data = _possibly_convert_objects(data)\n+\n+    elif data.dtype.kind == \"m\":\n+        data = _possibly_convert_objects(data)\n+\n+    return _maybe_wrap_data(data)\n+      use the values.\n+\n+    Finally, wrap it up with an adapter if necessary.\n+    \"\"\"\n+    if fastpath and getattr(data, \"ndim\", 0) > 0:\n+        # can't use fastpath (yet) for scalars\n+        return _maybe_wrap_data(data)\n+\n+    if isinstance(data, Variable):\n+        return data.data\n+\n+    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n+        return _maybe_wrap_data(data)\n+\n+    if isinstance(data, tuple):\n+        data = utils.to_0d_object_array(data)\n+\n+    if isinstance(data, pd.Timestamp):\n+        # TODO: convert, handle datetime objects, too\n+        data = np.datetime64(data.value, \"ns\")\n \n+    if isinstance(data, timedelta):\n+        data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n+\n+\n+    # we don't want nested self-described arrays, but preserve arbitrary objects\n+    # only extract .values from known pandas/xarray types\n+    if hasattr(data, \"values\") and isinstance(data, (pd.Series, pd.DataFrame, pd.Index)):\n+        data = data.values\n     if isinstance(data, np.ma.MaskedArray):\n         mask = np.ma.getmaskarray(data)\n         if mask.any():\n@@ -854,6 +917,7 @@ class Variable(\n         \"\"\"\n         dims, index_tuple, new_order = self._broadcast_indexes(key)\n \n+\n         if not isinstance(value, Variable):\n             value = as_compatible_data(value)\n             if value.ndim > len(dims):\n@@ -866,6 +930,15 @@ class Variable(\n                 value = Variable((), value)\n             else:\n                 value = Variable(dims[-value.ndim :], value)\n+                raise ValueError(\n+                    \"shape mismatch: value array of shape %s could not be \"\n+                    \"broadcast to indexing result with %s dimensions\"\n+                    % (value.shape, len(dims))\n+                )\n+            if value.ndim == 0:\n+                value = Variable((), value)\n+            else:\n+                value = Variable(dims[-value.ndim :], value)\n         # broadcast to become assignable\n         value = value.set_dims(dims).data\n \ndiff --git a/xarray/tests/test_variable.py b/xarray/tests/test_variable.py\nindex e1ae3e1f..fabbe212 100644\n--- a/xarray/tests/test_variable.py\n+++ b/xarray/tests/test_variable.py\n@@ -2167,6 +2167,7 @@ class TestIndexVariable(VariableSubclassobjects):\n         super().test_coarsen_2d()\n \n \n+\n class TestAsCompatibleData:\n     def test_unchanged_types(self):\n         types = (np.asarray, PandasIndexAdapter, LazilyOuterIndexedArray)\n@@ -2291,6 +2292,24 @@ class TestAsCompatibleData:\n         assert_identical(ones_like(orig), full_like(orig, 1))\n         assert_identical(ones_like(orig, dtype=int), full_like(orig, 1, dtype=int))\n \n+    def test_object_with_values_property(self):\n+        # Test that objects with .values property are preserved when intended\n+        class HasValues:\n+            def __init__(self):\n+                self.values = 5\n+        \n+        obj = HasValues()\n+        # Test direct conversion preserves the object\n+        actual = as_compatible_data(obj)\n+        assert isinstance(actual, np.ndarray)\n+        assert actual.dtype == object\n+        assert actual.item() is obj\n+        \n+        # Test that it works in Variable creation with object dtype\n+        var = Variable(dims=(\"x\",), data=[obj], attrs={})\n+        assert var.dtype == object\n+        assert var.values[0] is obj\n+\n     def test_unsupported_type(self):\n         # Non indexable type\n         class CustomArray(NDArrayMixin):\n@@ -2308,7 +2327,6 @@ class TestAsCompatibleData:\n         orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n         assert isinstance(orig._data, CustomIndexable)\n \n-\n def test_raise_no_warning_for_nan_in_binary_ops():\n     with pytest.warns(None) as record:\n         Variable(\"x\", [1, 2, np.NaN]) > 0\n",
    "variant_7": "diff --git a/xarray/core/variable.py b/xarray/core/variable.py\nindex 45553eb9..5875a4de 100644\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -1,3 +1,4 @@\n+\n import copy\n import functools\n import itertools\n@@ -186,6 +187,7 @@ def _possibly_convert_objects(values):\n     return np.asarray(pd.Series(values.ravel())).reshape(values.shape)\n \n \n+\n def as_compatible_data(data, fastpath=False):\n     \"\"\"Prepare and wrap data to put in a Variable.\n \n@@ -194,6 +196,60 @@ def as_compatible_data(data, fastpath=False):\n       pandas.Timestamp, convert it to datetime64.\n     - If data is already a pandas or xarray object (other than an Index), just\n       use the values.\n+    - For arbitrary objects with .values properties, preserve the object itself\n+      unless it's a known pandas/xarray type.\n+\n+    Finally, wrap it up with an adapter if necessary.\n+    \"\"\"\n+    if fastpath and getattr(data, \"ndim\", 0) > 0:\n+        # can't use fastpath (yet) for scalars\n+        return _maybe_wrap_data(data)\n+\n+    if isinstance(data, Variable):\n+        return data.data\n+\n+    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n+        data = _maybe_wrap_data(data)\n+        return data\n+\n+    if isinstance(data, tuple):\n+        data = utils.to_0d_object_array(data)\n+\n+    if hasattr(data, \"values\"):\n+        # Only extract .values from known pandas/xarray objects\n+        # Preserve arbitrary objects with .values properties\n+        if isinstance(data, (pd.Series, pd.DataFrame, pd.Index)) or hasattr(data, '_xarray_cls'):\n+            data = getattr(data, \"values\", data)\n+\n+    # we don't want nested self-described arrays\n+    if isinstance(data, (pd.Series, pd.DataFrame)):\n+        data = data.values\n+\n+    if isinstance(data, np.ma.MaskedArray):\n+        mask = np.ma.getmaskarray(data)\n+        if mask.any():\n+            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n+            data = np.asarray(data, dtype=dtype)\n+            data[mask] = fill_value\n+        else:\n+            data = np.asarray(data)\n+\n+    if not isinstance(data, np.ndarray):\n+        if hasattr(data, \"__array_function__\") or hasattr(data, \"__array_ufunc__\"):\n+            return _maybe_wrap_data(data)\n+\n+        # validate whether the data is valid data types.\n+        data = np.asarray(data)\n+\n+    if data.dtype.kind == \"O\":\n+        data = _possibly_convert_objects(data)\n+    elif data.dtype.kind == \"M\":\n+        data = _possibly_convert_objects(data)\n+    elif data.dtype.kind == \"m\":\n+        data = _possibly_convert_objects(data)\n+\n+    return _maybe_wrap_data(data)\n+      use the values.\n \n     Finally, wrap it up with an adapter if necessary.\n     \"\"\"\n@@ -217,9 +273,11 @@ def as_compatible_data(data, fastpath=False):\n     if isinstance(data, timedelta):\n         data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n \n-    # we don't want nested self-described arrays\n-    data = getattr(data, \"values\", data)\n \n+    # we don't want nested self-described arrays, but preserve objects with .values\n+    # only extract .values from known pandas/xarray types\n+    if hasattr(data, 'values') and isinstance(data, (pd.Series, pd.DataFrame, pd.Index)):\n+        data = data.values\n     if isinstance(data, np.ma.MaskedArray):\n         mask = np.ma.getmaskarray(data)\n         if mask.any():\n@@ -854,6 +912,7 @@ class Variable(\n         \"\"\"\n         dims, index_tuple, new_order = self._broadcast_indexes(key)\n \n+\n         if not isinstance(value, Variable):\n             value = as_compatible_data(value)\n             if value.ndim > len(dims):\n@@ -866,6 +925,15 @@ class Variable(\n                 value = Variable((), value)\n             else:\n                 value = Variable(dims[-value.ndim :], value)\n+                raise ValueError(\n+                    \"shape mismatch: value array of shape %s could not be \"\n+                    \"broadcast to indexing result with %s dimensions\"\n+                    % (value.shape, len(dims))\n+                )\n+            if value.ndim == 0:\n+                value = Variable((), value)\n+            else:\n+                value = Variable(dims[-value.ndim :], value)\n         # broadcast to become assignable\n         value = value.set_dims(dims).data\n \ndiff --git a/xarray/tests/test_variable.py b/xarray/tests/test_variable.py\nindex e1ae3e1f..b9724a9d 100644\n--- a/xarray/tests/test_variable.py\n+++ b/xarray/tests/test_variable.py\n@@ -2167,6 +2167,7 @@ class TestIndexVariable(VariableSubclassobjects):\n         super().test_coarsen_2d()\n \n \n+\n class TestAsCompatibleData:\n     def test_unchanged_types(self):\n         types = (np.asarray, PandasIndexAdapter, LazilyOuterIndexedArray)\n@@ -2308,6 +2309,30 @@ class TestAsCompatibleData:\n         orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n         assert isinstance(orig._data, CustomIndexable)\n \n+    def test_objects_with_values_property(self):\n+        # Test that objects with .values property are preserved in object arrays\n+        class HasValues:\n+            def __init__(self, values=5):\n+                self.values = values\n+        \n+        obj = HasValues()\n+        \n+        # Test as_compatible_data preserves the object\n+        actual = as_compatible_data(obj)\n+        assert isinstance(actual, np.ndarray)\n+        assert actual.dtype == object\n+        assert actual.item() is obj\n+        \n+        # Test Variable preserves the object\n+        var = Variable(dims=(\"x\",), data=[obj])\n+        assert var.dtype == object\n+        assert var.values[0] is obj\n+        \n+        # Test that setitem preserves the object\n+        var2 = Variable(dims=(\"x\",), data=[None], attrs={})\n+        var2[0] = obj\n+        assert var2.dtype == object\n+        assert var2.values[0] is obj\n \n def test_raise_no_warning_for_nan_in_binary_ops():\n     with pytest.warns(None) as record:\n",
    "variant_8": "diff --git a/xarray/core/variable.py b/xarray/core/variable.py\nindex 45553eb9..6ad8bcef 100644\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -1,3 +1,4 @@\n+\n import copy\n import functools\n import itertools\n@@ -186,6 +187,7 @@ def _possibly_convert_objects(values):\n     return np.asarray(pd.Series(values.ravel())).reshape(values.shape)\n \n \n+\n def as_compatible_data(data, fastpath=False):\n     \"\"\"Prepare and wrap data to put in a Variable.\n \n@@ -194,6 +196,8 @@ def as_compatible_data(data, fastpath=False):\n       pandas.Timestamp, convert it to datetime64.\n     - If data is already a pandas or xarray object (other than an Index), just\n       use the values.\n+    - For arbitrary objects with .values properties, preserve the object itself\n+      unless it's a known pandas/xarray type.\n \n     Finally, wrap it up with an adapter if necessary.\n     \"\"\"\n@@ -205,7 +209,8 @@ def as_compatible_data(data, fastpath=False):\n         return data.data\n \n     if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n-        return _maybe_wrap_data(data)\n+        data = _maybe_wrap_data(data)\n+        return data\n \n     if isinstance(data, tuple):\n         data = utils.to_0d_object_array(data)\n@@ -218,7 +223,9 @@ def as_compatible_data(data, fastpath=False):\n         data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n \n     # we don't want nested self-described arrays\n-    data = getattr(data, \"values\", data)\n+    # Only extract .values from known pandas/xarray objects, not arbitrary objects\n+    if hasattr(data, \"values\") and isinstance(data, (pd.Series, pd.DataFrame, pd.Index, DataArray)):\n+        data = getattr(data, \"values\", data)\n \n     if isinstance(data, np.ma.MaskedArray):\n         mask = np.ma.getmaskarray(data)\n@@ -229,6 +236,58 @@ def as_compatible_data(data, fastpath=False):\n         else:\n             data = np.asarray(data)\n \n+    if not isinstance(data, np.ndarray):\n+        if hasattr(data, \"__array_function__\") or hasattr(data, \"__array_ufunc__\"):\n+            return _maybe_wrap_data(data)\n+        else:\n+            data = np.asarray(data)\n+\n+    if data.dtype.kind == \"O\":\n+        data = _possibly_convert_objects(data)\n+    elif data.dtype.kind == \"M\":\n+        data = _possibly_convert_objects(data)\n+    elif data.dtype.kind == \"m\":\n+        data = _possibly_convert_objects(data)\n+\n+    return _maybe_wrap_data(data)\n+      use the values.\n+\n+    Finally, wrap it up with an adapter if necessary.\n+    \"\"\"\n+    if fastpath and getattr(data, \"ndim\", 0) > 0:\n+        # can't use fastpath (yet) for scalars\n+        return _maybe_wrap_data(data)\n+\n+    if isinstance(data, Variable):\n+        return data.data\n+\n+    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n+        return _maybe_wrap_data(data)\n+\n+    if isinstance(data, tuple):\n+        data = utils.to_0d_object_array(data)\n+\n+    if isinstance(data, pd.Timestamp):\n+        # TODO: convert, handle datetime objects, too\n+        data = np.datetime64(data.value, \"ns\")\n+\n+    if isinstance(data, timedelta):\n+        data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n+\n+\n+    # we don't want nested self-described arrays, but only for known pandas/xarray types\n+    # preserve arbitrary objects with .values properties when storing in object arrays\n+    if isinstance(data, (pd.Series, pd.DataFrame, pd.Index)) or hasattr(data, '_constructor'):\n+        data = getattr(data, \"values\", data)\n+    if isinstance(data, np.ma.MaskedArray):\n+        mask = np.ma.getmaskarray(data)\n+        if mask.any():\n+            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n+            data = np.asarray(data, dtype=dtype)\n+            data[mask] = fill_value\n+        else:\n+            data = np.asarray(data)\n+\n     if not isinstance(data, np.ndarray):\n         if hasattr(data, \"__array_function__\"):\n             if IS_NEP18_ACTIVE:\n@@ -854,6 +913,7 @@ class Variable(\n         \"\"\"\n         dims, index_tuple, new_order = self._broadcast_indexes(key)\n \n+\n         if not isinstance(value, Variable):\n             value = as_compatible_data(value)\n             if value.ndim > len(dims):\n@@ -866,6 +926,15 @@ class Variable(\n                 value = Variable((), value)\n             else:\n                 value = Variable(dims[-value.ndim :], value)\n+                raise ValueError(\n+                    \"shape mismatch: value array of shape %s could not be \"\n+                    \"broadcast to indexing result with %s dimensions\"\n+                    % (value.shape, len(dims))\n+                )\n+            if value.ndim == 0:\n+                value = Variable((), value)\n+            else:\n+                value = Variable(dims[-value.ndim :], value)\n         # broadcast to become assignable\n         value = value.set_dims(dims).data\n \ndiff --git a/xarray/tests/test_variable.py b/xarray/tests/test_variable.py\nindex e1ae3e1f..ad1bca59 100644\n--- a/xarray/tests/test_variable.py\n+++ b/xarray/tests/test_variable.py\n@@ -2167,6 +2167,7 @@ class TestIndexVariable(VariableSubclassobjects):\n         super().test_coarsen_2d()\n \n \n+\n class TestAsCompatibleData:\n     def test_unchanged_types(self):\n         types = (np.asarray, PandasIndexAdapter, LazilyOuterIndexedArray)\n@@ -2308,6 +2309,31 @@ class TestAsCompatibleData:\n         orig = Variable(dims=(\"x\"), data=array, attrs={\"foo\": \"bar\"})\n         assert isinstance(orig._data, CustomIndexable)\n \n+    def test_objects_with_values_property(self):\n+        # Test that objects with .values property are preserved when stored in object arrays\n+        class HasValues:\n+            def __init__(self, val=5):\n+                self.values = val\n+\n+        # Create object with .values property\n+        obj = HasValues()\n+        \n+        # Test that as_compatible_data preserves the object for object dtype\n+        result = as_compatible_data(obj)\n+        assert result is obj  # Should be preserved as-is\n+        \n+        # Test with array of such objects\n+        obj_array = np.array([HasValues(1), HasValues(2)], dtype=object)\n+        result = as_compatible_data(obj_array)\n+        assert isinstance(result[0], HasValues)\n+        assert result[0].values == 1\n+        assert isinstance(result[1], HasValues)  \n+        assert result[1].values == 2\n+        \n+        # Test Variable creation with object containing .values\n+        var = Variable(dims=(\"x\",), data=[obj], attrs={})\n+        assert isinstance(var.data[0], HasValues)\n+        assert var.data[0].values == 5\n \n def test_raise_no_warning_for_nan_in_binary_ops():\n     with pytest.warns(None) as record:\n"
  }
}