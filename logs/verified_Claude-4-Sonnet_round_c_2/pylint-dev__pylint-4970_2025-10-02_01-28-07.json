{
  "zero_patches": {
    "Location 1 (/root/hy/projects/pylint/pylint/checkers/similar.py lines 860-865)": "\n    def reduce_map_data(self, linter, data):\n        \"\"\"Reduces and recombines data into a format that we can report on\n\n        The partner function of get_map_data()\"\"\"\n        recombined = SimilarChecker(linter)\n        # Re-initialize Similar with correct configuration values\n        Similar.__init__(\n            recombined,\n            min_lines=self.min_lines,\n            ignore_comments=self.ignore_comments,\n            ignore_docstrings=self.ignore_docstrings,\n            ignore_imports=self.ignore_imports,\n            ignore_signatures=self.ignore_signatures,\n        )\n        recombined.open()\n        Similar.combine_mapreduce_data(recombined, linesets_collection=data)\n        recombined.close()\n",
    "Location 2 (/root/hy/projects/pylint/pylint/checkers/similar.py lines 477-478)": "\n        index_to_lines_2: IndexToLines_T\n        hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n",
    "Location 3 (/root/hy/projects/pylint/pylint/checkers/similar.py lines 495-495)": "\n            ):\n",
    "Location 4 (/root/hy/projects/pylint/pylint/checkers/similar.py lines 527-527)": "\n            if self.min_lines > 0 and eff_cmn_nb > self.min_lines:\n                yield com\n",
    "Location 5 (/root/hy/projects/pylint/pylint/checkers/similar.py lines 534-536)": "\n    def _iter_sims(self) -> Generator[Commonality, None, None]:\n        \"\"\"iterate on similarities among all files, by making a cartesian\n        product\n        \"\"\"\n        # Disable similarity checking when min_lines is 0\n        if self.min_lines <= 0:\n            return\n        \n        for idx, lineset in enumerate(self.linesets[:-1]):\n            for lineset2 in self.linesets[idx + 1 :]:\n                yield from self._find_common(lineset, lineset2)\n"
  },
  "variant_patches": {
    "Location 1 (/root/hy/projects/pylint/pylint/checkers/similar.py lines 860-865)": [
      "\ndef reduce_map_data(self, linter, data):\n    \"\"\"Reduces and recombines data into a format that we can report on\n\n    The partner function of get_map_data()\"\"\"\n    recombined = SimilarChecker(linter)\n    # Re-initialize Similar with correct configuration values\n    Similar.__init__(\n        recombined,\n        min_lines=self.min_lines,\n        ignore_comments=self.ignore_comments,\n        ignore_docstrings=self.ignore_docstrings,\n        ignore_imports=self.ignore_imports,\n        ignore_signatures=self.ignore_signatures,\n    )\n    recombined.open()\n    Similar.combine_mapreduce_data(recombined, linesets_collection=data)\n    recombined.close()\n",
      "\n    def reduce_map_data(self, linter, data):\n        \"\"\"Reduces and recombines data into a format that we can report on\n\n        The partner function of get_map_data()\"\"\"\n        recombined = SimilarChecker(linter)\n        # Re-initialize Similar with correct configuration values\n        Similar.__init__(\n            recombined,\n            min_lines=self.min_lines,\n            ignore_comments=self.ignore_comments,\n            ignore_docstrings=self.ignore_docstrings,\n            ignore_imports=self.ignore_imports,\n            ignore_signatures=self.ignore_signatures,\n        )\n        recombined.open()\n        Similar.combine_mapreduce_data(recombined, linesets_collection=data)\n        recombined.close()\n",
      "\n    def reduce_map_data(self, linter, data):\n        \"\"\"Reduces and recombines data into a format that we can report on\n\n        The partner function of get_map_data()\"\"\"\n        recombined = SimilarChecker(linter)\n        # Re-initialize Similar with correct configuration values\n        Similar.__init__(\n            recombined,\n            min_lines=self.min_lines,\n            ignore_comments=self.ignore_comments,\n            ignore_docstrings=self.ignore_docstrings,\n            ignore_imports=self.ignore_imports,\n            ignore_signatures=self.ignore_signatures,\n        )\n",
      "\n    def reduce_map_data(self, linter, data):\n        \"\"\"Reduces and recombines data into a format that we can report on\n\n        The partner function of get_map_data()\"\"\"\n        recombined = SimilarChecker(linter)\n        # Re-initialize Similar with correct configuration values\n        Similar.__init__(\n            recombined,\n            min_lines=self.min_lines,\n            ignore_comments=self.ignore_comments,\n            ignore_docstrings=self.ignore_docstrings,\n            ignore_imports=self.ignore_imports,\n            ignore_signatures=self.ignore_signatures,\n        )\n        recombined.open()\n        Similar.combine_mapreduce_data(recombined, linesets_collection=data)\n        recombined.close()\n",
      "\n    def reduce_map_data(self, linter, data):\n        \"\"\"Reduces and recombines data into a format that we can report on\n\n        The partner function of get_map_data()\"\"\"\n        recombined = SimilarChecker(linter)\n        # Re-initialize Similar with correct configuration values\n        Similar.__init__(\n            recombined,\n            min_lines=self.min_lines,\n            ignore_comments=self.ignore_comments,\n            ignore_docstrings=self.ignore_docstrings,\n            ignore_imports=self.ignore_imports,\n            ignore_signatures=self.ignore_signatures,\n        )\n",
      "\n    def reduce_map_data(self, linter, data):\n        \"\"\"Reduces and recombines data into a format that we can report on\n\n        The partner function of get_map_data()\"\"\"\n        recombined = SimilarChecker(linter)\n        # Re-initialize Similar with correct configuration values\n        Similar.__init__(\n            recombined,\n            min_lines=self.min_lines,\n            ignore_comments=self.ignore_comments,\n            ignore_docstrings=self.ignore_docstrings,\n            ignore_imports=self.ignore_imports,\n            ignore_signatures=self.ignore_signatures,\n        )\n",
      "\n    def reduce_map_data(self, linter, data):\n        \"\"\"Reduces and recombines data into a format that we can report on\n\n        The partner function of get_map_data()\"\"\"\n        recombined = SimilarChecker(linter)\n        # Re-initialize Similar with correct configuration values\n        Similar.__init__(\n            recombined,\n            min_lines=self.min_lines,\n            ignore_comments=self.ignore_comments,\n            ignore_docstrings=self.ignore_docstrings,\n            ignore_imports=self.ignore_imports,\n            ignore_signatures=self.ignore_signatures,\n        )\n        recombined.open()\n        Similar.combine_mapreduce_data(recombined, linesets_collection=data)\n        recombined.close()\n",
      "\n    def reduce_map_data(self, linter, data):\n        \"\"\"Reduces and recombines data into a format that we can report on\n\n        The partner function of get_map_data()\"\"\"\n        recombined = SimilarChecker(linter)\n        # Re-initialize Similar with correct configuration values\n        Similar.__init__(\n            recombined,\n            min_lines=self.min_lines,\n            ignore_comments=self.ignore_comments,\n            ignore_docstrings=self.ignore_docstrings,\n            ignore_imports=self.ignore_imports,\n            ignore_signatures=self.ignore_signatures,\n        )\n"
    ],
    "Location 2 (/root/hy/projects/pylint/pylint/checkers/similar.py lines 477-478)": [
      "\n        index_to_lines_2: IndexToLines_T\n        hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n",
      "\n        index_to_lines_2: IndexToLines_T\n        hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n",
      "\n        index_to_lines_2: IndexToLines_T\n        hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n",
      "\n        index_to_lines_2: IndexToLines_T\n        hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n",
      "\n        index_to_lines_2: IndexToLines_T\n        hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n",
      "\n        index_to_lines_2: IndexToLines_T\n        hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n",
      "\n        index_to_lines_2: IndexToLines_T\n        hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n",
      "\n        index_to_lines_2: IndexToLines_T\n        hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n"
    ],
    "Location 3 (/root/hy/projects/pylint/pylint/checkers/similar.py lines 495-495)": [
      "\n            ):\n",
      "\n            ):\n",
      "\n            ):\n",
      "\n            ):\n",
      "\n            ):\n                # Disable similarity checking when min_lines is 0\n                if self.min_lines <= 0:\n                    continue\n",
      "\n            ):\n",
      "\n            ):\n                # Disable similarity checking when min_lines is 0\n                if self.min_lines <= 0:\n                    return\n                \n",
      "\n            ):\n"
    ],
    "Location 4 (/root/hy/projects/pylint/pylint/checkers/similar.py lines 527-527)": [
      "\n            if self.min_lines > 0 and eff_cmn_nb > self.min_lines:\n                yield com\n",
      "\n        if self.min_lines <= 0:\n            return\n\n        if eff_cmn_nb > self.min_lines:\n",
      "\n            if self.min_lines <= 0:\n                return\n            \n            if eff_cmn_nb > self.min_lines:\n",
      "\n            if self.min_lines <= 0:\n                return\n            \n            if eff_cmn_nb > self.min_lines:\n",
      "\n            if self.min_lines <= 0 or eff_cmn_nb > self.min_lines:\n                yield com\n",
      "\n        if self.min_lines <= 0:\n            return\n\n        if eff_cmn_nb > self.min_lines:\n",
      "\ndef _iter_sims(self) -> Generator[Commonality, None, None]:\n    \"\"\"iterate on similarities among all files, by making a cartesian\n    product\n    \"\"\"\n    # Disable similarity checking when min_lines is 0\n    if self.min_lines <= 0:\n        return\n    \n    for idx, lineset in enumerate(self.linesets[:-1]):\n        for lineset2 in self.linesets[idx + 1 :]:\n            yield from self._find_common(lineset, lineset2)\n",
      "\n            if self.min_lines <= 0 or eff_cmn_nb > self.min_lines:\n                yield com\n"
    ],
    "Location 5 (/root/hy/projects/pylint/pylint/checkers/similar.py lines 534-536)": [
      "\n    def _iter_sims(self) -> Generator[Commonality, None, None]:\n        \"\"\"iterate on similarities among all files, by making a cartesian\n        product\n        \"\"\"\n        # Disable similarity checking when min_lines is 0\n        if self.min_lines <= 0:\n            return\n            \n        for idx, lineset in enumerate(self.linesets[:-1]):\n            for lineset2 in self.linesets[idx + 1 :]:\n                yield from self._find_common(lineset, lineset2)\n",
      "\n    def _iter_sims(self) -> Generator[Commonality, None, None]:\n        \"\"\"iterate on similarities among all files, by making a cartesian\n        product\n        \"\"\"\n        # Disable similarity checking when min_lines is 0\n        if self.min_lines <= 0:\n            return\n        \n        for idx, lineset in enumerate(self.linesets[:-1]):\n            for lineset2 in self.linesets[idx + 1 :]:\n                yield from self._find_common(lineset, lineset2)\n",
      "\n    def _iter_sims(self) -> Generator[Commonality, None, None]:\n        \"\"\"iterate on similarities among all files, by making a cartesian\n        product\n        \"\"\"\n        # Disable similarity checking when min_lines is 0\n        if self.min_lines <= 0:\n            return\n        \n        for idx, lineset in enumerate(self.linesets[:-1]):\n            for lineset2 in self.linesets[idx + 1 :]:\n                yield from self._find_common(lineset, lineset2)\n",
      "\n    def _iter_sims(self) -> Generator[Commonality, None, None]:\n        \"\"\"iterate on similarities among all files, by making a cartesian\n        product\n        \"\"\"\n        # Disable similarity checking when min_lines is 0\n        if self.min_lines <= 0:\n            return\n        \n        for idx, lineset in enumerate(self.linesets[:-1]):\n            for lineset2 in self.linesets[idx + 1 :]:\n                yield from self._find_common(lineset, lineset2)\n",
      "\n    def _iter_sims(self) -> Generator[Commonality, None, None]:\n        \"\"\"iterate on similarities among all files, by making a cartesian\n        product\n        \"\"\"\n        # Disable similarity checking when min_lines is 0\n        if self.min_lines <= 0:\n            return\n        \n        for idx, lineset in enumerate(self.linesets[:-1]):\n            for lineset2 in self.linesets[idx + 1 :]:\n                yield from self._find_common(lineset, lineset2)\n",
      "\n    def _iter_sims(self) -> Generator[Commonality, None, None]:\n        \"\"\"iterate on similarities among all files, by making a cartesian\n        product\n        \"\"\"\n        # Disable similarity checking when min_lines is 0\n        if self.min_lines <= 0:\n            return\n        \n        for idx, lineset in enumerate(self.linesets[:-1]):\n            for lineset2 in self.linesets[idx + 1 :]:\n                yield from self._find_common(lineset, lineset2)\n",
      "\n    def _iter_sims(self) -> Generator[Commonality, None, None]:\n        \"\"\"iterate on similarities among all files, by making a cartesian\n        product\n        \"\"\"\n        # Disable similarity checking when min_lines is 0\n        if self.min_lines <= 0:\n            return\n            \n        for idx, lineset in enumerate(self.linesets[:-1]):\n            for lineset2 in self.linesets[idx + 1 :]:\n                yield from self._find_common(lineset, lineset2)\n",
      "\n    def _iter_sims(self) -> Generator[Commonality, None, None]:\n        \"\"\"iterate on similarities among all files, by making a cartesian\n        product\n        \"\"\"\n        # Disable similarity checking when min_lines is 0\n        if self.min_lines <= 0:\n            return\n        \n        for idx, lineset in enumerate(self.linesets[:-1]):\n            for lineset2 in self.linesets[idx + 1 :]:\n                yield from self._find_common(lineset, lineset2)\n"
    ]
  },
  "combined_diffs": {
    "raw_patch": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex c65b1c893..2e1e7a1e1 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -474,6 +474,7 @@ class Similar:\n         hash_to_index_1: HashToIndex_T\n         hash_to_index_2: HashToIndex_T\n         index_to_lines_1: IndexToLines_T\n+\n         index_to_lines_2: IndexToLines_T\n         hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n         hash_to_index_2, index_to_lines_2 = hash_lineset(lineset2, self.min_lines)\n@@ -492,6 +493,7 @@ class Similar:\n         for c_hash in sorted(common_hashes, key=operator.attrgetter(\"_index\")):\n             for indices_in_linesets in itertools.product(\n                 hash_to_index_1[c_hash], hash_to_index_2[c_hash]\n+\n             ):\n                 index_1 = indices_in_linesets[0]\n                 index_2 = indices_in_linesets[1]\n@@ -524,6 +526,7 @@ class Similar:\n                 lineset1, start_index_1, lineset2, start_index_2, nb_common_lines\n             )\n \n+\n             if eff_cmn_nb > self.min_lines:\n                 yield com\n \n@@ -531,6 +534,11 @@ class Similar:\n         \"\"\"iterate on similarities among all files, by making a cartesian\n         product\n         \"\"\"\n+\n+        # Disable similarity checking when min_lines is 0\n+        if self.min_lines <= 0:\n+            return\n+        \n         for idx, lineset in enumerate(self.linesets[:-1]):\n             for lineset2 in self.linesets[idx + 1 :]:\n                 yield from self._find_common(lineset, lineset2)\n@@ -857,12 +865,17 @@ class SimilarChecker(BaseChecker, Similar, MapReduceMixin):\n         \"\"\"Reduces and recombines data into a format that we can report on\n \n         The partner function of get_map_data()\"\"\"\n+\n         recombined = SimilarChecker(linter)\n-        recombined.min_lines = self.min_lines\n-        recombined.ignore_comments = self.ignore_comments\n-        recombined.ignore_docstrings = self.ignore_docstrings\n-        recombined.ignore_imports = self.ignore_imports\n-        recombined.ignore_signatures = self.ignore_signatures\n+        # Re-initialize Similar with correct configuration values\n+        Similar.__init__(\n+            recombined,\n+            min_lines=self.min_lines,\n+            ignore_comments=self.ignore_comments,\n+            ignore_docstrings=self.ignore_docstrings,\n+            ignore_imports=self.ignore_imports,\n+            ignore_signatures=self.ignore_signatures,\n+        )\n         recombined.open()\n         Similar.combine_mapreduce_data(recombined, linesets_collection=data)\n         recombined.close()\n",
    "variant_0": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex c65b1c893..84a66adf2 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -474,6 +474,7 @@ class Similar:\n         hash_to_index_1: HashToIndex_T\n         hash_to_index_2: HashToIndex_T\n         index_to_lines_1: IndexToLines_T\n+\n         index_to_lines_2: IndexToLines_T\n         hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n         hash_to_index_2, index_to_lines_2 = hash_lineset(lineset2, self.min_lines)\n@@ -492,6 +493,7 @@ class Similar:\n         for c_hash in sorted(common_hashes, key=operator.attrgetter(\"_index\")):\n             for indices_in_linesets in itertools.product(\n                 hash_to_index_1[c_hash], hash_to_index_2[c_hash]\n+\n             ):\n                 index_1 = indices_in_linesets[0]\n                 index_2 = indices_in_linesets[1]\n@@ -524,13 +526,24 @@ class Similar:\n                 lineset1, start_index_1, lineset2, start_index_2, nb_common_lines\n             )\n \n-            if eff_cmn_nb > self.min_lines:\n+\n+            if self.min_lines > 0 and eff_cmn_nb > self.min_lines:\n                 yield com\n+                yield com\n+\n+    def _iter_sims(self) -> Generator[Commonality, None, None]:\n+        \"\"\"iterate on similarities among all files, by making a cartesian\n+        product\n+        \"\"\"\n \n     def _iter_sims(self) -> Generator[Commonality, None, None]:\n         \"\"\"iterate on similarities among all files, by making a cartesian\n         product\n         \"\"\"\n+        # Disable similarity checking when min_lines is 0\n+        if self.min_lines <= 0:\n+            return\n+        \n         for idx, lineset in enumerate(self.linesets[:-1]):\n             for lineset2 in self.linesets[idx + 1 :]:\n                 yield from self._find_common(lineset, lineset2)\n@@ -853,16 +866,28 @@ class SimilarChecker(BaseChecker, Similar, MapReduceMixin):\n         \"\"\"Passthru override\"\"\"\n         return Similar.get_map_data(self)\n \n+    def reduce_map_data(self, linter, data):\n+        \"\"\"Reduces and recombines data into a format that we can report on\n+\n+        The partner function of get_map_data()\"\"\"\n+\n     def reduce_map_data(self, linter, data):\n         \"\"\"Reduces and recombines data into a format that we can report on\n \n         The partner function of get_map_data()\"\"\"\n         recombined = SimilarChecker(linter)\n-        recombined.min_lines = self.min_lines\n-        recombined.ignore_comments = self.ignore_comments\n-        recombined.ignore_docstrings = self.ignore_docstrings\n-        recombined.ignore_imports = self.ignore_imports\n-        recombined.ignore_signatures = self.ignore_signatures\n+        # Re-initialize Similar with correct configuration values\n+        Similar.__init__(\n+            recombined,\n+            min_lines=self.min_lines,\n+            ignore_comments=self.ignore_comments,\n+            ignore_docstrings=self.ignore_docstrings,\n+            ignore_imports=self.ignore_imports,\n+            ignore_signatures=self.ignore_signatures,\n+        )\n+        recombined.open()\n+        Similar.combine_mapreduce_data(recombined, linesets_collection=data)\n+        recombined.close()\n         recombined.open()\n         Similar.combine_mapreduce_data(recombined, linesets_collection=data)\n         recombined.close()\n",
    "variant_1": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex c65b1c893..851b56377 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -474,6 +474,7 @@ class Similar:\n         hash_to_index_1: HashToIndex_T\n         hash_to_index_2: HashToIndex_T\n         index_to_lines_1: IndexToLines_T\n+\n         index_to_lines_2: IndexToLines_T\n         hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n         hash_to_index_2, index_to_lines_2 = hash_lineset(lineset2, self.min_lines)\n@@ -492,6 +493,7 @@ class Similar:\n         for c_hash in sorted(common_hashes, key=operator.attrgetter(\"_index\")):\n             for indices_in_linesets in itertools.product(\n                 hash_to_index_1[c_hash], hash_to_index_2[c_hash]\n+\n             ):\n                 index_1 = indices_in_linesets[0]\n                 index_2 = indices_in_linesets[1]\n@@ -524,13 +526,24 @@ class Similar:\n                 lineset1, start_index_1, lineset2, start_index_2, nb_common_lines\n             )\n \n-            if eff_cmn_nb > self.min_lines:\n+\n+            if self.min_lines > 0 and eff_cmn_nb > self.min_lines:\n+                yield com\n                 yield com\n \n     def _iter_sims(self) -> Generator[Commonality, None, None]:\n         \"\"\"iterate on similarities among all files, by making a cartesian\n         product\n         \"\"\"\n+\n+    def _iter_sims(self) -> Generator[Commonality, None, None]:\n+        \"\"\"iterate on similarities among all files, by making a cartesian\n+        product\n+        \"\"\"\n+        # Disable similarity checking when min_lines is 0\n+        if self.min_lines <= 0:\n+            return\n+            \n         for idx, lineset in enumerate(self.linesets[:-1]):\n             for lineset2 in self.linesets[idx + 1 :]:\n                 yield from self._find_common(lineset, lineset2)\n@@ -857,12 +870,24 @@ class SimilarChecker(BaseChecker, Similar, MapReduceMixin):\n         \"\"\"Reduces and recombines data into a format that we can report on\n \n         The partner function of get_map_data()\"\"\"\n-        recombined = SimilarChecker(linter)\n-        recombined.min_lines = self.min_lines\n-        recombined.ignore_comments = self.ignore_comments\n-        recombined.ignore_docstrings = self.ignore_docstrings\n-        recombined.ignore_imports = self.ignore_imports\n-        recombined.ignore_signatures = self.ignore_signatures\n+\n+def reduce_map_data(self, linter, data):\n+    \"\"\"Reduces and recombines data into a format that we can report on\n+\n+    The partner function of get_map_data()\"\"\"\n+    recombined = SimilarChecker(linter)\n+    # Re-initialize Similar with correct configuration values\n+    Similar.__init__(\n+        recombined,\n+        min_lines=self.min_lines,\n+        ignore_comments=self.ignore_comments,\n+        ignore_docstrings=self.ignore_docstrings,\n+        ignore_imports=self.ignore_imports,\n+        ignore_signatures=self.ignore_signatures,\n+    )\n+    recombined.open()\n+    Similar.combine_mapreduce_data(recombined, linesets_collection=data)\n+    recombined.close()\n         recombined.open()\n         Similar.combine_mapreduce_data(recombined, linesets_collection=data)\n         recombined.close()\n",
    "variant_2": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex c65b1c893..20ce1c018 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -474,6 +474,7 @@ class Similar:\n         hash_to_index_1: HashToIndex_T\n         hash_to_index_2: HashToIndex_T\n         index_to_lines_1: IndexToLines_T\n+\n         index_to_lines_2: IndexToLines_T\n         hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n         hash_to_index_2, index_to_lines_2 = hash_lineset(lineset2, self.min_lines)\n@@ -492,6 +493,7 @@ class Similar:\n         for c_hash in sorted(common_hashes, key=operator.attrgetter(\"_index\")):\n             for indices_in_linesets in itertools.product(\n                 hash_to_index_1[c_hash], hash_to_index_2[c_hash]\n+\n             ):\n                 index_1 = indices_in_linesets[0]\n                 index_2 = indices_in_linesets[1]\n@@ -524,13 +526,26 @@ class Similar:\n                 lineset1, start_index_1, lineset2, start_index_2, nb_common_lines\n             )\n \n-            if eff_cmn_nb > self.min_lines:\n+\n+        if self.min_lines <= 0:\n+            return\n+\n+        if eff_cmn_nb > self.min_lines:\n                 yield com\n \n     def _iter_sims(self) -> Generator[Commonality, None, None]:\n         \"\"\"iterate on similarities among all files, by making a cartesian\n         product\n         \"\"\"\n+\n+    def _iter_sims(self) -> Generator[Commonality, None, None]:\n+        \"\"\"iterate on similarities among all files, by making a cartesian\n+        product\n+        \"\"\"\n+        # Disable similarity checking when min_lines is 0\n+        if self.min_lines <= 0:\n+            return\n+        \n         for idx, lineset in enumerate(self.linesets[:-1]):\n             for lineset2 in self.linesets[idx + 1 :]:\n                 yield from self._find_common(lineset, lineset2)\n@@ -853,16 +868,28 @@ class SimilarChecker(BaseChecker, Similar, MapReduceMixin):\n         \"\"\"Passthru override\"\"\"\n         return Similar.get_map_data(self)\n \n+    def reduce_map_data(self, linter, data):\n+        \"\"\"Reduces and recombines data into a format that we can report on\n+\n+        The partner function of get_map_data()\"\"\"\n+\n     def reduce_map_data(self, linter, data):\n         \"\"\"Reduces and recombines data into a format that we can report on\n \n         The partner function of get_map_data()\"\"\"\n         recombined = SimilarChecker(linter)\n-        recombined.min_lines = self.min_lines\n-        recombined.ignore_comments = self.ignore_comments\n-        recombined.ignore_docstrings = self.ignore_docstrings\n-        recombined.ignore_imports = self.ignore_imports\n-        recombined.ignore_signatures = self.ignore_signatures\n+        # Re-initialize Similar with correct configuration values\n+        Similar.__init__(\n+            recombined,\n+            min_lines=self.min_lines,\n+            ignore_comments=self.ignore_comments,\n+            ignore_docstrings=self.ignore_docstrings,\n+            ignore_imports=self.ignore_imports,\n+            ignore_signatures=self.ignore_signatures,\n+        )\n+        recombined.open()\n+        Similar.combine_mapreduce_data(recombined, linesets_collection=data)\n+        recombined.close()\n         recombined.open()\n         Similar.combine_mapreduce_data(recombined, linesets_collection=data)\n         recombined.close()\n",
    "variant_3": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex c65b1c893..35deaf316 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -474,6 +474,7 @@ class Similar:\n         hash_to_index_1: HashToIndex_T\n         hash_to_index_2: HashToIndex_T\n         index_to_lines_1: IndexToLines_T\n+\n         index_to_lines_2: IndexToLines_T\n         hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n         hash_to_index_2, index_to_lines_2 = hash_lineset(lineset2, self.min_lines)\n@@ -492,6 +493,7 @@ class Similar:\n         for c_hash in sorted(common_hashes, key=operator.attrgetter(\"_index\")):\n             for indices_in_linesets in itertools.product(\n                 hash_to_index_1[c_hash], hash_to_index_2[c_hash]\n+\n             ):\n                 index_1 = indices_in_linesets[0]\n                 index_2 = indices_in_linesets[1]\n@@ -524,6 +526,10 @@ class Similar:\n                 lineset1, start_index_1, lineset2, start_index_2, nb_common_lines\n             )\n \n+\n+            if self.min_lines <= 0:\n+                return\n+            \n             if eff_cmn_nb > self.min_lines:\n                 yield com\n \n@@ -531,6 +537,15 @@ class Similar:\n         \"\"\"iterate on similarities among all files, by making a cartesian\n         product\n         \"\"\"\n+\n+    def _iter_sims(self) -> Generator[Commonality, None, None]:\n+        \"\"\"iterate on similarities among all files, by making a cartesian\n+        product\n+        \"\"\"\n+        # Disable similarity checking when min_lines is 0\n+        if self.min_lines <= 0:\n+            return\n+        \n         for idx, lineset in enumerate(self.linesets[:-1]):\n             for lineset2 in self.linesets[idx + 1 :]:\n                 yield from self._find_common(lineset, lineset2)\n@@ -853,16 +868,25 @@ class SimilarChecker(BaseChecker, Similar, MapReduceMixin):\n         \"\"\"Passthru override\"\"\"\n         return Similar.get_map_data(self)\n \n+    def reduce_map_data(self, linter, data):\n+        \"\"\"Reduces and recombines data into a format that we can report on\n+\n+        The partner function of get_map_data()\"\"\"\n+\n     def reduce_map_data(self, linter, data):\n         \"\"\"Reduces and recombines data into a format that we can report on\n \n         The partner function of get_map_data()\"\"\"\n         recombined = SimilarChecker(linter)\n-        recombined.min_lines = self.min_lines\n-        recombined.ignore_comments = self.ignore_comments\n-        recombined.ignore_docstrings = self.ignore_docstrings\n-        recombined.ignore_imports = self.ignore_imports\n-        recombined.ignore_signatures = self.ignore_signatures\n+        # Re-initialize Similar with correct configuration values\n+        Similar.__init__(\n+            recombined,\n+            min_lines=self.min_lines,\n+            ignore_comments=self.ignore_comments,\n+            ignore_docstrings=self.ignore_docstrings,\n+            ignore_imports=self.ignore_imports,\n+            ignore_signatures=self.ignore_signatures,\n+        )\n         recombined.open()\n         Similar.combine_mapreduce_data(recombined, linesets_collection=data)\n         recombined.close()\n",
    "variant_4": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex c65b1c893..4829a7347 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -474,6 +474,7 @@ class Similar:\n         hash_to_index_1: HashToIndex_T\n         hash_to_index_2: HashToIndex_T\n         index_to_lines_1: IndexToLines_T\n+\n         index_to_lines_2: IndexToLines_T\n         hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n         hash_to_index_2, index_to_lines_2 = hash_lineset(lineset2, self.min_lines)\n@@ -492,6 +493,7 @@ class Similar:\n         for c_hash in sorted(common_hashes, key=operator.attrgetter(\"_index\")):\n             for indices_in_linesets in itertools.product(\n                 hash_to_index_1[c_hash], hash_to_index_2[c_hash]\n+\n             ):\n                 index_1 = indices_in_linesets[0]\n                 index_2 = indices_in_linesets[1]\n@@ -524,6 +526,10 @@ class Similar:\n                 lineset1, start_index_1, lineset2, start_index_2, nb_common_lines\n             )\n \n+\n+            if self.min_lines <= 0:\n+                return\n+            \n             if eff_cmn_nb > self.min_lines:\n                 yield com\n \n@@ -531,6 +537,15 @@ class Similar:\n         \"\"\"iterate on similarities among all files, by making a cartesian\n         product\n         \"\"\"\n+\n+    def _iter_sims(self) -> Generator[Commonality, None, None]:\n+        \"\"\"iterate on similarities among all files, by making a cartesian\n+        product\n+        \"\"\"\n+        # Disable similarity checking when min_lines is 0\n+        if self.min_lines <= 0:\n+            return\n+        \n         for idx, lineset in enumerate(self.linesets[:-1]):\n             for lineset2 in self.linesets[idx + 1 :]:\n                 yield from self._find_common(lineset, lineset2)\n@@ -853,16 +868,28 @@ class SimilarChecker(BaseChecker, Similar, MapReduceMixin):\n         \"\"\"Passthru override\"\"\"\n         return Similar.get_map_data(self)\n \n+    def reduce_map_data(self, linter, data):\n+        \"\"\"Reduces and recombines data into a format that we can report on\n+\n+        The partner function of get_map_data()\"\"\"\n+\n     def reduce_map_data(self, linter, data):\n         \"\"\"Reduces and recombines data into a format that we can report on\n \n         The partner function of get_map_data()\"\"\"\n         recombined = SimilarChecker(linter)\n-        recombined.min_lines = self.min_lines\n-        recombined.ignore_comments = self.ignore_comments\n-        recombined.ignore_docstrings = self.ignore_docstrings\n-        recombined.ignore_imports = self.ignore_imports\n-        recombined.ignore_signatures = self.ignore_signatures\n+        # Re-initialize Similar with correct configuration values\n+        Similar.__init__(\n+            recombined,\n+            min_lines=self.min_lines,\n+            ignore_comments=self.ignore_comments,\n+            ignore_docstrings=self.ignore_docstrings,\n+            ignore_imports=self.ignore_imports,\n+            ignore_signatures=self.ignore_signatures,\n+        )\n+        recombined.open()\n+        Similar.combine_mapreduce_data(recombined, linesets_collection=data)\n+        recombined.close()\n         recombined.open()\n         Similar.combine_mapreduce_data(recombined, linesets_collection=data)\n         recombined.close()\n",
    "variant_5": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex c65b1c893..e09433a61 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -474,6 +474,7 @@ class Similar:\n         hash_to_index_1: HashToIndex_T\n         hash_to_index_2: HashToIndex_T\n         index_to_lines_1: IndexToLines_T\n+\n         index_to_lines_2: IndexToLines_T\n         hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n         hash_to_index_2, index_to_lines_2 = hash_lineset(lineset2, self.min_lines)\n@@ -492,7 +493,11 @@ class Similar:\n         for c_hash in sorted(common_hashes, key=operator.attrgetter(\"_index\")):\n             for indices_in_linesets in itertools.product(\n                 hash_to_index_1[c_hash], hash_to_index_2[c_hash]\n+\n             ):\n+                # Disable similarity checking when min_lines is 0\n+                if self.min_lines <= 0:\n+                    continue\n                 index_1 = indices_in_linesets[0]\n                 index_2 = indices_in_linesets[1]\n                 all_couples[\n@@ -524,13 +529,24 @@ class Similar:\n                 lineset1, start_index_1, lineset2, start_index_2, nb_common_lines\n             )\n \n-            if eff_cmn_nb > self.min_lines:\n+\n+            if self.min_lines <= 0 or eff_cmn_nb > self.min_lines:\n+                yield com\n                 yield com\n \n     def _iter_sims(self) -> Generator[Commonality, None, None]:\n         \"\"\"iterate on similarities among all files, by making a cartesian\n         product\n         \"\"\"\n+\n+    def _iter_sims(self) -> Generator[Commonality, None, None]:\n+        \"\"\"iterate on similarities among all files, by making a cartesian\n+        product\n+        \"\"\"\n+        # Disable similarity checking when min_lines is 0\n+        if self.min_lines <= 0:\n+            return\n+        \n         for idx, lineset in enumerate(self.linesets[:-1]):\n             for lineset2 in self.linesets[idx + 1 :]:\n                 yield from self._find_common(lineset, lineset2)\n@@ -853,16 +869,25 @@ class SimilarChecker(BaseChecker, Similar, MapReduceMixin):\n         \"\"\"Passthru override\"\"\"\n         return Similar.get_map_data(self)\n \n+    def reduce_map_data(self, linter, data):\n+        \"\"\"Reduces and recombines data into a format that we can report on\n+\n+        The partner function of get_map_data()\"\"\"\n+\n     def reduce_map_data(self, linter, data):\n         \"\"\"Reduces and recombines data into a format that we can report on\n \n         The partner function of get_map_data()\"\"\"\n         recombined = SimilarChecker(linter)\n-        recombined.min_lines = self.min_lines\n-        recombined.ignore_comments = self.ignore_comments\n-        recombined.ignore_docstrings = self.ignore_docstrings\n-        recombined.ignore_imports = self.ignore_imports\n-        recombined.ignore_signatures = self.ignore_signatures\n+        # Re-initialize Similar with correct configuration values\n+        Similar.__init__(\n+            recombined,\n+            min_lines=self.min_lines,\n+            ignore_comments=self.ignore_comments,\n+            ignore_docstrings=self.ignore_docstrings,\n+            ignore_imports=self.ignore_imports,\n+            ignore_signatures=self.ignore_signatures,\n+        )\n         recombined.open()\n         Similar.combine_mapreduce_data(recombined, linesets_collection=data)\n         recombined.close()\n",
    "variant_6": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex c65b1c893..d0b076d3a 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -474,6 +474,7 @@ class Similar:\n         hash_to_index_1: HashToIndex_T\n         hash_to_index_2: HashToIndex_T\n         index_to_lines_1: IndexToLines_T\n+\n         index_to_lines_2: IndexToLines_T\n         hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n         hash_to_index_2, index_to_lines_2 = hash_lineset(lineset2, self.min_lines)\n@@ -492,6 +493,7 @@ class Similar:\n         for c_hash in sorted(common_hashes, key=operator.attrgetter(\"_index\")):\n             for indices_in_linesets in itertools.product(\n                 hash_to_index_1[c_hash], hash_to_index_2[c_hash]\n+\n             ):\n                 index_1 = indices_in_linesets[0]\n                 index_2 = indices_in_linesets[1]\n@@ -524,13 +526,26 @@ class Similar:\n                 lineset1, start_index_1, lineset2, start_index_2, nb_common_lines\n             )\n \n-            if eff_cmn_nb > self.min_lines:\n+\n+        if self.min_lines <= 0:\n+            return\n+\n+        if eff_cmn_nb > self.min_lines:\n                 yield com\n \n     def _iter_sims(self) -> Generator[Commonality, None, None]:\n         \"\"\"iterate on similarities among all files, by making a cartesian\n         product\n         \"\"\"\n+\n+    def _iter_sims(self) -> Generator[Commonality, None, None]:\n+        \"\"\"iterate on similarities among all files, by making a cartesian\n+        product\n+        \"\"\"\n+        # Disable similarity checking when min_lines is 0\n+        if self.min_lines <= 0:\n+            return\n+        \n         for idx, lineset in enumerate(self.linesets[:-1]):\n             for lineset2 in self.linesets[idx + 1 :]:\n                 yield from self._find_common(lineset, lineset2)\n@@ -853,16 +868,25 @@ class SimilarChecker(BaseChecker, Similar, MapReduceMixin):\n         \"\"\"Passthru override\"\"\"\n         return Similar.get_map_data(self)\n \n+    def reduce_map_data(self, linter, data):\n+        \"\"\"Reduces and recombines data into a format that we can report on\n+\n+        The partner function of get_map_data()\"\"\"\n+\n     def reduce_map_data(self, linter, data):\n         \"\"\"Reduces and recombines data into a format that we can report on\n \n         The partner function of get_map_data()\"\"\"\n         recombined = SimilarChecker(linter)\n-        recombined.min_lines = self.min_lines\n-        recombined.ignore_comments = self.ignore_comments\n-        recombined.ignore_docstrings = self.ignore_docstrings\n-        recombined.ignore_imports = self.ignore_imports\n-        recombined.ignore_signatures = self.ignore_signatures\n+        # Re-initialize Similar with correct configuration values\n+        Similar.__init__(\n+            recombined,\n+            min_lines=self.min_lines,\n+            ignore_comments=self.ignore_comments,\n+            ignore_docstrings=self.ignore_docstrings,\n+            ignore_imports=self.ignore_imports,\n+            ignore_signatures=self.ignore_signatures,\n+        )\n         recombined.open()\n         Similar.combine_mapreduce_data(recombined, linesets_collection=data)\n         recombined.close()\n",
    "variant_7": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex c65b1c893..58d7ff278 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -474,6 +474,7 @@ class Similar:\n         hash_to_index_1: HashToIndex_T\n         hash_to_index_2: HashToIndex_T\n         index_to_lines_1: IndexToLines_T\n+\n         index_to_lines_2: IndexToLines_T\n         hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n         hash_to_index_2, index_to_lines_2 = hash_lineset(lineset2, self.min_lines)\n@@ -492,7 +493,12 @@ class Similar:\n         for c_hash in sorted(common_hashes, key=operator.attrgetter(\"_index\")):\n             for indices_in_linesets in itertools.product(\n                 hash_to_index_1[c_hash], hash_to_index_2[c_hash]\n+\n             ):\n+                # Disable similarity checking when min_lines is 0\n+                if self.min_lines <= 0:\n+                    return\n+                \n                 index_1 = indices_in_linesets[0]\n                 index_2 = indices_in_linesets[1]\n                 all_couples[\n@@ -524,13 +530,33 @@ class Similar:\n                 lineset1, start_index_1, lineset2, start_index_2, nb_common_lines\n             )\n \n-            if eff_cmn_nb > self.min_lines:\n+\n+def _iter_sims(self) -> Generator[Commonality, None, None]:\n+    \"\"\"iterate on similarities among all files, by making a cartesian\n+    product\n+    \"\"\"\n+    # Disable similarity checking when min_lines is 0\n+    if self.min_lines <= 0:\n+        return\n+    \n+    for idx, lineset in enumerate(self.linesets[:-1]):\n+        for lineset2 in self.linesets[idx + 1 :]:\n+            yield from self._find_common(lineset, lineset2)\n                 yield com\n \n     def _iter_sims(self) -> Generator[Commonality, None, None]:\n         \"\"\"iterate on similarities among all files, by making a cartesian\n         product\n         \"\"\"\n+\n+    def _iter_sims(self) -> Generator[Commonality, None, None]:\n+        \"\"\"iterate on similarities among all files, by making a cartesian\n+        product\n+        \"\"\"\n+        # Disable similarity checking when min_lines is 0\n+        if self.min_lines <= 0:\n+            return\n+            \n         for idx, lineset in enumerate(self.linesets[:-1]):\n             for lineset2 in self.linesets[idx + 1 :]:\n                 yield from self._find_common(lineset, lineset2)\n@@ -853,16 +879,28 @@ class SimilarChecker(BaseChecker, Similar, MapReduceMixin):\n         \"\"\"Passthru override\"\"\"\n         return Similar.get_map_data(self)\n \n+    def reduce_map_data(self, linter, data):\n+        \"\"\"Reduces and recombines data into a format that we can report on\n+\n+        The partner function of get_map_data()\"\"\"\n+\n     def reduce_map_data(self, linter, data):\n         \"\"\"Reduces and recombines data into a format that we can report on\n \n         The partner function of get_map_data()\"\"\"\n         recombined = SimilarChecker(linter)\n-        recombined.min_lines = self.min_lines\n-        recombined.ignore_comments = self.ignore_comments\n-        recombined.ignore_docstrings = self.ignore_docstrings\n-        recombined.ignore_imports = self.ignore_imports\n-        recombined.ignore_signatures = self.ignore_signatures\n+        # Re-initialize Similar with correct configuration values\n+        Similar.__init__(\n+            recombined,\n+            min_lines=self.min_lines,\n+            ignore_comments=self.ignore_comments,\n+            ignore_docstrings=self.ignore_docstrings,\n+            ignore_imports=self.ignore_imports,\n+            ignore_signatures=self.ignore_signatures,\n+        )\n+        recombined.open()\n+        Similar.combine_mapreduce_data(recombined, linesets_collection=data)\n+        recombined.close()\n         recombined.open()\n         Similar.combine_mapreduce_data(recombined, linesets_collection=data)\n         recombined.close()\n",
    "variant_8": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex c65b1c893..281aa7a86 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -474,6 +474,7 @@ class Similar:\n         hash_to_index_1: HashToIndex_T\n         hash_to_index_2: HashToIndex_T\n         index_to_lines_1: IndexToLines_T\n+\n         index_to_lines_2: IndexToLines_T\n         hash_to_index_1, index_to_lines_1 = hash_lineset(lineset1, self.min_lines)\n         hash_to_index_2, index_to_lines_2 = hash_lineset(lineset2, self.min_lines)\n@@ -492,6 +493,7 @@ class Similar:\n         for c_hash in sorted(common_hashes, key=operator.attrgetter(\"_index\")):\n             for indices_in_linesets in itertools.product(\n                 hash_to_index_1[c_hash], hash_to_index_2[c_hash]\n+\n             ):\n                 index_1 = indices_in_linesets[0]\n                 index_2 = indices_in_linesets[1]\n@@ -524,13 +526,24 @@ class Similar:\n                 lineset1, start_index_1, lineset2, start_index_2, nb_common_lines\n             )\n \n-            if eff_cmn_nb > self.min_lines:\n+\n+            if self.min_lines <= 0 or eff_cmn_nb > self.min_lines:\n+                yield com\n                 yield com\n \n     def _iter_sims(self) -> Generator[Commonality, None, None]:\n         \"\"\"iterate on similarities among all files, by making a cartesian\n         product\n         \"\"\"\n+\n+    def _iter_sims(self) -> Generator[Commonality, None, None]:\n+        \"\"\"iterate on similarities among all files, by making a cartesian\n+        product\n+        \"\"\"\n+        # Disable similarity checking when min_lines is 0\n+        if self.min_lines <= 0:\n+            return\n+        \n         for idx, lineset in enumerate(self.linesets[:-1]):\n             for lineset2 in self.linesets[idx + 1 :]:\n                 yield from self._find_common(lineset, lineset2)\n@@ -853,16 +866,25 @@ class SimilarChecker(BaseChecker, Similar, MapReduceMixin):\n         \"\"\"Passthru override\"\"\"\n         return Similar.get_map_data(self)\n \n+    def reduce_map_data(self, linter, data):\n+        \"\"\"Reduces and recombines data into a format that we can report on\n+\n+        The partner function of get_map_data()\"\"\"\n+\n     def reduce_map_data(self, linter, data):\n         \"\"\"Reduces and recombines data into a format that we can report on\n \n         The partner function of get_map_data()\"\"\"\n         recombined = SimilarChecker(linter)\n-        recombined.min_lines = self.min_lines\n-        recombined.ignore_comments = self.ignore_comments\n-        recombined.ignore_docstrings = self.ignore_docstrings\n-        recombined.ignore_imports = self.ignore_imports\n-        recombined.ignore_signatures = self.ignore_signatures\n+        # Re-initialize Similar with correct configuration values\n+        Similar.__init__(\n+            recombined,\n+            min_lines=self.min_lines,\n+            ignore_comments=self.ignore_comments,\n+            ignore_docstrings=self.ignore_docstrings,\n+            ignore_imports=self.ignore_imports,\n+            ignore_signatures=self.ignore_signatures,\n+        )\n         recombined.open()\n         Similar.combine_mapreduce_data(recombined, linesets_collection=data)\n         recombined.close()\n"
  }
}