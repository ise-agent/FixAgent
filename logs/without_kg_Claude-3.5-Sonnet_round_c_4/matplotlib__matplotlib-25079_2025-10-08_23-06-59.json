{
  "zero_patches": {
    "Location 1 (/root/hy/projects_4/matplotlib/lib/matplotlib/colors.py lines 1720-1725)": "\ndef autoscale_None(self, A):\n    # i.e. A[np.isfinite(...)], but also for non-array A's\n    in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n    if in_trf_domain.size == 0:\n        # If no valid data exists in transform domain, check if vmin/vmax are already set\n        if self.vmin is not None and self.vmax is not None:\n            # Already have valid bounds, no need to autoscale\n            return\n        else:\n            # Set reasonable default values for log scale\n            if isinstance(self._trf, scale.LogTransform):\n                self.vmin, self.vmax = 1.0, 10.0\n            else:\n                # For other transforms, use masked array as fallback\n                in_trf_domain = np.ma.masked\n                super().autoscale_None(in_trf_domain)\n            return\n    super().autoscale_None(in_trf_domain)\n",
    "Location 2 (/root/hy/projects_4/matplotlib/lib/matplotlib/colors.py lines 1695-1697)": "\n            t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n            if not np.isfinite([t_vmin, t_vmax]).all():\n                # Reset to reasonable defaults for this transform type\n                if hasattr(self._trf, 'inverted'):\n                    # For LogTransform, use safe default range\n                    self.vmin, self.vmax = 1.0, 10.0\n                    t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n                if not np.isfinite([t_vmin, t_vmax]).all():\n                    raise ValueError(\"Invalid vmin or vmax\")\n",
    "Location 3 (/root/hy/projects_4/matplotlib/lib/matplotlib/colors.py lines 1708-1710)": "\n        def autoscale_None(self, A):\n            # only autoscale if vmin or vmax are not set\n            if self.vmin is not None and self.vmax is not None:\n                return\n            if A is not None:\n                A = np.asarray(A)\n                # Transform the data to the log domain for autoscaling\n                with np.errstate(invalid='ignore', divide='ignore'):\n                    A_transformed = self._trf.transform(A)\n                # Filter out non-finite values after transformation\n                A_transformed = A_transformed[np.isfinite(A_transformed)]\n                \n                # If no valid data remains after transformation, use reasonable defaults\n                if A_transformed.size == 0:\n                    if self.vmin is None:\n                        self.vmin = 1.0\n                    if self.vmax is None:\n                        self.vmax = 10.0\n                    return\n                \n                # Use the transformed data for autoscaling\n                super().autoscale_None(A_transformed)\n",
    "Location 4 (/root/hy/projects_4/matplotlib/lib/matplotlib/colors.py lines 1684-1685)": "\n            if self.vmin is not None and self.vmax is not None:\n                # Skip autoscaling if both bounds are already set and valid\n                return\n            if self.vmin is None or self.vmax is None:\n                self.autoscale_None(value)\n",
    "Location 5 (/root/hy/projects_4/matplotlib/lib/matplotlib/colors.py lines 1368-1374)": "\n    def autoscale_None(self, A):\n        \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n        A = np.asanyarray(A)\n        \n        # Check if we need to autoscale at all\n        if self.vmin is not None and self.vmax is not None:\n            return\n            \n        if A.size == 0:\n            return\n            \n        # Transform the data to handle log scale appropriately\n        try:\n            # Filter out non-positive values for log scale\n            if hasattr(self, '_transform') and hasattr(self._transform, 'transform_non_affine'):\n                # For log scales, only consider positive values\n                valid_mask = A > 0\n                if np.ma.is_masked(A):\n                    valid_mask = valid_mask & ~A.mask\n                \n                if not np.any(valid_mask):\n                    # No valid data for log scale, use reasonable defaults\n                    if self.vmin is None:\n                        self.vmin = 1.0\n                    if self.vmax is None:\n                        self.vmax = 10.0\n                    return\n                \n                valid_data = A[valid_mask]\n                if self.vmin is None:\n                    self.vmin = valid_data.min()\n                if self.vmax is None:\n                    self.vmax = valid_data.max()\n            else:\n                # Fall back to base class behavior for non-log scales\n                super().autoscale_None(A)\n        except (ValueError, TypeError):\n            # If transform fails, fall back to base class or set defaults\n            if hasattr(self, '_transform') and 'log' in str(type(self._transform)).lower():\n                # For log scales, use safe defaults\n                if self.vmin is None:\n                    self.vmin = 1.0\n                if self.vmax is None:\n                    self.vmax = 10.0\n            else:\n                super().autoscale_None(A)\n"
  },
  "variant_patches": {
    "Location 1 (/root/hy/projects_4/matplotlib/lib/matplotlib/colors.py lines 1720-1725)": [
      "\n        def autoscale_None(self, A):\n            # i.e. A[np.isfinite(...)], but also for non-array A's\n            in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n            if in_trf_domain.size == 0:\n                # If no valid data in transform domain, skip autoscaling\n                # to avoid setting invalid vmin/vmax values\n                return\n            return super().autoscale_None(in_trf_domain)\n",
      "\n        def autoscale_None(self, A):\n            # i.e. A[np.isfinite(...)], but also for non-array A's\n            in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n            if in_trf_domain.size == 0:\n                # If no valid data exists in transform domain, skip autoscaling\n                # to avoid setting invalid vmin/vmax values\n                return\n            return super().autoscale_None(in_trf_domain)\n",
      "\n        def autoscale_None(self, A):\n            # i.e. A[np.isfinite(...)], but also for non-array A's\n            in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n            if in_trf_domain.size == 0:\n                # If no valid data exists in transform domain, skip autoscaling\n                # to avoid setting invalid vmin/vmax that would cause validation errors\n                return\n            return super().autoscale_None(in_trf_domain)\n",
      "\n        def autoscale_None(self, A):\n            # i.e. A[np.isfinite(...)], but also for non-array A's\n            in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n            if in_trf_domain.size == 0:\n                # If no valid data in transform domain, skip autoscaling if bounds are already set\n                if self.vmin is not None and self.vmax is not None:\n                    return\n                # Otherwise set reasonable defaults for the scale type\n                if hasattr(self._trf, '_base') and self._trf._base == 10:  # LogScale\n                    self.vmin, self.vmax = 1.0, 10.0\n                else:\n                    self.vmin, self.vmax = 0.0, 1.0\n                return\n            return super().autoscale_None(in_trf_domain)\n",
      "\n        def autoscale_None(self, A):\n            # i.e. A[np.isfinite(...)], but also for non-array A's\n            in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n            if in_trf_domain.size == 0:\n                # If no valid data in transform domain, don't autoscale\n                # This prevents invalid vmin/vmax from being set\n                return\n            return super().autoscale_None(in_trf_domain)\n",
      "\n        def autoscale_None(self, A):\n            # i.e. A[np.isfinite(...)], but also for non-array A's\n            in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n            if in_trf_domain.size == 0:\n                # If no valid data in transform domain, skip autoscaling\n                # to avoid setting invalid vmin/vmax that would cause validation errors\n                return\n            return super().autoscale_None(in_trf_domain)\n",
      "\n        def autoscale_None(self, A):\n            # i.e. A[np.isfinite(...)], but also for non-array A's\n            in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n            if in_trf_domain.size == 0:\n                # If no valid data in transform domain, skip autoscaling\n                # to avoid setting invalid vmin/vmax that would cause validation errors\n                return\n            return super().autoscale_None(in_trf_domain)\n",
      "\n        def autoscale_None(self, A):\n            # i.e. A[np.isfinite(...)], but also for non-array A's\n            in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n            if in_trf_domain.size == 0:\n                # If no valid data in transform domain, skip autoscaling\n                # to avoid setting invalid vmin/vmax values\n                return\n            return super().autoscale_None(in_trf_domain)\n"
    ],
    "Location 2 (/root/hy/projects_4/matplotlib/lib/matplotlib/colors.py lines 1695-1697)": [
      "\n            def autoscale_None(self, A):\n                # Only autoscale if vmin or vmax are not already set\n                if self.vmin is not None and self.vmax is not None:\n                    return\n                \n                # Apply transform and filter valid values\n                A = np.asarray(A)\n                A_transformed = self._trf.transform(A)\n                valid_mask = np.isfinite(A_transformed) & (A_transformed > -np.inf)\n                \n                if not valid_mask.any():\n                    # No valid data in transform domain - set reasonable defaults for LogNorm\n                    if self.vmin is None:\n                        self.vmin = 1.0\n                    if self.vmax is None:\n                        self.vmax = 10.0\n                    return\n                \n                # Use only valid transformed data for autoscaling\n                A_valid = A[valid_mask]\n                super().autoscale_None(A_valid)\n",
      "\n            def autoscale_None(self, A):\n                # Guard against autoscaling when vmin/vmax are already set and valid\n                if (self.vmin is not None and self.vmax is not None and \n                    self.vmin > 0 and self.vmax > 0 and self.vmin <= self.vmax):\n                    return\n                \n                # Apply transform and filter out invalid values\n                if A is not None:\n                    A = np.asarray(A)\n                    # For LogNorm, filter out non-positive values before transform\n                    valid_mask = A > 0\n                    if not np.any(valid_mask):\n                        # No valid data for LogNorm, use reasonable defaults\n                        if self.vmin is None:\n                            self.vmin = 1.0\n                        if self.vmax is None:\n                            self.vmax = 10.0\n                        return\n                    \n                    # Only use valid positive values for autoscaling\n                    A_valid = A[valid_mask]\n                    super().autoscale_None(A_valid)\n                else:\n                    super().autoscale_None(A)\n                \n                # Ensure vmin/vmax are valid for LogNorm after autoscaling\n                if self.vmin is not None and self.vmin <= 0:\n                    self.vmin = np.min([v for v in [1.0, self.vmax/1000] if v > 0])\n                if self.vmax is not None and self.vmax <= 0:\n                    self.vmax = max(10.0, self.vmin * 10 if self.vmin else 10.0)\n",
      "\n            def autoscale_None(self, A):\n                # guard against calling autoscale_None multiple times before\n                # the transform has been set up\n                if not self._transform_set:\n                    return\n                    \n                # If vmin and vmax are already set and valid, don't autoscale\n                if self.vmin is not None and self.vmax is not None:\n                    try:\n                        t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n                        if np.isfinite([t_vmin, t_vmax]).all():\n                            return\n                    except (ValueError, TypeError):\n                        pass  # Continue with autoscaling if current values are invalid\n                \n                # Apply transform and filter valid data\n                A_transformed = self._trf.transform(A)\n                valid_mask = np.isfinite(A_transformed)\n                \n                # If no valid data after transform, use reasonable defaults for LogNorm\n                if not np.any(valid_mask):\n                    if self.vmin is None:\n                        self.vmin = 1.0\n                    if self.vmax is None:\n                        self.vmax = 10.0\n                    return\n                \n                # Extract valid transformed data\n                valid_data = A_transformed[valid_mask]\n                \n                # Call parent autoscale with valid data only\n                super().autoscale_None(valid_data)\n",
      "\n            def autoscale_None(self, A):\n                # First check if we already have valid bounds\n                if self.vmin is not None and self.vmax is not None:\n                    try:\n                        t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n                        if np.isfinite([t_vmin, t_vmax]).all() and t_vmin < t_vmax:\n                            return  # Already have valid bounds, no need to autoscale\n                    except (ValueError, OverflowError):\n                        pass  # Current bounds are invalid, proceed with autoscaling\n                \n                # Apply transform and filter valid values\n                A = np.asarray(A)\n                if A.size == 0:\n                    return\n                \n                # Get valid values in transform domain\n                valid_mask = np.isfinite(A) & (A > 0)\n                if not valid_mask.any():\n                    # No valid data for log transform, set reasonable defaults\n                    if self.vmin is None:\n                        self.vmin = 1.0\n                    if self.vmax is None:\n                        self.vmax = 10.0\n                    return\n                \n                # Use only valid values for autoscaling\n                valid_A = A[valid_mask]\n                super().autoscale_None(valid_A)\n",
      "\n            def autoscale_None(self, A):\n                # Guard against unnecessary autoscaling when vmin/vmax already set\n                if self.vmin is not None and self.vmax is not None:\n                    try:\n                        # Validate current vmin/vmax are appropriate for this transform\n                        t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n                        if np.isfinite([t_vmin, t_vmax]).all():\n                            return  # Current bounds are valid, no autoscaling needed\n                    except (ValueError, OverflowError):\n                        pass  # Current bounds invalid, proceed with autoscaling\n                \n                # Apply transform and filter valid data\n                A = np.asarray(A)\n                if A.size == 0:\n                    return\n                \n                # Transform the data and get valid (finite, positive for log) values\n                try:\n                    with np.errstate(invalid='ignore', divide='ignore'):\n                        transformed_A = self._trf.transform(A)\n                    valid_mask = np.isfinite(transformed_A)\n                    if hasattr(A, 'mask'):\n                        valid_mask = valid_mask & ~A.mask\n                    \n                    if not np.any(valid_mask):\n                        # No valid data - use reasonable defaults for LogNorm\n                        if self.vmin is None:\n                            self.vmin = 1.0\n                        if self.vmax is None:\n                            self.vmax = 10.0\n                        return\n                    \n                    # Use only valid data for autoscaling\n                    valid_data = A[valid_mask] if valid_mask.ndim > 0 else A\n                    super().autoscale_None(valid_data)\n                    \n                except (ValueError, OverflowError):\n                    # Fallback to reasonable defaults if transform fails\n                    if self.vmin is None:\n                        self.vmin = 1.0\n                    if self.vmax is None:\n                        self.vmax = 10.0\n",
      "\n            def autoscale_None(self, A):\n                # Only autoscale if vmin or vmax are not set\n                if self.vmin is not None and self.vmax is not None:\n                    return\n                \n                # Apply the transform to get valid data for scaling\n                if A is not None:\n                    A = np.asarray(A)\n                    # Apply transform and get valid (finite, positive) values\n                    with np.errstate(invalid='ignore', divide='ignore'):\n                        transformed = self._trf.transform(A)\n                    # Only use finite values for scaling\n                    valid_mask = np.isfinite(transformed)\n                    if np.any(valid_mask):\n                        valid_transformed = transformed[valid_mask]\n                        # Convert back to original domain for setting vmin/vmax\n                        if self.vmin is None and len(valid_transformed) > 0:\n                            t_min = np.min(valid_transformed)\n                            self.vmin = self._trf.inverted().transform(t_min)\n                        if self.vmax is None and len(valid_transformed) > 0:\n                            t_max = np.max(valid_transformed)\n                            self.vmax = self._trf.inverted().transform(t_max)\n                    else:\n                        # No valid data - set reasonable defaults for this transform\n                        if self.vmin is None:\n                            self.vmin = 1.0 if hasattr(self._trf, 'transform') else 0.0\n                        if self.vmax is None:\n                            self.vmax = 10.0 if hasattr(self._trf, 'transform') else 1.0\n",
      "\n            def autoscale_None(self, A):\n                # Prevent autoscaling when vmin and vmax are already set and valid\n                if self.vmin is not None and self.vmax is not None:\n                    try:\n                        t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n                        if np.isfinite([t_vmin, t_vmax]).all():\n                            return  # Skip autoscaling if current bounds are valid\n                    except (ValueError, OverflowError):\n                        pass  # Continue with autoscaling if current bounds are invalid\n                \n                # Apply transform and filter out invalid values\n                A = np.asarray(A)\n                if A.size == 0:\n                    return\n                \n                # Transform the data and check for valid values\n                try:\n                    transformed_A = self._trf.transform(A.ravel())\n                    valid_mask = np.isfinite(transformed_A)\n                    \n                    if not valid_mask.any():\n                        # No valid data in transform domain, use reasonable defaults for LogNorm\n                        if name == 'log':\n                            self.vmin = 1.0\n                            self.vmax = 10.0\n                        else:\n                            # For other transforms, fall back to base behavior with original data\n                            super(Normalize, self).autoscale_None(A)\n                        return\n                    \n                    # Create filtered array with only valid transformed values\n                    valid_transformed = transformed_A[valid_mask]\n                    \n                    # Inverse transform back to original domain for vmin/vmax\n                    if hasattr(self._trf, 'inverted'):\n                        inv_trf = self._trf.inverted()\n                        vmin_candidate = inv_trf.transform(valid_transformed.min())\n                        vmax_candidate = inv_trf.transform(valid_transformed.max())\n                        \n                        # Validate the candidates are reasonable\n                        if np.isfinite([vmin_candidate, vmax_candidate]).all():\n                            self.vmin = vmin_candidate\n                            self.vmax = vmax_candidate\n                        else:\n                            # Fallback to reasonable defaults\n                            if name == 'log':\n                                self.vmin = 1.0\n                                self.vmax = 10.0\n                    else:\n                        # If no inverse available, use base autoscale with filtered data\n                        original_valid = A.ravel()[valid_mask] if len(A.ravel()) == len(valid_mask) else A\n                        super(Normalize, self).autoscale_None(original_valid)\n                        \n                except (ValueError, OverflowError, AttributeError):\n                    # If transform fails, fall back to base autoscale behavior\n                    super(Normalize, self).autoscale_None(A)\n",
      "\n            def autoscale_None(self, A):\n                # Handle the case where all data might be filtered out by the transform\n                if A is not None:\n                    # Apply transform to check for valid data\n                    try:\n                        transformed_A = self._trf.transform(A)\n                        # Check if we have any finite values after transform\n                        if np.ma.is_masked(transformed_A):\n                            valid_data = transformed_A[~transformed_A.mask]\n                        else:\n                            valid_data = transformed_A[np.isfinite(transformed_A)]\n                        \n                        # If no valid data exists after transform, use reasonable defaults\n                        if len(valid_data) == 0:\n                            if self.vmin is None:\n                                self.vmin = 1.0\n                            if self.vmax is None:\n                                self.vmax = 10.0\n                            return\n                    except (ValueError, RuntimeError):\n                        # Transform failed, use reasonable defaults\n                        if self.vmin is None:\n                            self.vmin = 1.0\n                        if self.vmax is None:\n                            self.vmax = 10.0\n                        return\n                \n                # Proceed with normal autoscaling if we have valid data\n                super().autoscale_None(A)\n"
    ],
    "Location 3 (/root/hy/projects_4/matplotlib/lib/matplotlib/colors.py lines 1708-1710)": [
      "\n        def autoscale_None(self, A):\n            \"\"\"\n            Set *vmin*, *vmax* to min, max of *A*.\n            \"\"\"\n            A = np.asanyarray(A)\n            if A.size == 0:\n                return\n            \n            # Check if vmin and vmax are already set and valid\n            if self.vmin is not None and self.vmax is not None:\n                try:\n                    t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n                    if np.isfinite([t_vmin, t_vmax]).all() and t_vmin < t_vmax:\n                        return  # Already have valid bounds, no need to autoscale\n                except (ValueError, OverflowError):\n                    pass  # Continue with autoscaling if current bounds are invalid\n            \n            # Apply transform to data for autoscaling\n            with np.errstate(invalid='ignore', divide='ignore'):\n                transformed = self._trf.transform(A)\n            \n            # Filter out non-finite values\n            finite_mask = np.isfinite(transformed)\n            if not np.any(finite_mask):\n                # No valid data in transform domain, use reasonable defaults\n                if isinstance(self, LogNorm):\n                    # For LogNorm, use default range that works well\n                    if self.vmin is None:\n                        self.vmin = 1.0\n                    if self.vmax is None:\n                        self.vmax = 10.0\n                return\n            \n            # Get valid transformed data\n            valid_transformed = transformed[finite_mask]\n            \n            # Set vmin/vmax in original domain\n            if self.vmin is None:\n                try:\n                    self.vmin = self._trf.inverted().transform(valid_transformed.min())\n                    if not np.isfinite(self.vmin):\n                        self.vmin = A[A > 0].min() if np.any(A > 0) else 1.0\n                except (ValueError, OverflowError):\n                    self.vmin = A[A > 0].min() if np.any(A > 0) else 1.0\n            \n            if self.vmax is None:\n                try:\n                    self.vmax = self._trf.inverted().transform(valid_transformed.max())\n                    if not np.isfinite(self.vmax):\n                        self.vmax = A.max() if A.size > 0 else 10.0\n                except (ValueError, OverflowError):\n                    self.vmax = A.max() if A.size > 0 else 10.0\n",
      "\n        def autoscale_None(self, A):\n            # only autoscale if vmin or vmax are not set\n            if self.vmin is not None and self.vmax is not None:\n                return\n            val = np.ma.masked_invalid(A, copy=False).compressed()\n            if len(val) > 0:\n                # Transform the data to check for valid range in log space\n                try:\n                    transformed = self._trf.transform(val)\n                    # Only proceed if we have valid transformed data\n                    if len(transformed) > 0 and np.isfinite(transformed).any():\n                        super().autoscale_None(A)\n                    else:\n                        # Fallback to reasonable defaults for LogNorm\n                        if self.vmin is None:\n                            self.vmin = 1.0\n                        if self.vmax is None:\n                            self.vmax = 10.0\n                except (ValueError, ZeroDivisionError):\n                    # Transform failed, use reasonable defaults for LogNorm\n                    if self.vmin is None:\n                        self.vmin = 1.0\n                    if self.vmax is None:\n                        self.vmax = 10.0\n            else:\n                # No valid data, use reasonable defaults for LogNorm\n                if self.vmin is None:\n                    self.vmin = 1.0\n                if self.vmax is None:\n                    self.vmax = 10.0\n",
      "\n        def autoscale_None(self, A):\n            # only autoscale if vmin or vmax are not set\n            if self.vmin is not None and self.vmax is not None:\n                return\n            if A is not None:\n                # Transform to avoid issues with zero/negative values for log scale\n                A = np.asanyarray(A)\n                # Filter out non-positive values for log scale\n                if hasattr(self._trf, 'transform'):\n                    # Only consider positive values for log transforms\n                    if hasattr(self._trf, '_transform_non_affine'):\n                        # This is likely a log transform, filter positive values\n                        valid_mask = A > 0\n                        if np.any(valid_mask):\n                            A_filtered = A[valid_mask]\n                        else:\n                            # No valid data for log scale, use reasonable defaults\n                            if self.vmin is None:\n                                self.vmin = 1.0\n                            if self.vmax is None:\n                                self.vmax = 10.0\n                            return\n                        A = A_filtered\n            super().autoscale_None(A)\n",
      "\n        def autoscale_None(self, A):\n            # only autoscale if vmin or vmax are not set\n            if self.vmin is not None and self.vmax is not None:\n                return\n            A = np.asanyarray(A)\n            if A.size == 0:\n                return\n            # Transform the data to handle the scale appropriately\n            with np.errstate(invalid='ignore', divide='ignore'):\n                transformed_A = self._trf.transform(A)\n            # Check if we have any valid transformed data\n            valid_mask = np.isfinite(transformed_A)\n            if not np.any(valid_mask):\n                # No valid data in transform domain, use reasonable defaults\n                if self.vmin is None:\n                    self.vmin = 1.0\n                if self.vmax is None:\n                    self.vmax = 10.0\n                return\n            # Use only valid transformed data for autoscaling\n            valid_transformed = transformed_A[valid_mask]\n            # Create a temporary array for the base class autoscale\n            temp_A = np.ma.masked_invalid(valid_transformed, copy=False)\n            super().autoscale_None(temp_A)\n            # Transform the computed bounds back to original space\n            if self.vmin is not None and self.vmax is not None:\n                try:\n                    t_vmin, t_vmax = self.vmin, self.vmax\n                    orig_bounds = self._trf.inverted().transform([t_vmin, t_vmax])\n                    if np.isfinite(orig_bounds).all():\n                        self.vmin, self.vmax = orig_bounds\n                    else:\n                        # Fallback to reasonable defaults if inverse transform fails\n                        self.vmin, self.vmax = 1.0, 10.0\n                except (ValueError, OverflowError):\n                    # Fallback to reasonable defaults if transform fails\n                    self.vmin, self.vmax = 1.0, 10.0\n",
      "\n        def autoscale_None(self, A):\n            # Avoid autoscaling if vmin/vmax are already set and valid\n            if self.vmin is not None and self.vmax is not None:\n                try:\n                    # Check if current bounds are valid for this transform\n                    t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n                    if np.isfinite([t_vmin, t_vmax]).all() and t_vmin < t_vmax:\n                        return\n                except (ValueError, OverflowError):\n                    # Current bounds are invalid, proceed with autoscaling\n                    pass\n            \n            # Only autoscale using positive values for LogNorm\n            if A is not None:\n                # Filter out non-positive values for log transform\n                A_positive = np.ma.masked_where(A <= 0, A, copy=False)\n                if A_positive.count() > 0:\n                    # Use positive values for autoscaling\n                    super().autoscale_None(A_positive)\n                else:\n                    # No positive values available, set reasonable defaults for LogNorm\n                    if self.vmin is None:\n                        self.vmin = 1.0\n                    if self.vmax is None:\n                        self.vmax = 10.0\n            else:\n                # A is None, set reasonable defaults if not already set\n                if self.vmin is None:\n                    self.vmin = 1.0\n                if self.vmax is None:\n                    self.vmax = 10.0\n",
      "\n        def autoscale_None(self, A):\n            \"\"\"\n            Autoscale only None-valued vmin or vmax.\n            \"\"\"\n            if self.vmin is not None and self.vmax is not None:\n                return\n            if A is not None:\n                # Transform to the scaled space for min/max calculation\n                A = np.asarray(A)\n                # Only process finite values\n                A_finite = A[np.isfinite(A)]\n                if A_finite.size == 0:\n                    # No finite data available, use reasonable defaults for LogNorm\n                    if self.vmin is None:\n                        self.vmin = 1.0\n                    if self.vmax is None:\n                        self.vmax = 10.0\n                    return\n                \n                # Filter out values that are invalid for the transform\n                # For LogNorm, we need positive values\n                if hasattr(self._trf, 'transform'):\n                    # Check if transform can handle the data\n                    try:\n                        # Test transform with a small sample to avoid full computation\n                        test_vals = A_finite[:min(10, len(A_finite))]\n                        transformed_test = self._trf.transform(test_vals)\n                        if not np.isfinite(transformed_test).any():\n                            # Transform produces no finite values, use defaults\n                            if self.vmin is None:\n                                self.vmin = 1.0\n                            if self.vmax is None:\n                                self.vmax = 10.0\n                            return\n                    except (ValueError, RuntimeWarning):\n                        # Transform failed, use defaults\n                        if self.vmin is None:\n                            self.vmin = 1.0\n                        if self.vmax is None:\n                            self.vmax = 10.0\n                        return\n                \n                # Proceed with normal autoscaling using valid data\n                super().autoscale_None(A_finite)\n                \n                # Ensure the resulting vmin/vmax are valid for this transform\n                if self.vmin is not None and self.vmax is not None:\n                    try:\n                        t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n                        if not np.isfinite([t_vmin, t_vmax]).all():\n                            # Reset to safe defaults if transform produces invalid results\n                            self.vmin = 1.0\n                            self.vmax = 10.0\n                    except (ValueError, RuntimeWarning):\n                        # Reset to safe defaults if transform fails\n                        self.vmin = 1.0\n                        self.vmax = 10.0\n",
      "\n        def autoscale_None(self, A):\n            # Only autoscale if vmin or vmax are not set\n            if self.vmin is not None and self.vmax is not None:\n                return\n            \n            # Flatten A and handle masking\n            A = np.asanyarray(A)\n            A = A.ravel()\n            \n            # If A is empty, use default values for LogNorm\n            if A.size == 0:\n                if self.vmin is None:\n                    self.vmin = 1.0\n                if self.vmax is None:\n                    self.vmax = 10.0\n                return\n            \n            # For LogNorm, filter out non-positive values before transformation\n            if hasattr(self._trf, 'transform'):\n                # Remove non-positive values which are invalid for log transform\n                valid_mask = A > 0\n                if hasattr(A, 'mask'):\n                    valid_mask = valid_mask & ~A.mask\n                \n                if not valid_mask.any():\n                    # No valid positive values, use defaults\n                    if self.vmin is None:\n                        self.vmin = 1.0\n                    if self.vmax is None:\n                        self.vmax = 10.0\n                    return\n                \n                A_valid = A[valid_mask]\n                \n                # Set vmin and vmax from valid data\n                if self.vmin is None:\n                    self.vmin = A_valid.min()\n                if self.vmax is None:\n                    self.vmax = A_valid.max()\n                    \n                # Ensure vmin and vmax are valid for log transform\n                if self.vmin <= 0:\n                    self.vmin = np.finfo(float).eps\n                if self.vmax <= 0:\n                    self.vmax = 1.0\n                if self.vmin >= self.vmax:\n                    self.vmax = self.vmin * 10\n            else:\n                # Fallback to parent implementation for non-transform cases\n                super().autoscale_None(A)\n",
      "\n        def autoscale_None(self, A):\n            \"\"\"\n            Autoscale only None-valued vmin or vmax.\n            \"\"\"\n            if self.vmin is not None and self.vmax is not None:\n                return\n            if A is not None:\n                # Filter out non-positive values for log scaling\n                A = np.ma.masked_where(A <= 0, A, copy=False)\n                if A.mask is np.ma.nomask:\n                    # No masked values, proceed normally\n                    super().autoscale_None(A)\n                elif not A.mask.all():\n                    # Some valid values remain after masking\n                    super().autoscale_None(A)\n                else:\n                    # All values are masked (non-positive), use fallback defaults\n                    if self.vmin is None:\n                        self.vmin = 1.0\n                    if self.vmax is None:\n                        self.vmax = 10.0\n"
    ],
    "Location 4 (/root/hy/projects_4/matplotlib/lib/matplotlib/colors.py lines 1684-1685)": [
      "\n        def autoscale_None(self, A):\n            # Guard against unnecessary autoscaling if bounds are already valid\n            if (self.vmin is not None and self.vmax is not None and \n                self.vmin > 0 and self.vmax > 0 and self.vmin <= self.vmax):\n                return\n            \n            # For LogNorm, we need positive values only\n            if A is not None:\n                A = np.asarray(A)\n                # Filter out non-positive values for log scale\n                positive_mask = A > 0\n                if np.ma.is_masked(A):\n                    positive_mask = positive_mask & ~A.mask\n                \n                if np.any(positive_mask):\n                    # Only autoscale if we have valid positive data\n                    valid_data = A[positive_mask]\n                    super().autoscale_None(valid_data)\n                else:\n                    # No valid data for log scale - set reasonable defaults\n                    if self.vmin is None:\n                        self.vmin = 1.0\n                    if self.vmax is None:\n                        self.vmax = 10.0\n            else:\n                # No data provided - set reasonable defaults for log scale\n                if self.vmin is None:\n                    self.vmin = 1.0\n                if self.vmax is None:\n                    self.vmax = 10.0\n",
      "\n        def autoscale_None(self, A):\n            # Handle the case where all data is filtered out by the transform\n            if A is not None:\n                # Check if we have any valid data after transformation\n                try:\n                    # For LogNorm, we need positive values\n                    valid_data = A[A > 0] if hasattr(A, '__getitem__') else A if A > 0 else None\n                    if valid_data is not None and len(np.atleast_1d(valid_data)) > 0:\n                        super().autoscale_None(valid_data)\n                    elif self.vmin is None or self.vmax is None:\n                        # No valid data for this transform, set reasonable defaults\n                        if self.vmin is None:\n                            self.vmin = 1.0\n                        if self.vmax is None:\n                            self.vmax = 10.0\n                except (TypeError, IndexError, ValueError):\n                    # Fallback for edge cases\n                    if self.vmin is None:\n                        self.vmin = 1.0\n                    if self.vmax is None:\n                        self.vmax = 10.0\n",
      "\n        def autoscale_None(self, A):\n            # Prevent autoscaling when vmin/vmax are already explicitly set\n            if self.vmin is not None and self.vmax is not None:\n                return\n                \n            # Handle the case where A might be filtered/masked for this scale\n            A = np.asarray(A)\n            if A.size == 0:\n                # No data to autoscale from, use reasonable defaults for this scale\n                if self.vmin is None:\n                    self.vmin = 1.0\n                if self.vmax is None:\n                    self.vmax = 10.0\n                return\n                \n            # Apply scale transform to get valid range for autoscaling\n            try:\n                A_transformed = self._trf.transform(A)\n                # Filter out invalid transformed values (inf, -inf, nan)\n                valid_mask = np.isfinite(A_transformed)\n                if not np.any(valid_mask):\n                    # No valid transformed values, use defaults\n                    if self.vmin is None:\n                        self.vmin = 1.0\n                    if self.vmax is None:\n                        self.vmax = 10.0\n                    return\n                    \n                # Use only valid transformed data for autoscaling\n                A_valid = A[valid_mask] if valid_mask.ndim > 0 else A\n                super().autoscale_None(A_valid)\n                \n                # Validate the resulting vmin/vmax are appropriate for this scale\n                if self.vmin is not None and self.vmax is not None:\n                    try:\n                        self._trf.transform([self.vmin, self.vmax])\n                    except (ValueError, OverflowError):\n                        # Reset to safe defaults if transform fails\n                        self.vmin = 1.0\n                        self.vmax = 10.0\n                        \n            except (ValueError, OverflowError):\n                # Transform failed entirely, use safe defaults\n                if self.vmin is None:\n                    self.vmin = 1.0\n                if self.vmax is None:\n                    self.vmax = 10.0\n",
      "\n        def autoscale_None(self, A):\n            # Get the valid (unmasked) values in the scale's domain\n            A = np.asarray(A)\n            valid_mask = (A > 0) if hasattr(self._scale, 'get_transform') else np.ones(A.shape, dtype=bool)\n            if np.ma.is_masked(A):\n                valid_mask = valid_mask & ~np.ma.getmaskarray(A)\n            \n            if not np.any(valid_mask):\n                # No valid data for this scale - use reasonable defaults if not already set\n                if self.vmin is None:\n                    self.vmin = 1.0 if hasattr(self._scale, 'get_transform') and 'log' in str(type(self._scale)).lower() else 0.0\n                if self.vmax is None:\n                    self.vmax = 10.0 if hasattr(self._scale, 'get_transform') and 'log' in str(type(self._scale)).lower() else 1.0\n                return\n            \n            # Extract valid values for autoscaling\n            valid_values = A[valid_mask]\n            super().autoscale_None(valid_values)\n",
      "\n        def autoscale_None(self, A):\n            # First check if we already have valid bounds\n            if (self.vmin is not None and self.vmax is not None and \n                self.vmin > 0 and self.vmax > 0 and self.vmin <= self.vmax):\n                return\n            \n            # Apply the transform to filter valid data\n            A = np.asarray(A)\n            if A.size == 0:\n                return\n            \n            # Get valid data in transform domain\n            valid_data = A[np.isfinite(A) & (A > 0)]\n            \n            # If no valid data for log transform, set reasonable defaults\n            if valid_data.size == 0:\n                if self.vmin is None:\n                    self.vmin = 1.0\n                if self.vmax is None:\n                    self.vmax = 10.0\n                return\n            \n            # Use valid data for autoscaling\n            super().autoscale_None(valid_data)\n            \n            # Ensure bounds are valid for log scale\n            if self.vmin is not None and self.vmin <= 0:\n                self.vmin = np.min(valid_data[valid_data > 0]) if valid_data.size > 0 else 1.0\n            if self.vmax is not None and self.vmax <= 0:\n                self.vmax = np.max(valid_data) if valid_data.size > 0 else 10.0\n",
      "\n        def autoscale_None(self, A):\n            # Store current vmin/vmax to check if they're already valid\n            current_vmin, current_vmax = self.vmin, self.vmax\n            \n            # If both vmin and vmax are already set and valid, skip autoscaling\n            if (current_vmin is not None and current_vmax is not None and \n                current_vmin > 0 and current_vmax > 0 and current_vmin <= current_vmax):\n                return\n            \n            # Transform the data to the scale domain for autoscaling\n            A_scaled = self._trf.transform_non_affine(A)\n            \n            # Check if we have any valid (non-masked, finite) data after transform\n            if np.ma.is_masked(A_scaled):\n                valid_data = A_scaled.compressed()\n            else:\n                valid_data = A_scaled[np.isfinite(A_scaled)]\n            \n            # If no valid data exists after transformation, use fallback values\n            if len(valid_data) == 0:\n                if self.vmin is None:\n                    self.vmin = 1.0  # Safe default for log scale\n                if self.vmax is None:\n                    self.vmax = 10.0  # Safe default for log scale\n                return\n            \n            # Call the base autoscale_None with the transformed data\n            super().autoscale_None(A_scaled)\n",
      "\n        def autoscale_None(self, A):\n            # Transform to the scale's domain for autoscaling, but handle edge cases\n            A = np.asarray(A)\n            if A.size == 0:\n                return\n            \n            # Apply the transform and check for valid results\n            transformed = self._trf.transform_non_affine(A)\n            \n            # Filter out invalid values (inf, nan, negative for log scales)\n            valid_mask = np.isfinite(transformed)\n            if not np.any(valid_mask):\n                # No valid data after transformation - use sensible defaults for LogNorm\n                if self.vmin is None:\n                    self.vmin = 1.0\n                if self.vmax is None:\n                    self.vmax = 10.0\n                return\n            \n            valid_transformed = transformed[valid_mask]\n            super().autoscale_None(valid_transformed)\n",
      "\n        def autoscale_None(self, A):\n            # Prevent autoscaling if both vmin and vmax are already set and valid\n            if (self.vmin is not None and self.vmax is not None and \n                self.vmin > 0 and self.vmax > 0 and self.vmin <= self.vmax):\n                return\n            \n            # For LogNorm, we need positive values - filter out non-positive data\n            A = np.asarray(A)\n            if A.size == 0:\n                return\n                \n            # Filter to positive values only for log scale\n            positive_mask = A > 0\n            if not np.any(positive_mask):\n                # No positive values - set reasonable defaults for log scale\n                if self.vmin is None:\n                    self.vmin = 1.0\n                if self.vmax is None:\n                    self.vmax = 10.0\n                return\n            \n            # Use only positive values for autoscaling\n            positive_values = A[positive_mask]\n            \n            # Call parent's autoscale_None with filtered positive values\n            super().autoscale_None(positive_values)\n            \n            # Ensure vmin and vmax are positive after autoscaling\n            if self.vmin is not None and self.vmin <= 0:\n                self.vmin = np.min(positive_values) if positive_values.size > 0 else 1.0\n            if self.vmax is not None and self.vmax <= 0:\n                self.vmax = np.max(positive_values) if positive_values.size > 0 else 10.0\n"
    ],
    "Location 5 (/root/hy/projects_4/matplotlib/lib/matplotlib/colors.py lines 1368-1374)": [
      "\n    def autoscale_None(self, A):\n        \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n        A = np.asanyarray(A)\n        if A.size == 0:\n            return\n        \n        # For LogNorm, we need to filter out non-positive values before computing min/max\n        if hasattr(self, '_transform') and hasattr(self._transform, 'transform_non_affine'):\n            # Filter out values that would be invalid for the transform\n            if A.dtype.kind in 'fc':  # float or complex\n                valid_mask = A > 0\n                if np.ma.is_masked(A):\n                    valid_mask = valid_mask & ~A.mask\n                if not np.any(valid_mask):\n                    # No valid data for this transform, use reasonable defaults\n                    if self.vmin is None:\n                        self.vmin = 1.0\n                    if self.vmax is None:\n                        self.vmax = 10.0\n                    return\n                A_valid = A[valid_mask]\n                if self.vmin is None and A_valid.size:\n                    self.vmin = A_valid.min()\n                if self.vmax is None and A_valid.size:\n                    self.vmax = A_valid.max()\n            else:\n                # Fall back to standard behavior for non-numeric data\n                if self.vmin is None and A.size:\n                    self.vmin = A.min()\n                if self.vmax is None and A.size:\n                    self.vmax = A.max()\n        else:\n            # Standard autoscale behavior for non-transform normalizers\n            if self.vmin is None and A.size:\n                self.vmin = A.min()\n            if self.vmax is None and A.size:\n                self.vmax = A.max()\n",
      "\n    def autoscale_None(self, A):\n        \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n        A = np.asanyarray(A)\n        if self.vmin is None and A.size:\n            # For masked arrays, get the minimum of valid (unmasked) data\n            if np.ma.is_masked(A):\n                valid_data = A.compressed()\n                if valid_data.size > 0:\n                    self.vmin = valid_data.min()\n            else:\n                self.vmin = A.min()\n        if self.vmax is None and A.size:\n            # For masked arrays, get the maximum of valid (unmasked) data\n            if np.ma.is_masked(A):\n                valid_data = A.compressed()\n                if valid_data.size > 0:\n                    self.vmax = valid_data.max()\n            else:\n                self.vmax = A.max()\n",
      "\n    def autoscale_None(self, A):\n        \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n        A = np.asanyarray(A)\n        if self.vmin is None and A.size:\n            # For LogNorm, ensure we only consider positive values\n            if hasattr(self, '_transform') and hasattr(self._transform, 'transform_non_affine'):\n                # This is a scale-specific norm, filter data appropriately\n                valid_mask = A > 0 if hasattr(self._transform, 'base') else np.ones(A.shape, dtype=bool)\n                valid_data = A[valid_mask]\n                if valid_data.size > 0:\n                    self.vmin = valid_data.min()\n                # If no valid data, leave vmin as None to avoid invalid state\n            else:\n                self.vmin = A.min()\n        if self.vmax is None and A.size:\n            if hasattr(self, '_transform') and hasattr(self._transform, 'transform_non_affine'):\n                valid_mask = A > 0 if hasattr(self._transform, 'base') else np.ones(A.shape, dtype=bool)\n                valid_data = A[valid_mask]\n                if valid_data.size > 0:\n                    self.vmax = valid_data.max()\n                # If no valid data, leave vmax as None to avoid invalid state\n            else:\n                self.vmax = A.max()\n",
      "\n    def autoscale_None(self, A):\n        \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n        A = np.asanyarray(A)\n        if A.size == 0:\n            return\n        \n        # For log scale, we need to filter out non-positive values\n        if hasattr(self, '_transform') and hasattr(self._transform, 'transform_non_affine'):\n            # This is likely a log-scale norm, filter out invalid values\n            valid_mask = A > 0\n            if np.ma.is_masked(A):\n                valid_mask = valid_mask & ~A.mask\n            \n            if not np.any(valid_mask):\n                # No valid data for log scale, skip autoscaling\n                return\n            \n            valid_A = A[valid_mask] if np.any(valid_mask) else A\n        else:\n            valid_A = A\n            \n        if self.vmin is None and valid_A.size:\n            self.vmin = valid_A.min()\n        if self.vmax is None and valid_A.size:\n            self.vmax = valid_A.max()\n",
      "\n    def autoscale_None(self, A):\n        \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n        A = np.asanyarray(A)\n        if self.vmin is None and A.size:\n            # For masked arrays, use compressed() to get only valid values\n            if np.ma.is_masked(A):\n                valid_data = A.compressed()\n                if valid_data.size > 0:\n                    self.vmin = valid_data.min()\n            else:\n                self.vmin = A.min()\n        if self.vmax is None and A.size:\n            # For masked arrays, use compressed() to get only valid values\n            if np.ma.is_masked(A):\n                valid_data = A.compressed()\n                if valid_data.size > 0:\n                    self.vmax = valid_data.max()\n            else:\n                self.vmax = A.max()\n",
      "\n    def autoscale_None(self, A):\n        \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n        A = np.asanyarray(A)\n        if A.size == 0:\n            return  # No data to autoscale from\n        \n        # For LogNorm, we need to filter out invalid values before computing min/max\n        if hasattr(self, 'transform') and hasattr(self.transform, 'transform_non_affine'):\n            # This is likely a scale-based norm, filter data appropriately\n            valid_mask = np.isfinite(A) & (A > 0)\n            if hasattr(A, 'mask'):\n                valid_mask = valid_mask & ~A.mask\n            if not np.any(valid_mask):\n                # No valid data for this transform, use reasonable defaults\n                if self.vmin is None:\n                    self.vmin = 1.0 if not hasattr(self, 'vmin') or self.vmin is None else self.vmin\n                if self.vmax is None:\n                    self.vmax = 10.0 if not hasattr(self, 'vmax') or self.vmax is None else self.vmax\n                return\n            A_filtered = A[valid_mask]\n        else:\n            A_filtered = A\n            \n        if self.vmin is None and A_filtered.size:\n            self.vmin = A_filtered.min()\n        if self.vmax is None and A_filtered.size:\n            self.vmax = A_filtered.max()\n",
      "\ndef autoscale_None(self, A):\n    \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n    A = np.asanyarray(A)\n    if A.size == 0:\n        return\n    \n    # For LogNorm, we need to work with positive values only\n    if hasattr(self, '_transform') and hasattr(self._transform, 'transform_non_affine'):\n        # Filter out non-positive values for log transform\n        if np.ma.is_masked(A):\n            valid_mask = (A.data > 0) & ~A.mask\n            if not np.any(valid_mask):\n                return  # No valid data for log transform\n            valid_A = A.data[valid_mask]\n        else:\n            valid_A = A[A > 0]\n            if valid_A.size == 0:\n                return  # No valid data for log transform\n        \n        if self.vmin is None:\n            self.vmin = valid_A.min()\n        if self.vmax is None:\n            self.vmax = valid_A.max()\n    else:\n        # Use original logic for other normalizations\n        if self.vmin is None and A.size:\n            self.vmin = A.min()\n        if self.vmax is None and A.size:\n            self.vmax = A.max()\n",
      "\n    def autoscale_None(self, A):\n        \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n        A = np.asanyarray(A)\n        if A.size == 0:\n            # No data to autoscale from\n            return\n            \n        # For LogNorm, we need to ensure we only consider positive values\n        if hasattr(self, 'transform') and hasattr(self.transform, 'transform_non_affine'):\n            # Filter out non-positive values for log scale\n            valid_mask = A > 0\n            if np.any(valid_mask):\n                A_valid = A[valid_mask]\n                if self.vmin is None:\n                    self.vmin = A_valid.min()\n                if self.vmax is None:\n                    self.vmax = A_valid.max()\n            else:\n                # All values are non-positive, set reasonable defaults for log scale\n                if self.vmin is None:\n                    self.vmin = 1.0\n                if self.vmax is None:\n                    self.vmax = 10.0\n        else:\n            # Standard behavior for non-log normalizations\n            if self.vmin is None and A.size:\n                self.vmin = A.min()\n            if self.vmax is None and A.size:\n                self.vmax = A.max()\n"
    ]
  },
  "combined_diffs": {
    "raw_patch": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex f9e4dcbd62..69160a4034 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -1365,9 +1365,13 @@ class Normalize:\n         self.vmin = self.vmax = None\n         self.autoscale_None(A)\n \n+\n     def autoscale_None(self, A):\n         \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n         A = np.asanyarray(A)\n+        # Handle masked arrays properly - don't set vmin/vmax if A is masked\n+        if np.ma.is_masked(A) and A is np.ma.masked:\n+            return\n         if self.vmin is None and A.size:\n             self.vmin = A.min()\n         if self.vmax is None and A.size:\n@@ -1681,6 +1685,7 @@ def _make_norm_from_scale(\n \n         def __call__(self, value, clip=None):\n             value, is_scalar = self.process_value(value)\n+\n             if self.vmin is None or self.vmax is None:\n                 self.autoscale_None(value)\n             if self.vmin > self.vmax:\n@@ -1692,6 +1697,7 @@ def _make_norm_from_scale(\n             if clip:\n                 value = np.clip(value, self.vmin, self.vmax)\n             t_value = self._trf.transform(value).reshape(np.shape(value))\n+\n             t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n             if not np.isfinite([t_vmin, t_vmax]).all():\n                 raise ValueError(\"Invalid vmin or vmax\")\n@@ -1705,6 +1711,7 @@ def _make_norm_from_scale(\n                 raise ValueError(\"Not invertible until scaled\")\n             if self.vmin > self.vmax:\n                 raise ValueError(\"vmin must be less or equal to vmax\")\n+\n             t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n             if not np.isfinite([t_vmin, t_vmax]).all():\n                 raise ValueError(\"Invalid vmin or vmax\")\n@@ -1717,11 +1724,14 @@ def _make_norm_from_scale(\n                      .reshape(np.shape(value)))\n             return value[0] if is_scalar else value\n \n+\n         def autoscale_None(self, A):\n             # i.e. A[np.isfinite(...)], but also for non-array A's\n             in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n             if in_trf_domain.size == 0:\n-                in_trf_domain = np.ma.masked\n+                # Don't autoscale if no valid data exists in transform domain\n+                # This prevents setting invalid vmin/vmax that would fail validation\n+                return\n             return super().autoscale_None(in_trf_domain)\n \n     if base_norm_cls is Normalize:\n",
    "variant_0": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex f9e4dcbd62..923d437852 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -1365,13 +1365,53 @@ class Normalize:\n         self.vmin = self.vmax = None\n         self.autoscale_None(A)\n \n+\n     def autoscale_None(self, A):\n         \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n         A = np.asanyarray(A)\n-        if self.vmin is None and A.size:\n-            self.vmin = A.min()\n-        if self.vmax is None and A.size:\n-            self.vmax = A.max()\n+        \n+        # Check if we need to autoscale at all\n+        if self.vmin is not None and self.vmax is not None:\n+            return\n+            \n+        if A.size == 0:\n+            return\n+            \n+        # Transform the data to handle log scale appropriately\n+        try:\n+            # Filter out non-positive values for log scale\n+            if hasattr(self, '_transform') and hasattr(self._transform, 'transform_non_affine'):\n+                # For log scales, only consider positive values\n+                valid_mask = A > 0\n+                if np.ma.is_masked(A):\n+                    valid_mask = valid_mask & ~A.mask\n+                \n+                if not np.any(valid_mask):\n+                    # No valid data for log scale, use reasonable defaults\n+                    if self.vmin is None:\n+                        self.vmin = 1.0\n+                    if self.vmax is None:\n+                        self.vmax = 10.0\n+                    return\n+                \n+                valid_data = A[valid_mask]\n+                if self.vmin is None:\n+                    self.vmin = valid_data.min()\n+                if self.vmax is None:\n+                    self.vmax = valid_data.max()\n+            else:\n+                # Fall back to base class behavior for non-log scales\n+                super().autoscale_None(A)\n+        except (ValueError, TypeError):\n+            # If transform fails, fall back to base class or set defaults\n+            if hasattr(self, '_transform') and 'log' in str(type(self._transform)).lower():\n+                # For log scales, use safe defaults\n+                if self.vmin is None:\n+                    self.vmin = 1.0\n+                if self.vmax is None:\n+                    self.vmax = 10.0\n+            else:\n+                super().autoscale_None(A)\n \n     def scaled(self):\n         \"\"\"Return whether vmin and vmax are set.\"\"\"\n@@ -1681,6 +1721,10 @@ def _make_norm_from_scale(\n \n         def __call__(self, value, clip=None):\n             value, is_scalar = self.process_value(value)\n+\n+            if self.vmin is not None and self.vmax is not None:\n+                # Skip autoscaling if both bounds are already set and valid\n+                return\n             if self.vmin is None or self.vmax is None:\n                 self.autoscale_None(value)\n             if self.vmin > self.vmax:\n@@ -1692,9 +1736,16 @@ def _make_norm_from_scale(\n             if clip:\n                 value = np.clip(value, self.vmin, self.vmax)\n             t_value = self._trf.transform(value).reshape(np.shape(value))\n+\n             t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n             if not np.isfinite([t_vmin, t_vmax]).all():\n-                raise ValueError(\"Invalid vmin or vmax\")\n+                # Reset to reasonable defaults for this transform type\n+                if hasattr(self._trf, 'inverted'):\n+                    # For LogTransform, use safe default range\n+                    self.vmin, self.vmax = 1.0, 10.0\n+                    t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n+                if not np.isfinite([t_vmin, t_vmax]).all():\n+                    raise ValueError(\"Invalid vmin or vmax\")\n             t_value -= t_vmin\n             t_value /= (t_vmax - t_vmin)\n             t_value = np.ma.masked_invalid(t_value, copy=False)\n@@ -1705,9 +1756,29 @@ def _make_norm_from_scale(\n                 raise ValueError(\"Not invertible until scaled\")\n             if self.vmin > self.vmax:\n                 raise ValueError(\"vmin must be less or equal to vmax\")\n-            t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n-            if not np.isfinite([t_vmin, t_vmax]).all():\n-                raise ValueError(\"Invalid vmin or vmax\")\n+\n+        def autoscale_None(self, A):\n+            # only autoscale if vmin or vmax are not set\n+            if self.vmin is not None and self.vmax is not None:\n+                return\n+            if A is not None:\n+                A = np.asarray(A)\n+                # Transform the data to the log domain for autoscaling\n+                with np.errstate(invalid='ignore', divide='ignore'):\n+                    A_transformed = self._trf.transform(A)\n+                # Filter out non-finite values after transformation\n+                A_transformed = A_transformed[np.isfinite(A_transformed)]\n+                \n+                # If no valid data remains after transformation, use reasonable defaults\n+                if A_transformed.size == 0:\n+                    if self.vmin is None:\n+                        self.vmin = 1.0\n+                    if self.vmax is None:\n+                        self.vmax = 10.0\n+                    return\n+                \n+                # Use the transformed data for autoscaling\n+                super().autoscale_None(A_transformed)\n             value, is_scalar = self.process_value(value)\n             rescaled = value * (t_vmax - t_vmin)\n             rescaled += t_vmin\n@@ -1717,12 +1788,25 @@ def _make_norm_from_scale(\n                      .reshape(np.shape(value)))\n             return value[0] if is_scalar else value\n \n-        def autoscale_None(self, A):\n-            # i.e. A[np.isfinite(...)], but also for non-array A's\n-            in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n-            if in_trf_domain.size == 0:\n+\n+def autoscale_None(self, A):\n+    # i.e. A[np.isfinite(...)], but also for non-array A's\n+    in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n+    if in_trf_domain.size == 0:\n+        # If no valid data exists in transform domain, check if vmin/vmax are already set\n+        if self.vmin is not None and self.vmax is not None:\n+            # Already have valid bounds, no need to autoscale\n+            return\n+        else:\n+            # Set reasonable default values for log scale\n+            if isinstance(self._trf, scale.LogTransform):\n+                self.vmin, self.vmax = 1.0, 10.0\n+            else:\n+                # For other transforms, use masked array as fallback\n                 in_trf_domain = np.ma.masked\n-            return super().autoscale_None(in_trf_domain)\n+                super().autoscale_None(in_trf_domain)\n+            return\n+    super().autoscale_None(in_trf_domain)\n \n     if base_norm_cls is Normalize:\n         Norm.__name__ = f\"{scale_cls.__name__}Norm\"\n",
    "variant_1": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex f9e4dcbd62..42d0a1f212 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -1365,13 +1365,44 @@ class Normalize:\n         self.vmin = self.vmax = None\n         self.autoscale_None(A)\n \n+\n     def autoscale_None(self, A):\n         \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n         A = np.asanyarray(A)\n-        if self.vmin is None and A.size:\n-            self.vmin = A.min()\n-        if self.vmax is None and A.size:\n-            self.vmax = A.max()\n+        if A.size == 0:\n+            return\n+        \n+        # For LogNorm, we need to filter out non-positive values before computing min/max\n+        if hasattr(self, '_transform') and hasattr(self._transform, 'transform_non_affine'):\n+            # Filter out values that would be invalid for the transform\n+            if A.dtype.kind in 'fc':  # float or complex\n+                valid_mask = A > 0\n+                if np.ma.is_masked(A):\n+                    valid_mask = valid_mask & ~A.mask\n+                if not np.any(valid_mask):\n+                    # No valid data for this transform, use reasonable defaults\n+                    if self.vmin is None:\n+                        self.vmin = 1.0\n+                    if self.vmax is None:\n+                        self.vmax = 10.0\n+                    return\n+                A_valid = A[valid_mask]\n+                if self.vmin is None and A_valid.size:\n+                    self.vmin = A_valid.min()\n+                if self.vmax is None and A_valid.size:\n+                    self.vmax = A_valid.max()\n+            else:\n+                # Fall back to standard behavior for non-numeric data\n+                if self.vmin is None and A.size:\n+                    self.vmin = A.min()\n+                if self.vmax is None and A.size:\n+                    self.vmax = A.max()\n+        else:\n+            # Standard autoscale behavior for non-transform normalizers\n+            if self.vmin is None and A.size:\n+                self.vmin = A.min()\n+            if self.vmax is None and A.size:\n+                self.vmax = A.max()\n \n     def scaled(self):\n         \"\"\"Return whether vmin and vmax are set.\"\"\"\n@@ -1681,8 +1712,37 @@ def _make_norm_from_scale(\n \n         def __call__(self, value, clip=None):\n             value, is_scalar = self.process_value(value)\n-            if self.vmin is None or self.vmax is None:\n-                self.autoscale_None(value)\n+\n+        def autoscale_None(self, A):\n+            # Guard against unnecessary autoscaling if bounds are already valid\n+            if (self.vmin is not None and self.vmax is not None and \n+                self.vmin > 0 and self.vmax > 0 and self.vmin <= self.vmax):\n+                return\n+            \n+            # For LogNorm, we need positive values only\n+            if A is not None:\n+                A = np.asarray(A)\n+                # Filter out non-positive values for log scale\n+                positive_mask = A > 0\n+                if np.ma.is_masked(A):\n+                    positive_mask = positive_mask & ~A.mask\n+                \n+                if np.any(positive_mask):\n+                    # Only autoscale if we have valid positive data\n+                    valid_data = A[positive_mask]\n+                    super().autoscale_None(valid_data)\n+                else:\n+                    # No valid data for log scale - set reasonable defaults\n+                    if self.vmin is None:\n+                        self.vmin = 1.0\n+                    if self.vmax is None:\n+                        self.vmax = 10.0\n+            else:\n+                # No data provided - set reasonable defaults for log scale\n+                if self.vmin is None:\n+                    self.vmin = 1.0\n+                if self.vmax is None:\n+                    self.vmax = 10.0\n             if self.vmin > self.vmax:\n                 raise ValueError(\"vmin must be less or equal to vmax\")\n             if self.vmin == self.vmax:\n@@ -1692,9 +1752,28 @@ def _make_norm_from_scale(\n             if clip:\n                 value = np.clip(value, self.vmin, self.vmax)\n             t_value = self._trf.transform(value).reshape(np.shape(value))\n-            t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n-            if not np.isfinite([t_vmin, t_vmax]).all():\n-                raise ValueError(\"Invalid vmin or vmax\")\n+\n+            def autoscale_None(self, A):\n+                # Only autoscale if vmin or vmax are not already set\n+                if self.vmin is not None and self.vmax is not None:\n+                    return\n+                \n+                # Apply transform and filter valid values\n+                A = np.asarray(A)\n+                A_transformed = self._trf.transform(A)\n+                valid_mask = np.isfinite(A_transformed) & (A_transformed > -np.inf)\n+                \n+                if not valid_mask.any():\n+                    # No valid data in transform domain - set reasonable defaults for LogNorm\n+                    if self.vmin is None:\n+                        self.vmin = 1.0\n+                    if self.vmax is None:\n+                        self.vmax = 10.0\n+                    return\n+                \n+                # Use only valid transformed data for autoscaling\n+                A_valid = A[valid_mask]\n+                super().autoscale_None(A_valid)\n             t_value -= t_vmin\n             t_value /= (t_vmax - t_vmin)\n             t_value = np.ma.masked_invalid(t_value, copy=False)\n@@ -1705,9 +1784,59 @@ def _make_norm_from_scale(\n                 raise ValueError(\"Not invertible until scaled\")\n             if self.vmin > self.vmax:\n                 raise ValueError(\"vmin must be less or equal to vmax\")\n-            t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n-            if not np.isfinite([t_vmin, t_vmax]).all():\n-                raise ValueError(\"Invalid vmin or vmax\")\n+\n+        def autoscale_None(self, A):\n+            \"\"\"\n+            Set *vmin*, *vmax* to min, max of *A*.\n+            \"\"\"\n+            A = np.asanyarray(A)\n+            if A.size == 0:\n+                return\n+            \n+            # Check if vmin and vmax are already set and valid\n+            if self.vmin is not None and self.vmax is not None:\n+                try:\n+                    t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n+                    if np.isfinite([t_vmin, t_vmax]).all() and t_vmin < t_vmax:\n+                        return  # Already have valid bounds, no need to autoscale\n+                except (ValueError, OverflowError):\n+                    pass  # Continue with autoscaling if current bounds are invalid\n+            \n+            # Apply transform to data for autoscaling\n+            with np.errstate(invalid='ignore', divide='ignore'):\n+                transformed = self._trf.transform(A)\n+            \n+            # Filter out non-finite values\n+            finite_mask = np.isfinite(transformed)\n+            if not np.any(finite_mask):\n+                # No valid data in transform domain, use reasonable defaults\n+                if isinstance(self, LogNorm):\n+                    # For LogNorm, use default range that works well\n+                    if self.vmin is None:\n+                        self.vmin = 1.0\n+                    if self.vmax is None:\n+                        self.vmax = 10.0\n+                return\n+            \n+            # Get valid transformed data\n+            valid_transformed = transformed[finite_mask]\n+            \n+            # Set vmin/vmax in original domain\n+            if self.vmin is None:\n+                try:\n+                    self.vmin = self._trf.inverted().transform(valid_transformed.min())\n+                    if not np.isfinite(self.vmin):\n+                        self.vmin = A[A > 0].min() if np.any(A > 0) else 1.0\n+                except (ValueError, OverflowError):\n+                    self.vmin = A[A > 0].min() if np.any(A > 0) else 1.0\n+            \n+            if self.vmax is None:\n+                try:\n+                    self.vmax = self._trf.inverted().transform(valid_transformed.max())\n+                    if not np.isfinite(self.vmax):\n+                        self.vmax = A.max() if A.size > 0 else 10.0\n+                except (ValueError, OverflowError):\n+                    self.vmax = A.max() if A.size > 0 else 10.0\n             value, is_scalar = self.process_value(value)\n             rescaled = value * (t_vmax - t_vmin)\n             rescaled += t_vmin\n@@ -1717,11 +1846,14 @@ def _make_norm_from_scale(\n                      .reshape(np.shape(value)))\n             return value[0] if is_scalar else value\n \n+\n         def autoscale_None(self, A):\n             # i.e. A[np.isfinite(...)], but also for non-array A's\n             in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n             if in_trf_domain.size == 0:\n-                in_trf_domain = np.ma.masked\n+                # If no valid data in transform domain, skip autoscaling\n+                # to avoid setting invalid vmin/vmax values\n+                return\n             return super().autoscale_None(in_trf_domain)\n \n     if base_norm_cls is Normalize:\n",
    "variant_2": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex f9e4dcbd62..ec00867239 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -1365,13 +1365,26 @@ class Normalize:\n         self.vmin = self.vmax = None\n         self.autoscale_None(A)\n \n+\n     def autoscale_None(self, A):\n         \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n         A = np.asanyarray(A)\n         if self.vmin is None and A.size:\n-            self.vmin = A.min()\n+            # For masked arrays, get the minimum of valid (unmasked) data\n+            if np.ma.is_masked(A):\n+                valid_data = A.compressed()\n+                if valid_data.size > 0:\n+                    self.vmin = valid_data.min()\n+            else:\n+                self.vmin = A.min()\n         if self.vmax is None and A.size:\n-            self.vmax = A.max()\n+            # For masked arrays, get the maximum of valid (unmasked) data\n+            if np.ma.is_masked(A):\n+                valid_data = A.compressed()\n+                if valid_data.size > 0:\n+                    self.vmax = valid_data.max()\n+            else:\n+                self.vmax = A.max()\n \n     def scaled(self):\n         \"\"\"Return whether vmin and vmax are set.\"\"\"\n@@ -1681,8 +1694,28 @@ def _make_norm_from_scale(\n \n         def __call__(self, value, clip=None):\n             value, is_scalar = self.process_value(value)\n-            if self.vmin is None or self.vmax is None:\n-                self.autoscale_None(value)\n+\n+        def autoscale_None(self, A):\n+            # Handle the case where all data is filtered out by the transform\n+            if A is not None:\n+                # Check if we have any valid data after transformation\n+                try:\n+                    # For LogNorm, we need positive values\n+                    valid_data = A[A > 0] if hasattr(A, '__getitem__') else A if A > 0 else None\n+                    if valid_data is not None and len(np.atleast_1d(valid_data)) > 0:\n+                        super().autoscale_None(valid_data)\n+                    elif self.vmin is None or self.vmax is None:\n+                        # No valid data for this transform, set reasonable defaults\n+                        if self.vmin is None:\n+                            self.vmin = 1.0\n+                        if self.vmax is None:\n+                            self.vmax = 10.0\n+                except (TypeError, IndexError, ValueError):\n+                    # Fallback for edge cases\n+                    if self.vmin is None:\n+                        self.vmin = 1.0\n+                    if self.vmax is None:\n+                        self.vmax = 10.0\n             if self.vmin > self.vmax:\n                 raise ValueError(\"vmin must be less or equal to vmax\")\n             if self.vmin == self.vmax:\n@@ -1692,9 +1725,37 @@ def _make_norm_from_scale(\n             if clip:\n                 value = np.clip(value, self.vmin, self.vmax)\n             t_value = self._trf.transform(value).reshape(np.shape(value))\n-            t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n-            if not np.isfinite([t_vmin, t_vmax]).all():\n-                raise ValueError(\"Invalid vmin or vmax\")\n+\n+            def autoscale_None(self, A):\n+                # Guard against autoscaling when vmin/vmax are already set and valid\n+                if (self.vmin is not None and self.vmax is not None and \n+                    self.vmin > 0 and self.vmax > 0 and self.vmin <= self.vmax):\n+                    return\n+                \n+                # Apply transform and filter out invalid values\n+                if A is not None:\n+                    A = np.asarray(A)\n+                    # For LogNorm, filter out non-positive values before transform\n+                    valid_mask = A > 0\n+                    if not np.any(valid_mask):\n+                        # No valid data for LogNorm, use reasonable defaults\n+                        if self.vmin is None:\n+                            self.vmin = 1.0\n+                        if self.vmax is None:\n+                            self.vmax = 10.0\n+                        return\n+                    \n+                    # Only use valid positive values for autoscaling\n+                    A_valid = A[valid_mask]\n+                    super().autoscale_None(A_valid)\n+                else:\n+                    super().autoscale_None(A)\n+                \n+                # Ensure vmin/vmax are valid for LogNorm after autoscaling\n+                if self.vmin is not None and self.vmin <= 0:\n+                    self.vmin = np.min([v for v in [1.0, self.vmax/1000] if v > 0])\n+                if self.vmax is not None and self.vmax <= 0:\n+                    self.vmax = max(10.0, self.vmin * 10 if self.vmin else 10.0)\n             t_value -= t_vmin\n             t_value /= (t_vmax - t_vmin)\n             t_value = np.ma.masked_invalid(t_value, copy=False)\n@@ -1705,9 +1766,37 @@ def _make_norm_from_scale(\n                 raise ValueError(\"Not invertible until scaled\")\n             if self.vmin > self.vmax:\n                 raise ValueError(\"vmin must be less or equal to vmax\")\n-            t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n-            if not np.isfinite([t_vmin, t_vmax]).all():\n-                raise ValueError(\"Invalid vmin or vmax\")\n+\n+        def autoscale_None(self, A):\n+            # only autoscale if vmin or vmax are not set\n+            if self.vmin is not None and self.vmax is not None:\n+                return\n+            val = np.ma.masked_invalid(A, copy=False).compressed()\n+            if len(val) > 0:\n+                # Transform the data to check for valid range in log space\n+                try:\n+                    transformed = self._trf.transform(val)\n+                    # Only proceed if we have valid transformed data\n+                    if len(transformed) > 0 and np.isfinite(transformed).any():\n+                        super().autoscale_None(A)\n+                    else:\n+                        # Fallback to reasonable defaults for LogNorm\n+                        if self.vmin is None:\n+                            self.vmin = 1.0\n+                        if self.vmax is None:\n+                            self.vmax = 10.0\n+                except (ValueError, ZeroDivisionError):\n+                    # Transform failed, use reasonable defaults for LogNorm\n+                    if self.vmin is None:\n+                        self.vmin = 1.0\n+                    if self.vmax is None:\n+                        self.vmax = 10.0\n+            else:\n+                # No valid data, use reasonable defaults for LogNorm\n+                if self.vmin is None:\n+                    self.vmin = 1.0\n+                if self.vmax is None:\n+                    self.vmax = 10.0\n             value, is_scalar = self.process_value(value)\n             rescaled = value * (t_vmax - t_vmin)\n             rescaled += t_vmin\n@@ -1717,11 +1806,14 @@ def _make_norm_from_scale(\n                      .reshape(np.shape(value)))\n             return value[0] if is_scalar else value\n \n+\n         def autoscale_None(self, A):\n             # i.e. A[np.isfinite(...)], but also for non-array A's\n             in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n             if in_trf_domain.size == 0:\n-                in_trf_domain = np.ma.masked\n+                # If no valid data exists in transform domain, skip autoscaling\n+                # to avoid setting invalid vmin/vmax values\n+                return\n             return super().autoscale_None(in_trf_domain)\n \n     if base_norm_cls is Normalize:\n",
    "variant_3": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex f9e4dcbd62..aa2f777886 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -1365,13 +1365,30 @@ class Normalize:\n         self.vmin = self.vmax = None\n         self.autoscale_None(A)\n \n+\n     def autoscale_None(self, A):\n         \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n         A = np.asanyarray(A)\n         if self.vmin is None and A.size:\n-            self.vmin = A.min()\n+            # For LogNorm, ensure we only consider positive values\n+            if hasattr(self, '_transform') and hasattr(self._transform, 'transform_non_affine'):\n+                # This is a scale-specific norm, filter data appropriately\n+                valid_mask = A > 0 if hasattr(self._transform, 'base') else np.ones(A.shape, dtype=bool)\n+                valid_data = A[valid_mask]\n+                if valid_data.size > 0:\n+                    self.vmin = valid_data.min()\n+                # If no valid data, leave vmin as None to avoid invalid state\n+            else:\n+                self.vmin = A.min()\n         if self.vmax is None and A.size:\n-            self.vmax = A.max()\n+            if hasattr(self, '_transform') and hasattr(self._transform, 'transform_non_affine'):\n+                valid_mask = A > 0 if hasattr(self._transform, 'base') else np.ones(A.shape, dtype=bool)\n+                valid_data = A[valid_mask]\n+                if valid_data.size > 0:\n+                    self.vmax = valid_data.max()\n+                # If no valid data, leave vmax as None to avoid invalid state\n+            else:\n+                self.vmax = A.max()\n \n     def scaled(self):\n         \"\"\"Return whether vmin and vmax are set.\"\"\"\n@@ -1681,8 +1698,54 @@ def _make_norm_from_scale(\n \n         def __call__(self, value, clip=None):\n             value, is_scalar = self.process_value(value)\n-            if self.vmin is None or self.vmax is None:\n-                self.autoscale_None(value)\n+\n+        def autoscale_None(self, A):\n+            # Prevent autoscaling when vmin/vmax are already explicitly set\n+            if self.vmin is not None and self.vmax is not None:\n+                return\n+                \n+            # Handle the case where A might be filtered/masked for this scale\n+            A = np.asarray(A)\n+            if A.size == 0:\n+                # No data to autoscale from, use reasonable defaults for this scale\n+                if self.vmin is None:\n+                    self.vmin = 1.0\n+                if self.vmax is None:\n+                    self.vmax = 10.0\n+                return\n+                \n+            # Apply scale transform to get valid range for autoscaling\n+            try:\n+                A_transformed = self._trf.transform(A)\n+                # Filter out invalid transformed values (inf, -inf, nan)\n+                valid_mask = np.isfinite(A_transformed)\n+                if not np.any(valid_mask):\n+                    # No valid transformed values, use defaults\n+                    if self.vmin is None:\n+                        self.vmin = 1.0\n+                    if self.vmax is None:\n+                        self.vmax = 10.0\n+                    return\n+                    \n+                # Use only valid transformed data for autoscaling\n+                A_valid = A[valid_mask] if valid_mask.ndim > 0 else A\n+                super().autoscale_None(A_valid)\n+                \n+                # Validate the resulting vmin/vmax are appropriate for this scale\n+                if self.vmin is not None and self.vmax is not None:\n+                    try:\n+                        self._trf.transform([self.vmin, self.vmax])\n+                    except (ValueError, OverflowError):\n+                        # Reset to safe defaults if transform fails\n+                        self.vmin = 1.0\n+                        self.vmax = 10.0\n+                        \n+            except (ValueError, OverflowError):\n+                # Transform failed entirely, use safe defaults\n+                if self.vmin is None:\n+                    self.vmin = 1.0\n+                if self.vmax is None:\n+                    self.vmax = 10.0\n             if self.vmin > self.vmax:\n                 raise ValueError(\"vmin must be less or equal to vmax\")\n             if self.vmin == self.vmax:\n@@ -1692,9 +1755,39 @@ def _make_norm_from_scale(\n             if clip:\n                 value = np.clip(value, self.vmin, self.vmax)\n             t_value = self._trf.transform(value).reshape(np.shape(value))\n-            t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n-            if not np.isfinite([t_vmin, t_vmax]).all():\n-                raise ValueError(\"Invalid vmin or vmax\")\n+\n+            def autoscale_None(self, A):\n+                # guard against calling autoscale_None multiple times before\n+                # the transform has been set up\n+                if not self._transform_set:\n+                    return\n+                    \n+                # If vmin and vmax are already set and valid, don't autoscale\n+                if self.vmin is not None and self.vmax is not None:\n+                    try:\n+                        t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n+                        if np.isfinite([t_vmin, t_vmax]).all():\n+                            return\n+                    except (ValueError, TypeError):\n+                        pass  # Continue with autoscaling if current values are invalid\n+                \n+                # Apply transform and filter valid data\n+                A_transformed = self._trf.transform(A)\n+                valid_mask = np.isfinite(A_transformed)\n+                \n+                # If no valid data after transform, use reasonable defaults for LogNorm\n+                if not np.any(valid_mask):\n+                    if self.vmin is None:\n+                        self.vmin = 1.0\n+                    if self.vmax is None:\n+                        self.vmax = 10.0\n+                    return\n+                \n+                # Extract valid transformed data\n+                valid_data = A_transformed[valid_mask]\n+                \n+                # Call parent autoscale with valid data only\n+                super().autoscale_None(valid_data)\n             t_value -= t_vmin\n             t_value /= (t_vmax - t_vmin)\n             t_value = np.ma.masked_invalid(t_value, copy=False)\n@@ -1705,9 +1798,31 @@ def _make_norm_from_scale(\n                 raise ValueError(\"Not invertible until scaled\")\n             if self.vmin > self.vmax:\n                 raise ValueError(\"vmin must be less or equal to vmax\")\n-            t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n-            if not np.isfinite([t_vmin, t_vmax]).all():\n-                raise ValueError(\"Invalid vmin or vmax\")\n+\n+        def autoscale_None(self, A):\n+            # only autoscale if vmin or vmax are not set\n+            if self.vmin is not None and self.vmax is not None:\n+                return\n+            if A is not None:\n+                # Transform to avoid issues with zero/negative values for log scale\n+                A = np.asanyarray(A)\n+                # Filter out non-positive values for log scale\n+                if hasattr(self._trf, 'transform'):\n+                    # Only consider positive values for log transforms\n+                    if hasattr(self._trf, '_transform_non_affine'):\n+                        # This is likely a log transform, filter positive values\n+                        valid_mask = A > 0\n+                        if np.any(valid_mask):\n+                            A_filtered = A[valid_mask]\n+                        else:\n+                            # No valid data for log scale, use reasonable defaults\n+                            if self.vmin is None:\n+                                self.vmin = 1.0\n+                            if self.vmax is None:\n+                                self.vmax = 10.0\n+                            return\n+                        A = A_filtered\n+            super().autoscale_None(A)\n             value, is_scalar = self.process_value(value)\n             rescaled = value * (t_vmax - t_vmin)\n             rescaled += t_vmin\n@@ -1717,11 +1832,14 @@ def _make_norm_from_scale(\n                      .reshape(np.shape(value)))\n             return value[0] if is_scalar else value\n \n+\n         def autoscale_None(self, A):\n             # i.e. A[np.isfinite(...)], but also for non-array A's\n             in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n             if in_trf_domain.size == 0:\n-                in_trf_domain = np.ma.masked\n+                # If no valid data exists in transform domain, skip autoscaling\n+                # to avoid setting invalid vmin/vmax that would cause validation errors\n+                return\n             return super().autoscale_None(in_trf_domain)\n \n     if base_norm_cls is Normalize:\n",
    "variant_4": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex f9e4dcbd62..0fb8e6f3e3 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -1365,13 +1365,32 @@ class Normalize:\n         self.vmin = self.vmax = None\n         self.autoscale_None(A)\n \n+\n     def autoscale_None(self, A):\n         \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n         A = np.asanyarray(A)\n-        if self.vmin is None and A.size:\n-            self.vmin = A.min()\n-        if self.vmax is None and A.size:\n-            self.vmax = A.max()\n+        if A.size == 0:\n+            return\n+        \n+        # For log scale, we need to filter out non-positive values\n+        if hasattr(self, '_transform') and hasattr(self._transform, 'transform_non_affine'):\n+            # This is likely a log-scale norm, filter out invalid values\n+            valid_mask = A > 0\n+            if np.ma.is_masked(A):\n+                valid_mask = valid_mask & ~A.mask\n+            \n+            if not np.any(valid_mask):\n+                # No valid data for log scale, skip autoscaling\n+                return\n+            \n+            valid_A = A[valid_mask] if np.any(valid_mask) else A\n+        else:\n+            valid_A = A\n+            \n+        if self.vmin is None and valid_A.size:\n+            self.vmin = valid_A.min()\n+        if self.vmax is None and valid_A.size:\n+            self.vmax = valid_A.max()\n \n     def scaled(self):\n         \"\"\"Return whether vmin and vmax are set.\"\"\"\n@@ -1681,8 +1700,25 @@ def _make_norm_from_scale(\n \n         def __call__(self, value, clip=None):\n             value, is_scalar = self.process_value(value)\n-            if self.vmin is None or self.vmax is None:\n-                self.autoscale_None(value)\n+\n+        def autoscale_None(self, A):\n+            # Get the valid (unmasked) values in the scale's domain\n+            A = np.asarray(A)\n+            valid_mask = (A > 0) if hasattr(self._scale, 'get_transform') else np.ones(A.shape, dtype=bool)\n+            if np.ma.is_masked(A):\n+                valid_mask = valid_mask & ~np.ma.getmaskarray(A)\n+            \n+            if not np.any(valid_mask):\n+                # No valid data for this scale - use reasonable defaults if not already set\n+                if self.vmin is None:\n+                    self.vmin = 1.0 if hasattr(self._scale, 'get_transform') and 'log' in str(type(self._scale)).lower() else 0.0\n+                if self.vmax is None:\n+                    self.vmax = 10.0 if hasattr(self._scale, 'get_transform') and 'log' in str(type(self._scale)).lower() else 1.0\n+                return\n+            \n+            # Extract valid values for autoscaling\n+            valid_values = A[valid_mask]\n+            super().autoscale_None(valid_values)\n             if self.vmin > self.vmax:\n                 raise ValueError(\"vmin must be less or equal to vmax\")\n             if self.vmin == self.vmax:\n@@ -1692,9 +1728,35 @@ def _make_norm_from_scale(\n             if clip:\n                 value = np.clip(value, self.vmin, self.vmax)\n             t_value = self._trf.transform(value).reshape(np.shape(value))\n-            t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n-            if not np.isfinite([t_vmin, t_vmax]).all():\n-                raise ValueError(\"Invalid vmin or vmax\")\n+\n+            def autoscale_None(self, A):\n+                # First check if we already have valid bounds\n+                if self.vmin is not None and self.vmax is not None:\n+                    try:\n+                        t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n+                        if np.isfinite([t_vmin, t_vmax]).all() and t_vmin < t_vmax:\n+                            return  # Already have valid bounds, no need to autoscale\n+                    except (ValueError, OverflowError):\n+                        pass  # Current bounds are invalid, proceed with autoscaling\n+                \n+                # Apply transform and filter valid values\n+                A = np.asarray(A)\n+                if A.size == 0:\n+                    return\n+                \n+                # Get valid values in transform domain\n+                valid_mask = np.isfinite(A) & (A > 0)\n+                if not valid_mask.any():\n+                    # No valid data for log transform, set reasonable defaults\n+                    if self.vmin is None:\n+                        self.vmin = 1.0\n+                    if self.vmax is None:\n+                        self.vmax = 10.0\n+                    return\n+                \n+                # Use only valid values for autoscaling\n+                valid_A = A[valid_mask]\n+                super().autoscale_None(valid_A)\n             t_value -= t_vmin\n             t_value /= (t_vmax - t_vmin)\n             t_value = np.ma.masked_invalid(t_value, copy=False)\n@@ -1705,9 +1767,44 @@ def _make_norm_from_scale(\n                 raise ValueError(\"Not invertible until scaled\")\n             if self.vmin > self.vmax:\n                 raise ValueError(\"vmin must be less or equal to vmax\")\n-            t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n-            if not np.isfinite([t_vmin, t_vmax]).all():\n-                raise ValueError(\"Invalid vmin or vmax\")\n+\n+        def autoscale_None(self, A):\n+            # only autoscale if vmin or vmax are not set\n+            if self.vmin is not None and self.vmax is not None:\n+                return\n+            A = np.asanyarray(A)\n+            if A.size == 0:\n+                return\n+            # Transform the data to handle the scale appropriately\n+            with np.errstate(invalid='ignore', divide='ignore'):\n+                transformed_A = self._trf.transform(A)\n+            # Check if we have any valid transformed data\n+            valid_mask = np.isfinite(transformed_A)\n+            if not np.any(valid_mask):\n+                # No valid data in transform domain, use reasonable defaults\n+                if self.vmin is None:\n+                    self.vmin = 1.0\n+                if self.vmax is None:\n+                    self.vmax = 10.0\n+                return\n+            # Use only valid transformed data for autoscaling\n+            valid_transformed = transformed_A[valid_mask]\n+            # Create a temporary array for the base class autoscale\n+            temp_A = np.ma.masked_invalid(valid_transformed, copy=False)\n+            super().autoscale_None(temp_A)\n+            # Transform the computed bounds back to original space\n+            if self.vmin is not None and self.vmax is not None:\n+                try:\n+                    t_vmin, t_vmax = self.vmin, self.vmax\n+                    orig_bounds = self._trf.inverted().transform([t_vmin, t_vmax])\n+                    if np.isfinite(orig_bounds).all():\n+                        self.vmin, self.vmax = orig_bounds\n+                    else:\n+                        # Fallback to reasonable defaults if inverse transform fails\n+                        self.vmin, self.vmax = 1.0, 10.0\n+                except (ValueError, OverflowError):\n+                    # Fallback to reasonable defaults if transform fails\n+                    self.vmin, self.vmax = 1.0, 10.0\n             value, is_scalar = self.process_value(value)\n             rescaled = value * (t_vmax - t_vmin)\n             rescaled += t_vmin\n@@ -1717,11 +1814,20 @@ def _make_norm_from_scale(\n                      .reshape(np.shape(value)))\n             return value[0] if is_scalar else value\n \n+\n         def autoscale_None(self, A):\n             # i.e. A[np.isfinite(...)], but also for non-array A's\n             in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n             if in_trf_domain.size == 0:\n-                in_trf_domain = np.ma.masked\n+                # If no valid data in transform domain, skip autoscaling if bounds are already set\n+                if self.vmin is not None and self.vmax is not None:\n+                    return\n+                # Otherwise set reasonable defaults for the scale type\n+                if hasattr(self._trf, '_base') and self._trf._base == 10:  # LogScale\n+                    self.vmin, self.vmax = 1.0, 10.0\n+                else:\n+                    self.vmin, self.vmax = 0.0, 1.0\n+                return\n             return super().autoscale_None(in_trf_domain)\n \n     if base_norm_cls is Normalize:\n",
    "variant_5": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex f9e4dcbd62..a56bb0e49e 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -1365,13 +1365,26 @@ class Normalize:\n         self.vmin = self.vmax = None\n         self.autoscale_None(A)\n \n+\n     def autoscale_None(self, A):\n         \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n         A = np.asanyarray(A)\n         if self.vmin is None and A.size:\n-            self.vmin = A.min()\n+            # For masked arrays, use compressed() to get only valid values\n+            if np.ma.is_masked(A):\n+                valid_data = A.compressed()\n+                if valid_data.size > 0:\n+                    self.vmin = valid_data.min()\n+            else:\n+                self.vmin = A.min()\n         if self.vmax is None and A.size:\n-            self.vmax = A.max()\n+            # For masked arrays, use compressed() to get only valid values\n+            if np.ma.is_masked(A):\n+                valid_data = A.compressed()\n+                if valid_data.size > 0:\n+                    self.vmax = valid_data.max()\n+            else:\n+                self.vmax = A.max()\n \n     def scaled(self):\n         \"\"\"Return whether vmin and vmax are set.\"\"\"\n@@ -1681,8 +1694,37 @@ def _make_norm_from_scale(\n \n         def __call__(self, value, clip=None):\n             value, is_scalar = self.process_value(value)\n-            if self.vmin is None or self.vmax is None:\n-                self.autoscale_None(value)\n+\n+        def autoscale_None(self, A):\n+            # First check if we already have valid bounds\n+            if (self.vmin is not None and self.vmax is not None and \n+                self.vmin > 0 and self.vmax > 0 and self.vmin <= self.vmax):\n+                return\n+            \n+            # Apply the transform to filter valid data\n+            A = np.asarray(A)\n+            if A.size == 0:\n+                return\n+            \n+            # Get valid data in transform domain\n+            valid_data = A[np.isfinite(A) & (A > 0)]\n+            \n+            # If no valid data for log transform, set reasonable defaults\n+            if valid_data.size == 0:\n+                if self.vmin is None:\n+                    self.vmin = 1.0\n+                if self.vmax is None:\n+                    self.vmax = 10.0\n+                return\n+            \n+            # Use valid data for autoscaling\n+            super().autoscale_None(valid_data)\n+            \n+            # Ensure bounds are valid for log scale\n+            if self.vmin is not None and self.vmin <= 0:\n+                self.vmin = np.min(valid_data[valid_data > 0]) if valid_data.size > 0 else 1.0\n+            if self.vmax is not None and self.vmax <= 0:\n+                self.vmax = np.max(valid_data) if valid_data.size > 0 else 10.0\n             if self.vmin > self.vmax:\n                 raise ValueError(\"vmin must be less or equal to vmax\")\n             if self.vmin == self.vmax:\n@@ -1692,9 +1734,49 @@ def _make_norm_from_scale(\n             if clip:\n                 value = np.clip(value, self.vmin, self.vmax)\n             t_value = self._trf.transform(value).reshape(np.shape(value))\n-            t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n-            if not np.isfinite([t_vmin, t_vmax]).all():\n-                raise ValueError(\"Invalid vmin or vmax\")\n+\n+            def autoscale_None(self, A):\n+                # Guard against unnecessary autoscaling when vmin/vmax already set\n+                if self.vmin is not None and self.vmax is not None:\n+                    try:\n+                        # Validate current vmin/vmax are appropriate for this transform\n+                        t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n+                        if np.isfinite([t_vmin, t_vmax]).all():\n+                            return  # Current bounds are valid, no autoscaling needed\n+                    except (ValueError, OverflowError):\n+                        pass  # Current bounds invalid, proceed with autoscaling\n+                \n+                # Apply transform and filter valid data\n+                A = np.asarray(A)\n+                if A.size == 0:\n+                    return\n+                \n+                # Transform the data and get valid (finite, positive for log) values\n+                try:\n+                    with np.errstate(invalid='ignore', divide='ignore'):\n+                        transformed_A = self._trf.transform(A)\n+                    valid_mask = np.isfinite(transformed_A)\n+                    if hasattr(A, 'mask'):\n+                        valid_mask = valid_mask & ~A.mask\n+                    \n+                    if not np.any(valid_mask):\n+                        # No valid data - use reasonable defaults for LogNorm\n+                        if self.vmin is None:\n+                            self.vmin = 1.0\n+                        if self.vmax is None:\n+                            self.vmax = 10.0\n+                        return\n+                    \n+                    # Use only valid data for autoscaling\n+                    valid_data = A[valid_mask] if valid_mask.ndim > 0 else A\n+                    super().autoscale_None(valid_data)\n+                    \n+                except (ValueError, OverflowError):\n+                    # Fallback to reasonable defaults if transform fails\n+                    if self.vmin is None:\n+                        self.vmin = 1.0\n+                    if self.vmax is None:\n+                        self.vmax = 10.0\n             t_value -= t_vmin\n             t_value /= (t_vmax - t_vmin)\n             t_value = np.ma.masked_invalid(t_value, copy=False)\n@@ -1705,9 +1787,38 @@ def _make_norm_from_scale(\n                 raise ValueError(\"Not invertible until scaled\")\n             if self.vmin > self.vmax:\n                 raise ValueError(\"vmin must be less or equal to vmax\")\n-            t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n-            if not np.isfinite([t_vmin, t_vmax]).all():\n-                raise ValueError(\"Invalid vmin or vmax\")\n+\n+        def autoscale_None(self, A):\n+            # Avoid autoscaling if vmin/vmax are already set and valid\n+            if self.vmin is not None and self.vmax is not None:\n+                try:\n+                    # Check if current bounds are valid for this transform\n+                    t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n+                    if np.isfinite([t_vmin, t_vmax]).all() and t_vmin < t_vmax:\n+                        return\n+                except (ValueError, OverflowError):\n+                    # Current bounds are invalid, proceed with autoscaling\n+                    pass\n+            \n+            # Only autoscale using positive values for LogNorm\n+            if A is not None:\n+                # Filter out non-positive values for log transform\n+                A_positive = np.ma.masked_where(A <= 0, A, copy=False)\n+                if A_positive.count() > 0:\n+                    # Use positive values for autoscaling\n+                    super().autoscale_None(A_positive)\n+                else:\n+                    # No positive values available, set reasonable defaults for LogNorm\n+                    if self.vmin is None:\n+                        self.vmin = 1.0\n+                    if self.vmax is None:\n+                        self.vmax = 10.0\n+            else:\n+                # A is None, set reasonable defaults if not already set\n+                if self.vmin is None:\n+                    self.vmin = 1.0\n+                if self.vmax is None:\n+                    self.vmax = 10.0\n             value, is_scalar = self.process_value(value)\n             rescaled = value * (t_vmax - t_vmin)\n             rescaled += t_vmin\n@@ -1717,11 +1828,14 @@ def _make_norm_from_scale(\n                      .reshape(np.shape(value)))\n             return value[0] if is_scalar else value\n \n+\n         def autoscale_None(self, A):\n             # i.e. A[np.isfinite(...)], but also for non-array A's\n             in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n             if in_trf_domain.size == 0:\n-                in_trf_domain = np.ma.masked\n+                # If no valid data in transform domain, don't autoscale\n+                # This prevents invalid vmin/vmax from being set\n+                return\n             return super().autoscale_None(in_trf_domain)\n \n     if base_norm_cls is Normalize:\n",
    "variant_6": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex f9e4dcbd62..066ce720f3 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -1365,13 +1365,34 @@ class Normalize:\n         self.vmin = self.vmax = None\n         self.autoscale_None(A)\n \n+\n     def autoscale_None(self, A):\n         \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n         A = np.asanyarray(A)\n-        if self.vmin is None and A.size:\n-            self.vmin = A.min()\n-        if self.vmax is None and A.size:\n-            self.vmax = A.max()\n+        if A.size == 0:\n+            return  # No data to autoscale from\n+        \n+        # For LogNorm, we need to filter out invalid values before computing min/max\n+        if hasattr(self, 'transform') and hasattr(self.transform, 'transform_non_affine'):\n+            # This is likely a scale-based norm, filter data appropriately\n+            valid_mask = np.isfinite(A) & (A > 0)\n+            if hasattr(A, 'mask'):\n+                valid_mask = valid_mask & ~A.mask\n+            if not np.any(valid_mask):\n+                # No valid data for this transform, use reasonable defaults\n+                if self.vmin is None:\n+                    self.vmin = 1.0 if not hasattr(self, 'vmin') or self.vmin is None else self.vmin\n+                if self.vmax is None:\n+                    self.vmax = 10.0 if not hasattr(self, 'vmax') or self.vmax is None else self.vmax\n+                return\n+            A_filtered = A[valid_mask]\n+        else:\n+            A_filtered = A\n+            \n+        if self.vmin is None and A_filtered.size:\n+            self.vmin = A_filtered.min()\n+        if self.vmax is None and A_filtered.size:\n+            self.vmax = A_filtered.max()\n \n     def scaled(self):\n         \"\"\"Return whether vmin and vmax are set.\"\"\"\n@@ -1681,8 +1702,35 @@ def _make_norm_from_scale(\n \n         def __call__(self, value, clip=None):\n             value, is_scalar = self.process_value(value)\n-            if self.vmin is None or self.vmax is None:\n-                self.autoscale_None(value)\n+\n+        def autoscale_None(self, A):\n+            # Store current vmin/vmax to check if they're already valid\n+            current_vmin, current_vmax = self.vmin, self.vmax\n+            \n+            # If both vmin and vmax are already set and valid, skip autoscaling\n+            if (current_vmin is not None and current_vmax is not None and \n+                current_vmin > 0 and current_vmax > 0 and current_vmin <= current_vmax):\n+                return\n+            \n+            # Transform the data to the scale domain for autoscaling\n+            A_scaled = self._trf.transform_non_affine(A)\n+            \n+            # Check if we have any valid (non-masked, finite) data after transform\n+            if np.ma.is_masked(A_scaled):\n+                valid_data = A_scaled.compressed()\n+            else:\n+                valid_data = A_scaled[np.isfinite(A_scaled)]\n+            \n+            # If no valid data exists after transformation, use fallback values\n+            if len(valid_data) == 0:\n+                if self.vmin is None:\n+                    self.vmin = 1.0  # Safe default for log scale\n+                if self.vmax is None:\n+                    self.vmax = 10.0  # Safe default for log scale\n+                return\n+            \n+            # Call the base autoscale_None with the transformed data\n+            super().autoscale_None(A_scaled)\n             if self.vmin > self.vmax:\n                 raise ValueError(\"vmin must be less or equal to vmax\")\n             if self.vmin == self.vmax:\n@@ -1692,9 +1740,35 @@ def _make_norm_from_scale(\n             if clip:\n                 value = np.clip(value, self.vmin, self.vmax)\n             t_value = self._trf.transform(value).reshape(np.shape(value))\n-            t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n-            if not np.isfinite([t_vmin, t_vmax]).all():\n-                raise ValueError(\"Invalid vmin or vmax\")\n+\n+            def autoscale_None(self, A):\n+                # Only autoscale if vmin or vmax are not set\n+                if self.vmin is not None and self.vmax is not None:\n+                    return\n+                \n+                # Apply the transform to get valid data for scaling\n+                if A is not None:\n+                    A = np.asarray(A)\n+                    # Apply transform and get valid (finite, positive) values\n+                    with np.errstate(invalid='ignore', divide='ignore'):\n+                        transformed = self._trf.transform(A)\n+                    # Only use finite values for scaling\n+                    valid_mask = np.isfinite(transformed)\n+                    if np.any(valid_mask):\n+                        valid_transformed = transformed[valid_mask]\n+                        # Convert back to original domain for setting vmin/vmax\n+                        if self.vmin is None and len(valid_transformed) > 0:\n+                            t_min = np.min(valid_transformed)\n+                            self.vmin = self._trf.inverted().transform(t_min)\n+                        if self.vmax is None and len(valid_transformed) > 0:\n+                            t_max = np.max(valid_transformed)\n+                            self.vmax = self._trf.inverted().transform(t_max)\n+                    else:\n+                        # No valid data - set reasonable defaults for this transform\n+                        if self.vmin is None:\n+                            self.vmin = 1.0 if hasattr(self._trf, 'transform') else 0.0\n+                        if self.vmax is None:\n+                            self.vmax = 10.0 if hasattr(self._trf, 'transform') else 1.0\n             t_value -= t_vmin\n             t_value /= (t_vmax - t_vmin)\n             t_value = np.ma.masked_invalid(t_value, copy=False)\n@@ -1705,9 +1779,64 @@ def _make_norm_from_scale(\n                 raise ValueError(\"Not invertible until scaled\")\n             if self.vmin > self.vmax:\n                 raise ValueError(\"vmin must be less or equal to vmax\")\n-            t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n-            if not np.isfinite([t_vmin, t_vmax]).all():\n-                raise ValueError(\"Invalid vmin or vmax\")\n+\n+        def autoscale_None(self, A):\n+            \"\"\"\n+            Autoscale only None-valued vmin or vmax.\n+            \"\"\"\n+            if self.vmin is not None and self.vmax is not None:\n+                return\n+            if A is not None:\n+                # Transform to the scaled space for min/max calculation\n+                A = np.asarray(A)\n+                # Only process finite values\n+                A_finite = A[np.isfinite(A)]\n+                if A_finite.size == 0:\n+                    # No finite data available, use reasonable defaults for LogNorm\n+                    if self.vmin is None:\n+                        self.vmin = 1.0\n+                    if self.vmax is None:\n+                        self.vmax = 10.0\n+                    return\n+                \n+                # Filter out values that are invalid for the transform\n+                # For LogNorm, we need positive values\n+                if hasattr(self._trf, 'transform'):\n+                    # Check if transform can handle the data\n+                    try:\n+                        # Test transform with a small sample to avoid full computation\n+                        test_vals = A_finite[:min(10, len(A_finite))]\n+                        transformed_test = self._trf.transform(test_vals)\n+                        if not np.isfinite(transformed_test).any():\n+                            # Transform produces no finite values, use defaults\n+                            if self.vmin is None:\n+                                self.vmin = 1.0\n+                            if self.vmax is None:\n+                                self.vmax = 10.0\n+                            return\n+                    except (ValueError, RuntimeWarning):\n+                        # Transform failed, use defaults\n+                        if self.vmin is None:\n+                            self.vmin = 1.0\n+                        if self.vmax is None:\n+                            self.vmax = 10.0\n+                        return\n+                \n+                # Proceed with normal autoscaling using valid data\n+                super().autoscale_None(A_finite)\n+                \n+                # Ensure the resulting vmin/vmax are valid for this transform\n+                if self.vmin is not None and self.vmax is not None:\n+                    try:\n+                        t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n+                        if not np.isfinite([t_vmin, t_vmax]).all():\n+                            # Reset to safe defaults if transform produces invalid results\n+                            self.vmin = 1.0\n+                            self.vmax = 10.0\n+                    except (ValueError, RuntimeWarning):\n+                        # Reset to safe defaults if transform fails\n+                        self.vmin = 1.0\n+                        self.vmax = 10.0\n             value, is_scalar = self.process_value(value)\n             rescaled = value * (t_vmax - t_vmin)\n             rescaled += t_vmin\n@@ -1717,11 +1846,14 @@ def _make_norm_from_scale(\n                      .reshape(np.shape(value)))\n             return value[0] if is_scalar else value\n \n+\n         def autoscale_None(self, A):\n             # i.e. A[np.isfinite(...)], but also for non-array A's\n             in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n             if in_trf_domain.size == 0:\n-                in_trf_domain = np.ma.masked\n+                # If no valid data in transform domain, skip autoscaling\n+                # to avoid setting invalid vmin/vmax that would cause validation errors\n+                return\n             return super().autoscale_None(in_trf_domain)\n \n     if base_norm_cls is Normalize:\n",
    "variant_7": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex f9e4dcbd62..19c65b9f74 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -1365,9 +1365,32 @@ class Normalize:\n         self.vmin = self.vmax = None\n         self.autoscale_None(A)\n \n-    def autoscale_None(self, A):\n-        \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n-        A = np.asanyarray(A)\n+\n+def autoscale_None(self, A):\n+    \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n+    A = np.asanyarray(A)\n+    if A.size == 0:\n+        return\n+    \n+    # For LogNorm, we need to work with positive values only\n+    if hasattr(self, '_transform') and hasattr(self._transform, 'transform_non_affine'):\n+        # Filter out non-positive values for log transform\n+        if np.ma.is_masked(A):\n+            valid_mask = (A.data > 0) & ~A.mask\n+            if not np.any(valid_mask):\n+                return  # No valid data for log transform\n+            valid_A = A.data[valid_mask]\n+        else:\n+            valid_A = A[A > 0]\n+            if valid_A.size == 0:\n+                return  # No valid data for log transform\n+        \n+        if self.vmin is None:\n+            self.vmin = valid_A.min()\n+        if self.vmax is None:\n+            self.vmax = valid_A.max()\n+    else:\n+        # Use original logic for other normalizations\n         if self.vmin is None and A.size:\n             self.vmin = A.min()\n         if self.vmax is None and A.size:\n@@ -1681,8 +1704,28 @@ def _make_norm_from_scale(\n \n         def __call__(self, value, clip=None):\n             value, is_scalar = self.process_value(value)\n-            if self.vmin is None or self.vmax is None:\n-                self.autoscale_None(value)\n+\n+        def autoscale_None(self, A):\n+            # Transform to the scale's domain for autoscaling, but handle edge cases\n+            A = np.asarray(A)\n+            if A.size == 0:\n+                return\n+            \n+            # Apply the transform and check for valid results\n+            transformed = self._trf.transform_non_affine(A)\n+            \n+            # Filter out invalid values (inf, nan, negative for log scales)\n+            valid_mask = np.isfinite(transformed)\n+            if not np.any(valid_mask):\n+                # No valid data after transformation - use sensible defaults for LogNorm\n+                if self.vmin is None:\n+                    self.vmin = 1.0\n+                if self.vmax is None:\n+                    self.vmax = 10.0\n+                return\n+            \n+            valid_transformed = transformed[valid_mask]\n+            super().autoscale_None(valid_transformed)\n             if self.vmin > self.vmax:\n                 raise ValueError(\"vmin must be less or equal to vmax\")\n             if self.vmin == self.vmax:\n@@ -1692,9 +1735,63 @@ def _make_norm_from_scale(\n             if clip:\n                 value = np.clip(value, self.vmin, self.vmax)\n             t_value = self._trf.transform(value).reshape(np.shape(value))\n-            t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n-            if not np.isfinite([t_vmin, t_vmax]).all():\n-                raise ValueError(\"Invalid vmin or vmax\")\n+\n+            def autoscale_None(self, A):\n+                # Prevent autoscaling when vmin and vmax are already set and valid\n+                if self.vmin is not None and self.vmax is not None:\n+                    try:\n+                        t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n+                        if np.isfinite([t_vmin, t_vmax]).all():\n+                            return  # Skip autoscaling if current bounds are valid\n+                    except (ValueError, OverflowError):\n+                        pass  # Continue with autoscaling if current bounds are invalid\n+                \n+                # Apply transform and filter out invalid values\n+                A = np.asarray(A)\n+                if A.size == 0:\n+                    return\n+                \n+                # Transform the data and check for valid values\n+                try:\n+                    transformed_A = self._trf.transform(A.ravel())\n+                    valid_mask = np.isfinite(transformed_A)\n+                    \n+                    if not valid_mask.any():\n+                        # No valid data in transform domain, use reasonable defaults for LogNorm\n+                        if name == 'log':\n+                            self.vmin = 1.0\n+                            self.vmax = 10.0\n+                        else:\n+                            # For other transforms, fall back to base behavior with original data\n+                            super(Normalize, self).autoscale_None(A)\n+                        return\n+                    \n+                    # Create filtered array with only valid transformed values\n+                    valid_transformed = transformed_A[valid_mask]\n+                    \n+                    # Inverse transform back to original domain for vmin/vmax\n+                    if hasattr(self._trf, 'inverted'):\n+                        inv_trf = self._trf.inverted()\n+                        vmin_candidate = inv_trf.transform(valid_transformed.min())\n+                        vmax_candidate = inv_trf.transform(valid_transformed.max())\n+                        \n+                        # Validate the candidates are reasonable\n+                        if np.isfinite([vmin_candidate, vmax_candidate]).all():\n+                            self.vmin = vmin_candidate\n+                            self.vmax = vmax_candidate\n+                        else:\n+                            # Fallback to reasonable defaults\n+                            if name == 'log':\n+                                self.vmin = 1.0\n+                                self.vmax = 10.0\n+                    else:\n+                        # If no inverse available, use base autoscale with filtered data\n+                        original_valid = A.ravel()[valid_mask] if len(A.ravel()) == len(valid_mask) else A\n+                        super(Normalize, self).autoscale_None(original_valid)\n+                        \n+                except (ValueError, OverflowError, AttributeError):\n+                    # If transform fails, fall back to base autoscale behavior\n+                    super(Normalize, self).autoscale_None(A)\n             t_value -= t_vmin\n             t_value /= (t_vmax - t_vmin)\n             t_value = np.ma.masked_invalid(t_value, copy=False)\n@@ -1705,9 +1802,57 @@ def _make_norm_from_scale(\n                 raise ValueError(\"Not invertible until scaled\")\n             if self.vmin > self.vmax:\n                 raise ValueError(\"vmin must be less or equal to vmax\")\n-            t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n-            if not np.isfinite([t_vmin, t_vmax]).all():\n-                raise ValueError(\"Invalid vmin or vmax\")\n+\n+        def autoscale_None(self, A):\n+            # Only autoscale if vmin or vmax are not set\n+            if self.vmin is not None and self.vmax is not None:\n+                return\n+            \n+            # Flatten A and handle masking\n+            A = np.asanyarray(A)\n+            A = A.ravel()\n+            \n+            # If A is empty, use default values for LogNorm\n+            if A.size == 0:\n+                if self.vmin is None:\n+                    self.vmin = 1.0\n+                if self.vmax is None:\n+                    self.vmax = 10.0\n+                return\n+            \n+            # For LogNorm, filter out non-positive values before transformation\n+            if hasattr(self._trf, 'transform'):\n+                # Remove non-positive values which are invalid for log transform\n+                valid_mask = A > 0\n+                if hasattr(A, 'mask'):\n+                    valid_mask = valid_mask & ~A.mask\n+                \n+                if not valid_mask.any():\n+                    # No valid positive values, use defaults\n+                    if self.vmin is None:\n+                        self.vmin = 1.0\n+                    if self.vmax is None:\n+                        self.vmax = 10.0\n+                    return\n+                \n+                A_valid = A[valid_mask]\n+                \n+                # Set vmin and vmax from valid data\n+                if self.vmin is None:\n+                    self.vmin = A_valid.min()\n+                if self.vmax is None:\n+                    self.vmax = A_valid.max()\n+                    \n+                # Ensure vmin and vmax are valid for log transform\n+                if self.vmin <= 0:\n+                    self.vmin = np.finfo(float).eps\n+                if self.vmax <= 0:\n+                    self.vmax = 1.0\n+                if self.vmin >= self.vmax:\n+                    self.vmax = self.vmin * 10\n+            else:\n+                # Fallback to parent implementation for non-transform cases\n+                super().autoscale_None(A)\n             value, is_scalar = self.process_value(value)\n             rescaled = value * (t_vmax - t_vmin)\n             rescaled += t_vmin\n@@ -1717,11 +1862,14 @@ def _make_norm_from_scale(\n                      .reshape(np.shape(value)))\n             return value[0] if is_scalar else value\n \n+\n         def autoscale_None(self, A):\n             # i.e. A[np.isfinite(...)], but also for non-array A's\n             in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n             if in_trf_domain.size == 0:\n-                in_trf_domain = np.ma.masked\n+                # If no valid data in transform domain, skip autoscaling\n+                # to avoid setting invalid vmin/vmax that would cause validation errors\n+                return\n             return super().autoscale_None(in_trf_domain)\n \n     if base_norm_cls is Normalize:\n",
    "variant_8": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex f9e4dcbd62..b1b7922cb5 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -1365,13 +1365,36 @@ class Normalize:\n         self.vmin = self.vmax = None\n         self.autoscale_None(A)\n \n+\n     def autoscale_None(self, A):\n         \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n         A = np.asanyarray(A)\n-        if self.vmin is None and A.size:\n-            self.vmin = A.min()\n-        if self.vmax is None and A.size:\n-            self.vmax = A.max()\n+        if A.size == 0:\n+            # No data to autoscale from\n+            return\n+            \n+        # For LogNorm, we need to ensure we only consider positive values\n+        if hasattr(self, 'transform') and hasattr(self.transform, 'transform_non_affine'):\n+            # Filter out non-positive values for log scale\n+            valid_mask = A > 0\n+            if np.any(valid_mask):\n+                A_valid = A[valid_mask]\n+                if self.vmin is None:\n+                    self.vmin = A_valid.min()\n+                if self.vmax is None:\n+                    self.vmax = A_valid.max()\n+            else:\n+                # All values are non-positive, set reasonable defaults for log scale\n+                if self.vmin is None:\n+                    self.vmin = 1.0\n+                if self.vmax is None:\n+                    self.vmax = 10.0\n+        else:\n+            # Standard behavior for non-log normalizations\n+            if self.vmin is None and A.size:\n+                self.vmin = A.min()\n+            if self.vmax is None and A.size:\n+                self.vmax = A.max()\n \n     def scaled(self):\n         \"\"\"Return whether vmin and vmax are set.\"\"\"\n@@ -1681,8 +1704,39 @@ def _make_norm_from_scale(\n \n         def __call__(self, value, clip=None):\n             value, is_scalar = self.process_value(value)\n-            if self.vmin is None or self.vmax is None:\n-                self.autoscale_None(value)\n+\n+        def autoscale_None(self, A):\n+            # Prevent autoscaling if both vmin and vmax are already set and valid\n+            if (self.vmin is not None and self.vmax is not None and \n+                self.vmin > 0 and self.vmax > 0 and self.vmin <= self.vmax):\n+                return\n+            \n+            # For LogNorm, we need positive values - filter out non-positive data\n+            A = np.asarray(A)\n+            if A.size == 0:\n+                return\n+                \n+            # Filter to positive values only for log scale\n+            positive_mask = A > 0\n+            if not np.any(positive_mask):\n+                # No positive values - set reasonable defaults for log scale\n+                if self.vmin is None:\n+                    self.vmin = 1.0\n+                if self.vmax is None:\n+                    self.vmax = 10.0\n+                return\n+            \n+            # Use only positive values for autoscaling\n+            positive_values = A[positive_mask]\n+            \n+            # Call parent's autoscale_None with filtered positive values\n+            super().autoscale_None(positive_values)\n+            \n+            # Ensure vmin and vmax are positive after autoscaling\n+            if self.vmin is not None and self.vmin <= 0:\n+                self.vmin = np.min(positive_values) if positive_values.size > 0 else 1.0\n+            if self.vmax is not None and self.vmax <= 0:\n+                self.vmax = np.max(positive_values) if positive_values.size > 0 else 10.0\n             if self.vmin > self.vmax:\n                 raise ValueError(\"vmin must be less or equal to vmax\")\n             if self.vmin == self.vmax:\n@@ -1692,9 +1746,36 @@ def _make_norm_from_scale(\n             if clip:\n                 value = np.clip(value, self.vmin, self.vmax)\n             t_value = self._trf.transform(value).reshape(np.shape(value))\n-            t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n-            if not np.isfinite([t_vmin, t_vmax]).all():\n-                raise ValueError(\"Invalid vmin or vmax\")\n+\n+            def autoscale_None(self, A):\n+                # Handle the case where all data might be filtered out by the transform\n+                if A is not None:\n+                    # Apply transform to check for valid data\n+                    try:\n+                        transformed_A = self._trf.transform(A)\n+                        # Check if we have any finite values after transform\n+                        if np.ma.is_masked(transformed_A):\n+                            valid_data = transformed_A[~transformed_A.mask]\n+                        else:\n+                            valid_data = transformed_A[np.isfinite(transformed_A)]\n+                        \n+                        # If no valid data exists after transform, use reasonable defaults\n+                        if len(valid_data) == 0:\n+                            if self.vmin is None:\n+                                self.vmin = 1.0\n+                            if self.vmax is None:\n+                                self.vmax = 10.0\n+                            return\n+                    except (ValueError, RuntimeError):\n+                        # Transform failed, use reasonable defaults\n+                        if self.vmin is None:\n+                            self.vmin = 1.0\n+                        if self.vmax is None:\n+                            self.vmax = 10.0\n+                        return\n+                \n+                # Proceed with normal autoscaling if we have valid data\n+                super().autoscale_None(A)\n             t_value -= t_vmin\n             t_value /= (t_vmax - t_vmin)\n             t_value = np.ma.masked_invalid(t_value, copy=False)\n@@ -1705,9 +1786,28 @@ def _make_norm_from_scale(\n                 raise ValueError(\"Not invertible until scaled\")\n             if self.vmin > self.vmax:\n                 raise ValueError(\"vmin must be less or equal to vmax\")\n-            t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n-            if not np.isfinite([t_vmin, t_vmax]).all():\n-                raise ValueError(\"Invalid vmin or vmax\")\n+\n+        def autoscale_None(self, A):\n+            \"\"\"\n+            Autoscale only None-valued vmin or vmax.\n+            \"\"\"\n+            if self.vmin is not None and self.vmax is not None:\n+                return\n+            if A is not None:\n+                # Filter out non-positive values for log scaling\n+                A = np.ma.masked_where(A <= 0, A, copy=False)\n+                if A.mask is np.ma.nomask:\n+                    # No masked values, proceed normally\n+                    super().autoscale_None(A)\n+                elif not A.mask.all():\n+                    # Some valid values remain after masking\n+                    super().autoscale_None(A)\n+                else:\n+                    # All values are masked (non-positive), use fallback defaults\n+                    if self.vmin is None:\n+                        self.vmin = 1.0\n+                    if self.vmax is None:\n+                        self.vmax = 10.0\n             value, is_scalar = self.process_value(value)\n             rescaled = value * (t_vmax - t_vmin)\n             rescaled += t_vmin\n@@ -1717,11 +1817,14 @@ def _make_norm_from_scale(\n                      .reshape(np.shape(value)))\n             return value[0] if is_scalar else value\n \n+\n         def autoscale_None(self, A):\n             # i.e. A[np.isfinite(...)], but also for non-array A's\n             in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n             if in_trf_domain.size == 0:\n-                in_trf_domain = np.ma.masked\n+                # If no valid data in transform domain, skip autoscaling\n+                # to avoid setting invalid vmin/vmax values\n+                return\n             return super().autoscale_None(in_trf_domain)\n \n     if base_norm_cls is Normalize:\n"
  }
}