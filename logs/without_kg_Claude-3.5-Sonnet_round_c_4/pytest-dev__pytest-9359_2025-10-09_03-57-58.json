{
  "zero_patches": {
    "Location 1 (/root/hy/projects_4/pytest/src/_pytest/assertion/rewrite.py lines 605-607)": "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                _write_and_reset()\n            elif lines and lineno not in seen_lines:\n                # Check if this token starts a new statement that's not part of the assertion\n                if tp == tokenize.OP and string == '@':\n                    # Decorator - not part of assertion\n                    _write_and_reset()\n                elif tp == tokenize.NAME and string in {'def', 'class', 'async', 'if', 'for', 'while', 'try', 'with'}:\n                    # Statement keywords - not part of assertion\n                    _write_and_reset()\n                else:\n                    lines.append(line)\n                    seen_lines.add(lineno)\n",
    "Location 2 (/root/hy/projects_4/pytest/src/_pytest/assertion/rewrite.py lines 603-604)": "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                _write_and_reset()\n            elif tp == tokenize.NAME and s in {'def', 'class', 'async'}:\n                _write_and_reset()\n            elif tp == tokenize.OP and s == '@':\n                _write_and_reset()\n",
    "Location 3 (/root/hy/projects_4/pytest/src/_pytest/assertion/rewrite.py lines 587-589)": "\n            if not lines:\n                lines.append(line[offset:])\n                seen_lines.add(lineno)\n",
    "Location 4 (/root/hy/projects_4/pytest/src/_pytest/assertion/rewrite.py lines 591-602)": "\n            # a non-nested comma separates the expression from the message\n            elif depth == 0 and tp == tokenize.OP and source == \",\":\n                # one line assert with message\n                if lineno in seen_lines and len(lines) == 1:\n                    offset_in_trimmed = offset + len(lines[-1]) - len(line)\n                    lines[-1] = lines[-1][:offset_in_trimmed]\n                # multi-line assert with message\n                elif lineno in seen_lines:\n                    lines[-1] = lines[-1][:offset]\n                # multi line assert with escapd newline before message\n                else:\n                    lines.append(line[:offset])\n                _write_and_reset()\n            # Stop capturing when we encounter decorators or other statement beginnings\n            elif depth == 0 and tp == tokenize.OP and source == \"@\":\n                _write_and_reset()\n            elif depth == 0 and tp == tokenize.NAME and source in {\"def\", \"class\", \"if\", \"for\", \"while\", \"with\", \"try\", \"async\"}:\n                _write_and_reset()\n",
    "Location 5 (/root/hy/projects_4/pytest/src/_pytest/assertion/rewrite.py lines 567-574)": "\n    def _write_and_reset() -> None:\n        nonlocal depth, lines, assert_lineno, seen_lines\n        assert assert_lineno is not None\n        ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n        depth = 0\n        lines = []\n        assert_lineno = None\n        seen_lines = set()\n"
  },
  "variant_patches": {
    "Location 1 (/root/hy/projects_4/pytest/src/_pytest/assertion/rewrite.py lines 605-607)": [
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                _write_and_reset()\n            elif lines and lineno not in seen_lines:\n                # Check if this token indicates the start of a new statement\n                # that should terminate assertion collection\n                if tp == tokenize.OP and string == '@':\n                    # Decorator - end assertion collection\n                    _write_and_reset()\n                elif tp == tokenize.NAME and string in {'def', 'class', 'async'}:\n                    # Function/class definition - end assertion collection\n                    _write_and_reset()\n                else:\n                    lines.append(line)\n                    seen_lines.add(lineno)\n",
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                _write_and_reset()\n            elif lines and lineno not in seen_lines:\n                # Check if this token indicates the start of a new statement\n                # that's not part of the assertion expression\n                if tp == tokenize.OP and source[token.start[1]:token.end[1]] == '@':\n                    # Decorator found - end assertion collection\n                    _write_and_reset()\n                elif tp == tokenize.NAME and source[token.start[1]:token.end[1]] in {'def', 'class', 'if', 'for', 'while', 'with', 'try'}:\n                    # Statement keyword found - end assertion collection\n                    _write_and_reset()\n                else:\n                    lines.append(line)\n                    seen_lines.add(lineno)\n",
      "\n            elif lines and lineno not in seen_lines:\n                # Check if this token is actually part of the assertion expression\n                # by ensuring it's not a decorator, function definition, or other statement\n                if not (tp == tokenize.OP and string == '@') and not (tp == tokenize.NAME and string in {'def', 'class', 'async'}):\n                    lines.append(line)\n                    seen_lines.add(lineno)\n                else:\n                    # We've hit a new statement/decorator, stop collecting assertion lines\n                    _write_and_reset()\n",
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                _write_and_reset()\n            elif lines and lineno not in seen_lines:\n                # Check if this token indicates the start of a new statement\n                # that's not part of the assertion expression\n                if tp == tokenize.OP and source[start[1]:end[1]] == '@':\n                    # Decorator found - end assertion collection\n                    _write_and_reset()\n                elif tp == tokenize.NAME and source[start[1]:end[1]] in {'def', 'class', 'if', 'for', 'while', 'with', 'try', 'except', 'finally', 'else', 'elif'}:\n                    # Statement keyword found - end assertion collection\n                    _write_and_reset()\n                else:\n                    lines.append(line)\n                    seen_lines.add(lineno)\n",
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                _write_and_reset()\n            elif lines and lineno not in seen_lines and tp not in {tokenize.OP} or (tp == tokenize.OP and string not in {'@'}):\n                # Only add lines that are part of the assertion expression\n                # Exclude decorator lines and other statement beginnings\n                if tp == tokenize.NAME and string in {'def', 'class', 'if', 'for', 'while', 'with', 'try', 'except', 'finally'}:\n                    _write_and_reset()\n                elif tp == tokenize.OP and string == '@':\n                    _write_and_reset()\n                else:\n                    lines.append(line)\n                    seen_lines.add(lineno)\n",
      "\n            elif lines and lineno not in seen_lines:\n                # Check if this token is actually part of the assertion expression\n                # by verifying it's not a decorator, function definition, or other statement\n                if (tp not in {tokenize.OP} or string not in {'@'}) and \\\n                   (tp != tokenize.NAME or string not in {'def', 'class', 'if', 'for', 'while', 'with', 'try', 'except', 'finally', 'else', 'elif'}):\n                    lines.append(line)\n                    seen_lines.add(lineno)\n                else:\n                    # We've hit a new statement, stop collecting\n                    _write_and_reset()\n",
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                _write_and_reset()\n            elif lines and lineno not in seen_lines:\n                # Check if this token indicates the start of a new statement\n                # that should terminate assertion collection\n                if tp == tokenize.OP and string == '@':\n                    # Decorator - end assertion collection\n                    _write_and_reset()\n                elif tp == tokenize.NAME and string in {'def', 'class', 'if', 'for', 'while', 'try', 'with'}:\n                    # New statement - end assertion collection\n                    _write_and_reset()\n                else:\n                    lines.append(line)\n                    seen_lines.add(lineno)\n",
      "\n            elif lines and lineno not in seen_lines:\n                # Check if this token could be part of the assertion expression\n                # Exclude decorators, function definitions, and other statements\n                if tp == tokenize.OP and string == '@':\n                    # This is a decorator, not part of the assertion\n                    _write_and_reset()\n                elif tp == tokenize.NAME and string in ('def', 'class', 'async'):\n                    # This is a function/class definition, not part of the assertion\n                    _write_and_reset()\n                elif tp == tokenize.INDENT:\n                    # New indentation level suggests end of assertion\n                    _write_and_reset()\n                else:\n                    # Only add the line if it's likely part of the assertion\n                    lines.append(line)\n                    seen_lines.add(lineno)\n"
    ],
    "Location 2 (/root/hy/projects_4/pytest/src/_pytest/assertion/rewrite.py lines 603-604)": [
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                _write_and_reset()\n            elif tp == tokenize.NAME and source[start[1]:end[1]] in {'def', 'class', 'async'}:\n                _write_and_reset()\n            elif tp == tokenize.OP and source[start[1]:end[1]] == '@':\n                _write_and_reset()\n",
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                _write_and_reset()\n            elif tp == tokenize.NAME and tok.string in {'def', 'class', 'async'}:\n                _write_and_reset()\n            elif tp == tokenize.OP and tok.string == '@':\n                _write_and_reset()\n",
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                _write_and_reset()\n            elif tp == tokenize.NAME and token.string in {'def', 'class', 'async'}:\n                _write_and_reset()\n            elif tp == tokenize.OP and token.string == '@':\n                _write_and_reset()\n",
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                _write_and_reset()\n            elif tp == tokenize.NAME and string in {'def', 'class', 'async'}:\n                _write_and_reset()\n            elif tp == tokenize.OP and string == '@':\n                _write_and_reset()\n",
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                _write_and_reset()\n            elif tp == tokenize.NAME and token_string in {'def', 'class', 'async'} and depth == 0:\n                _write_and_reset()\n            elif tp == tokenize.OP and token_string == '@' and depth == 0:\n                _write_and_reset()\n",
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                _write_and_reset()\n            elif tp == tokenize.NAME and s in {'def', 'class', 'async'} and depth == 0:\n                _write_and_reset()\n            elif tp == tokenize.OP and s == '@' and depth == 0:\n                _write_and_reset()\n",
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                _write_and_reset()\n            elif tp == tokenize.NAME and source[start[1]:end[1]] in {'def', 'class', 'async'}:\n                _write_and_reset()\n            elif tp == tokenize.OP and source[start[1]:end[1]] == '@':\n                _write_and_reset()\n",
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                _write_and_reset()\n            elif tp == tokenize.NAME and tok.string in {'def', 'class', 'async'}:\n                _write_and_reset()\n            elif tp == tokenize.OP and tok.string == '@':\n                _write_and_reset()\n"
    ],
    "Location 3 (/root/hy/projects_4/pytest/src/_pytest/assertion/rewrite.py lines 587-589)": [
      "\n            if not lines:\n                lines.append(line[offset:])\n                seen_lines.add(lineno)\n",
      "\n            if not lines:\n                lines.append(line[offset:])\n                seen_lines.add(lineno)\n",
      "\n            if not lines:\n                lines.append(line[offset:])\n                seen_lines.add(lineno)\n",
      "\n            if not lines:\n                lines.append(line[offset:])\n                seen_lines.add(lineno)\n",
      "\n            if not lines:\n                lines.append(line[offset:])\n                seen_lines.add(lineno)\n",
      "\n            if not lines:\n                lines.append(line[offset:])\n                seen_lines.add(lineno)\n",
      "\n            if not lines:\n                lines.append(line[offset:])\n                seen_lines.add(lineno)\n",
      "\n            if not lines:\n                lines.append(line[offset:])\n                seen_lines.add(lineno)\n"
    ],
    "Location 4 (/root/hy/projects_4/pytest/src/_pytest/assertion/rewrite.py lines 591-602)": [
      "\n            # a non-nested comma separates the expression from the message\n            elif depth == 0 and tp == tokenize.OP and source == \",\":\n                # one line assert with message\n                if lineno in seen_lines and len(lines) == 1:\n                    offset_in_trimmed = offset + len(lines[-1]) - len(line)\n                    lines[-1] = lines[-1][:offset_in_trimmed]\n                # multi-line assert with message\n                elif lineno in seen_lines:\n                    lines[-1] = lines[-1][:offset]\n                # multi line assert with escapd newline before message\n                else:\n                    lines.append(line[:offset])\n                _write_and_reset()\n            # Check for tokens that indicate end of assertion expression\n            elif tp == tokenize.OP and source == \"@\":\n                _write_and_reset()\n            elif tp == tokenize.NAME and source in (\"def\", \"class\", \"if\", \"for\", \"while\", \"try\", \"with\"):\n                _write_and_reset()\n",
      "\n            # a non-nested comma separates the expression from the message\n            elif depth == 0 and tp == tokenize.OP and source == \",\":\n                # one line assert with message\n                if lineno in seen_lines and len(lines) == 1:\n                    offset_in_trimmed = offset + len(lines[-1]) - len(line)\n                    lines[-1] = lines[-1][:offset_in_trimmed]\n                # multi-line assert with message\n                elif lineno in seen_lines:\n                    lines[-1] = lines[-1][:offset]\n                # multi line assert with escapd newline before message\n                else:\n                    lines.append(line[:offset])\n                _write_and_reset()\n            # Stop collecting when we encounter tokens that indicate end of assertion\n            elif tp == tokenize.OP and source == \"@\":\n                _write_and_reset()\n            elif tp == tokenize.NAME and source in {\"def\", \"class\", \"async\", \"with\", \"for\", \"while\", \"if\", \"elif\", \"else\", \"try\", \"except\", \"finally\", \"import\", \"from\"}:\n                _write_and_reset()\n",
      "\n            # a non-nested comma separates the expression from the message\n            elif depth == 0 and tp == tokenize.OP and source == \",\":\n                # one line assert with message\n                if lineno in seen_lines and len(lines) == 1:\n                    offset_in_trimmed = offset + len(lines[-1]) - len(line)\n                    lines[-1] = lines[-1][:offset_in_trimmed]\n                # multi-line assert with message\n                elif lineno in seen_lines:\n                    lines[-1] = lines[-1][:offset]\n                # multi line assert with escapd newline before message\n                else:\n                    lines.append(line[:offset])\n                _write_and_reset()\n",
      "\n            # a non-nested comma separates the expression from the message\n            elif depth == 0 and tp == tokenize.OP and source == \",\":\n                # one line assert with message\n                if lineno in seen_lines and len(lines) == 1:\n                    offset_in_trimmed = offset + len(lines[-1]) - len(line)\n                    lines[-1] = lines[-1][:offset_in_trimmed]\n                # multi-line assert with message\n                elif lineno in seen_lines:\n                    lines[-1] = lines[-1][:offset]\n                # multi line assert with escapd newline before message\n                else:\n                    lines.append(line[:offset])\n                _write_and_reset()\n",
      "\n            # a non-nested comma separates the expression from the message\n            elif depth == 0 and tp == tokenize.OP and source == \",\":\n                # one line assert with message\n                if lineno in seen_lines and len(lines) == 1:\n                    offset_in_trimmed = offset + len(lines[-1]) - len(line)\n                    lines[-1] = lines[-1][:offset_in_trimmed]\n                # multi-line assert with message\n                elif lineno in seen_lines:\n                    lines[-1] = lines[-1][:offset]\n                # multi line assert with escapd newline before message\n                else:\n                    lines.append(line[:offset])\n                _write_and_reset()\n            # stop collecting when we hit decorators, function definitions, or other statements\n            elif tp == tokenize.OP and source == \"@\":\n                _write_and_reset()\n            elif tp == tokenize.NAME and source in (\"def\", \"class\", \"if\", \"for\", \"while\", \"with\", \"try\", \"except\", \"finally\"):\n                _write_and_reset()\n",
      "\n            # a non-nested comma separates the expression from the message\n            elif depth == 0 and tp == tokenize.OP and source == \",\":\n                # one line assert with message\n                if lineno in seen_lines and len(lines) == 1:\n                    offset_in_trimmed = offset + len(lines[-1]) - len(line)\n                    lines[-1] = lines[-1][:offset_in_trimmed]\n                # multi-line assert with message\n                elif lineno in seen_lines:\n                    lines[-1] = lines[-1][:offset]\n                # multi line assert with escapd newline before message\n                else:\n                    lines.append(line[:offset])\n                _write_and_reset()\n            # check for tokens that indicate end of assertion expression\n            elif tp == tokenize.OP and source == \"@\":\n                _write_and_reset()\n            elif tp == tokenize.NAME and source in {\"def\", \"class\", \"async\", \"import\", \"from\"}:\n                _write_and_reset()\n",
      "\n            # a non-nested comma separates the expression from the message\n            elif depth == 0 and tp == tokenize.OP and source == \",\":\n                # one line assert with message\n                if lineno in seen_lines and len(lines) == 1:\n                    offset_in_trimmed = offset + len(lines[-1]) - len(line)\n                    lines[-1] = lines[-1][:offset_in_trimmed]\n                # multi-line assert with message\n                elif lineno in seen_lines:\n                    lines[-1] = lines[-1][:offset]\n                # multi line assert with escapd newline before message\n                else:\n                    lines.append(line[:offset])\n                _write_and_reset()\n            # Check for tokens that indicate end of assertion (decorators, function definitions, etc.)\n            elif depth == 0 and tp == tokenize.OP and source == \"@\":\n                _write_and_reset()\n            elif depth == 0 and tp == tokenize.NAME and source in {\"def\", \"class\", \"async\"}:\n                _write_and_reset()\n",
      "\n            # a non-nested comma separates the expression from the message\n            elif depth == 0 and tp == tokenize.OP and source == \",\":\n                # one line assert with message\n                if lineno in seen_lines and len(lines) == 1:\n                    offset_in_trimmed = offset + len(lines[-1]) - len(line)\n                    lines[-1] = lines[-1][:offset_in_trimmed]\n                # multi-line assert with message\n                elif lineno in seen_lines:\n                    lines[-1] = lines[-1][:offset]\n                # multi line assert with escapd newline before message\n                else:\n                    lines.append(line[:offset])\n                _write_and_reset()\n            # Check for tokens that indicate end of assertion (decorators, function defs, etc.)\n            elif tp == tokenize.OP and source == \"@\":\n                _write_and_reset()\n            elif tp == tokenize.NAME and source in (\"def\", \"class\", \"async\"):\n                _write_and_reset()\n"
    ],
    "Location 5 (/root/hy/projects_4/pytest/src/_pytest/assertion/rewrite.py lines 567-574)": [
      "\n    def _write_and_reset() -> None:\n        nonlocal depth, lines, assert_lineno, seen_lines\n        assert assert_lineno is not None\n        ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n        depth = 0\n        lines = []\n        assert_lineno = None\n        seen_lines = set()\n",
      "\n    def _write_and_reset() -> None:\n        nonlocal depth, lines, assert_lineno, seen_lines\n        assert assert_lineno is not None\n        ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n        depth = 0\n        lines = []\n        assert_lineno = None\n        seen_lines = set()\n",
      "\n    def _write_and_reset() -> None:\n        nonlocal depth, lines, assert_lineno, seen_lines\n        assert assert_lineno is not None\n        ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n        depth = 0\n        lines = []\n        assert_lineno = None\n        seen_lines = set()\n",
      "\n    def _write_and_reset() -> None:\n        nonlocal depth, lines, assert_lineno, seen_lines\n        if assert_lineno is not None and lines:\n            ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n        depth = 0\n        lines = []\n        assert_lineno = None\n        seen_lines = set()\n",
      "\n    def _write_and_reset() -> None:\n        nonlocal depth, lines, assert_lineno, seen_lines\n        assert assert_lineno is not None\n        ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n        depth = 0\n        lines = []\n        assert_lineno = None\n        seen_lines = set()\n",
      "\n    def _write_and_reset() -> None:\n        nonlocal depth, lines, assert_lineno, seen_lines\n        assert assert_lineno is not None\n        ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n        depth = 0\n        lines = []\n        assert_lineno = None\n        seen_lines = set()\n",
      "\ndef _write_and_reset() -> None:\n    nonlocal depth, lines, assert_lineno, seen_lines\n    assert assert_lineno is not None\n    ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n    depth = 0\n    lines = []\n    assert_lineno = None\n    seen_lines = set()\n",
      "\n    def _write_and_reset() -> None:\n        nonlocal depth, lines, assert_lineno, seen_lines\n        assert assert_lineno is not None\n        ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n        depth = 0\n        lines = []\n        assert_lineno = None\n        seen_lines = set()\n"
    ]
  },
  "combined_diffs": {
    "raw_patch": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..3a636b8e4 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -564,6 +564,7 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n     assert_lineno: Optional[int] = None\n     seen_lines: Set[int] = set()\n \n+\n     def _write_and_reset() -> None:\n         nonlocal depth, lines, assert_lineno, seen_lines\n         assert assert_lineno is not None\n@@ -584,10 +585,12 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n             elif tp == tokenize.OP and source in \")]}\":\n                 depth -= 1\n \n+\n             if not lines:\n                 lines.append(line[offset:])\n                 seen_lines.add(lineno)\n             # a non-nested comma separates the expression from the message\n+\n             elif depth == 0 and tp == tokenize.OP and source == \",\":\n                 # one line assert with message\n                 if lineno in seen_lines and len(lines) == 1:\n@@ -600,9 +603,11 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 else:\n                     lines.append(line[:offset])\n                 _write_and_reset()\n-            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n+\n+            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER} or (tp == tokenize.OP and source == \"@\" and depth == 0):\n                 _write_and_reset()\n-            elif lines and lineno not in seen_lines:\n+\n+            elif lines and lineno not in seen_lines and depth > 0:\n                 lines.append(line)\n                 seen_lines.add(lineno)\n \n",
    "variant_0": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..86fb42ec9 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -564,6 +564,7 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n     assert_lineno: Optional[int] = None\n     seen_lines: Set[int] = set()\n \n+\n     def _write_and_reset() -> None:\n         nonlocal depth, lines, assert_lineno, seen_lines\n         assert assert_lineno is not None\n@@ -584,10 +585,13 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n             elif tp == tokenize.OP and source in \")]}\":\n                 depth -= 1\n \n+\n             if not lines:\n                 lines.append(line[offset:])\n                 seen_lines.add(lineno)\n             # a non-nested comma separates the expression from the message\n+\n+            # a non-nested comma separates the expression from the message\n             elif depth == 0 and tp == tokenize.OP and source == \",\":\n                 # one line assert with message\n                 if lineno in seen_lines and len(lines) == 1:\n@@ -600,11 +604,32 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 else:\n                     lines.append(line[:offset])\n                 _write_and_reset()\n+            # Stop capturing when we encounter decorators or other statement beginnings\n+            elif depth == 0 and tp == tokenize.OP and source == \"@\":\n+                _write_and_reset()\n+            elif depth == 0 and tp == tokenize.NAME and source in {\"def\", \"class\", \"if\", \"for\", \"while\", \"with\", \"try\", \"async\"}:\n+                _write_and_reset()\n+\n+            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n+                _write_and_reset()\n+            elif tp == tokenize.NAME and s in {'def', 'class', 'async'}:\n+                _write_and_reset()\n+            elif tp == tokenize.OP and s == '@':\n+                _write_and_reset()\n+\n             elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                 _write_and_reset()\n             elif lines and lineno not in seen_lines:\n-                lines.append(line)\n-                seen_lines.add(lineno)\n+                # Check if this token starts a new statement that's not part of the assertion\n+                if tp == tokenize.OP and string == '@':\n+                    # Decorator - not part of assertion\n+                    _write_and_reset()\n+                elif tp == tokenize.NAME and string in {'def', 'class', 'async', 'if', 'for', 'while', 'try', 'with'}:\n+                    # Statement keywords - not part of assertion\n+                    _write_and_reset()\n+                else:\n+                    lines.append(line)\n+                    seen_lines.add(lineno)\n \n     return ret\n \n",
    "variant_1": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..67f2cdf96 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -564,6 +564,7 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n     assert_lineno: Optional[int] = None\n     seen_lines: Set[int] = set()\n \n+\n     def _write_and_reset() -> None:\n         nonlocal depth, lines, assert_lineno, seen_lines\n         assert assert_lineno is not None\n@@ -584,10 +585,13 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n             elif tp == tokenize.OP and source in \")]}\":\n                 depth -= 1\n \n+\n             if not lines:\n                 lines.append(line[offset:])\n                 seen_lines.add(lineno)\n             # a non-nested comma separates the expression from the message\n+\n+            # a non-nested comma separates the expression from the message\n             elif depth == 0 and tp == tokenize.OP and source == \",\":\n                 # one line assert with message\n                 if lineno in seen_lines and len(lines) == 1:\n@@ -600,11 +604,33 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 else:\n                     lines.append(line[:offset])\n                 _write_and_reset()\n+            # Check for tokens that indicate end of assertion expression\n+            elif tp == tokenize.OP and source == \"@\":\n+                _write_and_reset()\n+            elif tp == tokenize.NAME and source in (\"def\", \"class\", \"if\", \"for\", \"while\", \"try\", \"with\"):\n+                _write_and_reset()\n+\n+            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n+                _write_and_reset()\n+            elif tp == tokenize.NAME and source[start[1]:end[1]] in {'def', 'class', 'async'}:\n+                _write_and_reset()\n+            elif tp == tokenize.OP and source[start[1]:end[1]] == '@':\n+                _write_and_reset()\n+\n             elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                 _write_and_reset()\n             elif lines and lineno not in seen_lines:\n-                lines.append(line)\n-                seen_lines.add(lineno)\n+                # Check if this token indicates the start of a new statement\n+                # that should terminate assertion collection\n+                if tp == tokenize.OP and string == '@':\n+                    # Decorator - end assertion collection\n+                    _write_and_reset()\n+                elif tp == tokenize.NAME and string in {'def', 'class', 'async'}:\n+                    # Function/class definition - end assertion collection\n+                    _write_and_reset()\n+                else:\n+                    lines.append(line)\n+                    seen_lines.add(lineno)\n \n     return ret\n \n",
    "variant_2": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..5a159af7a 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -564,6 +564,7 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n     assert_lineno: Optional[int] = None\n     seen_lines: Set[int] = set()\n \n+\n     def _write_and_reset() -> None:\n         nonlocal depth, lines, assert_lineno, seen_lines\n         assert assert_lineno is not None\n@@ -584,10 +585,13 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n             elif tp == tokenize.OP and source in \")]}\":\n                 depth -= 1\n \n+\n             if not lines:\n                 lines.append(line[offset:])\n                 seen_lines.add(lineno)\n             # a non-nested comma separates the expression from the message\n+\n+            # a non-nested comma separates the expression from the message\n             elif depth == 0 and tp == tokenize.OP and source == \",\":\n                 # one line assert with message\n                 if lineno in seen_lines and len(lines) == 1:\n@@ -600,11 +604,33 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 else:\n                     lines.append(line[:offset])\n                 _write_and_reset()\n+            # Stop collecting when we encounter tokens that indicate end of assertion\n+            elif tp == tokenize.OP and source == \"@\":\n+                _write_and_reset()\n+            elif tp == tokenize.NAME and source in {\"def\", \"class\", \"async\", \"with\", \"for\", \"while\", \"if\", \"elif\", \"else\", \"try\", \"except\", \"finally\", \"import\", \"from\"}:\n+                _write_and_reset()\n+\n+            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n+                _write_and_reset()\n+            elif tp == tokenize.NAME and tok.string in {'def', 'class', 'async'}:\n+                _write_and_reset()\n+            elif tp == tokenize.OP and tok.string == '@':\n+                _write_and_reset()\n+\n             elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                 _write_and_reset()\n             elif lines and lineno not in seen_lines:\n-                lines.append(line)\n-                seen_lines.add(lineno)\n+                # Check if this token indicates the start of a new statement\n+                # that's not part of the assertion expression\n+                if tp == tokenize.OP and source[token.start[1]:token.end[1]] == '@':\n+                    # Decorator found - end assertion collection\n+                    _write_and_reset()\n+                elif tp == tokenize.NAME and source[token.start[1]:token.end[1]] in {'def', 'class', 'if', 'for', 'while', 'with', 'try'}:\n+                    # Statement keyword found - end assertion collection\n+                    _write_and_reset()\n+                else:\n+                    lines.append(line)\n+                    seen_lines.add(lineno)\n \n     return ret\n \n",
    "variant_3": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..3316885cf 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -564,6 +564,7 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n     assert_lineno: Optional[int] = None\n     seen_lines: Set[int] = set()\n \n+\n     def _write_and_reset() -> None:\n         nonlocal depth, lines, assert_lineno, seen_lines\n         assert assert_lineno is not None\n@@ -584,10 +585,13 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n             elif tp == tokenize.OP and source in \")]}\":\n                 depth -= 1\n \n+\n             if not lines:\n                 lines.append(line[offset:])\n                 seen_lines.add(lineno)\n             # a non-nested comma separates the expression from the message\n+\n+            # a non-nested comma separates the expression from the message\n             elif depth == 0 and tp == tokenize.OP and source == \",\":\n                 # one line assert with message\n                 if lineno in seen_lines and len(lines) == 1:\n@@ -600,11 +604,23 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 else:\n                     lines.append(line[:offset])\n                 _write_and_reset()\n+\n             elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                 _write_and_reset()\n+            elif tp == tokenize.NAME and token.string in {'def', 'class', 'async'}:\n+                _write_and_reset()\n+            elif tp == tokenize.OP and token.string == '@':\n+                _write_and_reset()\n+\n             elif lines and lineno not in seen_lines:\n-                lines.append(line)\n-                seen_lines.add(lineno)\n+                # Check if this token is actually part of the assertion expression\n+                # by ensuring it's not a decorator, function definition, or other statement\n+                if not (tp == tokenize.OP and string == '@') and not (tp == tokenize.NAME and string in {'def', 'class', 'async'}):\n+                    lines.append(line)\n+                    seen_lines.add(lineno)\n+                else:\n+                    # We've hit a new statement/decorator, stop collecting assertion lines\n+                    _write_and_reset()\n \n     return ret\n \n",
    "variant_4": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..9f8a80118 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -564,10 +564,11 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n     assert_lineno: Optional[int] = None\n     seen_lines: Set[int] = set()\n \n+\n     def _write_and_reset() -> None:\n         nonlocal depth, lines, assert_lineno, seen_lines\n-        assert assert_lineno is not None\n-        ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n+        if assert_lineno is not None and lines:\n+            ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n         depth = 0\n         lines = []\n         assert_lineno = None\n@@ -584,10 +585,13 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n             elif tp == tokenize.OP and source in \")]}\":\n                 depth -= 1\n \n+\n             if not lines:\n                 lines.append(line[offset:])\n                 seen_lines.add(lineno)\n             # a non-nested comma separates the expression from the message\n+\n+            # a non-nested comma separates the expression from the message\n             elif depth == 0 and tp == tokenize.OP and source == \",\":\n                 # one line assert with message\n                 if lineno in seen_lines and len(lines) == 1:\n@@ -600,11 +604,28 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 else:\n                     lines.append(line[:offset])\n                 _write_and_reset()\n+\n+            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n+                _write_and_reset()\n+            elif tp == tokenize.NAME and string in {'def', 'class', 'async'}:\n+                _write_and_reset()\n+            elif tp == tokenize.OP and string == '@':\n+                _write_and_reset()\n+\n             elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                 _write_and_reset()\n             elif lines and lineno not in seen_lines:\n-                lines.append(line)\n-                seen_lines.add(lineno)\n+                # Check if this token indicates the start of a new statement\n+                # that's not part of the assertion expression\n+                if tp == tokenize.OP and source[start[1]:end[1]] == '@':\n+                    # Decorator found - end assertion collection\n+                    _write_and_reset()\n+                elif tp == tokenize.NAME and source[start[1]:end[1]] in {'def', 'class', 'if', 'for', 'while', 'with', 'try', 'except', 'finally', 'else', 'elif'}:\n+                    # Statement keyword found - end assertion collection\n+                    _write_and_reset()\n+                else:\n+                    lines.append(line)\n+                    seen_lines.add(lineno)\n \n     return ret\n \n",
    "variant_5": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..be456f018 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -564,6 +564,7 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n     assert_lineno: Optional[int] = None\n     seen_lines: Set[int] = set()\n \n+\n     def _write_and_reset() -> None:\n         nonlocal depth, lines, assert_lineno, seen_lines\n         assert assert_lineno is not None\n@@ -584,10 +585,13 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n             elif tp == tokenize.OP and source in \")]}\":\n                 depth -= 1\n \n+\n             if not lines:\n                 lines.append(line[offset:])\n                 seen_lines.add(lineno)\n             # a non-nested comma separates the expression from the message\n+\n+            # a non-nested comma separates the expression from the message\n             elif depth == 0 and tp == tokenize.OP and source == \",\":\n                 # one line assert with message\n                 if lineno in seen_lines and len(lines) == 1:\n@@ -600,11 +604,31 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 else:\n                     lines.append(line[:offset])\n                 _write_and_reset()\n+            # stop collecting when we hit decorators, function definitions, or other statements\n+            elif tp == tokenize.OP and source == \"@\":\n+                _write_and_reset()\n+            elif tp == tokenize.NAME and source in (\"def\", \"class\", \"if\", \"for\", \"while\", \"with\", \"try\", \"except\", \"finally\"):\n+                _write_and_reset()\n+\n+            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n+                _write_and_reset()\n+            elif tp == tokenize.NAME and token_string in {'def', 'class', 'async'} and depth == 0:\n+                _write_and_reset()\n+            elif tp == tokenize.OP and token_string == '@' and depth == 0:\n+                _write_and_reset()\n+\n             elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                 _write_and_reset()\n-            elif lines and lineno not in seen_lines:\n-                lines.append(line)\n-                seen_lines.add(lineno)\n+            elif lines and lineno not in seen_lines and tp not in {tokenize.OP} or (tp == tokenize.OP and string not in {'@'}):\n+                # Only add lines that are part of the assertion expression\n+                # Exclude decorator lines and other statement beginnings\n+                if tp == tokenize.NAME and string in {'def', 'class', 'if', 'for', 'while', 'with', 'try', 'except', 'finally'}:\n+                    _write_and_reset()\n+                elif tp == tokenize.OP and string == '@':\n+                    _write_and_reset()\n+                else:\n+                    lines.append(line)\n+                    seen_lines.add(lineno)\n \n     return ret\n \n",
    "variant_6": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..f4388cad6 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -564,6 +564,7 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n     assert_lineno: Optional[int] = None\n     seen_lines: Set[int] = set()\n \n+\n     def _write_and_reset() -> None:\n         nonlocal depth, lines, assert_lineno, seen_lines\n         assert assert_lineno is not None\n@@ -584,10 +585,13 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n             elif tp == tokenize.OP and source in \")]}\":\n                 depth -= 1\n \n+\n             if not lines:\n                 lines.append(line[offset:])\n                 seen_lines.add(lineno)\n             # a non-nested comma separates the expression from the message\n+\n+            # a non-nested comma separates the expression from the message\n             elif depth == 0 and tp == tokenize.OP and source == \",\":\n                 # one line assert with message\n                 if lineno in seen_lines and len(lines) == 1:\n@@ -600,11 +604,29 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 else:\n                     lines.append(line[:offset])\n                 _write_and_reset()\n+            # check for tokens that indicate end of assertion expression\n+            elif tp == tokenize.OP and source == \"@\":\n+                _write_and_reset()\n+            elif tp == tokenize.NAME and source in {\"def\", \"class\", \"async\", \"import\", \"from\"}:\n+                _write_and_reset()\n+\n             elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                 _write_and_reset()\n+            elif tp == tokenize.NAME and s in {'def', 'class', 'async'} and depth == 0:\n+                _write_and_reset()\n+            elif tp == tokenize.OP and s == '@' and depth == 0:\n+                _write_and_reset()\n+\n             elif lines and lineno not in seen_lines:\n-                lines.append(line)\n-                seen_lines.add(lineno)\n+                # Check if this token is actually part of the assertion expression\n+                # by verifying it's not a decorator, function definition, or other statement\n+                if (tp not in {tokenize.OP} or string not in {'@'}) and \\\n+                   (tp != tokenize.NAME or string not in {'def', 'class', 'if', 'for', 'while', 'with', 'try', 'except', 'finally', 'else', 'elif'}):\n+                    lines.append(line)\n+                    seen_lines.add(lineno)\n+                else:\n+                    # We've hit a new statement, stop collecting\n+                    _write_and_reset()\n \n     return ret\n \n",
    "variant_7": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..4a6d69aea 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -564,14 +564,15 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n     assert_lineno: Optional[int] = None\n     seen_lines: Set[int] = set()\n \n-    def _write_and_reset() -> None:\n-        nonlocal depth, lines, assert_lineno, seen_lines\n-        assert assert_lineno is not None\n-        ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n-        depth = 0\n-        lines = []\n-        assert_lineno = None\n-        seen_lines = set()\n+\n+def _write_and_reset() -> None:\n+    nonlocal depth, lines, assert_lineno, seen_lines\n+    assert assert_lineno is not None\n+    ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n+    depth = 0\n+    lines = []\n+    assert_lineno = None\n+    seen_lines = set()\n \n     tokens = tokenize.tokenize(io.BytesIO(src).readline)\n     for tp, source, (lineno, offset), _, line in tokens:\n@@ -584,10 +585,13 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n             elif tp == tokenize.OP and source in \")]}\":\n                 depth -= 1\n \n+\n             if not lines:\n                 lines.append(line[offset:])\n                 seen_lines.add(lineno)\n             # a non-nested comma separates the expression from the message\n+\n+            # a non-nested comma separates the expression from the message\n             elif depth == 0 and tp == tokenize.OP and source == \",\":\n                 # one line assert with message\n                 if lineno in seen_lines and len(lines) == 1:\n@@ -600,11 +604,33 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 else:\n                     lines.append(line[:offset])\n                 _write_and_reset()\n+            # Check for tokens that indicate end of assertion (decorators, function definitions, etc.)\n+            elif depth == 0 and tp == tokenize.OP and source == \"@\":\n+                _write_and_reset()\n+            elif depth == 0 and tp == tokenize.NAME and source in {\"def\", \"class\", \"async\"}:\n+                _write_and_reset()\n+\n+            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n+                _write_and_reset()\n+            elif tp == tokenize.NAME and source[start[1]:end[1]] in {'def', 'class', 'async'}:\n+                _write_and_reset()\n+            elif tp == tokenize.OP and source[start[1]:end[1]] == '@':\n+                _write_and_reset()\n+\n             elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                 _write_and_reset()\n             elif lines and lineno not in seen_lines:\n-                lines.append(line)\n-                seen_lines.add(lineno)\n+                # Check if this token indicates the start of a new statement\n+                # that should terminate assertion collection\n+                if tp == tokenize.OP and string == '@':\n+                    # Decorator - end assertion collection\n+                    _write_and_reset()\n+                elif tp == tokenize.NAME and string in {'def', 'class', 'if', 'for', 'while', 'try', 'with'}:\n+                    # New statement - end assertion collection\n+                    _write_and_reset()\n+                else:\n+                    lines.append(line)\n+                    seen_lines.add(lineno)\n \n     return ret\n \n",
    "variant_8": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..a94c7340d 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -564,6 +564,7 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n     assert_lineno: Optional[int] = None\n     seen_lines: Set[int] = set()\n \n+\n     def _write_and_reset() -> None:\n         nonlocal depth, lines, assert_lineno, seen_lines\n         assert assert_lineno is not None\n@@ -584,10 +585,13 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n             elif tp == tokenize.OP and source in \")]}\":\n                 depth -= 1\n \n+\n             if not lines:\n                 lines.append(line[offset:])\n                 seen_lines.add(lineno)\n             # a non-nested comma separates the expression from the message\n+\n+            # a non-nested comma separates the expression from the message\n             elif depth == 0 and tp == tokenize.OP and source == \",\":\n                 # one line assert with message\n                 if lineno in seen_lines and len(lines) == 1:\n@@ -600,11 +604,35 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 else:\n                     lines.append(line[:offset])\n                 _write_and_reset()\n+            # Check for tokens that indicate end of assertion (decorators, function defs, etc.)\n+            elif tp == tokenize.OP and source == \"@\":\n+                _write_and_reset()\n+            elif tp == tokenize.NAME and source in (\"def\", \"class\", \"async\"):\n+                _write_and_reset()\n+\n             elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                 _write_and_reset()\n+            elif tp == tokenize.NAME and tok.string in {'def', 'class', 'async'}:\n+                _write_and_reset()\n+            elif tp == tokenize.OP and tok.string == '@':\n+                _write_and_reset()\n+\n             elif lines and lineno not in seen_lines:\n-                lines.append(line)\n-                seen_lines.add(lineno)\n+                # Check if this token could be part of the assertion expression\n+                # Exclude decorators, function definitions, and other statements\n+                if tp == tokenize.OP and string == '@':\n+                    # This is a decorator, not part of the assertion\n+                    _write_and_reset()\n+                elif tp == tokenize.NAME and string in ('def', 'class', 'async'):\n+                    # This is a function/class definition, not part of the assertion\n+                    _write_and_reset()\n+                elif tp == tokenize.INDENT:\n+                    # New indentation level suggests end of assertion\n+                    _write_and_reset()\n+                else:\n+                    # Only add the line if it's likely part of the assertion\n+                    lines.append(line)\n+                    seen_lines.add(lineno)\n \n     return ret\n \n"
  }
}