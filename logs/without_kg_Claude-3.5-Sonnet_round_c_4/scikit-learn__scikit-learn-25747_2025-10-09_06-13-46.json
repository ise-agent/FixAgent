{
  "zero_patches": {
    "Location 1 (/root/hy/projects_4/scikit-learn/sklearn/pipeline.py lines 1279-1289)": "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            result = pd.concat(Xs, axis=1)\n            # Mark the result to avoid automatic index wrapping since concat already\n            # creates proper DataFrame with appropriate index handling\n            if hasattr(result, '_sklearn_no_index_wrap'):\n                result._sklearn_no_index_wrap = True\n            else:\n                # Use a more compatible approach - store flag in attrs if available\n                try:\n                    result.attrs['_sklearn_no_index_wrap'] = True\n                except (AttributeError, TypeError):\n                    # Fallback: reset index to avoid length mismatch issues\n                    result = result.reset_index(drop=True)\n            return result\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n            Xs = np.hstack(Xs)\n        return Xs\n",
    "Location 2 (/root/hy/projects_4/scikit-learn/sklearn/utils/_set_output.py lines 56-62)": "\ndef _wrap_in_pandas_container(\n    data_to_wrap,\n    *,\n    columns,\n    index,\n):\n    \"\"\"Create a pandas container holding the data.\n\n    Parameters\n    ----------\n    data_to_wrap : {ndarray, dataframe}\n        Data to be wrapped in a pandas container.\n    columns : callable, ndarray, or None\n        The column names or a callable that returns the column names. The\n        number of names must match the number of columns in `data_to_wrap`.\n        If `None`, then no column names are set.\n    index : array-like, default=None\n        The index for the dataframe. If `None`, then the default index\n        is used.\n\n    Returns\n    -------\n    dataframe : DataFrame\n        Container with the data.\n    \"\"\"\n    if callable(columns):\n        try:\n            columns = columns()\n        except Exception:\n            columns = None\n\n    pd = check_pandas_support(\"Setting output container to 'pandas'\")\n\n    if isinstance(data_to_wrap, pd.DataFrame):\n        if columns is not None:\n            data_to_wrap.columns = columns\n        if index is not None and len(index) == len(data_to_wrap):\n            data_to_wrap.index = index\n        return data_to_wrap\n\n    return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n",
    "Location 3 (/root/hy/projects_4/scikit-learn/sklearn/utils/_set_output.py lines 127-134)": "\ndef _wrap_data_with_container(\n    method, data_to_wrap, original_input, estimator\n):\n    \"\"\"Wrap output with container based on an estimator's or global config.\n\n    Parameters\n    ----------\n    method : {\"transform\"}\n        Estimator's method to get container output for.\n\n    data_to_wrap : {ndarray, dataframe}\n        Data to wrap with container.\n\n    original_input : {ndarray, dataframe}\n        Original input of function.\n\n    estimator : estimator instance\n        Estimator with to get the output configuration from.\n\n    Returns\n    -------\n    output : {ndarray, dataframe}\n        If the output config is \"default\" or the estimator is not configured\n        for wrapping return `data_to_wrap` unchanged.\n        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n        DataFrame.\n    \"\"\"\n    output_config = _get_output_config(method, estimator)\n\n    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n        return data_to_wrap\n\n    # dense_config == \"pandas\"\n    # Check if data shape changed (e.g., due to aggregation)\n    original_index = getattr(original_input, \"index\", None)\n    if original_index is not None and hasattr(data_to_wrap, 'shape') and len(original_index) != data_to_wrap.shape[0]:\n        # Shape mismatch - don't use original index\n        original_index = None\n    \n    return _wrap_in_pandas_container(\n        data_to_wrap=data_to_wrap,\n        index=original_index,\n        columns=estimator.get_feature_names_out,\n    )\n",
    "Location 4 (/root/hy/projects_4/scikit-learn/sklearn/pipeline.py lines 1254-1277)": "\ndef transform(self, X):\n    \"\"\"Transform X separately by each transformer, concatenate results.\n\n    Parameters\n    ----------\n    X : iterable or array-like, depending on transformers\n        Input data to be transformed.\n\n    Returns\n    -------\n    X_t : array-like or sparse matrix of \\\n            shape (n_samples, sum_n_components)\n        The `hstack` of results of transformers. `sum_n_components` is the\n        sum of `n_components` (output dimension) over transformers.\n    \"\"\"\n    Xs = Parallel(n_jobs=self.n_jobs)(\n        delayed(_transform_one)(trans, X, None, weight)\n        for name, trans, weight in self._iter()\n    )\n    if not Xs:\n        # All transformers are None\n        return np.zeros((X.shape[0], 0))\n\n    # Check if any transformer changed the number of rows\n    original_n_rows = X.shape[0]\n    result_has_different_shape = any(\n        hasattr(Xt, 'shape') and Xt.shape[0] != original_n_rows \n        for Xt in Xs if Xt is not None\n    )\n    \n    result = self._hstack(Xs)\n    \n    # If shape changed and we're using pandas output, mark the result\n    # to prevent automatic index wrapping in _wrap_method_output\n    if result_has_different_shape:\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and hasattr(result, 'iloc'):\n            # Add a marker attribute to indicate shape change\n            result._sklearn_shape_changed = True\n    \n    return result\n",
    "Location 5 (/root/hy/projects_4/scikit-learn/sklearn/utils/_set_output.py lines 143-150)": "\ndef _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            # Check if the first output has same shape as input before wrapping\n            first_output = data_to_wrap[0]\n            if hasattr(X, 'shape') and hasattr(first_output, 'shape') and X.shape[0] != first_output.shape[0]:\n                # Shape mismatch detected, wrap without original index\n                wrapped_first = _wrap_data_with_container(method, first_output, None, self)\n            else:\n                wrapped_first = _wrap_data_with_container(method, first_output, X, self)\n            return (wrapped_first, *data_to_wrap[1:])\n\n        # Check if output has same shape as input before wrapping\n        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape') and X.shape[0] != data_to_wrap.shape[0]:\n            # Shape mismatch detected, wrap without original index\n            return _wrap_data_with_container(method, data_to_wrap, None, self)\n        \n        return _wrap_data_with_container(method, data_to_wrap, X, self)\n\n    return wrapped\n"
  },
  "variant_patches": {
    "Location 1 (/root/hy/projects_4/scikit-learn/sklearn/pipeline.py lines 1279-1289)": [
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            result = pd.concat(Xs, axis=1)\n            # Mark the result to skip index wrapping since concat already handles indexing\n            result._sklearn_skip_index_wrapping = True\n            return result\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n            Xs = np.hstack(Xs)\n        return Xs\n",
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            result = pd.concat(Xs, axis=1)\n            # Mark the result to skip automatic index wrapping since concat already handles indexing\n            result._sklearn_skip_index_wrap = True\n            return result\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n            Xs = np.hstack(Xs)\n        return Xs\n",
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            # Concatenate DataFrames and return directly to avoid index wrapping issues\n            # when transformers change the number of rows (e.g., aggregation)\n            result = pd.concat(Xs, axis=1)\n            # Reset index to avoid length mismatch with original input index\n            result.reset_index(drop=True, inplace=True)\n            return result\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n            Xs = np.hstack(Xs)\n        return Xs\n",
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            result = pd.concat(Xs, axis=1)\n            # Mark the result to indicate it was created by pandas concat\n            # and shouldn't have its index overwritten by the output wrapper\n            result._sklearn_pandas_concat = True\n            return result\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n            Xs = np.hstack(Xs)\n        return Xs\n",
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            result = pd.concat(Xs, axis=1)\n            # Mark the result to indicate it shouldn't have its index modified\n            # by the output wrapping mechanism, since concat already handles indexing\n            result._sklearn_no_index_wrap = True\n            return result\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n            Xs = np.hstack(Xs)\n        return Xs\n",
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            result = pd.concat(Xs, axis=1)\n            # Mark the result to indicate it should not have its index modified\n            # by the output wrapping mechanism, since concat already handles indexing\n            result._sklearn_no_index_wrap = True\n            return result\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n            Xs = np.hstack(Xs)\n        return Xs\n",
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            result = pd.concat(Xs, axis=1)\n            # Mark the result to skip automatic index wrapping since concat already handles indexing\n            result._sklearn_skip_index_wrap = True\n            return result\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n            Xs = np.hstack(Xs)\n        return Xs\n",
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            result = pd.concat(Xs, axis=1)\n            # Mark the result to indicate it should not have its index modified\n            # by the output wrapping mechanism, as concat already handles indexing properly\n            result._sklearn_no_index_wrap = True\n            return result\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n            Xs = np.hstack(Xs)\n        return Xs\n"
    ],
    "Location 2 (/root/hy/projects_4/scikit-learn/sklearn/utils/_set_output.py lines 56-62)": [
      "\ndef _wrap_in_pandas_container(\n    data_to_wrap, *, columns, index, data_to_wrap_original\n):\n    \"\"\"Wrap output in a pandas container.\n\n    If the output is a DataFrame and has the same shape as the original input,\n    then the columns and index can be set. Otherwise, only set columns and\n    index if they are compatible with the new shape.\n\n    Parameters\n    ----------\n    data_to_wrap : {ndarray, dataframe}\n        The output to be wrapped in a pandas container.\n    columns : callable, ndarray, or None\n        The column names or a callable that returns the column names. The\n        callable is useful if the column names require some computation.\n        If `columns` is a callable that raises an error, `columns` will have\n        the same semantics as `None`. If `None`, then no columns are set.\n    index : array-like, default=None\n        The index for the dataframe. If `None`, then the index is not set.\n    data_to_wrap_original : {ndarray, dataframe}\n        The original input passed to the estimator.\n\n    Returns\n    -------\n    dataframe\n        Container with the data_to_wrap.\n    \"\"\"\n    try:\n        import pandas as pd\n    except ImportError:\n        raise ImportError(\"pandas is required to use the 'pandas' output format.\")\n\n    if callable(columns):\n        try:\n            columns = columns()\n        except Exception:\n            columns = None\n\n    pd = check_pandas_support(\"Setting output container to 'pandas'\")\n\n    if isinstance(data_to_wrap, pd.DataFrame):\n        if columns is not None:\n            data_to_wrap.columns = columns\n        # Only set index if it's compatible with the data shape\n        if index is not None and len(index) == len(data_to_wrap):\n            data_to_wrap.index = index\n        return data_to_wrap\n\n    # For new DataFrames, only use index if it's compatible\n    if index is not None and hasattr(data_to_wrap, '__len__') and len(index) != len(data_to_wrap):\n        index = None\n    \n    return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n",
      "\ndef _wrap_in_pandas_container(\n    data_to_wrap,\n    *,\n    columns,\n    index,\n):\n    \"\"\"Create a pandas DataFrame.\n\n    If `data_to_wrap` is a DataFrame, then the `columns` and `index` will be\n    changed inplace. If `data_to_wrap` is a ndarray, then a new DataFrame is\n    created.\n    \"\"\"\n    if callable(columns):\n        try:\n            columns = columns()\n        except Exception:\n            columns = None\n\n    pd = check_pandas_support(\"Setting output container to 'pandas'\")\n\n    if isinstance(data_to_wrap, pd.DataFrame):\n        if columns is not None:\n            data_to_wrap.columns = columns\n        if index is not None and len(index) == len(data_to_wrap):\n            data_to_wrap.index = index\n        return data_to_wrap\n\n    return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n",
      "\ndef _wrap_in_pandas_container(\n    data_to_wrap,\n    *,\n    columns,\n    index,\n):\n    \"\"\"Create a pandas DataFrame.\n\n    If `data_to_wrap` is a DataFrame, then the `columns` and `index` will be\n    changed inplace. If `data_to_wrap` is a ndarray, then a new DataFrame is\n    created.\n    \"\"\"\n    if callable(columns):\n        try:\n            columns = columns()\n        except Exception:\n            columns = None\n\n    pd = check_pandas_support(\"Setting output container to 'pandas'\")\n\n    if isinstance(data_to_wrap, pd.DataFrame):\n        if columns is not None:\n            data_to_wrap.columns = columns\n        if index is not None and len(index) == len(data_to_wrap):\n            data_to_wrap.index = index\n        return data_to_wrap\n\n    return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n",
      "\ndef _wrap_in_pandas_container(\n    data_to_wrap, *, columns, index, data_to_wrap_original\n):\n    \"\"\"Create a Pandas DataFrame.\n\n    If `data_to_wrap` is a DataFrame, then the `columns` and `index` will be\n    changed inplace. If `data_to_wrap` is a ndarray, then a new DataFrame is\n    created.\n\n    Parameters\n    ----------\n    data_to_wrap : {ndarray, dataframe}\n        Data to be wrapped as pandas dataframe.\n\n    columns : callable, ndarray, or None\n        The column names or a callable that returns the column names. The\n        callable is useful if the column names require some computation.\n        If `columns` is a callable that raises an error, `columns` will have\n        the same semantics as `None`. If `None`, then the columns will be\n        numbered.\n\n    index : ndarray or None\n        Index for data. If `None`, then the index will be numbered.\n\n    data_to_wrap_original : ndarray\n        Original input data before transformation. This parameter is not used\n        directly but is part of the function signature for consistency.\n\n    Returns\n    -------\n    dataframe : DataFrame\n        Container with column names or unchanged `output`.\n    \"\"\"\n    if callable(columns):\n        try:\n            columns = columns()\n        except Exception:\n            columns = None\n\n    pd = check_pandas_support(\"Setting output container to 'pandas'\")\n\n    if isinstance(data_to_wrap, pd.DataFrame):\n        if columns is not None:\n            data_to_wrap.columns = columns\n        if index is not None and len(index) == len(data_to_wrap):\n            data_to_wrap.index = index\n        return data_to_wrap\n\n    return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n",
      "\ndef _wrap_in_pandas_container(\n    data_to_wrap, *, columns, index=None, force_all_finite=True\n):\n    \"\"\"Wrap output in a pandas container.\n\n    Parameters\n    ----------\n    data_to_wrap : {ndarray, dataframe}\n        Data to be wrapped as pandas dataframe.\n\n    columns : callable, ndarray, or None\n        The column names or a callable that returns the column names. The\n        callable is useful if the column names require some computation.\n        If `columns` is a callable that raises an error, `columns` will have\n        the same semantics as `None`. If `None` and `data_to_wrap` is already a\n        dataframe, then the column names are not changed. If `None` and\n        `data_to_wrap` is **not** a dataframe, then columns are\n        `range(n_features)`.\n\n    index : array-like, default=None\n        Index for data. `index` is ignored if `data_to_wrap` is already a\n        DataFrame.\n\n    force_all_finite : bool, default=True\n        Whether to raise an error on np.inf, np.nan, pd.NA in array.\n        The possibilities are:\n        - True: Force all values of array to be finite.\n        - False: accepts np.inf, np.nan, pd.NA in array.\n\n    Returns\n    -------\n    dataframe : DataFrame\n        Container with column names or unchanged `output`.\n    \"\"\"\n    if issparse(data_to_wrap):\n        raise ValueError(\"Pandas output does not support sparse data.\")\n\n    if force_all_finite:\n        _assert_all_finite(data_to_wrap, allow_nan=False)\n\n    if callable(columns):\n        try:\n            columns = columns()\n        except Exception:\n            columns = None\n\n    pd = check_pandas_support(\"Setting output container to 'pandas'\")\n\n    if isinstance(data_to_wrap, pd.DataFrame):\n        if columns is not None:\n            data_to_wrap.columns = columns\n        if index is not None and len(index) == len(data_to_wrap):\n            data_to_wrap.index = index\n        return data_to_wrap\n\n    return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n",
      "\ndef _wrap_in_pandas_container(\n    data_to_wrap, *, columns, index, data_to_wrap_original, original_input\n):\n    \"\"\"Create a Pandas DataFrame.\n\n    If `data_to_wrap` is a DataFrame, then the `columns` and `index` will be\n    changed inplace. If `data_to_wrap` is a ndarray, then a new DataFrame is\n    created.\n\n    Parameters\n    ----------\n    data_to_wrap : {ndarray, dataframe}\n        Data to be wrapped as pandas dataframe.\n\n    columns : callable, ndarray, or None\n        The column names or a callable that returns the column names. The\n        callable is useful if the column names require some computation.\n        If `columns` is a callable that raises an error, `columns` will have\n        the same semantics as `None`. If `None` and `data_to_wrap` is already a\n        dataframe, then the column names are not changed. If `None` and\n        `data_to_wrap` is **not** a dataframe, then columns are\n        `range(n_features)`.\n\n    index : array-like, default=None\n        Index for data.\n\n    data_to_wrap_original : {ndarray, dataframe}\n        Original data, before any processing.\n\n    original_input : {ndarray, dataframe}\n        The original input passed to the estimator.\n\n    Returns\n    -------\n    dataframe : DataFrame\n        Container with column names or unchanged `output`.\n    \"\"\"\n    if issparse(data_to_wrap):\n        raise ValueError(\"Pandas output does not support sparse data.\")\n\n    if callable(columns):\n        try:\n            columns = columns()\n        except Exception:\n            columns = None\n\n    pd = check_pandas_support(\"Setting output container to 'pandas'\")\n\n    if isinstance(data_to_wrap, pd.DataFrame):\n        if columns is not None:\n            data_to_wrap.columns = columns\n        # Check if index length matches before setting to avoid dimension mismatch\n        if index is not None and len(index) == len(data_to_wrap):\n            data_to_wrap.index = index\n        return data_to_wrap\n\n    return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n",
      "\ndef _wrap_in_pandas_container(\n    data_to_wrap, *, columns, index, data_to_wrap_original\n):\n    \"\"\"Wrap output in a pandas container.\n\n    Parameters\n    ----------\n    data_to_wrap : {ndarray, dataframe}\n        Data to be wrapped in a pandas container.\n    columns : callable, ndarray, or None\n        The column names or a callable that returns the column names. The\n        callable is useful if the column names require some computation.\n        If `columns` is a callable that raises an error, `columns` will have\n        the same semantics as `None`. If `None` and `data_to_wrap` is already a\n        dataframe, then the column names are not changed. If `None` and\n        `data_to_wrap` is **not** a dataframe, then columns are given the\n        default names.\n    index : array-like, default=None\n        Index for data.\n    data_to_wrap_original : {ndarray, dataframe}\n        Original input data.\n    \"\"\"\n    if issparse(data_to_wrap):\n        raise ValueError(\"Pandas output does not support sparse data.\")\n\n    if callable(columns):\n        try:\n            columns = columns()\n        except Exception:\n            columns = None\n\n    pd = check_pandas_support(\"Setting output container to 'pandas'\")\n\n    if isinstance(data_to_wrap, pd.DataFrame):\n        if columns is not None:\n            data_to_wrap.columns = columns\n        if index is not None and len(index) == len(data_to_wrap):\n            data_to_wrap.index = index\n        return data_to_wrap\n\n    # Check if index length matches data length before creating DataFrame\n    if index is not None and len(index) != len(data_to_wrap):\n        index = None\n    \n    return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n",
      "\ndef _wrap_in_pandas_container(\n    data_to_wrap, *, columns, index, data_to_wrap_original\n):\n    \"\"\"Create a pandas container holding the data.\n\n    Parameters\n    ----------\n    data_to_wrap : {ndarray, dataframe}\n        Data to be wrapped as pandas dataframe.\n\n    columns : callable, ndarray, or None\n        The column names or a callable that returns the column names. The\n        number of names must match the number of columns in `data_to_wrap`.\n        If `None`, then no column names are set.\n\n    index : array-like, default=None\n        Index for data. `index` is ignored if `data_to_wrap` is already a\n        DataFrame.\n\n    data_to_wrap_original : {ndarray, dataframe}\n        Original input data.\n\n    Returns\n    -------\n    dataframe : DataFrame\n        Container with the data.\n    \"\"\"\n    if callable(columns):\n        try:\n            columns = columns()\n        except Exception:\n            columns = None\n\n    pd = check_pandas_support(\"Setting output container to 'pandas'\")\n\n    if isinstance(data_to_wrap, pd.DataFrame):\n        if columns is not None:\n            data_to_wrap.columns = columns\n        # Only set index if it's compatible with the data shape\n        if index is not None and len(index) == len(data_to_wrap):\n            data_to_wrap.index = index\n        return data_to_wrap\n\n    return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n"
    ],
    "Location 3 (/root/hy/projects_4/scikit-learn/sklearn/utils/_set_output.py lines 127-134)": [
      "\ndef _wrap_data_with_container(\n    method, data_to_wrap, original_input, estimator\n):\n    \"\"\"Wrap output with container based on an estimator's or global config.\n\n    Parameters\n    ----------\n    method : {\"transform\"}\n        Estimator's method to get container output for.\n\n    data_to_wrap : {ndarray, dataframe}\n        Data to wrap with container.\n\n    original_input : {ndarray, dataframe}\n        Original input of function.\n\n    estimator : estimator instance\n        Estimator with to get the output configuration from.\n\n    Returns\n    -------\n    output : {ndarray, dataframe}\n        If the output config is \"default\" or the estimator is not configured\n        for wrapping return `data_to_wrap` unchanged.\n        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n        DataFrame.\n    \"\"\"\n    output_config = _get_output_config(method, estimator)\n\n    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n        return data_to_wrap\n\n    # dense_config == \"pandas\"\n    # Check if shape changed to avoid index mismatch\n    original_index = getattr(original_input, \"index\", None)\n    if (original_index is not None and \n        hasattr(data_to_wrap, '__len__') and \n        len(original_index) != len(data_to_wrap)):\n        original_index = None\n    \n    return _wrap_in_pandas_container(\n        data_to_wrap=data_to_wrap,\n        index=original_index,\n        columns=estimator.get_feature_names_out,\n    )\n",
      "\ndef _wrap_data_with_container(\n    method, data_to_wrap, original_input, estimator\n):\n    \"\"\"Wrap output with container based on an estimator's or global config.\n\n    Parameters\n    ----------\n    method : {\"transform\"}\n        Estimator's method to get container output for.\n\n    data_to_wrap : {ndarray, dataframe}\n        Data to wrap with container.\n\n    original_input : {ndarray, dataframe}\n        Original input of function.\n\n    estimator : estimator instance\n        Estimator with to get the output configuration from.\n\n    Returns\n    -------\n    output : {ndarray, dataframe}\n        If the output config is \"default\" or the estimator is not configured\n        for wrapping return `data_to_wrap` unchanged.\n        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n        DataFrame.\n    \"\"\"\n    output_config = _get_output_config(method, estimator)\n\n    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n        return data_to_wrap\n\n    # dense_config == \"pandas\"\n    # Check if data shape changed (e.g., from aggregation) to avoid index mismatch\n    original_index = getattr(original_input, \"index\", None)\n    if (original_index is not None and \n        hasattr(data_to_wrap, '__len__') and \n        len(original_index) != len(data_to_wrap)):\n        # Shape changed, don't use original index\n        original_index = None\n    \n    return _wrap_in_pandas_container(\n        data_to_wrap=data_to_wrap,\n        index=original_index,\n        columns=estimator.get_feature_names_out,\n    )\n",
      "\ndef _wrap_data_with_container(\n    method, data_to_wrap, original_input, estimator\n):\n    \"\"\"Wrap output with container based on an estimator's or global config.\n\n    Parameters\n    ----------\n    method : {\"transform\"}\n        Estimator's method to get container output for.\n\n    data_to_wrap : {ndarray, dataframe}\n        Data to wrap with container.\n\n    original_input : {ndarray, dataframe}\n        Original input of function.\n\n    estimator : estimator instance\n        Estimator with to get the output configuration from.\n\n    Returns\n    -------\n    output : {ndarray, dataframe}\n        If the output config is \"default\" or the estimator is not configured\n        for wrapping return `data_to_wrap` unchanged.\n        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n        DataFrame.\n    \"\"\"\n    output_config = _get_output_config(method, estimator)\n\n    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n        return data_to_wrap\n\n    # dense_config == \"pandas\"\n    # Check if the data shape is compatible with the original input's index\n    original_index = getattr(original_input, \"index\", None)\n    if original_index is not None and hasattr(data_to_wrap, '__len__') and len(data_to_wrap) != len(original_index):\n        # Shape mismatch detected, don't use original index\n        original_index = None\n    \n    return _wrap_in_pandas_container(\n        data_to_wrap=data_to_wrap,\n        index=original_index,\n        columns=estimator.get_feature_names_out,\n    )\n",
      "\ndef _wrap_data_with_container(\n    method, data_to_wrap, original_input, estimator\n):\n    \"\"\"Wrap output with container based on an estimator's or global config.\n\n    Parameters\n    ----------\n    method : str\n        The method name calling this function.\n    data_to_wrap : {ndarray, dataframe}\n        Data to be wrapped with container.\n    original_input : {ndarray, dataframe}\n        Original input of method.\n    estimator : estimator instance\n        Estimator with to get the output configuration from.\n\n    Returns\n    -------\n    output : {ndarray, dataframe}\n        If the output config is \"default\" or the estimator is not configured\n        for wrapping return `data_to_wrap` unchanged.\n        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n        DataFrame.\n    \"\"\"\n    output_config = _get_output_config(method, estimator)\n\n    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n        return data_to_wrap\n\n    # dense_config == \"pandas\"\n    # Check if shapes are compatible before passing original index\n    original_index = getattr(original_input, \"index\", None)\n    if original_index is not None and hasattr(data_to_wrap, \"__len__\"):\n        if len(data_to_wrap) != len(original_index):\n            # Shape mismatch - don't use original index\n            original_index = None\n    \n    return _wrap_in_pandas_container(\n        data_to_wrap=data_to_wrap,\n        index=original_index,\n        columns=estimator.get_feature_names_out,\n    )\n",
      "\ndef _wrap_data_with_container(\n    method, data_to_wrap, original_input, estimator, *, index=None\n):\n    \"\"\"Wrap output with container based on an estimator's or global config.\n\n    Parameters\n    ----------\n    method : str\n        Method to call on the estimator. Can be \"transform\" or \"fit_transform\".\n\n    data_to_wrap : {ndarray, dataframe}\n        Data to wrap with container.\n\n    original_input : {ndarray, dataframe}\n        Original input of function.\n\n    estimator : estimator instance\n        Estimator with to get the output configuration from.\n\n    index : array-like, default=None\n        Index for output data. Only used when the output container is a\n        pandas DataFrame. If `None`, then the index are taken from\n        `original_input`.\n\n    Returns\n    -------\n    output : {ndarray, dataframe}\n        If the output config is \"default\" or the estimator is not configured\n        for wrapping return `data_to_wrap` unchanged.\n        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n        DataFrame.\n    \"\"\"\n    output_config = _get_output_config(method, estimator)\n\n    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n        return data_to_wrap\n\n    # dense_config == \"pandas\"\n    # Check if original_input has an index and if it's compatible with data_to_wrap\n    original_index = getattr(original_input, \"index\", None)\n    if original_index is not None and hasattr(data_to_wrap, '__len__'):\n        # Only use original index if shapes are compatible\n        if len(original_index) != len(data_to_wrap):\n            original_index = None\n    \n    return _wrap_in_pandas_container(\n        data_to_wrap=data_to_wrap,\n        index=original_index,\n        columns=estimator.get_feature_names_out,\n    )\n",
      "\ndef _wrap_data_with_container(\n    method, data_to_wrap, original_input, estimator\n):\n    \"\"\"Wrap output with container based on an estimator's or global config.\n\n    Parameters\n    ----------\n    method : {\"transform\"}\n        Estimator's method to get container output for.\n\n    data_to_wrap : {ndarray, dataframe}\n        Data to wrap with container.\n\n    original_input : {ndarray, dataframe}\n        Original input of function.\n\n    estimator : estimator instance\n        Estimator with to get the output configuration from.\n\n    Returns\n    -------\n    output : {ndarray, dataframe}\n        If the output config is \"default\" or the estimator is not configured\n        for wrapping return `data_to_wrap` unchanged.\n        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n        DataFrame.\n    \"\"\"\n    output_config = _get_output_config(method, estimator)\n\n    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n        return data_to_wrap\n\n    # dense_config == \"pandas\"\n    # Check if data shape changed, if so don't pass original index\n    original_index = getattr(original_input, \"index\", None)\n    if original_index is not None and hasattr(data_to_wrap, '__len__') and len(data_to_wrap) != len(original_index):\n        original_index = None\n    \n    return _wrap_in_pandas_container(\n        data_to_wrap=data_to_wrap,\n        index=original_index,\n        columns=estimator.get_feature_names_out,\n    )\n",
      "\ndef _wrap_data_with_container(\n    method, data_to_wrap, original_input, estimator\n):\n    \"\"\"Wrap output with container based on an estimator's or global config.\n\n    Parameters\n    ----------\n    method : {\"transform\"}\n        Estimator's method to get container output for.\n\n    data_to_wrap : {ndarray, dataframe}\n        Data to wrap with container.\n\n    original_input : {ndarray, dataframe}\n        Original input of function.\n\n    estimator : estimator instance\n        Estimator with to get the output configuration from.\n\n    Returns\n    -------\n    output : {ndarray, dataframe}\n        If the output config is \"default\" or the estimator is not configured\n        for wrapping return `data_to_wrap` unchanged.\n        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n        DataFrame.\n    \"\"\"\n    output_config = _get_output_config(method, estimator)\n\n    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n        return data_to_wrap\n\n    # dense_config == \"pandas\"\n    # Check if shapes are compatible before using original index\n    original_index = getattr(original_input, \"index\", None)\n    if original_index is not None and len(original_index) != len(data_to_wrap):\n        # Shape mismatch detected, don't use original index\n        original_index = None\n    \n    return _wrap_in_pandas_container(\n        data_to_wrap=data_to_wrap,\n        index=original_index,\n        columns=estimator.get_feature_names_out,\n    )\n",
      "\ndef _wrap_data_with_container(\n    method, data_to_wrap, original_input, estimator, *, index=None\n):\n    \"\"\"Wrap output with container based on an estimator's or global config.\n\n    Parameters\n    ----------\n    method : {\"transform\"}\n        Estimator's method to get container output for.\n\n    data_to_wrap : {ndarray, dataframe}\n        Data to wrap with container.\n\n    original_input : {ndarray, dataframe}\n        Original input of function.\n\n    estimator : estimator instance\n        Estimator with to get the output configuration from.\n\n    index : array-like, default=None\n        Index for output.\n\n    Returns\n    -------\n    output : {ndarray, dataframe}\n        If the output config is \"default\" or the estimator is not configured\n        for wrapping return `data_to_wrap` unchanged.\n        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n        DataFrame.\n    \"\"\"\n    output_config = _get_output_config(method, estimator)\n\n    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n        return data_to_wrap\n\n    # dense_config == \"pandas\"\n    # Check if shapes are compatible before using original index\n    original_index = getattr(original_input, \"index\", None)\n    if (original_index is not None and \n        hasattr(data_to_wrap, '__len__') and \n        len(original_index) != len(data_to_wrap)):\n        # Shape mismatch detected, don't use original index\n        original_index = None\n    \n    return _wrap_in_pandas_container(\n        data_to_wrap=data_to_wrap,\n        index=original_index,\n        columns=estimator.get_feature_names_out,\n    )\n"
    ],
    "Location 4 (/root/hy/projects_4/scikit-learn/sklearn/pipeline.py lines 1254-1277)": [
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            # For pandas output, concatenate directly and return without further wrapping\n            # This avoids index length mismatch issues when transformers change data dimensions\n            result = pd.concat(Xs, axis=1)\n            # Reset index to avoid carrying over mismatched indices from individual transformers\n            result.reset_index(drop=True, inplace=True)\n            return result\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n",
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            # Return concatenated DataFrame directly without index wrapping\n            # to avoid length mismatch when transformers aggregate data\n            result = pd.concat(Xs, axis=1)\n            # Reset index to avoid inheritance of potentially mismatched indices\n            result.index = pd.RangeIndex(len(result))\n            return result\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n",
      "\ndef transform(self, X):\n    \"\"\"Transform X separately by each transformer, concatenate results.\n\n    Parameters\n    ----------\n    X : iterable or array-like, depending on transformers\n        Input data to be transformed.\n\n    Returns\n    -------\n    X_t : array-like or sparse matrix of \\\n            shape (n_samples, sum_n_components)\n        The `hstack` of results of transformers. `sum_n_components` is the\n        sum of `n_components` (output dimension) over transformers.\n    \"\"\"\n    Xs = Parallel(n_jobs=self.n_jobs)(\n        delayed(_transform_one)(trans, X, None, weight)\n        for name, trans, weight in self._iter()\n    )\n    if not Xs:\n        # All transformers are None\n        return np.zeros((X.shape[0], 0))\n\n    # Check if any transformer changed the number of rows\n    input_n_samples = X.shape[0] if hasattr(X, 'shape') else len(X)\n    output_n_samples = Xs[0].shape[0] if hasattr(Xs[0], 'shape') else len(Xs[0])\n    shape_changed = input_n_samples != output_n_samples\n    \n    result = self._hstack(Xs)\n    \n    # If shape changed and we have pandas output, mark it to avoid index wrapping\n    if shape_changed and hasattr(result, 'iloc'):\n        # Set a special attribute to signal that index wrapping should be skipped\n        result._sklearn_shape_changed = True\n    \n    return result\n",
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            # Return concatenated DataFrame directly without further index wrapping\n            # This prevents the output wrapper from trying to set the original input's index\n            # on the potentially aggregated result\n            result = pd.concat(Xs, axis=1)\n            # Mark this as already properly wrapped to avoid double-wrapping\n            if hasattr(result, '_sklearn_pandas_wrapped'):\n                result._sklearn_pandas_wrapped = True\n            return result\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n",
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            # Use ignore_index=True to avoid index length mismatch issues\n            # when transformers change the number of rows\n            return pd.concat(Xs, axis=1, ignore_index=True)\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n",
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            # Return concatenated DataFrame directly without index wrapping\n            # to avoid length mismatch when transformers aggregate data\n            result = pd.concat(Xs, axis=1)\n            # Reset index to avoid conflicts with original input index\n            result.reset_index(drop=True, inplace=True)\n            return result\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n",
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            result = pd.concat(Xs, axis=1)\n            # For pandas output, return the concatenated result directly\n            # to avoid index mismatch issues when transformers change data shape\n            return result\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n",
      "\n    def transform(self, X):\n        \"\"\"Transform X separately by each transformer, concatenate results.\n\n        Parameters\n        ----------\n        X : iterable or array-like, depending on transformers\n            Input data to be transformed.\n\n        Returns\n        -------\n        X_t : array-like or sparse matrix of \\\n                shape (n_samples, sum_n_components)\n            The `hstack` of results of transformers. `sum_n_components` is the\n            sum of `n_components` (output dimension) over transformers.\n        \"\"\"\n        Xs = Parallel(n_jobs=self.n_jobs)(\n            delayed(_transform_one)(trans, X, None, weight)\n            for name, trans, weight in self._iter()\n        )\n        if not Xs:\n            # All transformers are None\n            return np.zeros((X.shape[0], 0))\n\n        return self._hstack(Xs)\n"
    ],
    "Location 5 (/root/hy/projects_4/scikit-learn/sklearn/utils/_set_output.py lines 143-150)": [
      "\ndef _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            # Check if shape changed to avoid index mismatch\n            first_output = data_to_wrap[0]\n            if hasattr(X, 'shape') and hasattr(first_output, 'shape') and X.shape[0] != first_output.shape[0]:\n                # Shape changed, don't pass original index to avoid mismatch\n                wrapped_first = _wrap_data_with_container(method, first_output, None, self)\n            else:\n                wrapped_first = _wrap_data_with_container(method, first_output, X, self)\n            return (wrapped_first, *data_to_wrap[1:])\n\n        # Check if shape changed to avoid index mismatch\n        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape') and X.shape[0] != data_to_wrap.shape[0]:\n            # Shape changed, don't pass original index to avoid mismatch\n            return _wrap_data_with_container(method, data_to_wrap, None, self)\n        \n        return _wrap_data_with_container(method, data_to_wrap, X, self)\n\n    return wrapped\n",
      "\ndef _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            # Check if the first output has compatible shape with input\n            first_output = data_to_wrap[0]\n            if hasattr(X, 'shape') and hasattr(first_output, 'shape') and len(X.shape) > 0 and len(first_output.shape) > 0:\n                if X.shape[0] != first_output.shape[0]:\n                    # Shape mismatch detected, skip index preservation\n                    return (\n                        _wrap_data_with_container(method, first_output, None, self),\n                        *data_to_wrap[1:],\n                    )\n            return (\n                _wrap_data_with_container(method, first_output, X, self),\n                *data_to_wrap[1:],\n            )\n\n        # Check if output has compatible shape with input\n        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape') and len(X.shape) > 0 and len(data_to_wrap.shape) > 0:\n            if X.shape[0] != data_to_wrap.shape[0]:\n                # Shape mismatch detected, skip index preservation\n                return _wrap_data_with_container(method, data_to_wrap, None, self)\n        \n        return _wrap_data_with_container(method, data_to_wrap, X, self)\n\n    return wrapped\n",
      "\ndef _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        \n        # Check if data dimensions match input for safe pandas wrapping\n        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape'):\n            if isinstance(data_to_wrap, tuple):\n                # For tuple outputs, check the first element\n                first_output = data_to_wrap[0]\n                if hasattr(first_output, 'shape') and len(first_output) != len(X):\n                    # Shape mismatch detected, skip index preservation\n                    return data_to_wrap\n            elif len(data_to_wrap) != len(X):\n                # Shape mismatch detected, skip index preservation\n                return data_to_wrap\n        \n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            return (\n                _wrap_data_with_container(method, data_to_wrap[0], X, self),\n                *data_to_wrap[1:],\n            )\n\n        return _wrap_data_with_container(method, data_to_wrap, X, self)\n\n    return wrapped\n",
      "\ndef _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            # Check if first output has compatible shape with input\n            first_output = data_to_wrap[0]\n            if hasattr(first_output, 'shape') and hasattr(X, 'shape') and len(first_output.shape) >= 1 and len(X.shape) >= 1:\n                if first_output.shape[0] != X.shape[0]:\n                    # Shape mismatch detected, return unwrapped data\n                    return data_to_wrap\n            return (\n                _wrap_data_with_container(method, data_to_wrap[0], X, self),\n                *data_to_wrap[1:],\n            )\n\n        # Check if output has compatible shape with input\n        if hasattr(data_to_wrap, 'shape') and hasattr(X, 'shape') and len(data_to_wrap.shape) >= 1 and len(X.shape) >= 1:\n            if data_to_wrap.shape[0] != X.shape[0]:\n                # Shape mismatch detected, return unwrapped data\n                return data_to_wrap\n        return _wrap_data_with_container(method, data_to_wrap, X, self)\n\n    return wrapped\n",
      "\ndef _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            # Check if first output has same shape as input before wrapping\n            first_output = data_to_wrap[0]\n            if hasattr(X, 'shape') and hasattr(first_output, 'shape') and X.shape[0] != first_output.shape[0]:\n                # Shape mismatch - don't pass original input for index preservation\n                wrapped_first = _wrap_data_with_container(method, first_output, None, self)\n            else:\n                wrapped_first = _wrap_data_with_container(method, first_output, X, self)\n            return (\n                wrapped_first,\n                *data_to_wrap[1:],\n            )\n\n        # Check if output has same shape as input before wrapping\n        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape') and X.shape[0] != data_to_wrap.shape[0]:\n            # Shape mismatch - don't pass original input for index preservation\n            return _wrap_data_with_container(method, data_to_wrap, None, self)\n        \n        return _wrap_data_with_container(method, data_to_wrap, X, self)\n\n    return wrapped\n",
      "\ndef _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            # Check if first output has compatible shape with input\n            first_output = data_to_wrap[0]\n            if hasattr(first_output, 'shape') and hasattr(X, 'shape') and first_output.shape[0] != X.shape[0]:\n                # Shape mismatch detected, skip index preservation\n                return (\n                    _wrap_data_with_container(method, first_output, None, self),\n                    *data_to_wrap[1:],\n                )\n            return (\n                _wrap_data_with_container(method, first_output, X, self),\n                *data_to_wrap[1:],\n            )\n\n        # Check if output has compatible shape with input\n        if hasattr(data_to_wrap, 'shape') and hasattr(X, 'shape') and data_to_wrap.shape[0] != X.shape[0]:\n            # Shape mismatch detected, skip index preservation\n            return _wrap_data_with_container(method, data_to_wrap, None, self)\n\n        return _wrap_data_with_container(method, data_to_wrap, X, self)\n\n    return wrapped\n",
      "\ndef _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        \n        # Check if data dimensions changed (e.g., due to aggregation)\n        original_n_samples = getattr(X, 'shape', [len(X)])[0] if hasattr(X, '__len__') else None\n        \n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            result_data = data_to_wrap[0]\n            result_n_samples = getattr(result_data, 'shape', [len(result_data)])[0] if hasattr(result_data, '__len__') else None\n            \n            # Skip wrapping if dimensions don't match to avoid index length mismatch\n            if original_n_samples is not None and result_n_samples is not None and original_n_samples != result_n_samples:\n                return data_to_wrap\n            \n            return (\n                _wrap_data_with_container(method, result_data, X, self),\n                *data_to_wrap[1:],\n            )\n\n        # Check single output case\n        result_n_samples = getattr(data_to_wrap, 'shape', [len(data_to_wrap)])[0] if hasattr(data_to_wrap, '__len__') else None\n        \n        # Skip wrapping if dimensions don't match to avoid index length mismatch\n        if original_n_samples is not None and result_n_samples is not None and original_n_samples != result_n_samples:\n            return data_to_wrap\n\n        return _wrap_data_with_container(method, data_to_wrap, X, self)\n\n    return wrapped\n",
      "\ndef _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            # Check if first output has same shape as input before wrapping\n            first_output = data_to_wrap[0]\n            if hasattr(X, 'shape') and hasattr(first_output, 'shape') and X.shape[0] != first_output.shape[0]:\n                # Shape mismatch detected, skip pandas wrapping for this output\n                return data_to_wrap\n            return (\n                _wrap_data_with_container(method, first_output, X, self),\n                *data_to_wrap[1:],\n            )\n\n        # Check if output has same shape as input before wrapping\n        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape') and X.shape[0] != data_to_wrap.shape[0]:\n            # Shape mismatch detected, skip pandas wrapping\n            return data_to_wrap\n        return _wrap_data_with_container(method, data_to_wrap, X, self)\n\n    return wrapped\n"
    ]
  },
  "combined_diffs": {
    "raw_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..73a8e6256 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1251,6 +1251,7 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n             for idx, (name, transformer, weight) in enumerate(transformers, 1)\n         )\n \n+\n     def transform(self, X):\n         \"\"\"Transform X separately by each transformer, concatenate results.\n \n@@ -1276,6 +1277,7 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n \n         return self._hstack(Xs)\n \n+\n     def _hstack(self, Xs):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..797b77313 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -53,10 +53,13 @@ def _wrap_in_pandas_container(\n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n     if isinstance(data_to_wrap, pd.DataFrame):\n+\n         if columns is not None:\n             data_to_wrap.columns = columns\n         if index is not None:\n-            data_to_wrap.index = index\n+            # Check if index length matches data length to avoid length mismatch\n+            if len(index) == len(data_to_wrap):\n+                data_to_wrap.index = index\n         return data_to_wrap\n \n     return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n@@ -124,12 +127,21 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     output_config = _get_output_config(method, estimator)\n \n     if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n+\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    # Check if data shape matches original input before passing index\n+    original_index = getattr(original_input, \"index\", None)\n+    if (original_index is not None and \n+        hasattr(data_to_wrap, \"__len__\") and \n+        len(original_index) != len(data_to_wrap)):\n+        # Don't pass index if lengths don't match (e.g., aggregating transformers)\n+        original_index = None\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n+        index=original_index,\n         columns=estimator.get_feature_names_out,\n     )\n \n@@ -140,6 +152,7 @@ def _wrap_method_output(f, method):\n     @wraps(f)\n     def wrapped(self, X, *args, **kwargs):\n         data_to_wrap = f(self, X, *args, **kwargs)\n+\n         if isinstance(data_to_wrap, tuple):\n             # only wrap the first output for cross decomposition\n             return (\n",
    "variant_0": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..f079be335 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1251,36 +1251,67 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n             for idx, (name, transformer, weight) in enumerate(transformers, 1)\n         )\n \n-    def transform(self, X):\n-        \"\"\"Transform X separately by each transformer, concatenate results.\n \n-        Parameters\n-        ----------\n-        X : iterable or array-like, depending on transformers\n-            Input data to be transformed.\n+def transform(self, X):\n+    \"\"\"Transform X separately by each transformer, concatenate results.\n \n-        Returns\n-        -------\n-        X_t : array-like or sparse matrix of \\\n-                shape (n_samples, sum_n_components)\n-            The `hstack` of results of transformers. `sum_n_components` is the\n-            sum of `n_components` (output dimension) over transformers.\n-        \"\"\"\n-        Xs = Parallel(n_jobs=self.n_jobs)(\n-            delayed(_transform_one)(trans, X, None, weight)\n-            for name, trans, weight in self._iter()\n-        )\n-        if not Xs:\n-            # All transformers are None\n-            return np.zeros((X.shape[0], 0))\n+    Parameters\n+    ----------\n+    X : iterable or array-like, depending on transformers\n+        Input data to be transformed.\n+\n+    Returns\n+    -------\n+    X_t : array-like or sparse matrix of \\\n+            shape (n_samples, sum_n_components)\n+        The `hstack` of results of transformers. `sum_n_components` is the\n+        sum of `n_components` (output dimension) over transformers.\n+    \"\"\"\n+    Xs = Parallel(n_jobs=self.n_jobs)(\n+        delayed(_transform_one)(trans, X, None, weight)\n+        for name, trans, weight in self._iter()\n+    )\n+    if not Xs:\n+        # All transformers are None\n+        return np.zeros((X.shape[0], 0))\n+\n+    # Check if any transformer changed the number of rows\n+    original_n_rows = X.shape[0]\n+    result_has_different_shape = any(\n+        hasattr(Xt, 'shape') and Xt.shape[0] != original_n_rows \n+        for Xt in Xs if Xt is not None\n+    )\n+    \n+    result = self._hstack(Xs)\n+    \n+    # If shape changed and we're using pandas output, mark the result\n+    # to prevent automatic index wrapping in _wrap_method_output\n+    if result_has_different_shape:\n+        config = _get_output_config(\"transform\", self)\n+        if config[\"dense\"] == \"pandas\" and hasattr(result, 'iloc'):\n+            # Add a marker attribute to indicate shape change\n+            result._sklearn_shape_changed = True\n+    \n+    return result\n \n-        return self._hstack(Xs)\n \n     def _hstack(self, Xs):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            result = pd.concat(Xs, axis=1)\n+            # Mark the result to avoid automatic index wrapping since concat already\n+            # creates proper DataFrame with appropriate index handling\n+            if hasattr(result, '_sklearn_no_index_wrap'):\n+                result._sklearn_no_index_wrap = True\n+            else:\n+                # Use a more compatible approach - store flag in attrs if available\n+                try:\n+                    result.attrs['_sklearn_no_index_wrap'] = True\n+                except (AttributeError, TypeError):\n+                    # Fallback: reset index to avoid length mismatch issues\n+                    result = result.reset_index(drop=True)\n+            return result\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..2ddbfb890 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -52,10 +52,45 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n+    if isinstance(data_to_wrap, pd.DataFrame):\n+\n+def _wrap_in_pandas_container(\n+    data_to_wrap,\n+    *,\n+    columns,\n+    index,\n+):\n+    \"\"\"Create a pandas container holding the data.\n+\n+    Parameters\n+    ----------\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to be wrapped in a pandas container.\n+    columns : callable, ndarray, or None\n+        The column names or a callable that returns the column names. The\n+        number of names must match the number of columns in `data_to_wrap`.\n+        If `None`, then no column names are set.\n+    index : array-like, default=None\n+        The index for the dataframe. If `None`, then the default index\n+        is used.\n+\n+    Returns\n+    -------\n+    dataframe : DataFrame\n+        Container with the data.\n+    \"\"\"\n+    if callable(columns):\n+        try:\n+            columns = columns()\n+        except Exception:\n+            columns = None\n+\n+    pd = check_pandas_support(\"Setting output container to 'pandas'\")\n+\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n-        if index is not None:\n+        if index is not None and len(index) == len(data_to_wrap):\n             data_to_wrap.index = index\n         return data_to_wrap\n \n@@ -123,17 +158,61 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     \"\"\"\n     output_config = _get_output_config(method, estimator)\n \n+    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n+\n+def _wrap_data_with_container(\n+    method, data_to_wrap, original_input, estimator\n+):\n+    \"\"\"Wrap output with container based on an estimator's or global config.\n+\n+    Parameters\n+    ----------\n+    method : {\"transform\"}\n+        Estimator's method to get container output for.\n+\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to wrap with container.\n+\n+    original_input : {ndarray, dataframe}\n+        Original input of function.\n+\n+    estimator : estimator instance\n+        Estimator with to get the output configuration from.\n+\n+    Returns\n+    -------\n+    output : {ndarray, dataframe}\n+        If the output config is \"default\" or the estimator is not configured\n+        for wrapping return `data_to_wrap` unchanged.\n+        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n+        DataFrame.\n+    \"\"\"\n+    output_config = _get_output_config(method, estimator)\n+\n     if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    # Check if data shape changed (e.g., due to aggregation)\n+    original_index = getattr(original_input, \"index\", None)\n+    if original_index is not None and hasattr(data_to_wrap, 'shape') and len(original_index) != data_to_wrap.shape[0]:\n+        # Shape mismatch - don't use original index\n+        original_index = None\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n+        index=original_index,\n         columns=estimator.get_feature_names_out,\n     )\n \n \n+def _wrap_method_output(f, method):\n+    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n+\n+    @wraps(f)\n+    def wrapped(self, X, *args, **kwargs):\n+        data_to_wrap = f(self, X, *args, **kwargs)\n+\n def _wrap_method_output(f, method):\n     \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n \n@@ -142,15 +221,26 @@ def _wrap_method_output(f, method):\n         data_to_wrap = f(self, X, *args, **kwargs)\n         if isinstance(data_to_wrap, tuple):\n             # only wrap the first output for cross decomposition\n-            return (\n-                _wrap_data_with_container(method, data_to_wrap[0], X, self),\n-                *data_to_wrap[1:],\n-            )\n-\n+            # Check if the first output has same shape as input before wrapping\n+            first_output = data_to_wrap[0]\n+            if hasattr(X, 'shape') and hasattr(first_output, 'shape') and X.shape[0] != first_output.shape[0]:\n+                # Shape mismatch detected, wrap without original index\n+                wrapped_first = _wrap_data_with_container(method, first_output, None, self)\n+            else:\n+                wrapped_first = _wrap_data_with_container(method, first_output, X, self)\n+            return (wrapped_first, *data_to_wrap[1:])\n+\n+        # Check if output has same shape as input before wrapping\n+        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape') and X.shape[0] != data_to_wrap.shape[0]:\n+            # Shape mismatch detected, wrap without original index\n+            return _wrap_data_with_container(method, data_to_wrap, None, self)\n+        \n         return _wrap_data_with_container(method, data_to_wrap, X, self)\n \n     return wrapped\n \n+    return wrapped\n+\n \n def _auto_wrap_is_configured(estimator):\n     \"\"\"Return True if estimator is configured for auto-wrapping the transform method.\n",
    "variant_1": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..d2824ce04 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1251,36 +1251,31 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n             for idx, (name, transformer, weight) in enumerate(transformers, 1)\n         )\n \n-    def transform(self, X):\n-        \"\"\"Transform X separately by each transformer, concatenate results.\n \n-        Parameters\n-        ----------\n-        X : iterable or array-like, depending on transformers\n-            Input data to be transformed.\n+    def _hstack(self, Xs):\n+        config = _get_output_config(\"transform\", self)\n+        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n+            pd = check_pandas_support(\"transform\")\n+            # For pandas output, concatenate directly and return without further wrapping\n+            # This avoids index length mismatch issues when transformers change data dimensions\n+            result = pd.concat(Xs, axis=1)\n+            # Reset index to avoid carrying over mismatched indices from individual transformers\n+            result.reset_index(drop=True, inplace=True)\n+            return result\n \n-        Returns\n-        -------\n-        X_t : array-like or sparse matrix of \\\n-                shape (n_samples, sum_n_components)\n-            The `hstack` of results of transformers. `sum_n_components` is the\n-            sum of `n_components` (output dimension) over transformers.\n-        \"\"\"\n-        Xs = Parallel(n_jobs=self.n_jobs)(\n-            delayed(_transform_one)(trans, X, None, weight)\n-            for name, trans, weight in self._iter()\n-        )\n-        if not Xs:\n-            # All transformers are None\n-            return np.zeros((X.shape[0], 0))\n+        if any(sparse.issparse(f) for f in Xs):\n+            Xs = sparse.hstack(Xs).tocsr()\n+        else:\n \n-        return self._hstack(Xs)\n \n     def _hstack(self, Xs):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            result = pd.concat(Xs, axis=1)\n+            # Mark the result to skip index wrapping since concat already handles indexing\n+            result._sklearn_skip_index_wrapping = True\n+            return result\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..8eade29fc 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -52,13 +52,61 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n+    if isinstance(data_to_wrap, pd.DataFrame):\n+\n+def _wrap_in_pandas_container(\n+    data_to_wrap, *, columns, index, data_to_wrap_original\n+):\n+    \"\"\"Wrap output in a pandas container.\n+\n+    If the output is a DataFrame and has the same shape as the original input,\n+    then the columns and index can be set. Otherwise, only set columns and\n+    index if they are compatible with the new shape.\n+\n+    Parameters\n+    ----------\n+    data_to_wrap : {ndarray, dataframe}\n+        The output to be wrapped in a pandas container.\n+    columns : callable, ndarray, or None\n+        The column names or a callable that returns the column names. The\n+        callable is useful if the column names require some computation.\n+        If `columns` is a callable that raises an error, `columns` will have\n+        the same semantics as `None`. If `None`, then no columns are set.\n+    index : array-like, default=None\n+        The index for the dataframe. If `None`, then the index is not set.\n+    data_to_wrap_original : {ndarray, dataframe}\n+        The original input passed to the estimator.\n+\n+    Returns\n+    -------\n+    dataframe\n+        Container with the data_to_wrap.\n+    \"\"\"\n+    try:\n+        import pandas as pd\n+    except ImportError:\n+        raise ImportError(\"pandas is required to use the 'pandas' output format.\")\n+\n+    if callable(columns):\n+        try:\n+            columns = columns()\n+        except Exception:\n+            columns = None\n+\n+    pd = check_pandas_support(\"Setting output container to 'pandas'\")\n+\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n-        if index is not None:\n+        # Only set index if it's compatible with the data shape\n+        if index is not None and len(index) == len(data_to_wrap):\n             data_to_wrap.index = index\n         return data_to_wrap\n \n+    # For new DataFrames, only use index if it's compatible\n+    if index is not None and hasattr(data_to_wrap, '__len__') and len(index) != len(data_to_wrap):\n+        index = None\n+    \n     return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n \n \n@@ -123,17 +171,62 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     \"\"\"\n     output_config = _get_output_config(method, estimator)\n \n+    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n+\n+def _wrap_data_with_container(\n+    method, data_to_wrap, original_input, estimator\n+):\n+    \"\"\"Wrap output with container based on an estimator's or global config.\n+\n+    Parameters\n+    ----------\n+    method : {\"transform\"}\n+        Estimator's method to get container output for.\n+\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to wrap with container.\n+\n+    original_input : {ndarray, dataframe}\n+        Original input of function.\n+\n+    estimator : estimator instance\n+        Estimator with to get the output configuration from.\n+\n+    Returns\n+    -------\n+    output : {ndarray, dataframe}\n+        If the output config is \"default\" or the estimator is not configured\n+        for wrapping return `data_to_wrap` unchanged.\n+        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n+        DataFrame.\n+    \"\"\"\n+    output_config = _get_output_config(method, estimator)\n+\n     if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    # Check if shape changed to avoid index mismatch\n+    original_index = getattr(original_input, \"index\", None)\n+    if (original_index is not None and \n+        hasattr(data_to_wrap, '__len__') and \n+        len(original_index) != len(data_to_wrap)):\n+        original_index = None\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n+        index=original_index,\n         columns=estimator.get_feature_names_out,\n     )\n \n \n+def _wrap_method_output(f, method):\n+    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n+\n+    @wraps(f)\n+    def wrapped(self, X, *args, **kwargs):\n+        data_to_wrap = f(self, X, *args, **kwargs)\n+\n def _wrap_method_output(f, method):\n     \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n \n@@ -142,15 +235,26 @@ def _wrap_method_output(f, method):\n         data_to_wrap = f(self, X, *args, **kwargs)\n         if isinstance(data_to_wrap, tuple):\n             # only wrap the first output for cross decomposition\n-            return (\n-                _wrap_data_with_container(method, data_to_wrap[0], X, self),\n-                *data_to_wrap[1:],\n-            )\n-\n+            # Check if shape changed to avoid index mismatch\n+            first_output = data_to_wrap[0]\n+            if hasattr(X, 'shape') and hasattr(first_output, 'shape') and X.shape[0] != first_output.shape[0]:\n+                # Shape changed, don't pass original index to avoid mismatch\n+                wrapped_first = _wrap_data_with_container(method, first_output, None, self)\n+            else:\n+                wrapped_first = _wrap_data_with_container(method, first_output, X, self)\n+            return (wrapped_first, *data_to_wrap[1:])\n+\n+        # Check if shape changed to avoid index mismatch\n+        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape') and X.shape[0] != data_to_wrap.shape[0]:\n+            # Shape changed, don't pass original index to avoid mismatch\n+            return _wrap_data_with_container(method, data_to_wrap, None, self)\n+        \n         return _wrap_data_with_container(method, data_to_wrap, X, self)\n \n     return wrapped\n \n+    return wrapped\n+\n \n def _auto_wrap_is_configured(estimator):\n     \"\"\"Return True if estimator is configured for auto-wrapping the transform method.\n",
    "variant_2": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..b0ec46f9a 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1251,36 +1251,31 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n             for idx, (name, transformer, weight) in enumerate(transformers, 1)\n         )\n \n-    def transform(self, X):\n-        \"\"\"Transform X separately by each transformer, concatenate results.\n \n-        Parameters\n-        ----------\n-        X : iterable or array-like, depending on transformers\n-            Input data to be transformed.\n+    def _hstack(self, Xs):\n+        config = _get_output_config(\"transform\", self)\n+        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n+            pd = check_pandas_support(\"transform\")\n+            # Return concatenated DataFrame directly without index wrapping\n+            # to avoid length mismatch when transformers aggregate data\n+            result = pd.concat(Xs, axis=1)\n+            # Reset index to avoid inheritance of potentially mismatched indices\n+            result.index = pd.RangeIndex(len(result))\n+            return result\n \n-        Returns\n-        -------\n-        X_t : array-like or sparse matrix of \\\n-                shape (n_samples, sum_n_components)\n-            The `hstack` of results of transformers. `sum_n_components` is the\n-            sum of `n_components` (output dimension) over transformers.\n-        \"\"\"\n-        Xs = Parallel(n_jobs=self.n_jobs)(\n-            delayed(_transform_one)(trans, X, None, weight)\n-            for name, trans, weight in self._iter()\n-        )\n-        if not Xs:\n-            # All transformers are None\n-            return np.zeros((X.shape[0], 0))\n+        if any(sparse.issparse(f) for f in Xs):\n+            Xs = sparse.hstack(Xs).tocsr()\n+        else:\n \n-        return self._hstack(Xs)\n \n     def _hstack(self, Xs):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            result = pd.concat(Xs, axis=1)\n+            # Mark the result to skip automatic index wrapping since concat already handles indexing\n+            result._sklearn_skip_index_wrap = True\n+            return result\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..5153e651f 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -52,10 +52,32 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n+    if isinstance(data_to_wrap, pd.DataFrame):\n+\n+def _wrap_in_pandas_container(\n+    data_to_wrap,\n+    *,\n+    columns,\n+    index,\n+):\n+    \"\"\"Create a pandas DataFrame.\n+\n+    If `data_to_wrap` is a DataFrame, then the `columns` and `index` will be\n+    changed inplace. If `data_to_wrap` is a ndarray, then a new DataFrame is\n+    created.\n+    \"\"\"\n+    if callable(columns):\n+        try:\n+            columns = columns()\n+        except Exception:\n+            columns = None\n+\n+    pd = check_pandas_support(\"Setting output container to 'pandas'\")\n+\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n-        if index is not None:\n+        if index is not None and len(index) == len(data_to_wrap):\n             data_to_wrap.index = index\n         return data_to_wrap\n \n@@ -123,17 +145,63 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     \"\"\"\n     output_config = _get_output_config(method, estimator)\n \n+    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n+\n+def _wrap_data_with_container(\n+    method, data_to_wrap, original_input, estimator\n+):\n+    \"\"\"Wrap output with container based on an estimator's or global config.\n+\n+    Parameters\n+    ----------\n+    method : {\"transform\"}\n+        Estimator's method to get container output for.\n+\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to wrap with container.\n+\n+    original_input : {ndarray, dataframe}\n+        Original input of function.\n+\n+    estimator : estimator instance\n+        Estimator with to get the output configuration from.\n+\n+    Returns\n+    -------\n+    output : {ndarray, dataframe}\n+        If the output config is \"default\" or the estimator is not configured\n+        for wrapping return `data_to_wrap` unchanged.\n+        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n+        DataFrame.\n+    \"\"\"\n+    output_config = _get_output_config(method, estimator)\n+\n     if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    # Check if data shape changed (e.g., from aggregation) to avoid index mismatch\n+    original_index = getattr(original_input, \"index\", None)\n+    if (original_index is not None and \n+        hasattr(data_to_wrap, '__len__') and \n+        len(original_index) != len(data_to_wrap)):\n+        # Shape changed, don't use original index\n+        original_index = None\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n+        index=original_index,\n         columns=estimator.get_feature_names_out,\n     )\n \n \n+def _wrap_method_output(f, method):\n+    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n+\n+    @wraps(f)\n+    def wrapped(self, X, *args, **kwargs):\n+        data_to_wrap = f(self, X, *args, **kwargs)\n+\n def _wrap_method_output(f, method):\n     \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n \n@@ -142,15 +210,32 @@ def _wrap_method_output(f, method):\n         data_to_wrap = f(self, X, *args, **kwargs)\n         if isinstance(data_to_wrap, tuple):\n             # only wrap the first output for cross decomposition\n+            # Check if the first output has compatible shape with input\n+            first_output = data_to_wrap[0]\n+            if hasattr(X, 'shape') and hasattr(first_output, 'shape') and len(X.shape) > 0 and len(first_output.shape) > 0:\n+                if X.shape[0] != first_output.shape[0]:\n+                    # Shape mismatch detected, skip index preservation\n+                    return (\n+                        _wrap_data_with_container(method, first_output, None, self),\n+                        *data_to_wrap[1:],\n+                    )\n             return (\n-                _wrap_data_with_container(method, data_to_wrap[0], X, self),\n+                _wrap_data_with_container(method, first_output, X, self),\n                 *data_to_wrap[1:],\n             )\n \n+        # Check if output has compatible shape with input\n+        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape') and len(X.shape) > 0 and len(data_to_wrap.shape) > 0:\n+            if X.shape[0] != data_to_wrap.shape[0]:\n+                # Shape mismatch detected, skip index preservation\n+                return _wrap_data_with_container(method, data_to_wrap, None, self)\n+        \n         return _wrap_data_with_container(method, data_to_wrap, X, self)\n \n     return wrapped\n \n+    return wrapped\n+\n \n def _auto_wrap_is_configured(estimator):\n     \"\"\"Return True if estimator is configured for auto-wrapping the transform method.\n",
    "variant_3": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..70e33dfd8 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1251,36 +1251,55 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n             for idx, (name, transformer, weight) in enumerate(transformers, 1)\n         )\n \n-    def transform(self, X):\n-        \"\"\"Transform X separately by each transformer, concatenate results.\n \n-        Parameters\n-        ----------\n-        X : iterable or array-like, depending on transformers\n-            Input data to be transformed.\n+def transform(self, X):\n+    \"\"\"Transform X separately by each transformer, concatenate results.\n \n-        Returns\n-        -------\n-        X_t : array-like or sparse matrix of \\\n-                shape (n_samples, sum_n_components)\n-            The `hstack` of results of transformers. `sum_n_components` is the\n-            sum of `n_components` (output dimension) over transformers.\n-        \"\"\"\n-        Xs = Parallel(n_jobs=self.n_jobs)(\n-            delayed(_transform_one)(trans, X, None, weight)\n-            for name, trans, weight in self._iter()\n-        )\n-        if not Xs:\n-            # All transformers are None\n-            return np.zeros((X.shape[0], 0))\n+    Parameters\n+    ----------\n+    X : iterable or array-like, depending on transformers\n+        Input data to be transformed.\n+\n+    Returns\n+    -------\n+    X_t : array-like or sparse matrix of \\\n+            shape (n_samples, sum_n_components)\n+        The `hstack` of results of transformers. `sum_n_components` is the\n+        sum of `n_components` (output dimension) over transformers.\n+    \"\"\"\n+    Xs = Parallel(n_jobs=self.n_jobs)(\n+        delayed(_transform_one)(trans, X, None, weight)\n+        for name, trans, weight in self._iter()\n+    )\n+    if not Xs:\n+        # All transformers are None\n+        return np.zeros((X.shape[0], 0))\n+\n+    # Check if any transformer changed the number of rows\n+    input_n_samples = X.shape[0] if hasattr(X, 'shape') else len(X)\n+    output_n_samples = Xs[0].shape[0] if hasattr(Xs[0], 'shape') else len(Xs[0])\n+    shape_changed = input_n_samples != output_n_samples\n+    \n+    result = self._hstack(Xs)\n+    \n+    # If shape changed and we have pandas output, mark it to avoid index wrapping\n+    if shape_changed and hasattr(result, 'iloc'):\n+        # Set a special attribute to signal that index wrapping should be skipped\n+        result._sklearn_shape_changed = True\n+    \n+    return result\n \n-        return self._hstack(Xs)\n \n     def _hstack(self, Xs):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            # Concatenate DataFrames and return directly to avoid index wrapping issues\n+            # when transformers change the number of rows (e.g., aggregation)\n+            result = pd.concat(Xs, axis=1)\n+            # Reset index to avoid length mismatch with original input index\n+            result.reset_index(drop=True, inplace=True)\n+            return result\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..ee0d4d0bc 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -52,10 +52,32 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n+    if isinstance(data_to_wrap, pd.DataFrame):\n+\n+def _wrap_in_pandas_container(\n+    data_to_wrap,\n+    *,\n+    columns,\n+    index,\n+):\n+    \"\"\"Create a pandas DataFrame.\n+\n+    If `data_to_wrap` is a DataFrame, then the `columns` and `index` will be\n+    changed inplace. If `data_to_wrap` is a ndarray, then a new DataFrame is\n+    created.\n+    \"\"\"\n+    if callable(columns):\n+        try:\n+            columns = columns()\n+        except Exception:\n+            columns = None\n+\n+    pd = check_pandas_support(\"Setting output container to 'pandas'\")\n+\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n-        if index is not None:\n+        if index is not None and len(index) == len(data_to_wrap):\n             data_to_wrap.index = index\n         return data_to_wrap\n \n@@ -123,13 +145,50 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     \"\"\"\n     output_config = _get_output_config(method, estimator)\n \n+    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n+\n+def _wrap_data_with_container(\n+    method, data_to_wrap, original_input, estimator\n+):\n+    \"\"\"Wrap output with container based on an estimator's or global config.\n+\n+    Parameters\n+    ----------\n+    method : {\"transform\"}\n+        Estimator's method to get container output for.\n+\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to wrap with container.\n+\n+    original_input : {ndarray, dataframe}\n+        Original input of function.\n+\n+    estimator : estimator instance\n+        Estimator with to get the output configuration from.\n+\n+    Returns\n+    -------\n+    output : {ndarray, dataframe}\n+        If the output config is \"default\" or the estimator is not configured\n+        for wrapping return `data_to_wrap` unchanged.\n+        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n+        DataFrame.\n+    \"\"\"\n+    output_config = _get_output_config(method, estimator)\n+\n     if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    # Check if the data shape is compatible with the original input's index\n+    original_index = getattr(original_input, \"index\", None)\n+    if original_index is not None and hasattr(data_to_wrap, '__len__') and len(data_to_wrap) != len(original_index):\n+        # Shape mismatch detected, don't use original index\n+        original_index = None\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n+        index=original_index,\n         columns=estimator.get_feature_names_out,\n     )\n \n@@ -140,6 +199,26 @@ def _wrap_method_output(f, method):\n     @wraps(f)\n     def wrapped(self, X, *args, **kwargs):\n         data_to_wrap = f(self, X, *args, **kwargs)\n+\n+def _wrap_method_output(f, method):\n+    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n+\n+    @wraps(f)\n+    def wrapped(self, X, *args, **kwargs):\n+        data_to_wrap = f(self, X, *args, **kwargs)\n+        \n+        # Check if data dimensions match input for safe pandas wrapping\n+        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape'):\n+            if isinstance(data_to_wrap, tuple):\n+                # For tuple outputs, check the first element\n+                first_output = data_to_wrap[0]\n+                if hasattr(first_output, 'shape') and len(first_output) != len(X):\n+                    # Shape mismatch detected, skip index preservation\n+                    return data_to_wrap\n+            elif len(data_to_wrap) != len(X):\n+                # Shape mismatch detected, skip index preservation\n+                return data_to_wrap\n+        \n         if isinstance(data_to_wrap, tuple):\n             # only wrap the first output for cross decomposition\n             return (\n@@ -151,6 +230,8 @@ def _wrap_method_output(f, method):\n \n     return wrapped\n \n+    return wrapped\n+\n \n def _auto_wrap_is_configured(estimator):\n     \"\"\"Return True if estimator is configured for auto-wrapping the transform method.\n",
    "variant_4": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..ec16f6e0a 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1251,36 +1251,34 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n             for idx, (name, transformer, weight) in enumerate(transformers, 1)\n         )\n \n-    def transform(self, X):\n-        \"\"\"Transform X separately by each transformer, concatenate results.\n \n-        Parameters\n-        ----------\n-        X : iterable or array-like, depending on transformers\n-            Input data to be transformed.\n+    def _hstack(self, Xs):\n+        config = _get_output_config(\"transform\", self)\n+        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n+            pd = check_pandas_support(\"transform\")\n+            # Return concatenated DataFrame directly without further index wrapping\n+            # This prevents the output wrapper from trying to set the original input's index\n+            # on the potentially aggregated result\n+            result = pd.concat(Xs, axis=1)\n+            # Mark this as already properly wrapped to avoid double-wrapping\n+            if hasattr(result, '_sklearn_pandas_wrapped'):\n+                result._sklearn_pandas_wrapped = True\n+            return result\n \n-        Returns\n-        -------\n-        X_t : array-like or sparse matrix of \\\n-                shape (n_samples, sum_n_components)\n-            The `hstack` of results of transformers. `sum_n_components` is the\n-            sum of `n_components` (output dimension) over transformers.\n-        \"\"\"\n-        Xs = Parallel(n_jobs=self.n_jobs)(\n-            delayed(_transform_one)(trans, X, None, weight)\n-            for name, trans, weight in self._iter()\n-        )\n-        if not Xs:\n-            # All transformers are None\n-            return np.zeros((X.shape[0], 0))\n+        if any(sparse.issparse(f) for f in Xs):\n+            Xs = sparse.hstack(Xs).tocsr()\n+        else:\n \n-        return self._hstack(Xs)\n \n     def _hstack(self, Xs):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            result = pd.concat(Xs, axis=1)\n+            # Mark the result to indicate it was created by pandas concat\n+            # and shouldn't have its index overwritten by the output wrapper\n+            result._sklearn_pandas_concat = True\n+            return result\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..09acb958a 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -52,10 +52,53 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n+    if isinstance(data_to_wrap, pd.DataFrame):\n+\n+def _wrap_in_pandas_container(\n+    data_to_wrap, *, columns, index, data_to_wrap_original\n+):\n+    \"\"\"Create a Pandas DataFrame.\n+\n+    If `data_to_wrap` is a DataFrame, then the `columns` and `index` will be\n+    changed inplace. If `data_to_wrap` is a ndarray, then a new DataFrame is\n+    created.\n+\n+    Parameters\n+    ----------\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to be wrapped as pandas dataframe.\n+\n+    columns : callable, ndarray, or None\n+        The column names or a callable that returns the column names. The\n+        callable is useful if the column names require some computation.\n+        If `columns` is a callable that raises an error, `columns` will have\n+        the same semantics as `None`. If `None`, then the columns will be\n+        numbered.\n+\n+    index : ndarray or None\n+        Index for data. If `None`, then the index will be numbered.\n+\n+    data_to_wrap_original : ndarray\n+        Original input data before transformation. This parameter is not used\n+        directly but is part of the function signature for consistency.\n+\n+    Returns\n+    -------\n+    dataframe : DataFrame\n+        Container with column names or unchanged `output`.\n+    \"\"\"\n+    if callable(columns):\n+        try:\n+            columns = columns()\n+        except Exception:\n+            columns = None\n+\n+    pd = check_pandas_support(\"Setting output container to 'pandas'\")\n+\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n-        if index is not None:\n+        if index is not None and len(index) == len(data_to_wrap):\n             data_to_wrap.index = index\n         return data_to_wrap\n \n@@ -123,17 +166,59 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     \"\"\"\n     output_config = _get_output_config(method, estimator)\n \n+    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n+\n+def _wrap_data_with_container(\n+    method, data_to_wrap, original_input, estimator\n+):\n+    \"\"\"Wrap output with container based on an estimator's or global config.\n+\n+    Parameters\n+    ----------\n+    method : str\n+        The method name calling this function.\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to be wrapped with container.\n+    original_input : {ndarray, dataframe}\n+        Original input of method.\n+    estimator : estimator instance\n+        Estimator with to get the output configuration from.\n+\n+    Returns\n+    -------\n+    output : {ndarray, dataframe}\n+        If the output config is \"default\" or the estimator is not configured\n+        for wrapping return `data_to_wrap` unchanged.\n+        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n+        DataFrame.\n+    \"\"\"\n+    output_config = _get_output_config(method, estimator)\n+\n     if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    # Check if shapes are compatible before passing original index\n+    original_index = getattr(original_input, \"index\", None)\n+    if original_index is not None and hasattr(data_to_wrap, \"__len__\"):\n+        if len(data_to_wrap) != len(original_index):\n+            # Shape mismatch - don't use original index\n+            original_index = None\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n+        index=original_index,\n         columns=estimator.get_feature_names_out,\n     )\n \n \n+def _wrap_method_output(f, method):\n+    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n+\n+    @wraps(f)\n+    def wrapped(self, X, *args, **kwargs):\n+        data_to_wrap = f(self, X, *args, **kwargs)\n+\n def _wrap_method_output(f, method):\n     \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n \n@@ -142,15 +227,28 @@ def _wrap_method_output(f, method):\n         data_to_wrap = f(self, X, *args, **kwargs)\n         if isinstance(data_to_wrap, tuple):\n             # only wrap the first output for cross decomposition\n+            # Check if first output has compatible shape with input\n+            first_output = data_to_wrap[0]\n+            if hasattr(first_output, 'shape') and hasattr(X, 'shape') and len(first_output.shape) >= 1 and len(X.shape) >= 1:\n+                if first_output.shape[0] != X.shape[0]:\n+                    # Shape mismatch detected, return unwrapped data\n+                    return data_to_wrap\n             return (\n                 _wrap_data_with_container(method, data_to_wrap[0], X, self),\n                 *data_to_wrap[1:],\n             )\n \n+        # Check if output has compatible shape with input\n+        if hasattr(data_to_wrap, 'shape') and hasattr(X, 'shape') and len(data_to_wrap.shape) >= 1 and len(X.shape) >= 1:\n+            if data_to_wrap.shape[0] != X.shape[0]:\n+                # Shape mismatch detected, return unwrapped data\n+                return data_to_wrap\n         return _wrap_data_with_container(method, data_to_wrap, X, self)\n \n     return wrapped\n \n+    return wrapped\n+\n \n def _auto_wrap_is_configured(estimator):\n     \"\"\"Return True if estimator is configured for auto-wrapping the transform method.\n",
    "variant_5": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..b46d4b254 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1251,36 +1251,29 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n             for idx, (name, transformer, weight) in enumerate(transformers, 1)\n         )\n \n-    def transform(self, X):\n-        \"\"\"Transform X separately by each transformer, concatenate results.\n \n-        Parameters\n-        ----------\n-        X : iterable or array-like, depending on transformers\n-            Input data to be transformed.\n+    def _hstack(self, Xs):\n+        config = _get_output_config(\"transform\", self)\n+        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n+            pd = check_pandas_support(\"transform\")\n+            # Use ignore_index=True to avoid index length mismatch issues\n+            # when transformers change the number of rows\n+            return pd.concat(Xs, axis=1, ignore_index=True)\n \n-        Returns\n-        -------\n-        X_t : array-like or sparse matrix of \\\n-                shape (n_samples, sum_n_components)\n-            The `hstack` of results of transformers. `sum_n_components` is the\n-            sum of `n_components` (output dimension) over transformers.\n-        \"\"\"\n-        Xs = Parallel(n_jobs=self.n_jobs)(\n-            delayed(_transform_one)(trans, X, None, weight)\n-            for name, trans, weight in self._iter()\n-        )\n-        if not Xs:\n-            # All transformers are None\n-            return np.zeros((X.shape[0], 0))\n+        if any(sparse.issparse(f) for f in Xs):\n+            Xs = sparse.hstack(Xs).tocsr()\n+        else:\n \n-        return self._hstack(Xs)\n \n     def _hstack(self, Xs):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            result = pd.concat(Xs, axis=1)\n+            # Mark the result to indicate it shouldn't have its index modified\n+            # by the output wrapping mechanism, since concat already handles indexing\n+            result._sklearn_no_index_wrap = True\n+            return result\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..1d4102a45 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -52,10 +52,60 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n+    if isinstance(data_to_wrap, pd.DataFrame):\n+\n+def _wrap_in_pandas_container(\n+    data_to_wrap, *, columns, index=None, force_all_finite=True\n+):\n+    \"\"\"Wrap output in a pandas container.\n+\n+    Parameters\n+    ----------\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to be wrapped as pandas dataframe.\n+\n+    columns : callable, ndarray, or None\n+        The column names or a callable that returns the column names. The\n+        callable is useful if the column names require some computation.\n+        If `columns` is a callable that raises an error, `columns` will have\n+        the same semantics as `None`. If `None` and `data_to_wrap` is already a\n+        dataframe, then the column names are not changed. If `None` and\n+        `data_to_wrap` is **not** a dataframe, then columns are\n+        `range(n_features)`.\n+\n+    index : array-like, default=None\n+        Index for data. `index` is ignored if `data_to_wrap` is already a\n+        DataFrame.\n+\n+    force_all_finite : bool, default=True\n+        Whether to raise an error on np.inf, np.nan, pd.NA in array.\n+        The possibilities are:\n+        - True: Force all values of array to be finite.\n+        - False: accepts np.inf, np.nan, pd.NA in array.\n+\n+    Returns\n+    -------\n+    dataframe : DataFrame\n+        Container with column names or unchanged `output`.\n+    \"\"\"\n+    if issparse(data_to_wrap):\n+        raise ValueError(\"Pandas output does not support sparse data.\")\n+\n+    if force_all_finite:\n+        _assert_all_finite(data_to_wrap, allow_nan=False)\n+\n+    if callable(columns):\n+        try:\n+            columns = columns()\n+        except Exception:\n+            columns = None\n+\n+    pd = check_pandas_support(\"Setting output container to 'pandas'\")\n+\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n-        if index is not None:\n+        if index is not None and len(index) == len(data_to_wrap):\n             data_to_wrap.index = index\n         return data_to_wrap\n \n@@ -123,17 +173,67 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     \"\"\"\n     output_config = _get_output_config(method, estimator)\n \n+    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n+\n+def _wrap_data_with_container(\n+    method, data_to_wrap, original_input, estimator, *, index=None\n+):\n+    \"\"\"Wrap output with container based on an estimator's or global config.\n+\n+    Parameters\n+    ----------\n+    method : str\n+        Method to call on the estimator. Can be \"transform\" or \"fit_transform\".\n+\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to wrap with container.\n+\n+    original_input : {ndarray, dataframe}\n+        Original input of function.\n+\n+    estimator : estimator instance\n+        Estimator with to get the output configuration from.\n+\n+    index : array-like, default=None\n+        Index for output data. Only used when the output container is a\n+        pandas DataFrame. If `None`, then the index are taken from\n+        `original_input`.\n+\n+    Returns\n+    -------\n+    output : {ndarray, dataframe}\n+        If the output config is \"default\" or the estimator is not configured\n+        for wrapping return `data_to_wrap` unchanged.\n+        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n+        DataFrame.\n+    \"\"\"\n+    output_config = _get_output_config(method, estimator)\n+\n     if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    # Check if original_input has an index and if it's compatible with data_to_wrap\n+    original_index = getattr(original_input, \"index\", None)\n+    if original_index is not None and hasattr(data_to_wrap, '__len__'):\n+        # Only use original index if shapes are compatible\n+        if len(original_index) != len(data_to_wrap):\n+            original_index = None\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n+        index=original_index,\n         columns=estimator.get_feature_names_out,\n     )\n \n \n+def _wrap_method_output(f, method):\n+    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n+\n+    @wraps(f)\n+    def wrapped(self, X, *args, **kwargs):\n+        data_to_wrap = f(self, X, *args, **kwargs)\n+\n def _wrap_method_output(f, method):\n     \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n \n@@ -142,15 +242,29 @@ def _wrap_method_output(f, method):\n         data_to_wrap = f(self, X, *args, **kwargs)\n         if isinstance(data_to_wrap, tuple):\n             # only wrap the first output for cross decomposition\n+            # Check if first output has same shape as input before wrapping\n+            first_output = data_to_wrap[0]\n+            if hasattr(X, 'shape') and hasattr(first_output, 'shape') and X.shape[0] != first_output.shape[0]:\n+                # Shape mismatch - don't pass original input for index preservation\n+                wrapped_first = _wrap_data_with_container(method, first_output, None, self)\n+            else:\n+                wrapped_first = _wrap_data_with_container(method, first_output, X, self)\n             return (\n-                _wrap_data_with_container(method, data_to_wrap[0], X, self),\n+                wrapped_first,\n                 *data_to_wrap[1:],\n             )\n \n+        # Check if output has same shape as input before wrapping\n+        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape') and X.shape[0] != data_to_wrap.shape[0]:\n+            # Shape mismatch - don't pass original input for index preservation\n+            return _wrap_data_with_container(method, data_to_wrap, None, self)\n+        \n         return _wrap_data_with_container(method, data_to_wrap, X, self)\n \n     return wrapped\n \n+    return wrapped\n+\n \n def _auto_wrap_is_configured(estimator):\n     \"\"\"Return True if estimator is configured for auto-wrapping the transform method.\n",
    "variant_6": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..d0acf66f0 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1251,36 +1251,32 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n             for idx, (name, transformer, weight) in enumerate(transformers, 1)\n         )\n \n-    def transform(self, X):\n-        \"\"\"Transform X separately by each transformer, concatenate results.\n \n-        Parameters\n-        ----------\n-        X : iterable or array-like, depending on transformers\n-            Input data to be transformed.\n+    def _hstack(self, Xs):\n+        config = _get_output_config(\"transform\", self)\n+        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n+            pd = check_pandas_support(\"transform\")\n+            # Return concatenated DataFrame directly without index wrapping\n+            # to avoid length mismatch when transformers aggregate data\n+            result = pd.concat(Xs, axis=1)\n+            # Reset index to avoid conflicts with original input index\n+            result.reset_index(drop=True, inplace=True)\n+            return result\n \n-        Returns\n-        -------\n-        X_t : array-like or sparse matrix of \\\n-                shape (n_samples, sum_n_components)\n-            The `hstack` of results of transformers. `sum_n_components` is the\n-            sum of `n_components` (output dimension) over transformers.\n-        \"\"\"\n-        Xs = Parallel(n_jobs=self.n_jobs)(\n-            delayed(_transform_one)(trans, X, None, weight)\n-            for name, trans, weight in self._iter()\n-        )\n-        if not Xs:\n-            # All transformers are None\n-            return np.zeros((X.shape[0], 0))\n+        if any(sparse.issparse(f) for f in Xs):\n+            Xs = sparse.hstack(Xs).tocsr()\n+        else:\n \n-        return self._hstack(Xs)\n \n     def _hstack(self, Xs):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            result = pd.concat(Xs, axis=1)\n+            # Mark the result to indicate it should not have its index modified\n+            # by the output wrapping mechanism, since concat already handles indexing\n+            result._sklearn_no_index_wrap = True\n+            return result\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..2941b3e09 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -52,10 +52,61 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n+    if isinstance(data_to_wrap, pd.DataFrame):\n+\n+def _wrap_in_pandas_container(\n+    data_to_wrap, *, columns, index, data_to_wrap_original, original_input\n+):\n+    \"\"\"Create a Pandas DataFrame.\n+\n+    If `data_to_wrap` is a DataFrame, then the `columns` and `index` will be\n+    changed inplace. If `data_to_wrap` is a ndarray, then a new DataFrame is\n+    created.\n+\n+    Parameters\n+    ----------\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to be wrapped as pandas dataframe.\n+\n+    columns : callable, ndarray, or None\n+        The column names or a callable that returns the column names. The\n+        callable is useful if the column names require some computation.\n+        If `columns` is a callable that raises an error, `columns` will have\n+        the same semantics as `None`. If `None` and `data_to_wrap` is already a\n+        dataframe, then the column names are not changed. If `None` and\n+        `data_to_wrap` is **not** a dataframe, then columns are\n+        `range(n_features)`.\n+\n+    index : array-like, default=None\n+        Index for data.\n+\n+    data_to_wrap_original : {ndarray, dataframe}\n+        Original data, before any processing.\n+\n+    original_input : {ndarray, dataframe}\n+        The original input passed to the estimator.\n+\n+    Returns\n+    -------\n+    dataframe : DataFrame\n+        Container with column names or unchanged `output`.\n+    \"\"\"\n+    if issparse(data_to_wrap):\n+        raise ValueError(\"Pandas output does not support sparse data.\")\n+\n+    if callable(columns):\n+        try:\n+            columns = columns()\n+        except Exception:\n+            columns = None\n+\n+    pd = check_pandas_support(\"Setting output container to 'pandas'\")\n+\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n-        if index is not None:\n+        # Check if index length matches before setting to avoid dimension mismatch\n+        if index is not None and len(index) == len(data_to_wrap):\n             data_to_wrap.index = index\n         return data_to_wrap\n \n@@ -123,17 +174,60 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     \"\"\"\n     output_config = _get_output_config(method, estimator)\n \n+    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n+\n+def _wrap_data_with_container(\n+    method, data_to_wrap, original_input, estimator\n+):\n+    \"\"\"Wrap output with container based on an estimator's or global config.\n+\n+    Parameters\n+    ----------\n+    method : {\"transform\"}\n+        Estimator's method to get container output for.\n+\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to wrap with container.\n+\n+    original_input : {ndarray, dataframe}\n+        Original input of function.\n+\n+    estimator : estimator instance\n+        Estimator with to get the output configuration from.\n+\n+    Returns\n+    -------\n+    output : {ndarray, dataframe}\n+        If the output config is \"default\" or the estimator is not configured\n+        for wrapping return `data_to_wrap` unchanged.\n+        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n+        DataFrame.\n+    \"\"\"\n+    output_config = _get_output_config(method, estimator)\n+\n     if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    # Check if data shape changed, if so don't pass original index\n+    original_index = getattr(original_input, \"index\", None)\n+    if original_index is not None and hasattr(data_to_wrap, '__len__') and len(data_to_wrap) != len(original_index):\n+        original_index = None\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n+        index=original_index,\n         columns=estimator.get_feature_names_out,\n     )\n \n \n+def _wrap_method_output(f, method):\n+    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n+\n+    @wraps(f)\n+    def wrapped(self, X, *args, **kwargs):\n+        data_to_wrap = f(self, X, *args, **kwargs)\n+\n def _wrap_method_output(f, method):\n     \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n \n@@ -142,15 +236,30 @@ def _wrap_method_output(f, method):\n         data_to_wrap = f(self, X, *args, **kwargs)\n         if isinstance(data_to_wrap, tuple):\n             # only wrap the first output for cross decomposition\n+            # Check if first output has compatible shape with input\n+            first_output = data_to_wrap[0]\n+            if hasattr(first_output, 'shape') and hasattr(X, 'shape') and first_output.shape[0] != X.shape[0]:\n+                # Shape mismatch detected, skip index preservation\n+                return (\n+                    _wrap_data_with_container(method, first_output, None, self),\n+                    *data_to_wrap[1:],\n+                )\n             return (\n-                _wrap_data_with_container(method, data_to_wrap[0], X, self),\n+                _wrap_data_with_container(method, first_output, X, self),\n                 *data_to_wrap[1:],\n             )\n \n+        # Check if output has compatible shape with input\n+        if hasattr(data_to_wrap, 'shape') and hasattr(X, 'shape') and data_to_wrap.shape[0] != X.shape[0]:\n+            # Shape mismatch detected, skip index preservation\n+            return _wrap_data_with_container(method, data_to_wrap, None, self)\n+\n         return _wrap_data_with_container(method, data_to_wrap, X, self)\n \n     return wrapped\n \n+    return wrapped\n+\n \n def _auto_wrap_is_configured(estimator):\n     \"\"\"Return True if estimator is configured for auto-wrapping the transform method.\n",
    "variant_7": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..db72652c0 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1251,36 +1251,29 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n             for idx, (name, transformer, weight) in enumerate(transformers, 1)\n         )\n \n-    def transform(self, X):\n-        \"\"\"Transform X separately by each transformer, concatenate results.\n \n-        Parameters\n-        ----------\n-        X : iterable or array-like, depending on transformers\n-            Input data to be transformed.\n+    def _hstack(self, Xs):\n+        config = _get_output_config(\"transform\", self)\n+        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n+            pd = check_pandas_support(\"transform\")\n+            result = pd.concat(Xs, axis=1)\n+            # For pandas output, return the concatenated result directly\n+            # to avoid index mismatch issues when transformers change data shape\n+            return result\n \n-        Returns\n-        -------\n-        X_t : array-like or sparse matrix of \\\n-                shape (n_samples, sum_n_components)\n-            The `hstack` of results of transformers. `sum_n_components` is the\n-            sum of `n_components` (output dimension) over transformers.\n-        \"\"\"\n-        Xs = Parallel(n_jobs=self.n_jobs)(\n-            delayed(_transform_one)(trans, X, None, weight)\n-            for name, trans, weight in self._iter()\n-        )\n-        if not Xs:\n-            # All transformers are None\n-            return np.zeros((X.shape[0], 0))\n+        if any(sparse.issparse(f) for f in Xs):\n+            Xs = sparse.hstack(Xs).tocsr()\n+        else:\n \n-        return self._hstack(Xs)\n \n     def _hstack(self, Xs):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            result = pd.concat(Xs, axis=1)\n+            # Mark the result to skip automatic index wrapping since concat already handles indexing\n+            result._sklearn_skip_index_wrap = True\n+            return result\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..4648d6b6b 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -52,13 +52,52 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n+    if isinstance(data_to_wrap, pd.DataFrame):\n+\n+def _wrap_in_pandas_container(\n+    data_to_wrap, *, columns, index, data_to_wrap_original\n+):\n+    \"\"\"Wrap output in a pandas container.\n+\n+    Parameters\n+    ----------\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to be wrapped in a pandas container.\n+    columns : callable, ndarray, or None\n+        The column names or a callable that returns the column names. The\n+        callable is useful if the column names require some computation.\n+        If `columns` is a callable that raises an error, `columns` will have\n+        the same semantics as `None`. If `None` and `data_to_wrap` is already a\n+        dataframe, then the column names are not changed. If `None` and\n+        `data_to_wrap` is **not** a dataframe, then columns are given the\n+        default names.\n+    index : array-like, default=None\n+        Index for data.\n+    data_to_wrap_original : {ndarray, dataframe}\n+        Original input data.\n+    \"\"\"\n+    if issparse(data_to_wrap):\n+        raise ValueError(\"Pandas output does not support sparse data.\")\n+\n+    if callable(columns):\n+        try:\n+            columns = columns()\n+        except Exception:\n+            columns = None\n+\n+    pd = check_pandas_support(\"Setting output container to 'pandas'\")\n+\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n-        if index is not None:\n+        if index is not None and len(index) == len(data_to_wrap):\n             data_to_wrap.index = index\n         return data_to_wrap\n \n+    # Check if index length matches data length before creating DataFrame\n+    if index is not None and len(index) != len(data_to_wrap):\n+        index = None\n+    \n     return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n \n \n@@ -123,13 +162,50 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     \"\"\"\n     output_config = _get_output_config(method, estimator)\n \n+    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n+\n+def _wrap_data_with_container(\n+    method, data_to_wrap, original_input, estimator\n+):\n+    \"\"\"Wrap output with container based on an estimator's or global config.\n+\n+    Parameters\n+    ----------\n+    method : {\"transform\"}\n+        Estimator's method to get container output for.\n+\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to wrap with container.\n+\n+    original_input : {ndarray, dataframe}\n+        Original input of function.\n+\n+    estimator : estimator instance\n+        Estimator with to get the output configuration from.\n+\n+    Returns\n+    -------\n+    output : {ndarray, dataframe}\n+        If the output config is \"default\" or the estimator is not configured\n+        for wrapping return `data_to_wrap` unchanged.\n+        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n+        DataFrame.\n+    \"\"\"\n+    output_config = _get_output_config(method, estimator)\n+\n     if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    # Check if shapes are compatible before using original index\n+    original_index = getattr(original_input, \"index\", None)\n+    if original_index is not None and len(original_index) != len(data_to_wrap):\n+        # Shape mismatch detected, don't use original index\n+        original_index = None\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n+        index=original_index,\n         columns=estimator.get_feature_names_out,\n     )\n \n@@ -140,17 +216,44 @@ def _wrap_method_output(f, method):\n     @wraps(f)\n     def wrapped(self, X, *args, **kwargs):\n         data_to_wrap = f(self, X, *args, **kwargs)\n+\n+def _wrap_method_output(f, method):\n+    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n+\n+    @wraps(f)\n+    def wrapped(self, X, *args, **kwargs):\n+        data_to_wrap = f(self, X, *args, **kwargs)\n+        \n+        # Check if data dimensions changed (e.g., due to aggregation)\n+        original_n_samples = getattr(X, 'shape', [len(X)])[0] if hasattr(X, '__len__') else None\n+        \n         if isinstance(data_to_wrap, tuple):\n             # only wrap the first output for cross decomposition\n+            result_data = data_to_wrap[0]\n+            result_n_samples = getattr(result_data, 'shape', [len(result_data)])[0] if hasattr(result_data, '__len__') else None\n+            \n+            # Skip wrapping if dimensions don't match to avoid index length mismatch\n+            if original_n_samples is not None and result_n_samples is not None and original_n_samples != result_n_samples:\n+                return data_to_wrap\n+            \n             return (\n-                _wrap_data_with_container(method, data_to_wrap[0], X, self),\n+                _wrap_data_with_container(method, result_data, X, self),\n                 *data_to_wrap[1:],\n             )\n \n+        # Check single output case\n+        result_n_samples = getattr(data_to_wrap, 'shape', [len(data_to_wrap)])[0] if hasattr(data_to_wrap, '__len__') else None\n+        \n+        # Skip wrapping if dimensions don't match to avoid index length mismatch\n+        if original_n_samples is not None and result_n_samples is not None and original_n_samples != result_n_samples:\n+            return data_to_wrap\n+\n         return _wrap_data_with_container(method, data_to_wrap, X, self)\n \n     return wrapped\n \n+    return wrapped\n+\n \n def _auto_wrap_is_configured(estimator):\n     \"\"\"Return True if estimator is configured for auto-wrapping the transform method.\n",
    "variant_8": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..32b98a7ec 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1251,6 +1251,7 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n             for idx, (name, transformer, weight) in enumerate(transformers, 1)\n         )\n \n+\n     def transform(self, X):\n         \"\"\"Transform X separately by each transformer, concatenate results.\n \n@@ -1276,11 +1277,16 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n \n         return self._hstack(Xs)\n \n+\n     def _hstack(self, Xs):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            result = pd.concat(Xs, axis=1)\n+            # Mark the result to indicate it should not have its index modified\n+            # by the output wrapping mechanism, as concat already handles indexing properly\n+            result._sklearn_no_index_wrap = True\n+            return result\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..b9fe7993e 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -52,10 +52,48 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n+    if isinstance(data_to_wrap, pd.DataFrame):\n+\n+def _wrap_in_pandas_container(\n+    data_to_wrap, *, columns, index, data_to_wrap_original\n+):\n+    \"\"\"Create a pandas container holding the data.\n+\n+    Parameters\n+    ----------\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to be wrapped as pandas dataframe.\n+\n+    columns : callable, ndarray, or None\n+        The column names or a callable that returns the column names. The\n+        number of names must match the number of columns in `data_to_wrap`.\n+        If `None`, then no column names are set.\n+\n+    index : array-like, default=None\n+        Index for data. `index` is ignored if `data_to_wrap` is already a\n+        DataFrame.\n+\n+    data_to_wrap_original : {ndarray, dataframe}\n+        Original input data.\n+\n+    Returns\n+    -------\n+    dataframe : DataFrame\n+        Container with the data.\n+    \"\"\"\n+    if callable(columns):\n+        try:\n+            columns = columns()\n+        except Exception:\n+            columns = None\n+\n+    pd = check_pandas_support(\"Setting output container to 'pandas'\")\n+\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n-        if index is not None:\n+        # Only set index if it's compatible with the data shape\n+        if index is not None and len(index) == len(data_to_wrap):\n             data_to_wrap.index = index\n         return data_to_wrap\n \n@@ -123,17 +161,66 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     \"\"\"\n     output_config = _get_output_config(method, estimator)\n \n+    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n+\n+def _wrap_data_with_container(\n+    method, data_to_wrap, original_input, estimator, *, index=None\n+):\n+    \"\"\"Wrap output with container based on an estimator's or global config.\n+\n+    Parameters\n+    ----------\n+    method : {\"transform\"}\n+        Estimator's method to get container output for.\n+\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to wrap with container.\n+\n+    original_input : {ndarray, dataframe}\n+        Original input of function.\n+\n+    estimator : estimator instance\n+        Estimator with to get the output configuration from.\n+\n+    index : array-like, default=None\n+        Index for output.\n+\n+    Returns\n+    -------\n+    output : {ndarray, dataframe}\n+        If the output config is \"default\" or the estimator is not configured\n+        for wrapping return `data_to_wrap` unchanged.\n+        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n+        DataFrame.\n+    \"\"\"\n+    output_config = _get_output_config(method, estimator)\n+\n     if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    # Check if shapes are compatible before using original index\n+    original_index = getattr(original_input, \"index\", None)\n+    if (original_index is not None and \n+        hasattr(data_to_wrap, '__len__') and \n+        len(original_index) != len(data_to_wrap)):\n+        # Shape mismatch detected, don't use original index\n+        original_index = None\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n+        index=original_index,\n         columns=estimator.get_feature_names_out,\n     )\n \n \n+def _wrap_method_output(f, method):\n+    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n+\n+    @wraps(f)\n+    def wrapped(self, X, *args, **kwargs):\n+        data_to_wrap = f(self, X, *args, **kwargs)\n+\n def _wrap_method_output(f, method):\n     \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n \n@@ -142,15 +229,26 @@ def _wrap_method_output(f, method):\n         data_to_wrap = f(self, X, *args, **kwargs)\n         if isinstance(data_to_wrap, tuple):\n             # only wrap the first output for cross decomposition\n+            # Check if first output has same shape as input before wrapping\n+            first_output = data_to_wrap[0]\n+            if hasattr(X, 'shape') and hasattr(first_output, 'shape') and X.shape[0] != first_output.shape[0]:\n+                # Shape mismatch detected, skip pandas wrapping for this output\n+                return data_to_wrap\n             return (\n-                _wrap_data_with_container(method, data_to_wrap[0], X, self),\n+                _wrap_data_with_container(method, first_output, X, self),\n                 *data_to_wrap[1:],\n             )\n \n+        # Check if output has same shape as input before wrapping\n+        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape') and X.shape[0] != data_to_wrap.shape[0]:\n+            # Shape mismatch detected, skip pandas wrapping\n+            return data_to_wrap\n         return _wrap_data_with_container(method, data_to_wrap, X, self)\n \n     return wrapped\n \n+    return wrapped\n+\n \n def _auto_wrap_is_configured(estimator):\n     \"\"\"Return True if estimator is configured for auto-wrapping the transform method.\n"
  }
}