{
  "zero_patches": {
    "Location 1 (/root/hy/projects_1/scikit-learn/sklearn/compose/_column_transformer.py lines 865-872)": "\n                transformer_names = []\n                feature_names_outs = []\n                \n                # Only collect names for transformers that actually produced output\n                transformer_iter = self._iter(fitted=True, replace_strings=True)\n                for i, (name, transformer, columns) in enumerate(transformer_iter):\n                    if i < len(Xs) and hasattr(Xs[i], 'columns'):\n                        transformer_names.append(name)\n                        feature_names_outs.append(Xs[i].columns)\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
    "Location 2 (/root/hy/projects_1/scikit-learn/sklearn/compose/_column_transformer.py lines 394-395)": "\n                elif _is_empty_column_selection(columns):\n                    continue\n",
    "Location 3 (/root/hy/projects_1/scikit-learn/sklearn/compose/_column_transformer.py lines 659-663)": "\n        transformers = list(\n            self._iter(\n                fitted=fitted, replace_strings=True, column_as_strings=column_as_strings\n            )\n        )\n        # Track which transformers will actually produce output\n        valid_transformer_indices = []\n        for idx, (name, trans, column, weight) in enumerate(transformers):\n            if not _is_empty_column_selection(column):\n                valid_transformer_indices.append(idx)\n",
    "Location 4 (/root/hy/projects_1/scikit-learn/sklearn/compose/_column_transformer.py lines 907-922)": "\ndef _is_empty_column_selection(column):\n    \"\"\"\n    Return True if the column selection is empty (empty list or all-False\n    boolean array).\n\n    \"\"\"\n    if hasattr(column, \"dtype\") and np.issubdtype(column.dtype, np.bool_):\n        return not column.any()\n    elif hasattr(column, \"__len__\"):\n        return (\n            len(column) == 0\n            or (all(isinstance(col, bool) for col in column)\n            and not any(column))\n        )\n    else:\n        return False\n",
    "Location 5 (/root/hy/projects_1/scikit-learn/sklearn/compose/_column_transformer.py lines 533-580)": "\ndef _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n    \"\"\"Add prefix for feature names out that includes the transformer names.\n\n    Parameters\n    ----------\n    transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n        The tuple consistent of the transformer's name and its feature names out.\n\n    Returns\n    -------\n    feature_names_out : ndarray of shape (n_features,), dtype=str\n        Transformed feature names.\n    \"\"\"\n    # Filter out transformers with empty feature names\n    filtered_transformer_with_feature_names_out = [\n        (name, feature_names_out) \n        for name, feature_names_out in transformer_with_feature_names_out\n        if len(feature_names_out) > 0\n    ]\n    \n    if not filtered_transformer_with_feature_names_out:\n        # No feature names\n        return np.array([], dtype=object)\n    \n    if self.verbose_feature_names_out:\n        # Prefix the feature names out with the transformers name\n        names = list(\n            chain.from_iterable(\n                (f\"{name}__{i}\" for i in feature_names_out)\n                for name, feature_names_out in filtered_transformer_with_feature_names_out\n            )\n        )\n        return np.asarray(names, dtype=object)\n\n    # verbose_feature_names_out is False\n    # Check that names are all unique without a prefix\n    feature_names_count = Counter(\n        chain.from_iterable(s for _, s in filtered_transformer_with_feature_names_out)\n    )\n    top_6_overlap = [\n        name for name, count in feature_names_count.most_common(6) if count > 1\n    ]\n    top_6_overlap.sort()\n    if top_6_overlap:\n        if len(top_6_overlap) == 6:\n            # There are more than 5 overlapping names, we only show the 5\n            # of the feature names\n            names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n        else:\n            names_repr = str(top_6_overlap)\n        raise ValueError(\n            f\"Output feature names: {names_repr} are not unique. Please set \"\n            \"verbose_feature_names_out=True to add prefixes to feature names\"\n        )\n\n    return np.concatenate(\n        [name for _, name in filtered_transformer_with_feature_names_out],\n    )\n"
  },
  "variant_patches": {
    "Location 1 (/root/hy/projects_1/scikit-learn/sklearn/compose/_column_transformer.py lines 865-872)": [
      "\n                transformer_names = []\n                feature_names_outs = []\n                \n                # Only collect names for transformers that actually produced output\n                iter_transformers = list(self._iter(fitted=True, replace_strings=True))\n                for i, (name, transformer, columns) in enumerate(iter_transformers):\n                    if i < len(Xs) and hasattr(Xs[i], 'columns'):\n                        transformer_names.append(name)\n                        feature_names_outs.append(Xs[i].columns)\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
      "\n                transformer_names = []\n                feature_names_outs = []\n                \n                # Only collect names for transformers that actually produced output\n                transformer_iter = iter(self._iter(fitted=True, replace_strings=True))\n                for X in Xs:\n                    if X.shape[1] > 0:  # Only include transformers with actual output\n                        name, _, _ = next(transformer_iter)\n                        transformer_names.append(name)\n                        feature_names_outs.append(X.columns)\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
      "\n                transformer_names = []\n                feature_names_outs = []\n                \n                # Only collect names and features for transformers that actually produced output\n                transformer_iter = self._iter(fitted=True, replace_strings=True)\n                for i, (name, transformer, columns) in enumerate(transformer_iter):\n                    if i < len(Xs):  # Only include transformers that have corresponding output\n                        transformer_names.append(name)\n                        feature_names_outs.append(Xs[i].columns)\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
      "\n                transformer_names = []\n                feature_names_outs = []\n                \n                # Only collect names from transformers that actually produced output\n                transformer_iter = iter(self._iter(fitted=True, replace_strings=True))\n                for X in Xs:\n                    if X.shape[1] > 0:  # Only include if transformer produced columns\n                        name, _, _ = next(transformer_iter)\n                        transformer_names.append(name)\n                        feature_names_outs.append(X.columns)\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
      "\n                transformer_names = []\n                feature_names_outs = []\n                \n                # Only collect names for transformers that actually produced output\n                transformer_iter = self._iter(fitted=True, replace_strings=True)\n                for i, (name, transformer, columns) in enumerate(transformer_iter):\n                    if i < len(Xs) and Xs[i] is not None and Xs[i].shape[1] > 0:\n                        transformer_names.append(name)\n                        feature_names_outs.append(Xs[i].columns)\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
      "\n                transformer_names = []\n                feature_names_outs = []\n                \n                # Only collect names for transformers that actually produced outputs\n                iter_count = 0\n                for name, transformer, columns in self._iter(fitted=True, replace_strings=True):\n                    if not _is_empty_column_selection(columns):\n                        if iter_count < len(Xs):\n                            transformer_names.append(name)\n                            feature_names_outs.append(Xs[iter_count].columns)\n                            iter_count += 1\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
      "\n                transformer_names = [\n                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n                    if not _is_empty_column_selection(t[2])\n                ]\n                feature_names_outs = [X.columns for X in Xs]\n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
      "\n                transformer_names = []\n                feature_names_outs = []\n                \n                # Only collect names for transformers that actually contributed outputs\n                transformer_iter = self._iter(fitted=True, replace_strings=True)\n                for i, (name, transformer, columns) in enumerate(transformer_iter):\n                    if i < len(Xs):  # Only include if there's a corresponding output\n                        transformer_names.append(name)\n                        feature_names_outs.append(Xs[i].columns)\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n"
    ],
    "Location 2 (/root/hy/projects_1/scikit-learn/sklearn/compose/_column_transformer.py lines 394-395)": [
      "\n                # replace 'passthrough' with identity transformer and\n                # skip in case of 'drop'\n                if trans == \"passthrough\":\n                    trans = FunctionTransformer(\n                        accept_sparse=True,\n                        check_inverse=False,\n                        feature_names_out=\"one-to-one\",\n                    ).set_output(transform=output_config[\"dense\"])\n                elif trans == \"drop\":\n                    continue\n                elif _is_empty_column_selection(columns) and not fitted:\n                    continue\n",
      "\n                elif _is_empty_column_selection(columns):\n                    continue\n",
      "\n                elif _is_empty_column_selection(columns):\n                    continue\n",
      "\n                elif _is_empty_column_selection(columns):\n                    # Store information about empty transformers for feature naming\n                    if not fitted:\n                        continue\n                    # When fitted=True, we need to track empty transformers\n                    # to maintain consistency with feature naming\n                    yield name, trans, columns, weight\n                    continue\n",
      "\n                elif _is_empty_column_selection(columns):\n                    # Skip empty column selections, but track them for feature naming consistency\n                    if fitted and hasattr(self, '_empty_transformers'):\n                        self._empty_transformers.add(name)\n                    continue\n",
      "\n                elif _is_empty_column_selection(columns):\n                    # For empty column selections, we need to handle them differently\n                    # based on whether we're in fitted mode and need consistent naming\n                    if fitted and hasattr(self, '_empty_transformers_'):\n                        # Track empty transformers for consistent feature naming\n                        if not hasattr(self, '_empty_transformers_'):\n                            self._empty_transformers_ = []\n                        self._empty_transformers_.append(name)\n                    continue\n",
      "\n                elif _is_empty_column_selection(columns):\n                    if fitted:\n                        # When fitted=True, we need to track empty transformers\n                        # to maintain consistency with feature naming\n                        yield name, trans, columns, weight\n                    continue\n",
      "\n                elif _is_empty_column_selection(columns):\n                    # Skip transformers with empty column selections during iteration\n                    # but track them for consistent feature naming when needed\n                    continue\n"
    ],
    "Location 3 (/root/hy/projects_1/scikit-learn/sklearn/compose/_column_transformer.py lines 659-663)": [
      "\n        transformers = list(\n            self._iter(\n                fitted=fitted, replace_strings=True, column_as_strings=column_as_strings\n            )\n        )\n        # Track which transformers will actually contribute outputs\n        contributing_transformers = []\n        for name, trans, column, weight in transformers:\n            if not _is_empty_column_selection(column):\n                contributing_transformers.append((name, trans, column, weight))\n",
      "\n        transformers = list(\n            self._iter(\n                fitted=fitted, replace_strings=True, column_as_strings=column_as_strings\n            )\n        )\n        # Track which transformers will actually produce output\n        active_transformer_indices = []\n        for idx, (name, trans, column, weight) in enumerate(transformers):\n            if not _is_empty_column_selection(column):\n                active_transformer_indices.append(idx)\n",
      "\n        transformers = list(\n            self._iter(\n                fitted=fitted, replace_strings=True, column_as_strings=column_as_strings\n            )\n        )\n        # Track which transformers will actually produce output\n        active_transformer_indices = []\n        for idx, (name, trans, column, weight) in enumerate(transformers):\n            if not _is_empty_column_selection(column):\n                active_transformer_indices.append(idx)\n",
      "\n        transformers = list(\n            self._iter(\n                fitted=fitted, replace_strings=True, column_as_strings=column_as_strings\n            )\n        )\n        # Track which transformers will actually produce output\n        active_transformer_indices = []\n        for idx, (name, trans, column, weight) in enumerate(transformers):\n            if not _is_empty_column_selection(column):\n                active_transformer_indices.append(idx)\n",
      "\n        transformers = list(\n            self._iter(\n                fitted=fitted, replace_strings=True, column_as_strings=column_as_strings\n            )\n        )\n        # Track which transformers will actually contribute to output\n        contributing_transformers = []\n        for name, trans, column, weight in transformers:\n            if not _is_empty_column_selection(column):\n                contributing_transformers.append((name, trans, column, weight))\n",
      "\n        transformers = list(\n            self._iter(\n                fitted=fitted, replace_strings=True, column_as_strings=column_as_strings\n            )\n        )\n        # Track which transformers will actually produce output\n        active_transformer_indices = []\n        for idx, (name, trans, column, weight) in enumerate(transformers):\n            if not _is_empty_column_selection(column):\n                active_transformer_indices.append(idx)\n",
      "\n        transformers = list(\n            self._iter(\n                fitted=fitted, replace_strings=True, column_as_strings=column_as_strings\n            )\n        )\n        # Track which transformers will actually produce output\n        active_transformer_indices = []\n        for idx, (name, trans, column, weight) in enumerate(transformers):\n            if not _is_empty_column_selection(column):\n                active_transformer_indices.append(idx)\n",
      "\n        transformers = list(\n            self._iter(\n                fitted=fitted, replace_strings=True, column_as_strings=column_as_strings\n            )\n        )\n        # Track which transformers will actually produce outputs\n        active_transformer_indices = []\n        for idx, (name, trans, column, weight) in enumerate(transformers):\n            if not _is_empty_column_selection(column):\n                active_transformer_indices.append(idx)\n"
    ],
    "Location 4 (/root/hy/projects_1/scikit-learn/sklearn/compose/_column_transformer.py lines 907-922)": [
      "\ndef _is_empty_column_selection(column):\n    \"\"\"\n    Return True if the column selection is empty (empty list or all-False\n    boolean array).\n\n    \"\"\"\n    if hasattr(column, \"dtype\") and np.issubdtype(column.dtype, np.bool_):\n        return not column.any()\n    elif hasattr(column, \"__len__\"):\n        return (\n            len(column) == 0\n            or (all(isinstance(col, bool) for col in column)\n            and not any(column))\n        )\n    else:\n        return False\n",
      "\ndef _is_empty_column_selection(column):\n    \"\"\"\n    Return True if the column selection is empty (empty list or all-False\n    boolean array).\n\n    \"\"\"\n    if hasattr(column, \"dtype\") and np.issubdtype(column.dtype, np.bool_):\n        return not column.any()\n    elif hasattr(column, \"__len__\"):\n        return (\n            len(column) == 0\n            or (all(isinstance(col, bool) for col in column)\n                and not any(column))\n        )\n    else:\n        return False\n",
      "\ndef _is_empty_column_selection(column):\n    \"\"\"\n    Return True if the column selection is empty (empty list or all-False\n    boolean array).\n\n    \"\"\"\n    if hasattr(column, \"dtype\") and np.issubdtype(column.dtype, np.bool_):\n        return not column.any()\n    elif hasattr(column, \"__len__\"):\n        return (\n            len(column) == 0\n            or (all(isinstance(col, bool) for col in column)\n            and not any(column))\n        )\n    else:\n        return False\n",
      "\ndef _is_empty_column_selection(column):\n    \"\"\"\n    Return True if the column selection is empty (empty list or all-False\n    boolean array).\n\n    \"\"\"\n    if hasattr(column, \"dtype\") and np.issubdtype(column.dtype, np.bool_):\n        return not column.any()\n    elif hasattr(column, \"__len__\"):\n        return (\n            len(column) == 0\n            or (all(isinstance(col, bool) for col in column)\n                and not any(column))\n        )\n    else:\n        return False\n",
      "\ndef _is_empty_column_selection(column):\n    \"\"\"\n    Return True if the column selection is empty (empty list or all-False\n    boolean array).\n\n    \"\"\"\n    if hasattr(column, \"dtype\") and np.issubdtype(column.dtype, np.bool_):\n        return not column.any()\n    elif hasattr(column, \"__len__\"):\n        return (\n            len(column) == 0\n            or (all(isinstance(col, bool) for col in column)\n            and not any(column))\n        )\n    else:\n        return False\n",
      "\ndef _is_empty_column_selection(column):\n    \"\"\"\n    Return True if the column selection is empty (empty list or all-False\n    boolean array).\n\n    \"\"\"\n    if hasattr(column, \"dtype\") and np.issubdtype(column.dtype, np.bool_):\n        return not column.any()\n    elif hasattr(column, \"__len__\"):\n        return (\n            len(column) == 0\n            or (all(isinstance(col, bool) for col in column)\n                and not any(column))\n        )\n    else:\n        return False\n",
      "\ndef _is_empty_column_selection(column):\n    \"\"\"\n    Return True if the column selection is empty (empty list or all-False\n    boolean array).\n\n    \"\"\"\n    if hasattr(column, \"dtype\") and np.issubdtype(column.dtype, np.bool_):\n        return not column.any()\n    elif hasattr(column, \"__len__\"):\n        return (\n            len(column) == 0\n            or (all(isinstance(col, bool) for col in column)\n            and not any(column))\n        )\n    else:\n        return False\n",
      "\ndef _is_empty_column_selection(column):\n    \"\"\"\n    Return True if the column selection is empty (empty list or all-False\n    boolean array).\n\n    \"\"\"\n    if hasattr(column, \"dtype\") and np.issubdtype(column.dtype, np.bool_):\n        return not column.any()\n    elif hasattr(column, \"__len__\"):\n        return (\n            len(column) == 0\n            or (all(isinstance(col, bool) for col in column)\n                and not any(column))\n        )\n    else:\n        return False\n"
    ],
    "Location 5 (/root/hy/projects_1/scikit-learn/sklearn/compose/_column_transformer.py lines 533-580)": [
      "\ndef _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n    \"\"\"Add prefix for feature names out that includes the transformer names.\n\n    Parameters\n    ----------\n    transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n        The tuple consistent of the transformer's name and its feature names out.\n\n    Returns\n    -------\n    feature_names_out : ndarray of shape (n_features,), dtype=str\n        Transformed feature names.\n    \"\"\"\n    # Filter out transformers with empty feature names to maintain consistency\n    # with the actual output structure\n    non_empty_transformer_features = [\n        (name, feature_names_out) \n        for name, feature_names_out in transformer_with_feature_names_out\n        if len(feature_names_out) > 0\n    ]\n    \n    if not non_empty_transformer_features:\n        # No features from any transformer\n        return np.array([], dtype=object)\n    \n    if self.verbose_feature_names_out:\n        # Prefix the feature names out with the transformers name\n        names = list(\n            chain.from_iterable(\n                (f\"{name}__{i}\" for i in feature_names_out)\n                for name, feature_names_out in non_empty_transformer_features\n            )\n        )\n        return np.asarray(names, dtype=object)\n\n    # verbose_feature_names_out is False\n    # Check that names are all unique without a prefix\n    feature_names_count = Counter(\n        chain.from_iterable(s for _, s in non_empty_transformer_features)\n    )\n    top_6_overlap = [\n        name for name, count in feature_names_count.most_common(6) if count > 1\n    ]\n    top_6_overlap.sort()\n    if top_6_overlap:\n        if len(top_6_overlap) == 6:\n            # There are more than 5 overlapping names, we only show the 5\n            # of the feature names\n            names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n        else:\n            names_repr = str(top_6_overlap)\n        raise ValueError(\n            f\"Output feature names: {names_repr} are not unique. Please set \"\n            \"verbose_feature_names_out=True to add prefixes to feature names\"\n        )\n\n    return np.concatenate(\n        [name for _, name in non_empty_transformer_features],\n    )\n",
      "\ndef _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n    \"\"\"Add prefix for feature names out that includes the transformer names.\n\n    Parameters\n    ----------\n    transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n        The tuple consistent of the transformer's name and its feature names out.\n\n    Returns\n    -------\n    feature_names_out : ndarray of shape (n_features,), dtype=str\n        Transformed feature names.\n    \"\"\"\n    # Filter out transformers with empty feature names\n    non_empty_transformer_with_feature_names_out = [\n        (name, feature_names_out) \n        for name, feature_names_out in transformer_with_feature_names_out\n        if len(feature_names_out) > 0\n    ]\n    \n    if not non_empty_transformer_with_feature_names_out:\n        # No feature names\n        return np.array([], dtype=object)\n    \n    if self.verbose_feature_names_out:\n        # Prefix the feature names out with the transformers name\n        names = list(\n            chain.from_iterable(\n                (f\"{name}__{i}\" for i in feature_names_out)\n                for name, feature_names_out in non_empty_transformer_with_feature_names_out\n            )\n        )\n        return np.asarray(names, dtype=object)\n\n    # verbose_feature_names_out is False\n    # Check that names are all unique without a prefix\n    feature_names_count = Counter(\n        chain.from_iterable(s for _, s in non_empty_transformer_with_feature_names_out)\n    )\n    top_6_overlap = [\n        name for name, count in feature_names_count.most_common(6) if count > 1\n    ]\n    top_6_overlap.sort()\n    if top_6_overlap:\n        if len(top_6_overlap) == 6:\n            # There are more than 5 overlapping names, we only show the 5\n            # of the feature names\n            names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n        else:\n            names_repr = str(top_6_overlap)\n        raise ValueError(\n            f\"Output feature names: {names_repr} are not unique. Please set \"\n            \"verbose_feature_names_out=True to add prefixes to feature names\"\n        )\n\n    return np.concatenate(\n        [name for _, name in non_empty_transformer_with_feature_names_out],\n    )\n",
      "\ndef _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n    \"\"\"Add prefix for feature names out that includes the transformer names.\n\n    Parameters\n    ----------\n    transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n        The tuple consistent of the transformer's name and its feature names out.\n\n    Returns\n    -------\n    feature_names_out : ndarray of shape (n_features,), dtype=str\n        Transformed feature names.\n    \"\"\"\n    # Filter out transformers with empty feature names to avoid mismatches\n    transformer_with_feature_names_out = [\n        (name, feature_names_out) \n        for name, feature_names_out in transformer_with_feature_names_out\n        if len(feature_names_out) > 0\n    ]\n    \n    if not transformer_with_feature_names_out:\n        # No feature names\n        return np.array([], dtype=object)\n    \n    if self.verbose_feature_names_out:\n        # Prefix the feature names out with the transformers name\n        names = list(\n            chain.from_iterable(\n                (f\"{name}__{i}\" for i in feature_names_out)\n                for name, feature_names_out in transformer_with_feature_names_out\n            )\n        )\n        return np.asarray(names, dtype=object)\n\n    # verbose_feature_names_out is False\n    # Check that names are all unique without a prefix\n    feature_names_count = Counter(\n        chain.from_iterable(s for _, s in transformer_with_feature_names_out)\n    )\n    top_6_overlap = [\n        name for name, count in feature_names_count.most_common(6) if count > 1\n    ]\n    top_6_overlap.sort()\n    if top_6_overlap:\n        if len(top_6_overlap) == 6:\n            # There are more than 5 overlapping names, we only show the 5\n            # of the feature names\n            names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n        else:\n            names_repr = str(top_6_overlap)\n        raise ValueError(\n            f\"Output feature names: {names_repr} are not unique. Please set \"\n            \"verbose_feature_names_out=True to add prefixes to feature names\"\n        )\n\n    return np.concatenate(\n        [name for _, name in transformer_with_feature_names_out],\n    )\n",
      "\ndef _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n    \"\"\"Add prefix for feature names out that includes the transformer names.\n\n    Parameters\n    ----------\n    transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n        The tuple consistent of the transformer's name and its feature names out.\n\n    Returns\n    -------\n    feature_names_out : ndarray of shape (n_features,), dtype=str\n        Transformed feature names.\n    \"\"\"\n    # Filter out transformers that have no feature names (empty outputs)\n    transformer_with_feature_names_out = [\n        (name, feature_names) \n        for name, feature_names in transformer_with_feature_names_out\n        if len(feature_names) > 0\n    ]\n    \n    if not transformer_with_feature_names_out:\n        # No feature names after filtering\n        return np.array([], dtype=object)\n    \n    if self.verbose_feature_names_out:\n        # Prefix the feature names out with the transformers name\n        names = list(\n            chain.from_iterable(\n                (f\"{name}__{i}\" for i in feature_names_out)\n                for name, feature_names_out in transformer_with_feature_names_out\n            )\n        )\n        return np.asarray(names, dtype=object)\n\n    # verbose_feature_names_out is False\n    # Check that names are all unique without a prefix\n    feature_names_count = Counter(\n        chain.from_iterable(s for _, s in transformer_with_feature_names_out)\n    )\n    top_6_overlap = [\n        name for name, count in feature_names_count.most_common(6) if count > 1\n    ]\n    top_6_overlap.sort()\n    if top_6_overlap:\n        if len(top_6_overlap) == 6:\n            # There are more than 5 overlapping names, we only show the 5\n            # of the feature names\n            names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n        else:\n            names_repr = str(top_6_overlap)\n        raise ValueError(\n            f\"Output feature names: {names_repr} are not unique. Please set \"\n            \"verbose_feature_names_out=True to add prefixes to feature names\"\n        )\n\n    return np.concatenate(\n        [name for _, name in transformer_with_feature_names_out],\n    )\n",
      "\ndef _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n    \"\"\"Add prefix for feature names out that includes the transformer names.\n\n    Parameters\n    ----------\n    transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n        The tuple consistent of the transformer's name and its feature names out.\n\n    Returns\n    -------\n    feature_names_out : ndarray of shape (n_features,), dtype=str\n        Transformed feature names.\n    \"\"\"\n    # Filter out transformers with empty feature names to ensure consistency\n    non_empty_transformer_features = [\n        (name, feature_names_out) \n        for name, feature_names_out in transformer_with_feature_names_out\n        if len(feature_names_out) > 0\n    ]\n    \n    if not non_empty_transformer_features:\n        # No feature names after filtering empty ones\n        return np.array([], dtype=object)\n    \n    if self.verbose_feature_names_out:\n        # Prefix the feature names out with the transformers name\n        names = list(\n            chain.from_iterable(\n                (f\"{name}__{i}\" for i in feature_names_out)\n                for name, feature_names_out in non_empty_transformer_features\n            )\n        )\n        return np.asarray(names, dtype=object)\n\n    # verbose_feature_names_out is False\n    # Check that names are all unique without a prefix\n    feature_names_count = Counter(\n        chain.from_iterable(s for _, s in non_empty_transformer_features)\n    )\n    top_6_overlap = [\n        name for name, count in feature_names_count.most_common(6) if count > 1\n    ]\n    top_6_overlap.sort()\n    if top_6_overlap:\n        if len(top_6_overlap) == 6:\n            # There are more than 5 overlapping names, we only show the 5\n            # of the feature names\n            names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n        else:\n            names_repr = str(top_6_overlap)\n        raise ValueError(\n            f\"Output feature names: {names_repr} are not unique. Please set \"\n            \"verbose_feature_names_out=True to add prefixes to feature names\"\n        )\n\n    return np.concatenate(\n        [name for _, name in non_empty_transformer_features],\n    )\n",
      "\ndef _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n    \"\"\"Add prefix for feature names out that includes the transformer names.\n\n    Parameters\n    ----------\n    transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n        The tuple consistent of the transformer's name and its feature names out.\n\n    Returns\n    -------\n    feature_names_out : ndarray of shape (n_features,), dtype=str\n        Transformed feature names.\n    \"\"\"\n    # Filter out transformers with empty feature names\n    non_empty_transformer_features = [\n        (name, features) for name, features in transformer_with_feature_names_out\n        if len(features) > 0\n    ]\n    \n    if not non_empty_transformer_features:\n        # No feature names\n        return np.array([], dtype=object)\n    \n    if self.verbose_feature_names_out:\n        # Prefix the feature names out with the transformers name\n        names = list(\n            chain.from_iterable(\n                (f\"{name}__{i}\" for i in feature_names_out)\n                for name, feature_names_out in non_empty_transformer_features\n            )\n        )\n        return np.asarray(names, dtype=object)\n\n    # verbose_feature_names_out is False\n    # Check that names are all unique without a prefix\n    feature_names_count = Counter(\n        chain.from_iterable(s for _, s in non_empty_transformer_features)\n    )\n    top_6_overlap = [\n        name for name, count in feature_names_count.most_common(6) if count > 1\n    ]\n    top_6_overlap.sort()\n    if top_6_overlap:\n        if len(top_6_overlap) == 6:\n            # There are more than 5 overlapping names, we only show the 5\n            # of the feature names\n            names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n        else:\n            names_repr = str(top_6_overlap)\n        raise ValueError(\n            f\"Output feature names: {names_repr} are not unique. Please set \"\n            \"verbose_feature_names_out=True to add prefixes to feature names\"\n        )\n\n    return np.concatenate(\n        [name for _, name in non_empty_transformer_features],\n    )\n",
      "\ndef _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n    \"\"\"Add prefix for feature names out that includes the transformer names.\n\n    Parameters\n    ----------\n    transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n        The tuple consistent of the transformer's name and its feature names out.\n\n    Returns\n    -------\n    feature_names_out : ndarray of shape (n_features,), dtype=str\n        Transformed feature names.\n    \"\"\"\n    # Filter out transformers with empty feature names\n    transformer_with_feature_names_out = [\n        (name, feature_names_out) \n        for name, feature_names_out in transformer_with_feature_names_out\n        if len(feature_names_out) > 0\n    ]\n    \n    if not transformer_with_feature_names_out:\n        # No feature names after filtering\n        return np.array([], dtype=object)\n    \n    if self.verbose_feature_names_out:\n        # Prefix the feature names out with the transformers name\n        names = list(\n            chain.from_iterable(\n                (f\"{name}__{i}\" for i in feature_names_out)\n                for name, feature_names_out in transformer_with_feature_names_out\n            )\n        )\n        return np.asarray(names, dtype=object)\n\n    # verbose_feature_names_out is False\n    # Check that names are all unique without a prefix\n    feature_names_count = Counter(\n        chain.from_iterable(s for _, s in transformer_with_feature_names_out)\n    )\n    top_6_overlap = [\n        name for name, count in feature_names_count.most_common(6) if count > 1\n    ]\n    top_6_overlap.sort()\n    if top_6_overlap:\n        if len(top_6_overlap) == 6:\n            # There are more than 5 overlapping names, we only show the 5\n            # of the feature names\n            names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n        else:\n            names_repr = str(top_6_overlap)\n        raise ValueError(\n            f\"Output feature names: {names_repr} are not unique. Please set \"\n            \"verbose_feature_names_out=True to add prefixes to feature names\"\n        )\n\n    return np.concatenate(\n        [name for _, name in transformer_with_feature_names_out],\n    )\n",
      "\n    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n        \"\"\"Add prefix for feature names out that includes the transformer names.\n\n        Parameters\n        ----------\n        transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n            The tuple consistent of the transformer's name and its feature names out.\n\n        Returns\n        -------\n        feature_names_out : ndarray of shape (n_features,), dtype=str\n            Transformed feature names.\n        \"\"\"\n        # Filter out transformers with empty feature names to ensure consistency\n        # with the actual outputs that were produced\n        filtered_transformer_with_feature_names_out = [\n            (name, feature_names_out) \n            for name, feature_names_out in transformer_with_feature_names_out\n            if len(feature_names_out) > 0\n        ]\n        \n        if not filtered_transformer_with_feature_names_out:\n            # No transformers with actual features\n            return np.array([], dtype=object)\n        \n        if self.verbose_feature_names_out:\n            # Prefix the feature names out with the transformers name\n            names = list(\n                chain.from_iterable(\n                    (f\"{name}__{i}\" for i in feature_names_out)\n                    for name, feature_names_out in filtered_transformer_with_feature_names_out\n                )\n            )\n            return np.asarray(names, dtype=object)\n\n        # verbose_feature_names_out is False\n        # Check that names are all unique without a prefix\n        feature_names_count = Counter(\n            chain.from_iterable(s for _, s in filtered_transformer_with_feature_names_out)\n        )\n        top_6_overlap = [\n            name for name, count in feature_names_count.most_common(6) if count > 1\n        ]\n        top_6_overlap.sort()\n        if top_6_overlap:\n            if len(top_6_overlap) == 6:\n                # There are more than 5 overlapping names, we only show the 5\n                # of the feature names\n                names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n            else:\n                names_repr = str(top_6_overlap)\n            raise ValueError(\n                f\"Output feature names: {names_repr} are not unique. Please set \"\n                \"verbose_feature_names_out=True to add prefixes to feature names\"\n            )\n\n        return np.concatenate(\n            [name for _, name in filtered_transformer_with_feature_names_out],\n        )\n"
    ]
  },
  "combined_diffs": {
    "raw_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..1cb210d94 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -391,6 +391,7 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     ).set_output(transform=output_config[\"dense\"])\n                 elif trans == \"drop\":\n                     continue\n+\n                 elif _is_empty_column_selection(columns):\n                     continue\n \n@@ -530,6 +531,7 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             transformer_with_feature_names_out\n         )\n \n+\n     def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n         \"\"\"Add prefix for feature names out that includes the transformer names.\n \n@@ -577,7 +579,6 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         return np.concatenate(\n             [name for _, name in transformer_with_feature_names_out],\n         )\n-\n     def _update_fitted_transformers(self, transformers):\n         # transformers are fitted; excludes 'drop' cases\n         fitted_transformers = iter(transformers)\n@@ -656,6 +657,7 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         on the passed function.\n         ``fitted=True`` ensures the fitted transformers are used.\n         \"\"\"\n+\n         transformers = list(\n             self._iter(\n                 fitted=fitted, replace_strings=True, column_as_strings=column_as_strings\n@@ -862,10 +864,20 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 if not self.verbose_feature_names_out:\n                     return output\n \n-                transformer_names = [\n-                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n-                ]\n+\n+                # Only collect transformer names for transformers that actually have outputs\n+                transformers_with_outputs = list(\n+                    self._iter(fitted=True, replace_strings=True)\n+                )\n+                transformer_names = [t[0] for t in transformers_with_outputs]\n                 feature_names_outs = [X.columns for X in Xs]\n+                \n+                # Ensure we only use transformer names that correspond to actual outputs\n+                if len(transformer_names) != len(feature_names_outs):\n+                    # This should not happen if _iter and _fit_transform are consistent,\n+                    # but we add this safety check to handle edge cases\n+                    transformer_names = transformer_names[:len(feature_names_outs)]\n+                \n                 names_out = self._add_prefix_for_feature_names_out(\n                     list(zip(transformer_names, feature_names_outs))\n                 )\n@@ -904,6 +916,7 @@ def _check_X(X):\n     return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n \n \n+\n def _is_empty_column_selection(column):\n     \"\"\"\n     Return True if the column selection is empty (empty list or all-False\n",
    "variant_0": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..3f10559d5 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -391,6 +391,7 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     ).set_output(transform=output_config[\"dense\"])\n                 elif trans == \"drop\":\n                     continue\n+\n                 elif _is_empty_column_selection(columns):\n                     continue\n \n@@ -530,54 +531,65 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             transformer_with_feature_names_out\n         )\n \n-    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n-        \"\"\"Add prefix for feature names out that includes the transformer names.\n \n-        Parameters\n-        ----------\n-        transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n-            The tuple consistent of the transformer's name and its feature names out.\n+def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n+    \"\"\"Add prefix for feature names out that includes the transformer names.\n \n-        Returns\n-        -------\n-        feature_names_out : ndarray of shape (n_features,), dtype=str\n-            Transformed feature names.\n-        \"\"\"\n-        if self.verbose_feature_names_out:\n-            # Prefix the feature names out with the transformers name\n-            names = list(\n-                chain.from_iterable(\n-                    (f\"{name}__{i}\" for i in feature_names_out)\n-                    for name, feature_names_out in transformer_with_feature_names_out\n-                )\n-            )\n-            return np.asarray(names, dtype=object)\n+    Parameters\n+    ----------\n+    transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n+        The tuple consistent of the transformer's name and its feature names out.\n \n-        # verbose_feature_names_out is False\n-        # Check that names are all unique without a prefix\n-        feature_names_count = Counter(\n-            chain.from_iterable(s for _, s in transformer_with_feature_names_out)\n-        )\n-        top_6_overlap = [\n-            name for name, count in feature_names_count.most_common(6) if count > 1\n-        ]\n-        top_6_overlap.sort()\n-        if top_6_overlap:\n-            if len(top_6_overlap) == 6:\n-                # There are more than 5 overlapping names, we only show the 5\n-                # of the feature names\n-                names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n-            else:\n-                names_repr = str(top_6_overlap)\n-            raise ValueError(\n-                f\"Output feature names: {names_repr} are not unique. Please set \"\n-                \"verbose_feature_names_out=True to add prefixes to feature names\"\n+    Returns\n+    -------\n+    feature_names_out : ndarray of shape (n_features,), dtype=str\n+        Transformed feature names.\n+    \"\"\"\n+    # Filter out transformers with empty feature names\n+    filtered_transformer_with_feature_names_out = [\n+        (name, feature_names_out) \n+        for name, feature_names_out in transformer_with_feature_names_out\n+        if len(feature_names_out) > 0\n+    ]\n+    \n+    if not filtered_transformer_with_feature_names_out:\n+        # No feature names\n+        return np.array([], dtype=object)\n+    \n+    if self.verbose_feature_names_out:\n+        # Prefix the feature names out with the transformers name\n+        names = list(\n+            chain.from_iterable(\n+                (f\"{name}__{i}\" for i in feature_names_out)\n+                for name, feature_names_out in filtered_transformer_with_feature_names_out\n             )\n+        )\n+        return np.asarray(names, dtype=object)\n \n-        return np.concatenate(\n-            [name for _, name in transformer_with_feature_names_out],\n+    # verbose_feature_names_out is False\n+    # Check that names are all unique without a prefix\n+    feature_names_count = Counter(\n+        chain.from_iterable(s for _, s in filtered_transformer_with_feature_names_out)\n+    )\n+    top_6_overlap = [\n+        name for name, count in feature_names_count.most_common(6) if count > 1\n+    ]\n+    top_6_overlap.sort()\n+    if top_6_overlap:\n+        if len(top_6_overlap) == 6:\n+            # There are more than 5 overlapping names, we only show the 5\n+            # of the feature names\n+            names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n+        else:\n+            names_repr = str(top_6_overlap)\n+        raise ValueError(\n+            f\"Output feature names: {names_repr} are not unique. Please set \"\n+            \"verbose_feature_names_out=True to add prefixes to feature names\"\n         )\n \n+    return np.concatenate(\n+        [name for _, name in filtered_transformer_with_feature_names_out],\n+    )\n     def _update_fitted_transformers(self, transformers):\n         # transformers are fitted; excludes 'drop' cases\n         fitted_transformers = iter(transformers)\n@@ -656,11 +668,17 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         on the passed function.\n         ``fitted=True`` ensures the fitted transformers are used.\n         \"\"\"\n+\n         transformers = list(\n             self._iter(\n                 fitted=fitted, replace_strings=True, column_as_strings=column_as_strings\n             )\n         )\n+        # Track which transformers will actually produce output\n+        valid_transformer_indices = []\n+        for idx, (name, trans, column, weight) in enumerate(transformers):\n+            if not _is_empty_column_selection(column):\n+                valid_transformer_indices.append(idx)\n         try:\n             return Parallel(n_jobs=self.n_jobs)(\n                 delayed(func)(\n@@ -862,10 +880,17 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 if not self.verbose_feature_names_out:\n                     return output\n \n-                transformer_names = [\n-                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n-                ]\n-                feature_names_outs = [X.columns for X in Xs]\n+\n+                transformer_names = []\n+                feature_names_outs = []\n+                \n+                # Only collect names for transformers that actually produced output\n+                transformer_iter = self._iter(fitted=True, replace_strings=True)\n+                for i, (name, transformer, columns) in enumerate(transformer_iter):\n+                    if i < len(Xs) and hasattr(Xs[i], 'columns'):\n+                        transformer_names.append(name)\n+                        feature_names_outs.append(Xs[i].columns)\n+                \n                 names_out = self._add_prefix_for_feature_names_out(\n                     list(zip(transformer_names, feature_names_outs))\n                 )\n@@ -904,6 +929,7 @@ def _check_X(X):\n     return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n \n \n+\n def _is_empty_column_selection(column):\n     \"\"\"\n     Return True if the column selection is empty (empty list or all-False\n@@ -915,8 +941,8 @@ def _is_empty_column_selection(column):\n     elif hasattr(column, \"__len__\"):\n         return (\n             len(column) == 0\n-            or all(isinstance(col, bool) for col in column)\n-            and not any(column)\n+            or (all(isinstance(col, bool) for col in column)\n+            and not any(column))\n         )\n     else:\n         return False\n",
    "variant_1": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..d66060791 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -391,7 +391,18 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     ).set_output(transform=output_config[\"dense\"])\n                 elif trans == \"drop\":\n                     continue\n-                elif _is_empty_column_selection(columns):\n+\n+                # replace 'passthrough' with identity transformer and\n+                # skip in case of 'drop'\n+                if trans == \"passthrough\":\n+                    trans = FunctionTransformer(\n+                        accept_sparse=True,\n+                        check_inverse=False,\n+                        feature_names_out=\"one-to-one\",\n+                    ).set_output(transform=output_config[\"dense\"])\n+                elif trans == \"drop\":\n+                    continue\n+                elif _is_empty_column_selection(columns) and not fitted:\n                     continue\n \n             if column_as_strings:\n@@ -530,54 +541,66 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             transformer_with_feature_names_out\n         )\n \n-    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n-        \"\"\"Add prefix for feature names out that includes the transformer names.\n \n-        Parameters\n-        ----------\n-        transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n-            The tuple consistent of the transformer's name and its feature names out.\n+def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n+    \"\"\"Add prefix for feature names out that includes the transformer names.\n \n-        Returns\n-        -------\n-        feature_names_out : ndarray of shape (n_features,), dtype=str\n-            Transformed feature names.\n-        \"\"\"\n-        if self.verbose_feature_names_out:\n-            # Prefix the feature names out with the transformers name\n-            names = list(\n-                chain.from_iterable(\n-                    (f\"{name}__{i}\" for i in feature_names_out)\n-                    for name, feature_names_out in transformer_with_feature_names_out\n-                )\n-            )\n-            return np.asarray(names, dtype=object)\n+    Parameters\n+    ----------\n+    transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n+        The tuple consistent of the transformer's name and its feature names out.\n \n-        # verbose_feature_names_out is False\n-        # Check that names are all unique without a prefix\n-        feature_names_count = Counter(\n-            chain.from_iterable(s for _, s in transformer_with_feature_names_out)\n-        )\n-        top_6_overlap = [\n-            name for name, count in feature_names_count.most_common(6) if count > 1\n-        ]\n-        top_6_overlap.sort()\n-        if top_6_overlap:\n-            if len(top_6_overlap) == 6:\n-                # There are more than 5 overlapping names, we only show the 5\n-                # of the feature names\n-                names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n-            else:\n-                names_repr = str(top_6_overlap)\n-            raise ValueError(\n-                f\"Output feature names: {names_repr} are not unique. Please set \"\n-                \"verbose_feature_names_out=True to add prefixes to feature names\"\n+    Returns\n+    -------\n+    feature_names_out : ndarray of shape (n_features,), dtype=str\n+        Transformed feature names.\n+    \"\"\"\n+    # Filter out transformers with empty feature names to maintain consistency\n+    # with the actual output structure\n+    non_empty_transformer_features = [\n+        (name, feature_names_out) \n+        for name, feature_names_out in transformer_with_feature_names_out\n+        if len(feature_names_out) > 0\n+    ]\n+    \n+    if not non_empty_transformer_features:\n+        # No features from any transformer\n+        return np.array([], dtype=object)\n+    \n+    if self.verbose_feature_names_out:\n+        # Prefix the feature names out with the transformers name\n+        names = list(\n+            chain.from_iterable(\n+                (f\"{name}__{i}\" for i in feature_names_out)\n+                for name, feature_names_out in non_empty_transformer_features\n             )\n+        )\n+        return np.asarray(names, dtype=object)\n \n-        return np.concatenate(\n-            [name for _, name in transformer_with_feature_names_out],\n+    # verbose_feature_names_out is False\n+    # Check that names are all unique without a prefix\n+    feature_names_count = Counter(\n+        chain.from_iterable(s for _, s in non_empty_transformer_features)\n+    )\n+    top_6_overlap = [\n+        name for name, count in feature_names_count.most_common(6) if count > 1\n+    ]\n+    top_6_overlap.sort()\n+    if top_6_overlap:\n+        if len(top_6_overlap) == 6:\n+            # There are more than 5 overlapping names, we only show the 5\n+            # of the feature names\n+            names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n+        else:\n+            names_repr = str(top_6_overlap)\n+        raise ValueError(\n+            f\"Output feature names: {names_repr} are not unique. Please set \"\n+            \"verbose_feature_names_out=True to add prefixes to feature names\"\n         )\n \n+    return np.concatenate(\n+        [name for _, name in non_empty_transformer_features],\n+    )\n     def _update_fitted_transformers(self, transformers):\n         # transformers are fitted; excludes 'drop' cases\n         fitted_transformers = iter(transformers)\n@@ -656,11 +679,17 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         on the passed function.\n         ``fitted=True`` ensures the fitted transformers are used.\n         \"\"\"\n+\n         transformers = list(\n             self._iter(\n                 fitted=fitted, replace_strings=True, column_as_strings=column_as_strings\n             )\n         )\n+        # Track which transformers will actually contribute outputs\n+        contributing_transformers = []\n+        for name, trans, column, weight in transformers:\n+            if not _is_empty_column_selection(column):\n+                contributing_transformers.append((name, trans, column, weight))\n         try:\n             return Parallel(n_jobs=self.n_jobs)(\n                 delayed(func)(\n@@ -862,10 +891,17 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 if not self.verbose_feature_names_out:\n                     return output\n \n-                transformer_names = [\n-                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n-                ]\n-                feature_names_outs = [X.columns for X in Xs]\n+\n+                transformer_names = []\n+                feature_names_outs = []\n+                \n+                # Only collect names for transformers that actually produced output\n+                iter_transformers = list(self._iter(fitted=True, replace_strings=True))\n+                for i, (name, transformer, columns) in enumerate(iter_transformers):\n+                    if i < len(Xs) and hasattr(Xs[i], 'columns'):\n+                        transformer_names.append(name)\n+                        feature_names_outs.append(Xs[i].columns)\n+                \n                 names_out = self._add_prefix_for_feature_names_out(\n                     list(zip(transformer_names, feature_names_outs))\n                 )\n@@ -904,6 +940,7 @@ def _check_X(X):\n     return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n \n \n+\n def _is_empty_column_selection(column):\n     \"\"\"\n     Return True if the column selection is empty (empty list or all-False\n@@ -915,8 +952,8 @@ def _is_empty_column_selection(column):\n     elif hasattr(column, \"__len__\"):\n         return (\n             len(column) == 0\n-            or all(isinstance(col, bool) for col in column)\n-            and not any(column)\n+            or (all(isinstance(col, bool) for col in column)\n+            and not any(column))\n         )\n     else:\n         return False\n",
    "variant_2": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..780943dbb 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -391,6 +391,7 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     ).set_output(transform=output_config[\"dense\"])\n                 elif trans == \"drop\":\n                     continue\n+\n                 elif _is_empty_column_selection(columns):\n                     continue\n \n@@ -530,54 +531,65 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             transformer_with_feature_names_out\n         )\n \n-    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n-        \"\"\"Add prefix for feature names out that includes the transformer names.\n \n-        Parameters\n-        ----------\n-        transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n-            The tuple consistent of the transformer's name and its feature names out.\n+def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n+    \"\"\"Add prefix for feature names out that includes the transformer names.\n \n-        Returns\n-        -------\n-        feature_names_out : ndarray of shape (n_features,), dtype=str\n-            Transformed feature names.\n-        \"\"\"\n-        if self.verbose_feature_names_out:\n-            # Prefix the feature names out with the transformers name\n-            names = list(\n-                chain.from_iterable(\n-                    (f\"{name}__{i}\" for i in feature_names_out)\n-                    for name, feature_names_out in transformer_with_feature_names_out\n-                )\n-            )\n-            return np.asarray(names, dtype=object)\n+    Parameters\n+    ----------\n+    transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n+        The tuple consistent of the transformer's name and its feature names out.\n \n-        # verbose_feature_names_out is False\n-        # Check that names are all unique without a prefix\n-        feature_names_count = Counter(\n-            chain.from_iterable(s for _, s in transformer_with_feature_names_out)\n-        )\n-        top_6_overlap = [\n-            name for name, count in feature_names_count.most_common(6) if count > 1\n-        ]\n-        top_6_overlap.sort()\n-        if top_6_overlap:\n-            if len(top_6_overlap) == 6:\n-                # There are more than 5 overlapping names, we only show the 5\n-                # of the feature names\n-                names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n-            else:\n-                names_repr = str(top_6_overlap)\n-            raise ValueError(\n-                f\"Output feature names: {names_repr} are not unique. Please set \"\n-                \"verbose_feature_names_out=True to add prefixes to feature names\"\n+    Returns\n+    -------\n+    feature_names_out : ndarray of shape (n_features,), dtype=str\n+        Transformed feature names.\n+    \"\"\"\n+    # Filter out transformers with empty feature names\n+    non_empty_transformer_with_feature_names_out = [\n+        (name, feature_names_out) \n+        for name, feature_names_out in transformer_with_feature_names_out\n+        if len(feature_names_out) > 0\n+    ]\n+    \n+    if not non_empty_transformer_with_feature_names_out:\n+        # No feature names\n+        return np.array([], dtype=object)\n+    \n+    if self.verbose_feature_names_out:\n+        # Prefix the feature names out with the transformers name\n+        names = list(\n+            chain.from_iterable(\n+                (f\"{name}__{i}\" for i in feature_names_out)\n+                for name, feature_names_out in non_empty_transformer_with_feature_names_out\n             )\n+        )\n+        return np.asarray(names, dtype=object)\n \n-        return np.concatenate(\n-            [name for _, name in transformer_with_feature_names_out],\n+    # verbose_feature_names_out is False\n+    # Check that names are all unique without a prefix\n+    feature_names_count = Counter(\n+        chain.from_iterable(s for _, s in non_empty_transformer_with_feature_names_out)\n+    )\n+    top_6_overlap = [\n+        name for name, count in feature_names_count.most_common(6) if count > 1\n+    ]\n+    top_6_overlap.sort()\n+    if top_6_overlap:\n+        if len(top_6_overlap) == 6:\n+            # There are more than 5 overlapping names, we only show the 5\n+            # of the feature names\n+            names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n+        else:\n+            names_repr = str(top_6_overlap)\n+        raise ValueError(\n+            f\"Output feature names: {names_repr} are not unique. Please set \"\n+            \"verbose_feature_names_out=True to add prefixes to feature names\"\n         )\n \n+    return np.concatenate(\n+        [name for _, name in non_empty_transformer_with_feature_names_out],\n+    )\n     def _update_fitted_transformers(self, transformers):\n         # transformers are fitted; excludes 'drop' cases\n         fitted_transformers = iter(transformers)\n@@ -656,11 +668,17 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         on the passed function.\n         ``fitted=True`` ensures the fitted transformers are used.\n         \"\"\"\n+\n         transformers = list(\n             self._iter(\n                 fitted=fitted, replace_strings=True, column_as_strings=column_as_strings\n             )\n         )\n+        # Track which transformers will actually produce output\n+        active_transformer_indices = []\n+        for idx, (name, trans, column, weight) in enumerate(transformers):\n+            if not _is_empty_column_selection(column):\n+                active_transformer_indices.append(idx)\n         try:\n             return Parallel(n_jobs=self.n_jobs)(\n                 delayed(func)(\n@@ -862,10 +880,18 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 if not self.verbose_feature_names_out:\n                     return output\n \n-                transformer_names = [\n-                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n-                ]\n-                feature_names_outs = [X.columns for X in Xs]\n+\n+                transformer_names = []\n+                feature_names_outs = []\n+                \n+                # Only collect names for transformers that actually produced output\n+                transformer_iter = iter(self._iter(fitted=True, replace_strings=True))\n+                for X in Xs:\n+                    if X.shape[1] > 0:  # Only include transformers with actual output\n+                        name, _, _ = next(transformer_iter)\n+                        transformer_names.append(name)\n+                        feature_names_outs.append(X.columns)\n+                \n                 names_out = self._add_prefix_for_feature_names_out(\n                     list(zip(transformer_names, feature_names_outs))\n                 )\n@@ -904,6 +930,7 @@ def _check_X(X):\n     return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n \n \n+\n def _is_empty_column_selection(column):\n     \"\"\"\n     Return True if the column selection is empty (empty list or all-False\n@@ -915,8 +942,8 @@ def _is_empty_column_selection(column):\n     elif hasattr(column, \"__len__\"):\n         return (\n             len(column) == 0\n-            or all(isinstance(col, bool) for col in column)\n-            and not any(column)\n+            or (all(isinstance(col, bool) for col in column)\n+                and not any(column))\n         )\n     else:\n         return False\n",
    "variant_3": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..aaeee492c 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -391,6 +391,7 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     ).set_output(transform=output_config[\"dense\"])\n                 elif trans == \"drop\":\n                     continue\n+\n                 elif _is_empty_column_selection(columns):\n                     continue\n \n@@ -530,54 +531,65 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             transformer_with_feature_names_out\n         )\n \n-    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n-        \"\"\"Add prefix for feature names out that includes the transformer names.\n \n-        Parameters\n-        ----------\n-        transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n-            The tuple consistent of the transformer's name and its feature names out.\n+def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n+    \"\"\"Add prefix for feature names out that includes the transformer names.\n \n-        Returns\n-        -------\n-        feature_names_out : ndarray of shape (n_features,), dtype=str\n-            Transformed feature names.\n-        \"\"\"\n-        if self.verbose_feature_names_out:\n-            # Prefix the feature names out with the transformers name\n-            names = list(\n-                chain.from_iterable(\n-                    (f\"{name}__{i}\" for i in feature_names_out)\n-                    for name, feature_names_out in transformer_with_feature_names_out\n-                )\n-            )\n-            return np.asarray(names, dtype=object)\n+    Parameters\n+    ----------\n+    transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n+        The tuple consistent of the transformer's name and its feature names out.\n \n-        # verbose_feature_names_out is False\n-        # Check that names are all unique without a prefix\n-        feature_names_count = Counter(\n-            chain.from_iterable(s for _, s in transformer_with_feature_names_out)\n-        )\n-        top_6_overlap = [\n-            name for name, count in feature_names_count.most_common(6) if count > 1\n-        ]\n-        top_6_overlap.sort()\n-        if top_6_overlap:\n-            if len(top_6_overlap) == 6:\n-                # There are more than 5 overlapping names, we only show the 5\n-                # of the feature names\n-                names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n-            else:\n-                names_repr = str(top_6_overlap)\n-            raise ValueError(\n-                f\"Output feature names: {names_repr} are not unique. Please set \"\n-                \"verbose_feature_names_out=True to add prefixes to feature names\"\n+    Returns\n+    -------\n+    feature_names_out : ndarray of shape (n_features,), dtype=str\n+        Transformed feature names.\n+    \"\"\"\n+    # Filter out transformers with empty feature names to avoid mismatches\n+    transformer_with_feature_names_out = [\n+        (name, feature_names_out) \n+        for name, feature_names_out in transformer_with_feature_names_out\n+        if len(feature_names_out) > 0\n+    ]\n+    \n+    if not transformer_with_feature_names_out:\n+        # No feature names\n+        return np.array([], dtype=object)\n+    \n+    if self.verbose_feature_names_out:\n+        # Prefix the feature names out with the transformers name\n+        names = list(\n+            chain.from_iterable(\n+                (f\"{name}__{i}\" for i in feature_names_out)\n+                for name, feature_names_out in transformer_with_feature_names_out\n             )\n+        )\n+        return np.asarray(names, dtype=object)\n \n-        return np.concatenate(\n-            [name for _, name in transformer_with_feature_names_out],\n+    # verbose_feature_names_out is False\n+    # Check that names are all unique without a prefix\n+    feature_names_count = Counter(\n+        chain.from_iterable(s for _, s in transformer_with_feature_names_out)\n+    )\n+    top_6_overlap = [\n+        name for name, count in feature_names_count.most_common(6) if count > 1\n+    ]\n+    top_6_overlap.sort()\n+    if top_6_overlap:\n+        if len(top_6_overlap) == 6:\n+            # There are more than 5 overlapping names, we only show the 5\n+            # of the feature names\n+            names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n+        else:\n+            names_repr = str(top_6_overlap)\n+        raise ValueError(\n+            f\"Output feature names: {names_repr} are not unique. Please set \"\n+            \"verbose_feature_names_out=True to add prefixes to feature names\"\n         )\n \n+    return np.concatenate(\n+        [name for _, name in transformer_with_feature_names_out],\n+    )\n     def _update_fitted_transformers(self, transformers):\n         # transformers are fitted; excludes 'drop' cases\n         fitted_transformers = iter(transformers)\n@@ -656,11 +668,17 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         on the passed function.\n         ``fitted=True`` ensures the fitted transformers are used.\n         \"\"\"\n+\n         transformers = list(\n             self._iter(\n                 fitted=fitted, replace_strings=True, column_as_strings=column_as_strings\n             )\n         )\n+        # Track which transformers will actually produce output\n+        active_transformer_indices = []\n+        for idx, (name, trans, column, weight) in enumerate(transformers):\n+            if not _is_empty_column_selection(column):\n+                active_transformer_indices.append(idx)\n         try:\n             return Parallel(n_jobs=self.n_jobs)(\n                 delayed(func)(\n@@ -862,10 +880,17 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 if not self.verbose_feature_names_out:\n                     return output\n \n-                transformer_names = [\n-                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n-                ]\n-                feature_names_outs = [X.columns for X in Xs]\n+\n+                transformer_names = []\n+                feature_names_outs = []\n+                \n+                # Only collect names and features for transformers that actually produced output\n+                transformer_iter = self._iter(fitted=True, replace_strings=True)\n+                for i, (name, transformer, columns) in enumerate(transformer_iter):\n+                    if i < len(Xs):  # Only include transformers that have corresponding output\n+                        transformer_names.append(name)\n+                        feature_names_outs.append(Xs[i].columns)\n+                \n                 names_out = self._add_prefix_for_feature_names_out(\n                     list(zip(transformer_names, feature_names_outs))\n                 )\n@@ -904,6 +929,7 @@ def _check_X(X):\n     return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n \n \n+\n def _is_empty_column_selection(column):\n     \"\"\"\n     Return True if the column selection is empty (empty list or all-False\n@@ -915,8 +941,8 @@ def _is_empty_column_selection(column):\n     elif hasattr(column, \"__len__\"):\n         return (\n             len(column) == 0\n-            or all(isinstance(col, bool) for col in column)\n-            and not any(column)\n+            or (all(isinstance(col, bool) for col in column)\n+            and not any(column))\n         )\n     else:\n         return False\n",
    "variant_4": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..00768ed4a 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -391,7 +391,14 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     ).set_output(transform=output_config[\"dense\"])\n                 elif trans == \"drop\":\n                     continue\n+\n                 elif _is_empty_column_selection(columns):\n+                    # Store information about empty transformers for feature naming\n+                    if not fitted:\n+                        continue\n+                    # When fitted=True, we need to track empty transformers\n+                    # to maintain consistency with feature naming\n+                    yield name, trans, columns, weight\n                     continue\n \n             if column_as_strings:\n@@ -530,54 +537,65 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             transformer_with_feature_names_out\n         )\n \n-    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n-        \"\"\"Add prefix for feature names out that includes the transformer names.\n \n-        Parameters\n-        ----------\n-        transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n-            The tuple consistent of the transformer's name and its feature names out.\n+def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n+    \"\"\"Add prefix for feature names out that includes the transformer names.\n \n-        Returns\n-        -------\n-        feature_names_out : ndarray of shape (n_features,), dtype=str\n-            Transformed feature names.\n-        \"\"\"\n-        if self.verbose_feature_names_out:\n-            # Prefix the feature names out with the transformers name\n-            names = list(\n-                chain.from_iterable(\n-                    (f\"{name}__{i}\" for i in feature_names_out)\n-                    for name, feature_names_out in transformer_with_feature_names_out\n-                )\n-            )\n-            return np.asarray(names, dtype=object)\n+    Parameters\n+    ----------\n+    transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n+        The tuple consistent of the transformer's name and its feature names out.\n \n-        # verbose_feature_names_out is False\n-        # Check that names are all unique without a prefix\n-        feature_names_count = Counter(\n-            chain.from_iterable(s for _, s in transformer_with_feature_names_out)\n-        )\n-        top_6_overlap = [\n-            name for name, count in feature_names_count.most_common(6) if count > 1\n-        ]\n-        top_6_overlap.sort()\n-        if top_6_overlap:\n-            if len(top_6_overlap) == 6:\n-                # There are more than 5 overlapping names, we only show the 5\n-                # of the feature names\n-                names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n-            else:\n-                names_repr = str(top_6_overlap)\n-            raise ValueError(\n-                f\"Output feature names: {names_repr} are not unique. Please set \"\n-                \"verbose_feature_names_out=True to add prefixes to feature names\"\n+    Returns\n+    -------\n+    feature_names_out : ndarray of shape (n_features,), dtype=str\n+        Transformed feature names.\n+    \"\"\"\n+    # Filter out transformers that have no feature names (empty outputs)\n+    transformer_with_feature_names_out = [\n+        (name, feature_names) \n+        for name, feature_names in transformer_with_feature_names_out\n+        if len(feature_names) > 0\n+    ]\n+    \n+    if not transformer_with_feature_names_out:\n+        # No feature names after filtering\n+        return np.array([], dtype=object)\n+    \n+    if self.verbose_feature_names_out:\n+        # Prefix the feature names out with the transformers name\n+        names = list(\n+            chain.from_iterable(\n+                (f\"{name}__{i}\" for i in feature_names_out)\n+                for name, feature_names_out in transformer_with_feature_names_out\n             )\n+        )\n+        return np.asarray(names, dtype=object)\n \n-        return np.concatenate(\n-            [name for _, name in transformer_with_feature_names_out],\n+    # verbose_feature_names_out is False\n+    # Check that names are all unique without a prefix\n+    feature_names_count = Counter(\n+        chain.from_iterable(s for _, s in transformer_with_feature_names_out)\n+    )\n+    top_6_overlap = [\n+        name for name, count in feature_names_count.most_common(6) if count > 1\n+    ]\n+    top_6_overlap.sort()\n+    if top_6_overlap:\n+        if len(top_6_overlap) == 6:\n+            # There are more than 5 overlapping names, we only show the 5\n+            # of the feature names\n+            names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n+        else:\n+            names_repr = str(top_6_overlap)\n+        raise ValueError(\n+            f\"Output feature names: {names_repr} are not unique. Please set \"\n+            \"verbose_feature_names_out=True to add prefixes to feature names\"\n         )\n \n+    return np.concatenate(\n+        [name for _, name in transformer_with_feature_names_out],\n+    )\n     def _update_fitted_transformers(self, transformers):\n         # transformers are fitted; excludes 'drop' cases\n         fitted_transformers = iter(transformers)\n@@ -656,11 +674,17 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         on the passed function.\n         ``fitted=True`` ensures the fitted transformers are used.\n         \"\"\"\n+\n         transformers = list(\n             self._iter(\n                 fitted=fitted, replace_strings=True, column_as_strings=column_as_strings\n             )\n         )\n+        # Track which transformers will actually produce output\n+        active_transformer_indices = []\n+        for idx, (name, trans, column, weight) in enumerate(transformers):\n+            if not _is_empty_column_selection(column):\n+                active_transformer_indices.append(idx)\n         try:\n             return Parallel(n_jobs=self.n_jobs)(\n                 delayed(func)(\n@@ -862,10 +886,18 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 if not self.verbose_feature_names_out:\n                     return output\n \n-                transformer_names = [\n-                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n-                ]\n-                feature_names_outs = [X.columns for X in Xs]\n+\n+                transformer_names = []\n+                feature_names_outs = []\n+                \n+                # Only collect names from transformers that actually produced output\n+                transformer_iter = iter(self._iter(fitted=True, replace_strings=True))\n+                for X in Xs:\n+                    if X.shape[1] > 0:  # Only include if transformer produced columns\n+                        name, _, _ = next(transformer_iter)\n+                        transformer_names.append(name)\n+                        feature_names_outs.append(X.columns)\n+                \n                 names_out = self._add_prefix_for_feature_names_out(\n                     list(zip(transformer_names, feature_names_outs))\n                 )\n@@ -904,6 +936,7 @@ def _check_X(X):\n     return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n \n \n+\n def _is_empty_column_selection(column):\n     \"\"\"\n     Return True if the column selection is empty (empty list or all-False\n@@ -915,8 +948,8 @@ def _is_empty_column_selection(column):\n     elif hasattr(column, \"__len__\"):\n         return (\n             len(column) == 0\n-            or all(isinstance(col, bool) for col in column)\n-            and not any(column)\n+            or (all(isinstance(col, bool) for col in column)\n+                and not any(column))\n         )\n     else:\n         return False\n",
    "variant_5": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..dd86e5c30 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -391,7 +391,11 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     ).set_output(transform=output_config[\"dense\"])\n                 elif trans == \"drop\":\n                     continue\n+\n                 elif _is_empty_column_selection(columns):\n+                    # Skip empty column selections, but track them for feature naming consistency\n+                    if fitted and hasattr(self, '_empty_transformers'):\n+                        self._empty_transformers.add(name)\n                     continue\n \n             if column_as_strings:\n@@ -530,54 +534,65 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             transformer_with_feature_names_out\n         )\n \n-    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n-        \"\"\"Add prefix for feature names out that includes the transformer names.\n \n-        Parameters\n-        ----------\n-        transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n-            The tuple consistent of the transformer's name and its feature names out.\n+def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n+    \"\"\"Add prefix for feature names out that includes the transformer names.\n \n-        Returns\n-        -------\n-        feature_names_out : ndarray of shape (n_features,), dtype=str\n-            Transformed feature names.\n-        \"\"\"\n-        if self.verbose_feature_names_out:\n-            # Prefix the feature names out with the transformers name\n-            names = list(\n-                chain.from_iterable(\n-                    (f\"{name}__{i}\" for i in feature_names_out)\n-                    for name, feature_names_out in transformer_with_feature_names_out\n-                )\n-            )\n-            return np.asarray(names, dtype=object)\n+    Parameters\n+    ----------\n+    transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n+        The tuple consistent of the transformer's name and its feature names out.\n \n-        # verbose_feature_names_out is False\n-        # Check that names are all unique without a prefix\n-        feature_names_count = Counter(\n-            chain.from_iterable(s for _, s in transformer_with_feature_names_out)\n-        )\n-        top_6_overlap = [\n-            name for name, count in feature_names_count.most_common(6) if count > 1\n-        ]\n-        top_6_overlap.sort()\n-        if top_6_overlap:\n-            if len(top_6_overlap) == 6:\n-                # There are more than 5 overlapping names, we only show the 5\n-                # of the feature names\n-                names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n-            else:\n-                names_repr = str(top_6_overlap)\n-            raise ValueError(\n-                f\"Output feature names: {names_repr} are not unique. Please set \"\n-                \"verbose_feature_names_out=True to add prefixes to feature names\"\n+    Returns\n+    -------\n+    feature_names_out : ndarray of shape (n_features,), dtype=str\n+        Transformed feature names.\n+    \"\"\"\n+    # Filter out transformers with empty feature names to ensure consistency\n+    non_empty_transformer_features = [\n+        (name, feature_names_out) \n+        for name, feature_names_out in transformer_with_feature_names_out\n+        if len(feature_names_out) > 0\n+    ]\n+    \n+    if not non_empty_transformer_features:\n+        # No feature names after filtering empty ones\n+        return np.array([], dtype=object)\n+    \n+    if self.verbose_feature_names_out:\n+        # Prefix the feature names out with the transformers name\n+        names = list(\n+            chain.from_iterable(\n+                (f\"{name}__{i}\" for i in feature_names_out)\n+                for name, feature_names_out in non_empty_transformer_features\n             )\n+        )\n+        return np.asarray(names, dtype=object)\n \n-        return np.concatenate(\n-            [name for _, name in transformer_with_feature_names_out],\n+    # verbose_feature_names_out is False\n+    # Check that names are all unique without a prefix\n+    feature_names_count = Counter(\n+        chain.from_iterable(s for _, s in non_empty_transformer_features)\n+    )\n+    top_6_overlap = [\n+        name for name, count in feature_names_count.most_common(6) if count > 1\n+    ]\n+    top_6_overlap.sort()\n+    if top_6_overlap:\n+        if len(top_6_overlap) == 6:\n+            # There are more than 5 overlapping names, we only show the 5\n+            # of the feature names\n+            names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n+        else:\n+            names_repr = str(top_6_overlap)\n+        raise ValueError(\n+            f\"Output feature names: {names_repr} are not unique. Please set \"\n+            \"verbose_feature_names_out=True to add prefixes to feature names\"\n         )\n \n+    return np.concatenate(\n+        [name for _, name in non_empty_transformer_features],\n+    )\n     def _update_fitted_transformers(self, transformers):\n         # transformers are fitted; excludes 'drop' cases\n         fitted_transformers = iter(transformers)\n@@ -656,11 +671,17 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         on the passed function.\n         ``fitted=True`` ensures the fitted transformers are used.\n         \"\"\"\n+\n         transformers = list(\n             self._iter(\n                 fitted=fitted, replace_strings=True, column_as_strings=column_as_strings\n             )\n         )\n+        # Track which transformers will actually contribute to output\n+        contributing_transformers = []\n+        for name, trans, column, weight in transformers:\n+            if not _is_empty_column_selection(column):\n+                contributing_transformers.append((name, trans, column, weight))\n         try:\n             return Parallel(n_jobs=self.n_jobs)(\n                 delayed(func)(\n@@ -862,10 +883,17 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 if not self.verbose_feature_names_out:\n                     return output\n \n-                transformer_names = [\n-                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n-                ]\n-                feature_names_outs = [X.columns for X in Xs]\n+\n+                transformer_names = []\n+                feature_names_outs = []\n+                \n+                # Only collect names for transformers that actually produced output\n+                transformer_iter = self._iter(fitted=True, replace_strings=True)\n+                for i, (name, transformer, columns) in enumerate(transformer_iter):\n+                    if i < len(Xs) and Xs[i] is not None and Xs[i].shape[1] > 0:\n+                        transformer_names.append(name)\n+                        feature_names_outs.append(Xs[i].columns)\n+                \n                 names_out = self._add_prefix_for_feature_names_out(\n                     list(zip(transformer_names, feature_names_outs))\n                 )\n@@ -904,6 +932,7 @@ def _check_X(X):\n     return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n \n \n+\n def _is_empty_column_selection(column):\n     \"\"\"\n     Return True if the column selection is empty (empty list or all-False\n@@ -915,8 +944,8 @@ def _is_empty_column_selection(column):\n     elif hasattr(column, \"__len__\"):\n         return (\n             len(column) == 0\n-            or all(isinstance(col, bool) for col in column)\n-            and not any(column)\n+            or (all(isinstance(col, bool) for col in column)\n+            and not any(column))\n         )\n     else:\n         return False\n",
    "variant_6": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..5bb6d2f9e 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -391,7 +391,15 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     ).set_output(transform=output_config[\"dense\"])\n                 elif trans == \"drop\":\n                     continue\n+\n                 elif _is_empty_column_selection(columns):\n+                    # For empty column selections, we need to handle them differently\n+                    # based on whether we're in fitted mode and need consistent naming\n+                    if fitted and hasattr(self, '_empty_transformers_'):\n+                        # Track empty transformers for consistent feature naming\n+                        if not hasattr(self, '_empty_transformers_'):\n+                            self._empty_transformers_ = []\n+                        self._empty_transformers_.append(name)\n                     continue\n \n             if column_as_strings:\n@@ -530,54 +538,64 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             transformer_with_feature_names_out\n         )\n \n-    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n-        \"\"\"Add prefix for feature names out that includes the transformer names.\n \n-        Parameters\n-        ----------\n-        transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n-            The tuple consistent of the transformer's name and its feature names out.\n+def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n+    \"\"\"Add prefix for feature names out that includes the transformer names.\n \n-        Returns\n-        -------\n-        feature_names_out : ndarray of shape (n_features,), dtype=str\n-            Transformed feature names.\n-        \"\"\"\n-        if self.verbose_feature_names_out:\n-            # Prefix the feature names out with the transformers name\n-            names = list(\n-                chain.from_iterable(\n-                    (f\"{name}__{i}\" for i in feature_names_out)\n-                    for name, feature_names_out in transformer_with_feature_names_out\n-                )\n-            )\n-            return np.asarray(names, dtype=object)\n+    Parameters\n+    ----------\n+    transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n+        The tuple consistent of the transformer's name and its feature names out.\n \n-        # verbose_feature_names_out is False\n-        # Check that names are all unique without a prefix\n-        feature_names_count = Counter(\n-            chain.from_iterable(s for _, s in transformer_with_feature_names_out)\n-        )\n-        top_6_overlap = [\n-            name for name, count in feature_names_count.most_common(6) if count > 1\n-        ]\n-        top_6_overlap.sort()\n-        if top_6_overlap:\n-            if len(top_6_overlap) == 6:\n-                # There are more than 5 overlapping names, we only show the 5\n-                # of the feature names\n-                names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n-            else:\n-                names_repr = str(top_6_overlap)\n-            raise ValueError(\n-                f\"Output feature names: {names_repr} are not unique. Please set \"\n-                \"verbose_feature_names_out=True to add prefixes to feature names\"\n+    Returns\n+    -------\n+    feature_names_out : ndarray of shape (n_features,), dtype=str\n+        Transformed feature names.\n+    \"\"\"\n+    # Filter out transformers with empty feature names\n+    non_empty_transformer_features = [\n+        (name, features) for name, features in transformer_with_feature_names_out\n+        if len(features) > 0\n+    ]\n+    \n+    if not non_empty_transformer_features:\n+        # No feature names\n+        return np.array([], dtype=object)\n+    \n+    if self.verbose_feature_names_out:\n+        # Prefix the feature names out with the transformers name\n+        names = list(\n+            chain.from_iterable(\n+                (f\"{name}__{i}\" for i in feature_names_out)\n+                for name, feature_names_out in non_empty_transformer_features\n             )\n+        )\n+        return np.asarray(names, dtype=object)\n \n-        return np.concatenate(\n-            [name for _, name in transformer_with_feature_names_out],\n+    # verbose_feature_names_out is False\n+    # Check that names are all unique without a prefix\n+    feature_names_count = Counter(\n+        chain.from_iterable(s for _, s in non_empty_transformer_features)\n+    )\n+    top_6_overlap = [\n+        name for name, count in feature_names_count.most_common(6) if count > 1\n+    ]\n+    top_6_overlap.sort()\n+    if top_6_overlap:\n+        if len(top_6_overlap) == 6:\n+            # There are more than 5 overlapping names, we only show the 5\n+            # of the feature names\n+            names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n+        else:\n+            names_repr = str(top_6_overlap)\n+        raise ValueError(\n+            f\"Output feature names: {names_repr} are not unique. Please set \"\n+            \"verbose_feature_names_out=True to add prefixes to feature names\"\n         )\n \n+    return np.concatenate(\n+        [name for _, name in non_empty_transformer_features],\n+    )\n     def _update_fitted_transformers(self, transformers):\n         # transformers are fitted; excludes 'drop' cases\n         fitted_transformers = iter(transformers)\n@@ -656,11 +674,17 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         on the passed function.\n         ``fitted=True`` ensures the fitted transformers are used.\n         \"\"\"\n+\n         transformers = list(\n             self._iter(\n                 fitted=fitted, replace_strings=True, column_as_strings=column_as_strings\n             )\n         )\n+        # Track which transformers will actually produce output\n+        active_transformer_indices = []\n+        for idx, (name, trans, column, weight) in enumerate(transformers):\n+            if not _is_empty_column_selection(column):\n+                active_transformer_indices.append(idx)\n         try:\n             return Parallel(n_jobs=self.n_jobs)(\n                 delayed(func)(\n@@ -862,10 +886,19 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 if not self.verbose_feature_names_out:\n                     return output\n \n-                transformer_names = [\n-                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n-                ]\n-                feature_names_outs = [X.columns for X in Xs]\n+\n+                transformer_names = []\n+                feature_names_outs = []\n+                \n+                # Only collect names for transformers that actually produced outputs\n+                iter_count = 0\n+                for name, transformer, columns in self._iter(fitted=True, replace_strings=True):\n+                    if not _is_empty_column_selection(columns):\n+                        if iter_count < len(Xs):\n+                            transformer_names.append(name)\n+                            feature_names_outs.append(Xs[iter_count].columns)\n+                            iter_count += 1\n+                \n                 names_out = self._add_prefix_for_feature_names_out(\n                     list(zip(transformer_names, feature_names_outs))\n                 )\n@@ -904,6 +937,7 @@ def _check_X(X):\n     return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n \n \n+\n def _is_empty_column_selection(column):\n     \"\"\"\n     Return True if the column selection is empty (empty list or all-False\n@@ -915,8 +949,8 @@ def _is_empty_column_selection(column):\n     elif hasattr(column, \"__len__\"):\n         return (\n             len(column) == 0\n-            or all(isinstance(col, bool) for col in column)\n-            and not any(column)\n+            or (all(isinstance(col, bool) for col in column)\n+                and not any(column))\n         )\n     else:\n         return False\n",
    "variant_7": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..87b0af125 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -391,7 +391,12 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     ).set_output(transform=output_config[\"dense\"])\n                 elif trans == \"drop\":\n                     continue\n+\n                 elif _is_empty_column_selection(columns):\n+                    if fitted:\n+                        # When fitted=True, we need to track empty transformers\n+                        # to maintain consistency with feature naming\n+                        yield name, trans, columns, weight\n                     continue\n \n             if column_as_strings:\n@@ -530,54 +535,65 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             transformer_with_feature_names_out\n         )\n \n-    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n-        \"\"\"Add prefix for feature names out that includes the transformer names.\n \n-        Parameters\n-        ----------\n-        transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n-            The tuple consistent of the transformer's name and its feature names out.\n+def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n+    \"\"\"Add prefix for feature names out that includes the transformer names.\n \n-        Returns\n-        -------\n-        feature_names_out : ndarray of shape (n_features,), dtype=str\n-            Transformed feature names.\n-        \"\"\"\n-        if self.verbose_feature_names_out:\n-            # Prefix the feature names out with the transformers name\n-            names = list(\n-                chain.from_iterable(\n-                    (f\"{name}__{i}\" for i in feature_names_out)\n-                    for name, feature_names_out in transformer_with_feature_names_out\n-                )\n-            )\n-            return np.asarray(names, dtype=object)\n+    Parameters\n+    ----------\n+    transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n+        The tuple consistent of the transformer's name and its feature names out.\n \n-        # verbose_feature_names_out is False\n-        # Check that names are all unique without a prefix\n-        feature_names_count = Counter(\n-            chain.from_iterable(s for _, s in transformer_with_feature_names_out)\n-        )\n-        top_6_overlap = [\n-            name for name, count in feature_names_count.most_common(6) if count > 1\n-        ]\n-        top_6_overlap.sort()\n-        if top_6_overlap:\n-            if len(top_6_overlap) == 6:\n-                # There are more than 5 overlapping names, we only show the 5\n-                # of the feature names\n-                names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n-            else:\n-                names_repr = str(top_6_overlap)\n-            raise ValueError(\n-                f\"Output feature names: {names_repr} are not unique. Please set \"\n-                \"verbose_feature_names_out=True to add prefixes to feature names\"\n+    Returns\n+    -------\n+    feature_names_out : ndarray of shape (n_features,), dtype=str\n+        Transformed feature names.\n+    \"\"\"\n+    # Filter out transformers with empty feature names\n+    transformer_with_feature_names_out = [\n+        (name, feature_names_out) \n+        for name, feature_names_out in transformer_with_feature_names_out\n+        if len(feature_names_out) > 0\n+    ]\n+    \n+    if not transformer_with_feature_names_out:\n+        # No feature names after filtering\n+        return np.array([], dtype=object)\n+    \n+    if self.verbose_feature_names_out:\n+        # Prefix the feature names out with the transformers name\n+        names = list(\n+            chain.from_iterable(\n+                (f\"{name}__{i}\" for i in feature_names_out)\n+                for name, feature_names_out in transformer_with_feature_names_out\n             )\n+        )\n+        return np.asarray(names, dtype=object)\n \n-        return np.concatenate(\n-            [name for _, name in transformer_with_feature_names_out],\n+    # verbose_feature_names_out is False\n+    # Check that names are all unique without a prefix\n+    feature_names_count = Counter(\n+        chain.from_iterable(s for _, s in transformer_with_feature_names_out)\n+    )\n+    top_6_overlap = [\n+        name for name, count in feature_names_count.most_common(6) if count > 1\n+    ]\n+    top_6_overlap.sort()\n+    if top_6_overlap:\n+        if len(top_6_overlap) == 6:\n+            # There are more than 5 overlapping names, we only show the 5\n+            # of the feature names\n+            names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n+        else:\n+            names_repr = str(top_6_overlap)\n+        raise ValueError(\n+            f\"Output feature names: {names_repr} are not unique. Please set \"\n+            \"verbose_feature_names_out=True to add prefixes to feature names\"\n         )\n \n+    return np.concatenate(\n+        [name for _, name in transformer_with_feature_names_out],\n+    )\n     def _update_fitted_transformers(self, transformers):\n         # transformers are fitted; excludes 'drop' cases\n         fitted_transformers = iter(transformers)\n@@ -656,11 +672,17 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         on the passed function.\n         ``fitted=True`` ensures the fitted transformers are used.\n         \"\"\"\n+\n         transformers = list(\n             self._iter(\n                 fitted=fitted, replace_strings=True, column_as_strings=column_as_strings\n             )\n         )\n+        # Track which transformers will actually produce output\n+        active_transformer_indices = []\n+        for idx, (name, trans, column, weight) in enumerate(transformers):\n+            if not _is_empty_column_selection(column):\n+                active_transformer_indices.append(idx)\n         try:\n             return Parallel(n_jobs=self.n_jobs)(\n                 delayed(func)(\n@@ -862,8 +884,10 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 if not self.verbose_feature_names_out:\n                     return output\n \n+\n                 transformer_names = [\n                     t[0] for t in self._iter(fitted=True, replace_strings=True)\n+                    if not _is_empty_column_selection(t[2])\n                 ]\n                 feature_names_outs = [X.columns for X in Xs]\n                 names_out = self._add_prefix_for_feature_names_out(\n@@ -904,6 +928,7 @@ def _check_X(X):\n     return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n \n \n+\n def _is_empty_column_selection(column):\n     \"\"\"\n     Return True if the column selection is empty (empty list or all-False\n@@ -915,8 +940,8 @@ def _is_empty_column_selection(column):\n     elif hasattr(column, \"__len__\"):\n         return (\n             len(column) == 0\n-            or all(isinstance(col, bool) for col in column)\n-            and not any(column)\n+            or (all(isinstance(col, bool) for col in column)\n+            and not any(column))\n         )\n     else:\n         return False\n",
    "variant_8": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..18a9fbf6e 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -391,7 +391,10 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     ).set_output(transform=output_config[\"dense\"])\n                 elif trans == \"drop\":\n                     continue\n+\n                 elif _is_empty_column_selection(columns):\n+                    # Skip transformers with empty column selections during iteration\n+                    # but track them for consistent feature naming when needed\n                     continue\n \n             if column_as_strings:\n@@ -530,6 +533,7 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             transformer_with_feature_names_out\n         )\n \n+\n     def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n         \"\"\"Add prefix for feature names out that includes the transformer names.\n \n@@ -543,12 +547,24 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         feature_names_out : ndarray of shape (n_features,), dtype=str\n             Transformed feature names.\n         \"\"\"\n+        # Filter out transformers with empty feature names to ensure consistency\n+        # with the actual outputs that were produced\n+        filtered_transformer_with_feature_names_out = [\n+            (name, feature_names_out) \n+            for name, feature_names_out in transformer_with_feature_names_out\n+            if len(feature_names_out) > 0\n+        ]\n+        \n+        if not filtered_transformer_with_feature_names_out:\n+            # No transformers with actual features\n+            return np.array([], dtype=object)\n+        \n         if self.verbose_feature_names_out:\n             # Prefix the feature names out with the transformers name\n             names = list(\n                 chain.from_iterable(\n                     (f\"{name}__{i}\" for i in feature_names_out)\n-                    for name, feature_names_out in transformer_with_feature_names_out\n+                    for name, feature_names_out in filtered_transformer_with_feature_names_out\n                 )\n             )\n             return np.asarray(names, dtype=object)\n@@ -556,7 +572,7 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         # verbose_feature_names_out is False\n         # Check that names are all unique without a prefix\n         feature_names_count = Counter(\n-            chain.from_iterable(s for _, s in transformer_with_feature_names_out)\n+            chain.from_iterable(s for _, s in filtered_transformer_with_feature_names_out)\n         )\n         top_6_overlap = [\n             name for name, count in feature_names_count.most_common(6) if count > 1\n@@ -575,9 +591,8 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             )\n \n         return np.concatenate(\n-            [name for _, name in transformer_with_feature_names_out],\n+            [name for _, name in filtered_transformer_with_feature_names_out],\n         )\n-\n     def _update_fitted_transformers(self, transformers):\n         # transformers are fitted; excludes 'drop' cases\n         fitted_transformers = iter(transformers)\n@@ -656,11 +671,17 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         on the passed function.\n         ``fitted=True`` ensures the fitted transformers are used.\n         \"\"\"\n+\n         transformers = list(\n             self._iter(\n                 fitted=fitted, replace_strings=True, column_as_strings=column_as_strings\n             )\n         )\n+        # Track which transformers will actually produce outputs\n+        active_transformer_indices = []\n+        for idx, (name, trans, column, weight) in enumerate(transformers):\n+            if not _is_empty_column_selection(column):\n+                active_transformer_indices.append(idx)\n         try:\n             return Parallel(n_jobs=self.n_jobs)(\n                 delayed(func)(\n@@ -862,10 +883,17 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 if not self.verbose_feature_names_out:\n                     return output\n \n-                transformer_names = [\n-                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n-                ]\n-                feature_names_outs = [X.columns for X in Xs]\n+\n+                transformer_names = []\n+                feature_names_outs = []\n+                \n+                # Only collect names for transformers that actually contributed outputs\n+                transformer_iter = self._iter(fitted=True, replace_strings=True)\n+                for i, (name, transformer, columns) in enumerate(transformer_iter):\n+                    if i < len(Xs):  # Only include if there's a corresponding output\n+                        transformer_names.append(name)\n+                        feature_names_outs.append(Xs[i].columns)\n+                \n                 names_out = self._add_prefix_for_feature_names_out(\n                     list(zip(transformer_names, feature_names_outs))\n                 )\n@@ -904,6 +932,7 @@ def _check_X(X):\n     return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n \n \n+\n def _is_empty_column_selection(column):\n     \"\"\"\n     Return True if the column selection is empty (empty list or all-False\n@@ -915,8 +944,8 @@ def _is_empty_column_selection(column):\n     elif hasattr(column, \"__len__\"):\n         return (\n             len(column) == 0\n-            or all(isinstance(col, bool) for col in column)\n-            and not any(column)\n+            or (all(isinstance(col, bool) for col in column)\n+                and not any(column))\n         )\n     else:\n         return False\n"
  }
}