{
  "zero_patches": {
    "Location 1 (/root/hy/projects_1/pytest/src/_pytest/assertion/rewrite.py lines 605-607)": "\n            elif lines and lineno not in seen_lines:\n                # Check if this line contains assertion-related content\n                # Skip decorator lines and function definitions\n                stripped_line = line.strip()\n                if (not stripped_line.startswith('@') and \n                    not stripped_line.startswith('def ') and\n                    tp not in {tokenize.INDENT, tokenize.DEDENT, tokenize.COMMENT}):\n                    lines.append(line)\n                    seen_lines.add(lineno)\n",
    "Location 2 (/root/hy/projects_1/pytest/src/_pytest/assertion/rewrite.py lines 578-579)": "\n        if tp == tokenize.NAME and source == \"assert\":\n            assert_lineno = lineno\n        elif tp == tokenize.NAME and source.startswith(\"@\"):\n            # Stop collecting if we encounter a decorator\n            if assert_lineno is not None:\n                _write_and_reset()\n        elif assert_lineno is not None:\n",
    "Location 3 (/root/hy/projects_1/pytest/src/_pytest/assertion/rewrite.py lines 587-589)": "\n            if not lines:\n                # Only start collecting if this token is part of the assertion\n                if tp in (tokenize.NAME, tokenize.OP, tokenize.NUMBER, tokenize.STRING):\n                    lines.append(line[offset:])\n                    seen_lines.add(lineno)\n",
    "Location 4 (/root/hy/projects_1/pytest/src/_pytest/assertion/rewrite.py lines 603-604)": "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                # Check if we have any collected lines before writing\n                if lines:\n                    # Filter out any decorator lines that may have been incorrectly collected\n                    filtered_lines = []\n                    for collected_line in lines:\n                        stripped = collected_line.strip()\n                        # Skip decorator lines and function definitions\n                        if not (stripped.startswith('@') or stripped.startswith('def ')):\n                            filtered_lines.append(collected_line)\n                    \n                    # Only write if we have valid assertion lines\n                    if filtered_lines:\n                        lines[:] = filtered_lines\n                        _write_and_reset()\n                    else:\n                        # Clear invalid collection\n                        lines.clear()\n                        seen_lines.clear()\n                else:\n                    _write_and_reset()\n",
    "Location 5 (/root/hy/projects_1/pytest/src/_pytest/assertion/rewrite.py lines 567-574)": "\ndef _write_and_reset() -> None:\n    nonlocal depth, lines, assert_lineno, seen_lines\n    assert assert_lineno is not None\n    \n    # Filter out any lines that don't belong to the assertion expression\n    filtered_lines = []\n    for line in lines:\n        stripped = line.strip()\n        # Skip decorator lines and function definitions that got incorrectly collected\n        if not (stripped.startswith('@') or stripped.startswith('def ')):\n            filtered_lines.append(line)\n    \n    if filtered_lines:\n        ret[assert_lineno] = \"\".join(filtered_lines).rstrip().rstrip(\"\\\\\")\n    depth = 0\n    lines = []\n    assert_lineno = None\n    seen_lines = set()\n"
  },
  "variant_patches": {
    "Location 1 (/root/hy/projects_1/pytest/src/_pytest/assertion/rewrite.py lines 605-607)": [
      "\n            elif lines and lineno not in seen_lines:\n                # Check if this line contains assertion-related content\n                # Skip decorator lines and function definitions\n                stripped_line = line.strip()\n                if (stripped_line.startswith('@') or \n                    stripped_line.startswith('def ') or\n                    (tp == tokenize.NAME and source in ('def', 'class'))):\n                    # Stop collecting lines when we hit decorators or function definitions\n                    _write_and_reset()\n                else:\n                    lines.append(line)\n                    seen_lines.add(lineno)\n",
      "\n            elif lines and lineno not in seen_lines:\n                # Check if this line contains assertion-related content\n                # Skip lines that start with decorators or function definitions\n                stripped_line = line.strip()\n                if not (stripped_line.startswith('@') or stripped_line.startswith('def ')):\n                    lines.append(line)\n                    seen_lines.add(lineno)\n",
      "\n            elif lines and lineno not in seen_lines:\n                # Check if this line contains assertion-related content\n                # Skip decorator lines and function definitions\n                stripped_line = line.strip()\n                if (not stripped_line.startswith('@') and \n                    not stripped_line.startswith('def ') and\n                    tp not in {tokenize.OP} or source not in {'@'}):\n                    lines.append(line)\n                    seen_lines.add(lineno)\n",
      "\n            elif lines and lineno not in seen_lines:\n                # Check if this line contains assertion-related content\n                # Skip lines that start with decorators or function definitions\n                stripped_line = line.strip()\n                if not (stripped_line.startswith('@') or stripped_line.startswith('def ')):\n                    lines.append(line)\n                    seen_lines.add(lineno)\n",
      "\n            elif lines and lineno not in seen_lines:\n                # Only add lines that are part of the assertion expression\n                # Skip decorator lines and other non-assertion constructs\n                stripped_line = line.strip()\n                if not (stripped_line.startswith('@') or stripped_line.startswith('def ') or \n                       stripped_line.startswith('class ') or stripped_line.startswith('import ') or\n                       stripped_line.startswith('from ')):\n                    lines.append(line)\n                    seen_lines.add(lineno)\n",
      "\n            elif lines and lineno not in seen_lines:\n                # Only append lines that are part of the assertion expression\n                # Skip decorator lines (starting with @) and function definitions\n                stripped_line = line.strip()\n                if not (stripped_line.startswith('@') or stripped_line.startswith('def ')):\n                    lines.append(line)\n                    seen_lines.add(lineno)\n",
      "\n            elif lines and lineno not in seen_lines:\n                # Check if this line contains assertion-related content\n                # Skip decorator lines and function definitions\n                stripped_line = line.strip()\n                if not (stripped_line.startswith('@') or stripped_line.startswith('def ')):\n                    lines.append(line)\n                    seen_lines.add(lineno)\n",
      "\n            elif lines and lineno not in seen_lines:\n                # Check if this line contains assertion-related content\n                # Avoid collecting decorator lines or function definitions\n                stripped_line = line.strip()\n                if (not stripped_line.startswith('@') and \n                    not stripped_line.startswith('def ') and\n                    not stripped_line.startswith('class ') and\n                    tp not in {tokenize.OP} or source not in {'@'}):\n                    lines.append(line)\n                    seen_lines.add(lineno)\n"
    ],
    "Location 2 (/root/hy/projects_1/pytest/src/_pytest/assertion/rewrite.py lines 578-579)": [
      "\n        if tp == tokenize.NAME and source == \"assert\":\n            assert_lineno = lineno\n        elif tp == tokenize.NAME and source.startswith(\"@\"):\n            # Stop collecting lines when we encounter a decorator\n            if assert_lineno is not None:\n                _write_and_reset()\n        elif assert_lineno is not None:\n",
      "\n        if tp == tokenize.NAME and source == \"assert\":\n            assert_lineno = lineno\n",
      "\n        if tp == tokenize.NAME and source == \"assert\":\n            assert_lineno = lineno\n        elif tp == tokenize.NAME and source.startswith(\"@\"):\n            # Stop collecting lines if we encounter a decorator\n            if assert_lineno is not None:\n                _write_and_reset()\n        elif assert_lineno is not None:\n",
      "\n        if tp == tokenize.NAME and source == \"assert\":\n            assert_lineno = lineno\n        elif tp == tokenize.NAME and source.startswith(\"@\"):\n            # Decorator detected - stop collecting if we're in an assertion\n            if assert_lineno is not None:\n                _write_and_reset()\n        elif tp == tokenize.NAME and source == \"def\":\n            # Function definition detected - stop collecting if we're in an assertion\n            if assert_lineno is not None:\n                _write_and_reset()\n",
      "\n        if tp == tokenize.NAME and source == \"assert\":\n            assert_lineno = lineno\n        elif tp == tokenize.NAME and source.startswith(\"@\"):\n            # Stop collecting if we encounter a decorator\n            if assert_lineno is not None:\n                _write_and_reset()\n        elif assert_lineno is not None:\n",
      "\n        if tp == tokenize.NAME and source == \"assert\":\n            assert_lineno = lineno\n        elif tp == tokenize.NAME and source.startswith(\"@\"):\n            # Stop collecting if we encounter a decorator\n            if assert_lineno is not None:\n                _write_and_reset()\n        elif assert_lineno is not None:\n",
      "\n        if tp == tokenize.NAME and source == \"assert\":\n            assert_lineno = lineno\n        elif tp == tokenize.NAME and source.startswith(\"@\"):\n            # Stop collecting lines if we encounter a decorator\n            if assert_lineno is not None:\n                _write_and_reset()\n",
      "\n        if tp == tokenize.NAME and source == \"assert\":\n            assert_lineno = lineno\n        elif tp == tokenize.NAME and source.startswith(\"@\"):\n            # Stop collecting if we encounter a decorator\n            if assert_lineno is not None:\n                _write_and_reset()\n        elif assert_lineno is not None:\n"
    ],
    "Location 3 (/root/hy/projects_1/pytest/src/_pytest/assertion/rewrite.py lines 587-589)": [
      "\n            if not lines:\n                # Only start collecting lines if this token is part of the assertion\n                if tp in (tokenize.NAME, tokenize.OP, tokenize.NUMBER, tokenize.STRING):\n                    lines.append(line[offset:])\n                    seen_lines.add(lineno)\n",
      "\n            if not lines:\n                # Only start collecting if this token is part of the assertion\n                if tp in (tokenize.NAME, tokenize.OP, tokenize.NUMBER, tokenize.STRING):\n                    lines.append(line[offset:])\n                    seen_lines.add(lineno)\n",
      "\n            if not lines:\n                # Only start collecting if this token is part of the assertion\n                if tp in (tokenize.NAME, tokenize.OP, tokenize.NUMBER, tokenize.STRING):\n                    lines.append(line[offset:])\n                    seen_lines.add(lineno)\n",
      "\n            if not lines:\n                # Only start collecting if this token is part of the assertion\n                if tp in (tokenize.NAME, tokenize.OP, tokenize.NUMBER, tokenize.STRING):\n                    lines.append(line[offset:])\n                    seen_lines.add(lineno)\n",
      "\n            if not lines:\n                # Only start collecting if this token is part of assertion expression\n                if tp in (tokenize.NAME, tokenize.OP, tokenize.NUMBER, tokenize.STRING):\n                    lines.append(line[offset:])\n                    seen_lines.add(lineno)\n",
      "\n            if not lines:\n                # Only start collecting if this token is part of the assertion\n                if tp in (tokenize.NAME, tokenize.OP, tokenize.NUMBER, tokenize.STRING):\n                    lines.append(line[offset:])\n                    seen_lines.add(lineno)\n",
      "\n            if not lines:\n                # Only start collecting if this token is part of the assertion\n                if tp in (tokenize.NAME, tokenize.OP, tokenize.NUMBER, tokenize.STRING):\n                    lines.append(line[offset:])\n                    seen_lines.add(lineno)\n",
      "\n            if not lines:\n                # Only start collecting if this token is part of the assertion\n                if tp in (tokenize.NAME, tokenize.OP, tokenize.NUMBER, tokenize.STRING):\n                    lines.append(line[offset:])\n                    seen_lines.add(lineno)\n"
    ],
    "Location 4 (/root/hy/projects_1/pytest/src/_pytest/assertion/rewrite.py lines 603-604)": [
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                # Check if we have collected any lines and if the next line starts with a decorator\n                if lines and tokens_iter:\n                    try:\n                        # Peek ahead to see if next line starts with @ (decorator)\n                        next_token = next(tokens_iter)\n                        if next_token.type == tokenize.OP and next_token.string == \"@\":\n                            # Put the token back for normal processing\n                            tokens_iter = itertools.chain([next_token], tokens_iter)\n                            _write_and_reset()\n                        elif next_token.type == tokenize.NAME and next_token.string == \"def\":\n                            # Put the token back for normal processing  \n                            tokens_iter = itertools.chain([next_token], tokens_iter)\n                            _write_and_reset()\n                        else:\n                            # Put the token back and continue normal processing\n                            tokens_iter = itertools.chain([next_token], tokens_iter)\n                            _write_and_reset()\n                    except StopIteration:\n                        _write_and_reset()\n                else:\n                    _write_and_reset()\n",
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                # Check if we have a decorator or function definition on the next line\n                # which should terminate assertion collection\n                if lines:\n                    # Look ahead to see if next non-empty line starts with @ or def\n                    next_line_tokens = []\n                    try:\n                        # Get remaining tokens to check for decorators/function definitions\n                        temp_tokens = list(tokens)\n                        for future_token in temp_tokens:\n                            if future_token.type == tokenize.OP and future_token.string == '@':\n                                # Found decorator, should not include in assertion\n                                break\n                            elif future_token.type == tokenize.NAME and future_token.string == 'def':\n                                # Found function definition, should not include in assertion\n                                break\n                            elif future_token.type in {tokenize.NEWLINE, tokenize.NL}:\n                                continue\n                            elif future_token.type not in {tokenize.COMMENT, tokenize.ENCODING}:\n                                # Found other code, safe to continue\n                                break\n                    except:\n                        # If we can't look ahead, play it safe\n                        pass\n                _write_and_reset()\n",
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                # Check if we have any lines collected and if the next line starts with a decorator\n                # This prevents decorator lines from being included in assertion expressions\n                if lines and tp == tokenize.NEWLINE:\n                    # Look ahead to see if next non-whitespace line starts with '@' (decorator)\n                    next_line_start = offset + len(source[offset:].split('\\n', 1)[0])\n                    if next_line_start < len(source):\n                        remaining = source[next_line_start:].lstrip()\n                        if remaining.startswith('@') or remaining.startswith('def '):\n                            _write_and_reset()\n                            continue\n                _write_and_reset()\n",
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                # Check if we have any lines collected and if the next line starts with @ (decorator)\n                # or other non-assertion tokens that should terminate collection\n                if lines:\n                    try:\n                        # Look ahead to see if next line starts with decorator or function def\n                        current_pos = source.find('\\n', offset)\n                        if current_pos != -1:\n                            next_line_start = current_pos + 1\n                            if next_line_start < len(source):\n                                next_line = source[next_line_start:].lstrip()\n                                if next_line.startswith('@') or next_line.startswith('def '):\n                                    _write_and_reset()\n                                    return ret\n                    except (IndexError, AttributeError):\n                        pass\n                _write_and_reset()\n",
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                # Check if we have any pending lines and if the next line starts with a decorator\n                # This prevents decorator lines from being included in assertion expressions\n                if lines and tp == tokenize.NEWLINE:\n                    # Look ahead to see if next non-empty line starts with '@' (decorator)\n                    try:\n                        next_line_start = source.find('\\n', end) + 1\n                        if next_line_start > 0 and next_line_start < len(source):\n                            next_line = source[next_line_start:source.find('\\n', next_line_start)]\n                            if next_line.strip().startswith('@'):\n                                # Don't include decorator lines in assertion\n                                pass\n                    except (IndexError, ValueError):\n                        pass\n                _write_and_reset()\n",
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                # Check if we have a decorator or function definition on the next line\n                # that should terminate assertion collection\n                if lines:\n                    # Look ahead to see if next non-empty line starts with @ or def\n                    current_pos = tokenize_rt.src_to_offset(source, lineno + 1, 0) if lineno + 1 <= len(source.splitlines()) else len(source)\n                    if current_pos < len(source):\n                        remaining_source = source[current_pos:].lstrip()\n                        if remaining_source.startswith('@') or remaining_source.startswith('def '):\n                            _write_and_reset()\n                            break\n                _write_and_reset()\n",
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                # Check if we have any lines and the next token might be a decorator or function def\n                if lines:\n                    # Look ahead to see if next non-whitespace token is @ or def\n                    try:\n                        next_token = next(tokens)\n                        if next_token.type == tokenize.NAME and next_token.string in {'def', 'class'}:\n                            # Don't reset, we're done with this assertion\n                            pass\n                        elif next_token.type == tokenize.OP and next_token.string == '@':\n                            # Don't reset, we're done with this assertion\n                            pass\n                        else:\n                            # Put the token back by creating a new iterator\n                            tokens = itertools.chain([next_token], tokens)\n                            _write_and_reset()\n                    except StopIteration:\n                        _write_and_reset()\n                else:\n                    _write_and_reset()\n",
      "\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                # Check if we have collected any lines and if the next tokens suggest\n                # we're moving beyond the assertion expression (e.g., decorator, function def)\n                if lines:\n                    # Peek ahead to see if next non-whitespace token is a decorator or function def\n                    try:\n                        next_token = next(tokens, None)\n                        if next_token and next_token.type == tokenize.OP and next_token.string == '@':\n                            # Don't include decorator lines in assertion\n                            _write_and_reset()\n                            continue\n                        elif next_token and next_token.type == tokenize.NAME and next_token.string == 'def':\n                            # Don't include function definition lines in assertion\n                            _write_and_reset()\n                            continue\n                        else:\n                            # Put the token back by creating a new iterator\n                            if next_token:\n                                tokens = itertools.chain([next_token], tokens)\n                    except StopIteration:\n                        pass\n                _write_and_reset()\n"
    ],
    "Location 5 (/root/hy/projects_1/pytest/src/_pytest/assertion/rewrite.py lines 567-574)": [
      "\ndef _write_and_reset() -> None:\n    nonlocal depth, lines, assert_lineno, seen_lines\n    assert assert_lineno is not None\n    \n    # Filter out any lines that don't belong to the assertion expression\n    filtered_lines = []\n    for line in lines:\n        stripped = line.strip()\n        # Skip decorator lines and function definitions that got incorrectly collected\n        if stripped.startswith('@') or stripped.startswith('def '):\n            continue\n        filtered_lines.append(line)\n    \n    if filtered_lines:\n        ret[assert_lineno] = \"\".join(filtered_lines).rstrip().rstrip(\"\\\\\")\n    \n    depth = 0\n    lines = []\n    assert_lineno = None\n    seen_lines = set()\n",
      "\ndef _write_and_reset() -> None:\n    nonlocal depth, lines, assert_lineno, seen_lines\n    assert assert_lineno is not None\n    \n    # Filter out any lines that don't belong to the assertion expression\n    filtered_lines = []\n    for line in lines:\n        # Remove decorator lines that may have been incorrectly collected\n        stripped = line.strip()\n        if stripped.startswith('@') or stripped.startswith('def '):\n            break\n        filtered_lines.append(line)\n    \n    if filtered_lines:\n        ret[assert_lineno] = \"\".join(filtered_lines).rstrip().rstrip(\"\\\\\")\n    \n    depth = 0\n    lines = []\n    assert_lineno = None\n    seen_lines = set()\n",
      "\ndef _write_and_reset() -> None:\n    nonlocal depth, lines, assert_lineno, seen_lines\n    assert assert_lineno is not None\n    \n    # Filter out any lines that don't belong to the assertion expression\n    filtered_lines = []\n    for line in lines:\n        stripped = line.strip()\n        # Skip decorator lines and function definitions that shouldn't be part of assertion\n        if stripped.startswith('@') or stripped.startswith('def '):\n            continue\n        filtered_lines.append(line)\n    \n    if filtered_lines:\n        ret[assert_lineno] = \"\".join(filtered_lines).rstrip().rstrip(\"\\\\\")\n    \n    depth = 0\n    lines = []\n    assert_lineno = None\n    seen_lines = set()\n",
      "\ndef _write_and_reset() -> None:\n    nonlocal depth, lines, assert_lineno, seen_lines\n    assert assert_lineno is not None\n    \n    # Filter out lines that don't belong to the assertion expression\n    filtered_lines = []\n    for line in lines:\n        stripped = line.strip()\n        # Skip decorator lines and function definitions that got incorrectly collected\n        if stripped.startswith('@') or stripped.startswith('def '):\n            continue\n        filtered_lines.append(line)\n    \n    if filtered_lines:\n        ret[assert_lineno] = \"\".join(filtered_lines).rstrip().rstrip(\"\\\\\")\n    \n    depth = 0\n    lines = []\n    assert_lineno = None\n    seen_lines = set()\n",
      "\ndef _write_and_reset() -> None:\n    nonlocal depth, lines, assert_lineno, seen_lines\n    assert assert_lineno is not None\n    \n    # Filter out decorator lines and other non-assertion code\n    filtered_lines = []\n    for line in lines:\n        stripped = line.strip()\n        # Skip decorator lines and function definitions\n        if stripped.startswith('@') or stripped.startswith('def '):\n            continue\n        filtered_lines.append(line)\n    \n    if filtered_lines:\n        ret[assert_lineno] = \"\".join(filtered_lines).rstrip().rstrip(\"\\\\\")\n    \n    depth = 0\n    lines = []\n    assert_lineno = None\n    seen_lines = set()\n",
      "\ndef _write_and_reset() -> None:\n    nonlocal depth, lines, assert_lineno, seen_lines\n    assert assert_lineno is not None\n    \n    # Filter out any lines that don't belong to the assertion expression\n    filtered_lines = []\n    for line in lines:\n        stripped = line.strip()\n        # Skip decorator lines and function definitions that shouldn't be part of assertion\n        if stripped.startswith('@') or stripped.startswith('def '):\n            continue\n        filtered_lines.append(line)\n    \n    if filtered_lines:\n        ret[assert_lineno] = \"\".join(filtered_lines).rstrip().rstrip(\"\\\\\")\n    \n    depth = 0\n    lines = []\n    assert_lineno = None\n    seen_lines = set()\n",
      "\ndef _write_and_reset() -> None:\n    nonlocal depth, lines, assert_lineno, seen_lines\n    assert assert_lineno is not None\n    # Filter out any decorator lines that may have been incorrectly collected\n    filtered_lines = []\n    for line in lines:\n        stripped = line.strip()\n        # Skip decorator lines and function definitions\n        if not (stripped.startswith('@') or stripped.startswith('def ')):\n            filtered_lines.append(line)\n    ret[assert_lineno] = \"\".join(filtered_lines).rstrip().rstrip(\"\\\\\")\n    depth = 0\n    lines = []\n    assert_lineno = None\n    seen_lines = set()\n",
      "\ndef _write_and_reset() -> None:\n    nonlocal depth, lines, assert_lineno, seen_lines\n    assert assert_lineno is not None\n    \n    # Filter out any lines that don't belong to the assertion expression\n    filtered_lines = []\n    for line in lines:\n        stripped = line.strip()\n        # Skip decorator lines and function definitions that may have been incorrectly collected\n        if not (stripped.startswith('@') or stripped.startswith('def ') or stripped.startswith('async def ')):\n            filtered_lines.append(line)\n    \n    ret[assert_lineno] = \"\".join(filtered_lines).rstrip().rstrip(\"\\\\\")\n    depth = 0\n    lines = []\n    assert_lineno = None\n    seen_lines = set()\n"
    ]
  },
  "combined_diffs": {
    "raw_patch": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..1d08bfcae 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -564,6 +564,7 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n     assert_lineno: Optional[int] = None\n     seen_lines: Set[int] = set()\n \n+\n     def _write_and_reset() -> None:\n         nonlocal depth, lines, assert_lineno, seen_lines\n         assert assert_lineno is not None\n@@ -575,6 +576,7 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n \n     tokens = tokenize.tokenize(io.BytesIO(src).readline)\n     for tp, source, (lineno, offset), _, line in tokens:\n+\n         if tp == tokenize.NAME and source == \"assert\":\n             assert_lineno = lineno\n         elif assert_lineno is not None:\n@@ -584,6 +586,7 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n             elif tp == tokenize.OP and source in \")]}\":\n                 depth -= 1\n \n+\n             if not lines:\n                 lines.append(line[offset:])\n                 seen_lines.add(lineno)\n@@ -600,11 +603,20 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 else:\n                     lines.append(line[:offset])\n                 _write_and_reset()\n+\n             elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                 _write_and_reset()\n+\n             elif lines and lineno not in seen_lines:\n-                lines.append(line)\n-                seen_lines.add(lineno)\n+                # Check if this token indicates we've moved beyond the assertion\n+                # Stop collecting lines when encountering decorators or function definitions\n+                if tp == tokenize.OP and source == \"@\":\n+                    _write_and_reset()\n+                elif tp == tokenize.NAME and source == \"def\":\n+                    _write_and_reset()\n+                else:\n+                    lines.append(line)\n+                    seen_lines.add(lineno)\n \n     return ret\n \n",
    "variant_0": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..ae20e8c41 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -564,19 +564,36 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n     assert_lineno: Optional[int] = None\n     seen_lines: Set[int] = set()\n \n-    def _write_and_reset() -> None:\n-        nonlocal depth, lines, assert_lineno, seen_lines\n-        assert assert_lineno is not None\n-        ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n-        depth = 0\n-        lines = []\n-        assert_lineno = None\n-        seen_lines = set()\n+\n+def _write_and_reset() -> None:\n+    nonlocal depth, lines, assert_lineno, seen_lines\n+    assert assert_lineno is not None\n+    \n+    # Filter out any lines that don't belong to the assertion expression\n+    filtered_lines = []\n+    for line in lines:\n+        stripped = line.strip()\n+        # Skip decorator lines and function definitions that got incorrectly collected\n+        if not (stripped.startswith('@') or stripped.startswith('def ')):\n+            filtered_lines.append(line)\n+    \n+    if filtered_lines:\n+        ret[assert_lineno] = \"\".join(filtered_lines).rstrip().rstrip(\"\\\\\")\n+    depth = 0\n+    lines = []\n+    assert_lineno = None\n+    seen_lines = set()\n \n     tokens = tokenize.tokenize(io.BytesIO(src).readline)\n     for tp, source, (lineno, offset), _, line in tokens:\n+\n         if tp == tokenize.NAME and source == \"assert\":\n             assert_lineno = lineno\n+        elif tp == tokenize.NAME and source.startswith(\"@\"):\n+            # Stop collecting if we encounter a decorator\n+            if assert_lineno is not None:\n+                _write_and_reset()\n+        elif assert_lineno is not None:\n         elif assert_lineno is not None:\n             # keep track of depth for the assert-message `,` lookup\n             if tp == tokenize.OP and source in \"([{\":\n@@ -584,9 +601,12 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n             elif tp == tokenize.OP and source in \")]}\":\n                 depth -= 1\n \n+\n             if not lines:\n-                lines.append(line[offset:])\n-                seen_lines.add(lineno)\n+                # Only start collecting if this token is part of the assertion\n+                if tp in (tokenize.NAME, tokenize.OP, tokenize.NUMBER, tokenize.STRING):\n+                    lines.append(line[offset:])\n+                    seen_lines.add(lineno)\n             # a non-nested comma separates the expression from the message\n             elif depth == 0 and tp == tokenize.OP and source == \",\":\n                 # one line assert with message\n@@ -600,11 +620,38 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 else:\n                     lines.append(line[:offset])\n                 _write_and_reset()\n+\n             elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n-                _write_and_reset()\n+                # Check if we have any collected lines before writing\n+                if lines:\n+                    # Filter out any decorator lines that may have been incorrectly collected\n+                    filtered_lines = []\n+                    for collected_line in lines:\n+                        stripped = collected_line.strip()\n+                        # Skip decorator lines and function definitions\n+                        if not (stripped.startswith('@') or stripped.startswith('def ')):\n+                            filtered_lines.append(collected_line)\n+                    \n+                    # Only write if we have valid assertion lines\n+                    if filtered_lines:\n+                        lines[:] = filtered_lines\n+                        _write_and_reset()\n+                    else:\n+                        # Clear invalid collection\n+                        lines.clear()\n+                        seen_lines.clear()\n+                else:\n+                    _write_and_reset()\n+\n             elif lines and lineno not in seen_lines:\n-                lines.append(line)\n-                seen_lines.add(lineno)\n+                # Check if this line contains assertion-related content\n+                # Skip decorator lines and function definitions\n+                stripped_line = line.strip()\n+                if (not stripped_line.startswith('@') and \n+                    not stripped_line.startswith('def ') and\n+                    tp not in {tokenize.INDENT, tokenize.DEDENT, tokenize.COMMENT}):\n+                    lines.append(line)\n+                    seen_lines.add(lineno)\n \n     return ret\n \n",
    "variant_1": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..9348787a2 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -564,19 +564,38 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n     assert_lineno: Optional[int] = None\n     seen_lines: Set[int] = set()\n \n-    def _write_and_reset() -> None:\n-        nonlocal depth, lines, assert_lineno, seen_lines\n-        assert assert_lineno is not None\n-        ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n-        depth = 0\n-        lines = []\n-        assert_lineno = None\n-        seen_lines = set()\n+\n+def _write_and_reset() -> None:\n+    nonlocal depth, lines, assert_lineno, seen_lines\n+    assert assert_lineno is not None\n+    \n+    # Filter out any lines that don't belong to the assertion expression\n+    filtered_lines = []\n+    for line in lines:\n+        stripped = line.strip()\n+        # Skip decorator lines and function definitions that got incorrectly collected\n+        if stripped.startswith('@') or stripped.startswith('def '):\n+            continue\n+        filtered_lines.append(line)\n+    \n+    if filtered_lines:\n+        ret[assert_lineno] = \"\".join(filtered_lines).rstrip().rstrip(\"\\\\\")\n+    \n+    depth = 0\n+    lines = []\n+    assert_lineno = None\n+    seen_lines = set()\n \n     tokens = tokenize.tokenize(io.BytesIO(src).readline)\n     for tp, source, (lineno, offset), _, line in tokens:\n+\n         if tp == tokenize.NAME and source == \"assert\":\n             assert_lineno = lineno\n+        elif tp == tokenize.NAME and source.startswith(\"@\"):\n+            # Stop collecting lines when we encounter a decorator\n+            if assert_lineno is not None:\n+                _write_and_reset()\n+        elif assert_lineno is not None:\n         elif assert_lineno is not None:\n             # keep track of depth for the assert-message `,` lookup\n             if tp == tokenize.OP and source in \"([{\":\n@@ -584,9 +603,12 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n             elif tp == tokenize.OP and source in \")]}\":\n                 depth -= 1\n \n+\n             if not lines:\n-                lines.append(line[offset:])\n-                seen_lines.add(lineno)\n+                # Only start collecting lines if this token is part of the assertion\n+                if tp in (tokenize.NAME, tokenize.OP, tokenize.NUMBER, tokenize.STRING):\n+                    lines.append(line[offset:])\n+                    seen_lines.add(lineno)\n             # a non-nested comma separates the expression from the message\n             elif depth == 0 and tp == tokenize.OP and source == \",\":\n                 # one line assert with message\n@@ -600,11 +622,42 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 else:\n                     lines.append(line[:offset])\n                 _write_and_reset()\n+\n             elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n-                _write_and_reset()\n+                # Check if we have collected any lines and if the next line starts with a decorator\n+                if lines and tokens_iter:\n+                    try:\n+                        # Peek ahead to see if next line starts with @ (decorator)\n+                        next_token = next(tokens_iter)\n+                        if next_token.type == tokenize.OP and next_token.string == \"@\":\n+                            # Put the token back for normal processing\n+                            tokens_iter = itertools.chain([next_token], tokens_iter)\n+                            _write_and_reset()\n+                        elif next_token.type == tokenize.NAME and next_token.string == \"def\":\n+                            # Put the token back for normal processing  \n+                            tokens_iter = itertools.chain([next_token], tokens_iter)\n+                            _write_and_reset()\n+                        else:\n+                            # Put the token back and continue normal processing\n+                            tokens_iter = itertools.chain([next_token], tokens_iter)\n+                            _write_and_reset()\n+                    except StopIteration:\n+                        _write_and_reset()\n+                else:\n+                    _write_and_reset()\n+\n             elif lines and lineno not in seen_lines:\n-                lines.append(line)\n-                seen_lines.add(lineno)\n+                # Check if this line contains assertion-related content\n+                # Skip decorator lines and function definitions\n+                stripped_line = line.strip()\n+                if (stripped_line.startswith('@') or \n+                    stripped_line.startswith('def ') or\n+                    (tp == tokenize.NAME and source in ('def', 'class'))):\n+                    # Stop collecting lines when we hit decorators or function definitions\n+                    _write_and_reset()\n+                else:\n+                    lines.append(line)\n+                    seen_lines.add(lineno)\n \n     return ret\n \n",
    "variant_2": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..e46748d17 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -564,17 +564,31 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n     assert_lineno: Optional[int] = None\n     seen_lines: Set[int] = set()\n \n-    def _write_and_reset() -> None:\n-        nonlocal depth, lines, assert_lineno, seen_lines\n-        assert assert_lineno is not None\n-        ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n-        depth = 0\n-        lines = []\n-        assert_lineno = None\n-        seen_lines = set()\n+\n+def _write_and_reset() -> None:\n+    nonlocal depth, lines, assert_lineno, seen_lines\n+    assert assert_lineno is not None\n+    \n+    # Filter out any lines that don't belong to the assertion expression\n+    filtered_lines = []\n+    for line in lines:\n+        # Remove decorator lines that may have been incorrectly collected\n+        stripped = line.strip()\n+        if stripped.startswith('@') or stripped.startswith('def '):\n+            break\n+        filtered_lines.append(line)\n+    \n+    if filtered_lines:\n+        ret[assert_lineno] = \"\".join(filtered_lines).rstrip().rstrip(\"\\\\\")\n+    \n+    depth = 0\n+    lines = []\n+    assert_lineno = None\n+    seen_lines = set()\n \n     tokens = tokenize.tokenize(io.BytesIO(src).readline)\n     for tp, source, (lineno, offset), _, line in tokens:\n+\n         if tp == tokenize.NAME and source == \"assert\":\n             assert_lineno = lineno\n         elif assert_lineno is not None:\n@@ -584,9 +598,12 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n             elif tp == tokenize.OP and source in \")]}\":\n                 depth -= 1\n \n+\n             if not lines:\n-                lines.append(line[offset:])\n-                seen_lines.add(lineno)\n+                # Only start collecting if this token is part of the assertion\n+                if tp in (tokenize.NAME, tokenize.OP, tokenize.NUMBER, tokenize.STRING):\n+                    lines.append(line[offset:])\n+                    seen_lines.add(lineno)\n             # a non-nested comma separates the expression from the message\n             elif depth == 0 and tp == tokenize.OP and source == \",\":\n                 # one line assert with message\n@@ -600,11 +617,40 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 else:\n                     lines.append(line[:offset])\n                 _write_and_reset()\n+\n             elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n+                # Check if we have a decorator or function definition on the next line\n+                # which should terminate assertion collection\n+                if lines:\n+                    # Look ahead to see if next non-empty line starts with @ or def\n+                    next_line_tokens = []\n+                    try:\n+                        # Get remaining tokens to check for decorators/function definitions\n+                        temp_tokens = list(tokens)\n+                        for future_token in temp_tokens:\n+                            if future_token.type == tokenize.OP and future_token.string == '@':\n+                                # Found decorator, should not include in assertion\n+                                break\n+                            elif future_token.type == tokenize.NAME and future_token.string == 'def':\n+                                # Found function definition, should not include in assertion\n+                                break\n+                            elif future_token.type in {tokenize.NEWLINE, tokenize.NL}:\n+                                continue\n+                            elif future_token.type not in {tokenize.COMMENT, tokenize.ENCODING}:\n+                                # Found other code, safe to continue\n+                                break\n+                    except:\n+                        # If we can't look ahead, play it safe\n+                        pass\n                 _write_and_reset()\n+\n             elif lines and lineno not in seen_lines:\n-                lines.append(line)\n-                seen_lines.add(lineno)\n+                # Check if this line contains assertion-related content\n+                # Skip lines that start with decorators or function definitions\n+                stripped_line = line.strip()\n+                if not (stripped_line.startswith('@') or stripped_line.startswith('def ')):\n+                    lines.append(line)\n+                    seen_lines.add(lineno)\n \n     return ret\n \n",
    "variant_3": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..7e00964e1 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -564,19 +564,38 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n     assert_lineno: Optional[int] = None\n     seen_lines: Set[int] = set()\n \n-    def _write_and_reset() -> None:\n-        nonlocal depth, lines, assert_lineno, seen_lines\n-        assert assert_lineno is not None\n-        ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n-        depth = 0\n-        lines = []\n-        assert_lineno = None\n-        seen_lines = set()\n+\n+def _write_and_reset() -> None:\n+    nonlocal depth, lines, assert_lineno, seen_lines\n+    assert assert_lineno is not None\n+    \n+    # Filter out any lines that don't belong to the assertion expression\n+    filtered_lines = []\n+    for line in lines:\n+        stripped = line.strip()\n+        # Skip decorator lines and function definitions that shouldn't be part of assertion\n+        if stripped.startswith('@') or stripped.startswith('def '):\n+            continue\n+        filtered_lines.append(line)\n+    \n+    if filtered_lines:\n+        ret[assert_lineno] = \"\".join(filtered_lines).rstrip().rstrip(\"\\\\\")\n+    \n+    depth = 0\n+    lines = []\n+    assert_lineno = None\n+    seen_lines = set()\n \n     tokens = tokenize.tokenize(io.BytesIO(src).readline)\n     for tp, source, (lineno, offset), _, line in tokens:\n+\n         if tp == tokenize.NAME and source == \"assert\":\n             assert_lineno = lineno\n+        elif tp == tokenize.NAME and source.startswith(\"@\"):\n+            # Stop collecting lines if we encounter a decorator\n+            if assert_lineno is not None:\n+                _write_and_reset()\n+        elif assert_lineno is not None:\n         elif assert_lineno is not None:\n             # keep track of depth for the assert-message `,` lookup\n             if tp == tokenize.OP and source in \"([{\":\n@@ -584,9 +603,12 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n             elif tp == tokenize.OP and source in \")]}\":\n                 depth -= 1\n \n+\n             if not lines:\n-                lines.append(line[offset:])\n-                seen_lines.add(lineno)\n+                # Only start collecting if this token is part of the assertion\n+                if tp in (tokenize.NAME, tokenize.OP, tokenize.NUMBER, tokenize.STRING):\n+                    lines.append(line[offset:])\n+                    seen_lines.add(lineno)\n             # a non-nested comma separates the expression from the message\n             elif depth == 0 and tp == tokenize.OP and source == \",\":\n                 # one line assert with message\n@@ -600,11 +622,29 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 else:\n                     lines.append(line[:offset])\n                 _write_and_reset()\n+\n             elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n+                # Check if we have any lines collected and if the next line starts with a decorator\n+                # This prevents decorator lines from being included in assertion expressions\n+                if lines and tp == tokenize.NEWLINE:\n+                    # Look ahead to see if next non-whitespace line starts with '@' (decorator)\n+                    next_line_start = offset + len(source[offset:].split('\\n', 1)[0])\n+                    if next_line_start < len(source):\n+                        remaining = source[next_line_start:].lstrip()\n+                        if remaining.startswith('@') or remaining.startswith('def '):\n+                            _write_and_reset()\n+                            continue\n                 _write_and_reset()\n+\n             elif lines and lineno not in seen_lines:\n-                lines.append(line)\n-                seen_lines.add(lineno)\n+                # Check if this line contains assertion-related content\n+                # Skip decorator lines and function definitions\n+                stripped_line = line.strip()\n+                if (not stripped_line.startswith('@') and \n+                    not stripped_line.startswith('def ') and\n+                    tp not in {tokenize.OP} or source not in {'@'}):\n+                    lines.append(line)\n+                    seen_lines.add(lineno)\n \n     return ret\n \n",
    "variant_4": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..e4fad317f 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -564,19 +564,41 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n     assert_lineno: Optional[int] = None\n     seen_lines: Set[int] = set()\n \n-    def _write_and_reset() -> None:\n-        nonlocal depth, lines, assert_lineno, seen_lines\n-        assert assert_lineno is not None\n-        ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n-        depth = 0\n-        lines = []\n-        assert_lineno = None\n-        seen_lines = set()\n+\n+def _write_and_reset() -> None:\n+    nonlocal depth, lines, assert_lineno, seen_lines\n+    assert assert_lineno is not None\n+    \n+    # Filter out lines that don't belong to the assertion expression\n+    filtered_lines = []\n+    for line in lines:\n+        stripped = line.strip()\n+        # Skip decorator lines and function definitions that got incorrectly collected\n+        if stripped.startswith('@') or stripped.startswith('def '):\n+            continue\n+        filtered_lines.append(line)\n+    \n+    if filtered_lines:\n+        ret[assert_lineno] = \"\".join(filtered_lines).rstrip().rstrip(\"\\\\\")\n+    \n+    depth = 0\n+    lines = []\n+    assert_lineno = None\n+    seen_lines = set()\n \n     tokens = tokenize.tokenize(io.BytesIO(src).readline)\n     for tp, source, (lineno, offset), _, line in tokens:\n+\n         if tp == tokenize.NAME and source == \"assert\":\n             assert_lineno = lineno\n+        elif tp == tokenize.NAME and source.startswith(\"@\"):\n+            # Decorator detected - stop collecting if we're in an assertion\n+            if assert_lineno is not None:\n+                _write_and_reset()\n+        elif tp == tokenize.NAME and source == \"def\":\n+            # Function definition detected - stop collecting if we're in an assertion\n+            if assert_lineno is not None:\n+                _write_and_reset()\n         elif assert_lineno is not None:\n             # keep track of depth for the assert-message `,` lookup\n             if tp == tokenize.OP and source in \"([{\":\n@@ -584,9 +606,12 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n             elif tp == tokenize.OP and source in \")]}\":\n                 depth -= 1\n \n+\n             if not lines:\n-                lines.append(line[offset:])\n-                seen_lines.add(lineno)\n+                # Only start collecting if this token is part of the assertion\n+                if tp in (tokenize.NAME, tokenize.OP, tokenize.NUMBER, tokenize.STRING):\n+                    lines.append(line[offset:])\n+                    seen_lines.add(lineno)\n             # a non-nested comma separates the expression from the message\n             elif depth == 0 and tp == tokenize.OP and source == \",\":\n                 # one line assert with message\n@@ -600,11 +625,32 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 else:\n                     lines.append(line[:offset])\n                 _write_and_reset()\n+\n             elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n+                # Check if we have any lines collected and if the next line starts with @ (decorator)\n+                # or other non-assertion tokens that should terminate collection\n+                if lines:\n+                    try:\n+                        # Look ahead to see if next line starts with decorator or function def\n+                        current_pos = source.find('\\n', offset)\n+                        if current_pos != -1:\n+                            next_line_start = current_pos + 1\n+                            if next_line_start < len(source):\n+                                next_line = source[next_line_start:].lstrip()\n+                                if next_line.startswith('@') or next_line.startswith('def '):\n+                                    _write_and_reset()\n+                                    return ret\n+                    except (IndexError, AttributeError):\n+                        pass\n                 _write_and_reset()\n+\n             elif lines and lineno not in seen_lines:\n-                lines.append(line)\n-                seen_lines.add(lineno)\n+                # Check if this line contains assertion-related content\n+                # Skip lines that start with decorators or function definitions\n+                stripped_line = line.strip()\n+                if not (stripped_line.startswith('@') or stripped_line.startswith('def ')):\n+                    lines.append(line)\n+                    seen_lines.add(lineno)\n \n     return ret\n \n",
    "variant_5": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..137b14ebd 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -564,19 +564,38 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n     assert_lineno: Optional[int] = None\n     seen_lines: Set[int] = set()\n \n-    def _write_and_reset() -> None:\n-        nonlocal depth, lines, assert_lineno, seen_lines\n-        assert assert_lineno is not None\n-        ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n-        depth = 0\n-        lines = []\n-        assert_lineno = None\n-        seen_lines = set()\n+\n+def _write_and_reset() -> None:\n+    nonlocal depth, lines, assert_lineno, seen_lines\n+    assert assert_lineno is not None\n+    \n+    # Filter out decorator lines and other non-assertion code\n+    filtered_lines = []\n+    for line in lines:\n+        stripped = line.strip()\n+        # Skip decorator lines and function definitions\n+        if stripped.startswith('@') or stripped.startswith('def '):\n+            continue\n+        filtered_lines.append(line)\n+    \n+    if filtered_lines:\n+        ret[assert_lineno] = \"\".join(filtered_lines).rstrip().rstrip(\"\\\\\")\n+    \n+    depth = 0\n+    lines = []\n+    assert_lineno = None\n+    seen_lines = set()\n \n     tokens = tokenize.tokenize(io.BytesIO(src).readline)\n     for tp, source, (lineno, offset), _, line in tokens:\n+\n         if tp == tokenize.NAME and source == \"assert\":\n             assert_lineno = lineno\n+        elif tp == tokenize.NAME and source.startswith(\"@\"):\n+            # Stop collecting if we encounter a decorator\n+            if assert_lineno is not None:\n+                _write_and_reset()\n+        elif assert_lineno is not None:\n         elif assert_lineno is not None:\n             # keep track of depth for the assert-message `,` lookup\n             if tp == tokenize.OP and source in \"([{\":\n@@ -584,9 +603,12 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n             elif tp == tokenize.OP and source in \")]}\":\n                 depth -= 1\n \n+\n             if not lines:\n-                lines.append(line[offset:])\n-                seen_lines.add(lineno)\n+                # Only start collecting if this token is part of assertion expression\n+                if tp in (tokenize.NAME, tokenize.OP, tokenize.NUMBER, tokenize.STRING):\n+                    lines.append(line[offset:])\n+                    seen_lines.add(lineno)\n             # a non-nested comma separates the expression from the message\n             elif depth == 0 and tp == tokenize.OP and source == \",\":\n                 # one line assert with message\n@@ -600,11 +622,32 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 else:\n                     lines.append(line[:offset])\n                 _write_and_reset()\n+\n             elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n+                # Check if we have any pending lines and if the next line starts with a decorator\n+                # This prevents decorator lines from being included in assertion expressions\n+                if lines and tp == tokenize.NEWLINE:\n+                    # Look ahead to see if next non-empty line starts with '@' (decorator)\n+                    try:\n+                        next_line_start = source.find('\\n', end) + 1\n+                        if next_line_start > 0 and next_line_start < len(source):\n+                            next_line = source[next_line_start:source.find('\\n', next_line_start)]\n+                            if next_line.strip().startswith('@'):\n+                                # Don't include decorator lines in assertion\n+                                pass\n+                    except (IndexError, ValueError):\n+                        pass\n                 _write_and_reset()\n+\n             elif lines and lineno not in seen_lines:\n-                lines.append(line)\n-                seen_lines.add(lineno)\n+                # Only add lines that are part of the assertion expression\n+                # Skip decorator lines and other non-assertion constructs\n+                stripped_line = line.strip()\n+                if not (stripped_line.startswith('@') or stripped_line.startswith('def ') or \n+                       stripped_line.startswith('class ') or stripped_line.startswith('import ') or\n+                       stripped_line.startswith('from ')):\n+                    lines.append(line)\n+                    seen_lines.add(lineno)\n \n     return ret\n \n",
    "variant_6": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..a431e896a 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -564,19 +564,38 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n     assert_lineno: Optional[int] = None\n     seen_lines: Set[int] = set()\n \n-    def _write_and_reset() -> None:\n-        nonlocal depth, lines, assert_lineno, seen_lines\n-        assert assert_lineno is not None\n-        ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n-        depth = 0\n-        lines = []\n-        assert_lineno = None\n-        seen_lines = set()\n+\n+def _write_and_reset() -> None:\n+    nonlocal depth, lines, assert_lineno, seen_lines\n+    assert assert_lineno is not None\n+    \n+    # Filter out any lines that don't belong to the assertion expression\n+    filtered_lines = []\n+    for line in lines:\n+        stripped = line.strip()\n+        # Skip decorator lines and function definitions that shouldn't be part of assertion\n+        if stripped.startswith('@') or stripped.startswith('def '):\n+            continue\n+        filtered_lines.append(line)\n+    \n+    if filtered_lines:\n+        ret[assert_lineno] = \"\".join(filtered_lines).rstrip().rstrip(\"\\\\\")\n+    \n+    depth = 0\n+    lines = []\n+    assert_lineno = None\n+    seen_lines = set()\n \n     tokens = tokenize.tokenize(io.BytesIO(src).readline)\n     for tp, source, (lineno, offset), _, line in tokens:\n+\n         if tp == tokenize.NAME and source == \"assert\":\n             assert_lineno = lineno\n+        elif tp == tokenize.NAME and source.startswith(\"@\"):\n+            # Stop collecting if we encounter a decorator\n+            if assert_lineno is not None:\n+                _write_and_reset()\n+        elif assert_lineno is not None:\n         elif assert_lineno is not None:\n             # keep track of depth for the assert-message `,` lookup\n             if tp == tokenize.OP and source in \"([{\":\n@@ -584,9 +603,12 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n             elif tp == tokenize.OP and source in \")]}\":\n                 depth -= 1\n \n+\n             if not lines:\n-                lines.append(line[offset:])\n-                seen_lines.add(lineno)\n+                # Only start collecting if this token is part of the assertion\n+                if tp in (tokenize.NAME, tokenize.OP, tokenize.NUMBER, tokenize.STRING):\n+                    lines.append(line[offset:])\n+                    seen_lines.add(lineno)\n             # a non-nested comma separates the expression from the message\n             elif depth == 0 and tp == tokenize.OP and source == \",\":\n                 # one line assert with message\n@@ -600,11 +622,27 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 else:\n                     lines.append(line[:offset])\n                 _write_and_reset()\n+\n             elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n+                # Check if we have a decorator or function definition on the next line\n+                # that should terminate assertion collection\n+                if lines:\n+                    # Look ahead to see if next non-empty line starts with @ or def\n+                    current_pos = tokenize_rt.src_to_offset(source, lineno + 1, 0) if lineno + 1 <= len(source.splitlines()) else len(source)\n+                    if current_pos < len(source):\n+                        remaining_source = source[current_pos:].lstrip()\n+                        if remaining_source.startswith('@') or remaining_source.startswith('def '):\n+                            _write_and_reset()\n+                            break\n                 _write_and_reset()\n+\n             elif lines and lineno not in seen_lines:\n-                lines.append(line)\n-                seen_lines.add(lineno)\n+                # Only append lines that are part of the assertion expression\n+                # Skip decorator lines (starting with @) and function definitions\n+                stripped_line = line.strip()\n+                if not (stripped_line.startswith('@') or stripped_line.startswith('def ')):\n+                    lines.append(line)\n+                    seen_lines.add(lineno)\n \n     return ret\n \n",
    "variant_7": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..602028900 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -564,19 +564,32 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n     assert_lineno: Optional[int] = None\n     seen_lines: Set[int] = set()\n \n-    def _write_and_reset() -> None:\n-        nonlocal depth, lines, assert_lineno, seen_lines\n-        assert assert_lineno is not None\n-        ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n-        depth = 0\n-        lines = []\n-        assert_lineno = None\n-        seen_lines = set()\n+\n+def _write_and_reset() -> None:\n+    nonlocal depth, lines, assert_lineno, seen_lines\n+    assert assert_lineno is not None\n+    # Filter out any decorator lines that may have been incorrectly collected\n+    filtered_lines = []\n+    for line in lines:\n+        stripped = line.strip()\n+        # Skip decorator lines and function definitions\n+        if not (stripped.startswith('@') or stripped.startswith('def ')):\n+            filtered_lines.append(line)\n+    ret[assert_lineno] = \"\".join(filtered_lines).rstrip().rstrip(\"\\\\\")\n+    depth = 0\n+    lines = []\n+    assert_lineno = None\n+    seen_lines = set()\n \n     tokens = tokenize.tokenize(io.BytesIO(src).readline)\n     for tp, source, (lineno, offset), _, line in tokens:\n+\n         if tp == tokenize.NAME and source == \"assert\":\n             assert_lineno = lineno\n+        elif tp == tokenize.NAME and source.startswith(\"@\"):\n+            # Stop collecting lines if we encounter a decorator\n+            if assert_lineno is not None:\n+                _write_and_reset()\n         elif assert_lineno is not None:\n             # keep track of depth for the assert-message `,` lookup\n             if tp == tokenize.OP and source in \"([{\":\n@@ -584,9 +597,12 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n             elif tp == tokenize.OP and source in \")]}\":\n                 depth -= 1\n \n+\n             if not lines:\n-                lines.append(line[offset:])\n-                seen_lines.add(lineno)\n+                # Only start collecting if this token is part of the assertion\n+                if tp in (tokenize.NAME, tokenize.OP, tokenize.NUMBER, tokenize.STRING):\n+                    lines.append(line[offset:])\n+                    seen_lines.add(lineno)\n             # a non-nested comma separates the expression from the message\n             elif depth == 0 and tp == tokenize.OP and source == \",\":\n                 # one line assert with message\n@@ -600,11 +616,35 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 else:\n                     lines.append(line[:offset])\n                 _write_and_reset()\n+\n             elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n-                _write_and_reset()\n+                # Check if we have any lines and the next token might be a decorator or function def\n+                if lines:\n+                    # Look ahead to see if next non-whitespace token is @ or def\n+                    try:\n+                        next_token = next(tokens)\n+                        if next_token.type == tokenize.NAME and next_token.string in {'def', 'class'}:\n+                            # Don't reset, we're done with this assertion\n+                            pass\n+                        elif next_token.type == tokenize.OP and next_token.string == '@':\n+                            # Don't reset, we're done with this assertion\n+                            pass\n+                        else:\n+                            # Put the token back by creating a new iterator\n+                            tokens = itertools.chain([next_token], tokens)\n+                            _write_and_reset()\n+                    except StopIteration:\n+                        _write_and_reset()\n+                else:\n+                    _write_and_reset()\n+\n             elif lines and lineno not in seen_lines:\n-                lines.append(line)\n-                seen_lines.add(lineno)\n+                # Check if this line contains assertion-related content\n+                # Skip decorator lines and function definitions\n+                stripped_line = line.strip()\n+                if not (stripped_line.startswith('@') or stripped_line.startswith('def ')):\n+                    lines.append(line)\n+                    seen_lines.add(lineno)\n \n     return ret\n \n",
    "variant_8": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..046124693 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -564,19 +564,35 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n     assert_lineno: Optional[int] = None\n     seen_lines: Set[int] = set()\n \n-    def _write_and_reset() -> None:\n-        nonlocal depth, lines, assert_lineno, seen_lines\n-        assert assert_lineno is not None\n-        ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n-        depth = 0\n-        lines = []\n-        assert_lineno = None\n-        seen_lines = set()\n+\n+def _write_and_reset() -> None:\n+    nonlocal depth, lines, assert_lineno, seen_lines\n+    assert assert_lineno is not None\n+    \n+    # Filter out any lines that don't belong to the assertion expression\n+    filtered_lines = []\n+    for line in lines:\n+        stripped = line.strip()\n+        # Skip decorator lines and function definitions that may have been incorrectly collected\n+        if not (stripped.startswith('@') or stripped.startswith('def ') or stripped.startswith('async def ')):\n+            filtered_lines.append(line)\n+    \n+    ret[assert_lineno] = \"\".join(filtered_lines).rstrip().rstrip(\"\\\\\")\n+    depth = 0\n+    lines = []\n+    assert_lineno = None\n+    seen_lines = set()\n \n     tokens = tokenize.tokenize(io.BytesIO(src).readline)\n     for tp, source, (lineno, offset), _, line in tokens:\n+\n         if tp == tokenize.NAME and source == \"assert\":\n             assert_lineno = lineno\n+        elif tp == tokenize.NAME and source.startswith(\"@\"):\n+            # Stop collecting if we encounter a decorator\n+            if assert_lineno is not None:\n+                _write_and_reset()\n+        elif assert_lineno is not None:\n         elif assert_lineno is not None:\n             # keep track of depth for the assert-message `,` lookup\n             if tp == tokenize.OP and source in \"([{\":\n@@ -584,9 +600,12 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n             elif tp == tokenize.OP and source in \")]}\":\n                 depth -= 1\n \n+\n             if not lines:\n-                lines.append(line[offset:])\n-                seen_lines.add(lineno)\n+                # Only start collecting if this token is part of the assertion\n+                if tp in (tokenize.NAME, tokenize.OP, tokenize.NUMBER, tokenize.STRING):\n+                    lines.append(line[offset:])\n+                    seen_lines.add(lineno)\n             # a non-nested comma separates the expression from the message\n             elif depth == 0 and tp == tokenize.OP and source == \",\":\n                 # one line assert with message\n@@ -600,11 +619,40 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 else:\n                     lines.append(line[:offset])\n                 _write_and_reset()\n+\n             elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n+                # Check if we have collected any lines and if the next tokens suggest\n+                # we're moving beyond the assertion expression (e.g., decorator, function def)\n+                if lines:\n+                    # Peek ahead to see if next non-whitespace token is a decorator or function def\n+                    try:\n+                        next_token = next(tokens, None)\n+                        if next_token and next_token.type == tokenize.OP and next_token.string == '@':\n+                            # Don't include decorator lines in assertion\n+                            _write_and_reset()\n+                            continue\n+                        elif next_token and next_token.type == tokenize.NAME and next_token.string == 'def':\n+                            # Don't include function definition lines in assertion\n+                            _write_and_reset()\n+                            continue\n+                        else:\n+                            # Put the token back by creating a new iterator\n+                            if next_token:\n+                                tokens = itertools.chain([next_token], tokens)\n+                    except StopIteration:\n+                        pass\n                 _write_and_reset()\n+\n             elif lines and lineno not in seen_lines:\n-                lines.append(line)\n-                seen_lines.add(lineno)\n+                # Check if this line contains assertion-related content\n+                # Avoid collecting decorator lines or function definitions\n+                stripped_line = line.strip()\n+                if (not stripped_line.startswith('@') and \n+                    not stripped_line.startswith('def ') and\n+                    not stripped_line.startswith('class ') and\n+                    tp not in {tokenize.OP} or source not in {'@'}):\n+                    lines.append(line)\n+                    seen_lines.add(lineno)\n \n     return ret\n \n"
  }
}