{
  "zero_patches": {
    "Location 1 (/root/hy/projects_3/xarray/xarray/core/concat.py lines 222-233)": "\n            # Collect all variables from all datasets for validation\n            all_vars = set()\n            for ds in datasets:\n                all_vars.update(getattr(ds, subset))\n            \n            invalid_vars = [k for k in opt if k not in all_vars]\n            if invalid_vars:\n                if subset == \"coords\":\n                    raise ValueError(\n                        \"some variables in coords are not coordinates in \"\n                        \"any dataset: %s\" % (invalid_vars,)\n                    )\n                else:\n                    raise ValueError(\n                        \"some variables in data_vars are not data variables \"\n                        \"in any dataset: %s\" % (invalid_vars,)\n                    )\n",
    "Location 2 (/root/hy/projects_3/xarray/xarray/core/concat.py lines 315-320)": "\n    # determine which variables to merge, and then merge them according to compat\n    variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n\n    result_vars = {}\n    if variables_to_merge:\n        to_merge = {var: [] for var in variables_to_merge}\n\n        for ds in datasets:\n            for var in variables_to_merge:\n                if var in ds.variables:\n                    to_merge[var].append(ds.variables[var])\n                else:\n                    # Create a placeholder variable with fill_value for missing variables\n                    # Get the variable from a dataset that has it to determine shape and dtype\n                    reference_var = None\n                    for ref_ds in datasets:\n                        if var in ref_ds.variables:\n                            reference_var = ref_ds.variables[var]\n                            break\n                    \n                    if reference_var is not None:\n                        # Create a variable filled with fill_value matching the reference\n                        import numpy as np\n                        fill_val = fill_value if fill_value is not None else dtypes.get_fill_value(reference_var.dtype)\n                        filled_data = np.full_like(reference_var.data, fill_val)\n                        placeholder_var = Variable(reference_var.dims, filled_data, reference_var.attrs)\n                        to_merge[var].append(placeholder_var)\n\n        for var in variables_to_merge:\n            result_vars[var] = unique_variable(\n                var, to_merge[var], compat=compat, equals=equals.get(var, None)\n            )\n    else:\n        result_vars = {}\n",
    "Location 3 (/root/hy/projects_3/xarray/xarray/core/concat.py lines 362-364)": "\n    # stack up each variable to fill-out the dataset (in order)\n    # n.b. this loop preserves variable order, needed for groupby.\n    for k in datasets[0].variables:\n        if k in concat_over:\n            try:\n                # Safely collect variables, creating fill_value placeholders for missing ones\n                vars_list = []\n                for ds in datasets:\n                    if k in ds.variables:\n                        vars_list.append(ds.variables[k])\n                    else:\n                        # Create a placeholder variable with fill_value for missing data\n                        # Use the shape and dims from the first dataset that has this variable\n                        ref_var = next(d.variables[k] for d in datasets if k in d.variables)\n                        fill_var = Variable(ref_var.dims, \n                                          utils.full_like(ref_var.data, fill_value, ref_var.dtype),\n                                          ref_var.attrs.copy())\n                        vars_list.append(fill_var)\n                vars = ensure_common_dims(vars_list)\n            except KeyError:\n                raise ValueError(\"%r is not present in all datasets.\" % k)\n            combined = concat_vars(vars, dim, positions)\n            assert isinstance(combined, Variable)\n            result_vars[k] = combined\n"
  },
  "variant_patches": {
    "Location 1 (/root/hy/projects_3/xarray/xarray/core/concat.py lines 222-233)": [
      "\n            # Collect variables from all datasets to support outer join behavior\n            all_vars = set()\n            for ds in datasets:\n                all_vars.update(getattr(ds, subset))\n            \n            invalid_vars = [k for k in opt if k not in all_vars]\n            if invalid_vars:\n                if subset == \"coords\":\n                    raise ValueError(\n                        \"some variables in coords are not coordinates on \"\n                        \"any dataset: %s\" % (invalid_vars,)\n                    )\n                else:\n                    raise ValueError(\n                        \"some variables in data_vars are not data variables \"\n                        \"on any dataset: %s\" % (invalid_vars,)\n                    )\n",
      "\n            # Collect variables from all datasets instead of just the first one\n            all_vars_in_subset = set()\n            for ds in datasets:\n                all_vars_in_subset.update(getattr(ds, subset))\n            \n            invalid_vars = [k for k in opt if k not in all_vars_in_subset]\n            if invalid_vars:\n                if subset == \"coords\":\n                    raise ValueError(\n                        \"some variables in coords are not coordinates on \"\n                        \"any dataset: %s\" % (invalid_vars,)\n                    )\n                else:\n                    raise ValueError(\n                        \"some variables in data_vars are not data variables \"\n                        \"on any dataset: %s\" % (invalid_vars,)\n                    )\n",
      "\n            # Collect variables from all datasets to support outer join behavior\n            all_vars = set()\n            for ds in datasets:\n                all_vars.update(getattr(ds, subset))\n            \n            invalid_vars = [k for k in opt if k not in all_vars]\n            if invalid_vars:\n                if subset == \"coords\":\n                    raise ValueError(\n                        \"some variables in coords are not coordinates on \"\n                        \"any dataset: %s\" % (invalid_vars,)\n                    )\n                else:\n                    raise ValueError(\n                        \"some variables in data_vars are not data variables \"\n                        \"on any dataset: %s\" % (invalid_vars,)\n                    )\n",
      "\n        else:\n            # Collect variables from all datasets instead of just the first one\n            all_vars_in_subset = set()\n            for ds in datasets:\n                all_vars_in_subset.update(getattr(ds, subset))\n            \n            invalid_vars = [k for k in opt if k not in all_vars_in_subset]\n            if invalid_vars:\n                if subset == \"coords\":\n                    raise ValueError(\n                        \"some variables in coords are not coordinates on \"\n                        \"any dataset: %s\" % (invalid_vars,)\n                    )\n                else:\n                    raise ValueError(\n                        \"some variables in data_vars are not data variables \"\n                        \"on any dataset: %s\" % (invalid_vars,)\n                    )\n            concat_over.update(opt)\n",
      "\n            # Collect all variables from all datasets for validation\n            all_vars = set()\n            for ds in datasets:\n                all_vars.update(getattr(ds, subset))\n            \n            invalid_vars = [k for k in opt if k not in all_vars]\n            if invalid_vars:\n                if subset == \"coords\":\n                    raise ValueError(\n                        \"some variables in coords are not coordinates on \"\n                        \"any dataset: %s\" % (invalid_vars,)\n                    )\n                else:\n                    raise ValueError(\n                        \"some variables in data_vars are not data variables \"\n                        \"on any dataset: %s\" % (invalid_vars,)\n                    )\n",
      "\n            # Collect variables from all datasets for validation\n            all_vars = set()\n            for ds in datasets:\n                all_vars.update(getattr(ds, subset))\n            \n            invalid_vars = [k for k in opt if k not in all_vars]\n            if invalid_vars:\n                if subset == \"coords\":\n                    raise ValueError(\n                        \"some variables in coords are not coordinates on \"\n                        \"any dataset: %s\" % (invalid_vars,)\n                    )\n                else:\n                    raise ValueError(\n                        \"some variables in data_vars are not data variables \"\n                        \"on any dataset: %s\" % (invalid_vars,)\n                    )\n",
      "\n            # Collect variables from all datasets for validation\n            all_vars = set()\n            for ds in datasets:\n                all_vars.update(getattr(ds, subset))\n            \n            invalid_vars = [k for k in opt if k not in all_vars]\n            if invalid_vars:\n                if subset == \"coords\":\n                    raise ValueError(\n                        \"some variables in coords are not coordinates on \"\n                        \"any dataset: %s\" % (invalid_vars,)\n                    )\n                else:\n                    raise ValueError(\n                        \"some variables in data_vars are not data variables \"\n                        \"on any dataset: %s\" % (invalid_vars,)\n                    )\n",
      "\n            # Collect variables from all datasets instead of just the first one\n            all_vars = set()\n            for ds in datasets:\n                all_vars.update(getattr(ds, subset))\n            \n            invalid_vars = [k for k in opt if k not in all_vars]\n            if invalid_vars:\n                if subset == \"coords\":\n                    raise ValueError(\n                        \"some variables in coords are not coordinates on \"\n                        \"any dataset: %s\" % (invalid_vars,)\n                    )\n                else:\n                    raise ValueError(\n                        \"some variables in data_vars are not data variables \"\n                        \"on any dataset: %s\" % (invalid_vars,)\n                    )\n"
    ],
    "Location 2 (/root/hy/projects_3/xarray/xarray/core/concat.py lines 315-320)": [
      "\n    # determine which variables to merge, and then merge them according to compat\n    variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n\n    result_vars = {}\n    if variables_to_merge:\n        to_merge = {var: [] for var in variables_to_merge}\n\n        for ds in datasets:\n            for var in variables_to_merge:\n                if var in ds.variables:\n                    to_merge[var].append(ds.variables[var])\n                else:\n                    # Create a placeholder variable with fill_value for missing variables\n                    # Get shape from first available variable or use empty shape\n                    if to_merge[var]:\n                        template_var = to_merge[var][0]\n                        shape = template_var.shape\n                        dims = template_var.dims\n                        dtype = template_var.dtype\n                    else:\n                        # Find any variable from any dataset to use as template\n                        template_var = None\n                        for other_ds in datasets:\n                            if var in other_ds.variables:\n                                template_var = other_ds.variables[var]\n                                break\n                        if template_var is not None:\n                            shape = template_var.shape\n                            dims = template_var.dims\n                            dtype = template_var.dtype\n                        else:\n                            # Fallback if variable not found anywhere\n                            shape = ()\n                            dims = ()\n                            dtype = object\n                    \n                    # Create fill_value variable\n                    fill_val = fill_value if fill_value is not None else dtypes.NA\n                    fill_data = utils.full_like(template_var.data if template_var else None, \n                                              fill_val, shape=shape, dtype=dtype)\n                    fill_var = Variable(dims, fill_data)\n                    to_merge[var].append(fill_var)\n\n        for var in variables_to_merge:\n            result_vars[var] = unique_variable(\n                var, to_merge[var], compat=compat, equals=equals.get(var, None)\n            )\n    else:\n        result_vars = {}\n",
      "\n    # determine which variables to merge, and then merge them according to compat\n    variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n\n    result_vars = {}\n    if variables_to_merge:\n        to_merge = {var: [] for var in variables_to_merge}\n\n        for ds in datasets:\n            for var in variables_to_merge:\n                if var in ds.variables:\n                    to_merge[var].append(ds.variables[var])\n                else:\n                    # Create placeholder variable with fill_value for missing variables\n                    # Get variable info from first dataset that has this variable\n                    ref_var = None\n                    for ref_ds in datasets:\n                        if var in ref_ds.variables:\n                            ref_var = ref_ds.variables[var]\n                            break\n                    \n                    if ref_var is not None:\n                        # Create a variable filled with fill_value matching the reference variable's shape and dims\n                        fill_var = Variable(\n                            ref_var.dims,\n                            utils.full_like(ref_var.data, fill_value, dtype=ref_var.dtype),\n                            ref_var.attrs\n                        )\n                        to_merge[var].append(fill_var)\n\n        for var in variables_to_merge:\n            result_vars[var] = unique_variable(\n                var, to_merge[var], compat=compat, equals=equals.get(var, None)\n            )\n    else:\n        result_vars = {}\n",
      "\n    # determine which variables to merge, and then merge them according to compat\n    variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n\n    result_vars = {}\n    if variables_to_merge:\n        to_merge = {var: [] for var in variables_to_merge}\n\n        for ds in datasets:\n            for var in variables_to_merge:\n                if var in ds.variables:\n                    to_merge[var].append(ds.variables[var])\n                else:\n                    # Create a placeholder variable with fill_value for missing variables\n                    # Get the first available variable to determine shape and dims\n                    first_var = next((ds.variables[var] for ds in datasets if var in ds.variables), None)\n                    if first_var is not None:\n                        fill_var = Variable(\n                            first_var.dims,\n                            full(first_var.shape, fill_value, dtype=first_var.dtype),\n                            attrs=first_var.attrs.copy()\n                        )\n                        to_merge[var].append(fill_var)\n\n        for var in variables_to_merge:\n            result_vars[var] = unique_variable(\n                var, to_merge[var], compat=compat, equals=equals.get(var, None)\n            )\n    else:\n        result_vars = {}\n",
      "\n    # determine which variables to merge, and then merge them according to compat\n    variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n\n    result_vars = {}\n    if variables_to_merge:\n        to_merge = {var: [] for var in variables_to_merge}\n\n        for ds in datasets:\n            for var in variables_to_merge:\n                if var in ds.variables:\n                    to_merge[var].append(ds.variables[var])\n                else:\n                    # Create a placeholder variable with fill_value for missing variables\n                    # Get the variable from a dataset that has it to determine shape/dims\n                    reference_var = None\n                    for ref_ds in datasets:\n                        if var in ref_ds.variables:\n                            reference_var = ref_ds.variables[var]\n                            break\n                    \n                    if reference_var is not None:\n                        # Create fill_value variable with same dims and dtype as reference\n                        fill_var = Variable(\n                            reference_var.dims,\n                            dtypes.full_like(reference_var, fill_value, reference_var.dtype),\n                            reference_var.attrs\n                        )\n                        to_merge[var].append(fill_var)\n\n        for var in variables_to_merge:\n            result_vars[var] = unique_variable(\n                var, to_merge[var], compat=compat, equals=equals.get(var, None)\n            )\n    else:\n        result_vars = {}\n",
      "\n    # determine which variables to merge, and then merge them according to compat\n    variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n\n    result_vars = {}\n    if variables_to_merge:\n        to_merge = {var: [] for var in variables_to_merge}\n\n        for ds in datasets:\n            for var in variables_to_merge:\n                if var in ds.variables:\n                    to_merge[var].append(ds.variables[var])\n                else:\n                    # Create a placeholder variable with fill_value for missing variables\n                    # Get the variable from a dataset that has it to determine shape/dims\n                    template_var = None\n                    for other_ds in datasets:\n                        if var in other_ds.variables:\n                            template_var = other_ds.variables[var]\n                            break\n                    \n                    if template_var is not None:\n                        # Create a variable filled with fill_value matching template structure\n                        fill_var = template_var._constructor(\n                            template_var.dims,\n                            utils.full_like(template_var, fill_value, dtype=template_var.dtype),\n                            template_var.attrs,\n                            template_var.encoding,\n                            fastpath=True\n                        )\n                        to_merge[var].append(fill_var)\n\n        for var in variables_to_merge:\n            result_vars[var] = unique_variable(\n                var, to_merge[var], compat=compat, equals=equals.get(var, None)\n            )\n    else:\n        result_vars = {}\n",
      "\n    # determine which variables to merge, and then merge them according to compat\n    variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n\n    result_vars = {}\n    if variables_to_merge:\n        to_merge = {var: [] for var in variables_to_merge}\n\n        for ds in datasets:\n            for var in variables_to_merge:\n                if var in ds.variables:\n                    to_merge[var].append(ds.variables[var])\n                else:\n                    # Create a placeholder variable with fill_value for missing variables\n                    # Get the shape from a reference variable or use empty shape\n                    ref_var = None\n                    for other_ds in datasets:\n                        if var in other_ds.variables:\n                            ref_var = other_ds.variables[var]\n                            break\n                    \n                    if ref_var is not None:\n                        # Create compatible variable with fill_value\n                        fill_var = Variable(\n                            ref_var.dims,\n                            utils.full_like(ref_var.data, fill_value, dtype=ref_var.dtype),\n                            attrs=ref_var.attrs.copy()\n                        )\n                        to_merge[var].append(fill_var)\n\n        for var in variables_to_merge:\n            result_vars[var] = unique_variable(\n                var, to_merge[var], compat=compat, equals=equals.get(var, None)\n            )\n    else:\n        result_vars = {}\n",
      "\n    # determine which variables to merge, and then merge them according to compat\n    variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n\n    result_vars = {}\n    if variables_to_merge:\n        to_merge = {var: [] for var in variables_to_merge}\n\n        for ds in datasets:\n            for var in variables_to_merge:\n                if var in ds.variables:\n                    to_merge[var].append(ds.variables[var])\n                else:\n                    # Create a fill_value variable for missing variables\n                    # Use the first available variable as template for shape/dims\n                    template_var = None\n                    for other_ds in datasets:\n                        if var in other_ds.variables:\n                            template_var = other_ds.variables[var]\n                            break\n                    \n                    if template_var is not None:\n                        # Create variable with same dims/shape but filled with fill_value\n                        fill_var = Variable(\n                            template_var.dims,\n                            dtypes.NA if fill_value is None else fill_value,\n                            attrs=template_var.attrs.copy()\n                        )\n                        to_merge[var].append(fill_var)\n\n        for var in variables_to_merge:\n            result_vars[var] = unique_variable(\n                var, to_merge[var], compat=compat, equals=equals.get(var, None)\n            )\n    else:\n        result_vars = {}\n",
      "\n    # determine which variables to merge, and then merge them according to compat\n    variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n\n    result_vars = {}\n    if variables_to_merge:\n        to_merge = {var: [] for var in variables_to_merge}\n\n        for ds in datasets:\n            for var in variables_to_merge:\n                if var in ds.variables:\n                    to_merge[var].append(ds.variables[var])\n                else:\n                    # Create a placeholder variable with fill_value for missing variables\n                    # Get a reference variable to match dimensions and attributes\n                    ref_var = None\n                    for other_ds in datasets:\n                        if var in other_ds.variables:\n                            ref_var = other_ds.variables[var]\n                            break\n                    \n                    if ref_var is not None:\n                        # Create a variable filled with fill_value that matches reference dimensions\n                        import numpy as np\n                        fill_data = np.full(ref_var.shape, fill_value, dtype=ref_var.dtype)\n                        fill_var = Variable(ref_var.dims, fill_data, ref_var.attrs)\n                        to_merge[var].append(fill_var)\n\n        for var in variables_to_merge:\n            result_vars[var] = unique_variable(\n                var, to_merge[var], compat=compat, equals=equals.get(var, None)\n            )\n    else:\n        result_vars = {}\n"
    ],
    "Location 3 (/root/hy/projects_3/xarray/xarray/core/concat.py lines 362-364)": [
      "\n        if k in concat_over:\n            try:\n                # Safely collect variables, creating fill_value placeholders for missing ones\n                vars_list = []\n                for ds in datasets:\n                    if k in ds.variables:\n                        vars_list.append(ds.variables[k])\n                    else:\n                        # Create a compatible variable with fill_value for missing data\n                        # Use the first available variable as template for dims and shape\n                        template_var = next(ds.variables[k] for ds in datasets if k in ds.variables)\n                        fill_var = Variable(template_var.dims, \n                                           pd.core.arrays.masked.array(\n                                               [fill_value] * template_var.size, \n                                               mask=True).reshape(template_var.shape),\n                                           template_var.attrs)\n                        vars_list.append(fill_var)\n                vars = ensure_common_dims(vars_list)\n            except (KeyError, StopIteration):\n                raise ValueError(\"%r is not present in all datasets.\" % k)\n",
      "\n        # stack up each variable to fill-out the dataset (in order)\n        # n.b. this loop preserves variable order, needed for groupby.\n        for k in datasets[0].variables:\n            if k in concat_over:\n                try:\n                    # Safely collect variables, creating fill_value placeholders for missing ones\n                    vars_list = []\n                    for ds in datasets:\n                        if k in ds.variables:\n                            vars_list.append(ds.variables[k])\n                        else:\n                            # Create a placeholder variable with fill_value for missing variable\n                            # Use the shape and dims from a reference variable in the same dataset\n                            ref_var = next(iter(ds.data_vars.values())) if ds.data_vars else next(iter(ds.variables.values()))\n                            placeholder_shape = tuple(dims_sizes.get(d, s) for d, s in zip(ref_var.dims, ref_var.shape))\n                            placeholder = Variable(ref_var.dims, \n                                                 utils.full_like(ref_var.data, fill_value, shape=placeholder_shape),\n                                                 attrs={})\n                            vars_list.append(placeholder)\n                    vars = ensure_common_dims(vars_list)\n                except KeyError:\n                    raise ValueError(\"%r is not present in all datasets.\" % k)\n                combined = concat_vars(vars, dim, positions)\n                assert isinstance(combined, Variable)\n                result_vars[k] = combined\n",
      "\n        # stack up each variable to fill-out the dataset (in order)\n        # n.b. this loop preserves variable order, needed for groupby.\n        for k in datasets[0].variables:\n            if k in concat_over:\n                try:\n                    # Safely collect variables, creating fill_value placeholders for missing ones\n                    vars_list = []\n                    for ds in datasets:\n                        if k in ds.variables:\n                            vars_list.append(ds.variables[k])\n                        else:\n                            # Create a placeholder variable with fill_value for missing variable\n                            # Use the shape and dims from a reference variable (first available)\n                            ref_var = next(ds.variables[k] for ds in datasets if k in ds.variables)\n                            placeholder_shape = tuple(dims_sizes.get(d, ref_var.sizes.get(d, 1)) for d in ref_var.dims)\n                            placeholder_var = Variable(ref_var.dims, \n                                                     utils.full_like(ref_var.data, fill_value, shape=placeholder_shape),\n                                                     attrs=ref_var.attrs)\n                            vars_list.append(placeholder_var)\n                    vars = ensure_common_dims(vars_list)\n                except KeyError:\n                    raise ValueError(\"%r is not present in all datasets.\" % k)\n                combined = concat_vars(vars, dim, positions)\n                assert isinstance(combined, Variable)\n                result_vars[k] = combined\n",
      "\n        if k in concat_over:\n            try:\n                # Safely collect variables, using fill_value for missing ones\n                vars_list = []\n                for ds in datasets:\n                    if k in ds.variables:\n                        vars_list.append(ds.variables[k])\n                    else:\n                        # Create a compatible variable with fill_value for missing data\n                        # Use the first available variable as template for dimensions and shape\n                        template_var = None\n                        for other_ds in datasets:\n                            if k in other_ds.variables:\n                                template_var = other_ds.variables[k]\n                                break\n                        \n                        if template_var is not None:\n                            # Create variable filled with fill_value\n                            fill_data = utils.full_like(template_var.data, fill_value, template_var.dtype)\n                            fill_var = Variable(template_var.dims, fill_data, template_var.attrs)\n                            vars_list.append(fill_var)\n                        else:\n                            # This shouldn't happen if concat_over was calculated correctly\n                            raise ValueError(f\"Variable {k!r} not found in any dataset\")\n                \n                vars = ensure_common_dims(vars_list)\n            except KeyError:\n                raise ValueError(\"%r is not present in all datasets.\" % k)\n",
      "\n        if k in concat_over:\n            try:\n                # Safely collect variables, creating fill_value placeholders for missing ones\n                vars_list = []\n                for ds in datasets:\n                    if k in ds.variables:\n                        vars_list.append(ds.variables[k])\n                    else:\n                        # Create a fill_value placeholder variable with compatible shape\n                        template_var = next(ds.variables[k] for ds in datasets if k in ds.variables)\n                        fill_var = template_var._constructor(\n                            template_var.dims,\n                            utils.full_like(template_var, fill_value, dtype=template_var.dtype),\n                            template_var.attrs\n                        )\n                        vars_list.append(fill_var)\n                vars = ensure_common_dims(vars_list)\n            except (KeyError, StopIteration):\n                raise ValueError(\"%r is not present in any datasets.\" % k)\n            combined = concat_vars(vars, dim, positions)\n            assert isinstance(combined, Variable)\n            result_vars[k] = combined\n",
      "\n        if k in concat_over:\n            try:\n                # Safely collect variables, creating fill_value placeholders for missing ones\n                vars_list = []\n                for ds in datasets:\n                    if k in ds.variables:\n                        vars_list.append(ds.variables[k])\n                    else:\n                        # Create a fill_value placeholder variable with compatible shape\n                        ref_var = next(ds.variables[k] for ds in datasets if k in ds.variables)\n                        fill_var = ref_var._constructor(\n                            ref_var.dims,\n                            utils.full_like(ref_var, fill_value, dtype=ref_var.dtype),\n                            ref_var.attrs.copy()\n                        )\n                        vars_list.append(fill_var)\n                vars = ensure_common_dims(vars_list)\n            except (KeyError, StopIteration):\n                raise ValueError(\"%r is not present in any datasets.\" % k)\n            combined = concat_vars(vars, dim, positions)\n            assert isinstance(combined, Variable)\n            result_vars[k] = combined\n",
      "\n        if k in concat_over:\n            try:\n                # Collect variables from all datasets, handling missing ones with fill_value\n                vars_list = []\n                for ds in datasets:\n                    if k in ds.variables:\n                        vars_list.append(ds.variables[k])\n                    else:\n                        # Create a placeholder variable with fill_value for missing variable\n                        # Use the first available variable as template for dimensions and shape\n                        template_var = None\n                        for other_ds in datasets:\n                            if k in other_ds.variables:\n                                template_var = other_ds.variables[k]\n                                break\n                        \n                        if template_var is not None:\n                            # Create variable filled with fill_value matching template structure\n                            import numpy as np\n                            fill_data = np.full(template_var.shape, fill_value, dtype=template_var.dtype)\n                            fill_var = Variable(template_var.dims, fill_data, template_var.attrs)\n                            vars_list.append(fill_var)\n                \n                vars = ensure_common_dims(vars_list)\n            except KeyError:\n                raise ValueError(\"%r is not present in all datasets.\" % k)\n",
      "\n    # stack up each variable to fill-out the dataset (in order)\n    # n.b. this loop preserves variable order, needed for groupby.\n    for k in datasets[0].variables:\n        if k in concat_over:\n            try:\n                # Safely collect variables, creating fill_value placeholders for missing ones\n                vars_list = []\n                for ds in datasets:\n                    if k in ds.variables:\n                        vars_list.append(ds.variables[k])\n                    else:\n                        # Create a fill_value placeholder variable with compatible shape and dims\n                        first_var = next(d.variables[k] for d in datasets if k in d.variables)\n                        fill_var = Variable(first_var.dims, \n                                          utils.full_like(first_var.data, fill_value, first_var.dtype),\n                                          attrs=first_var.attrs)\n                        vars_list.append(fill_var)\n                vars = ensure_common_dims(vars_list)\n            except StopIteration:\n                # This should not happen if concat_over is properly calculated\n                raise ValueError(\"%r is not present in any datasets.\" % k)\n            combined = concat_vars(vars, dim, positions)\n            assert isinstance(combined, Variable)\n            result_vars[k] = combined\n"
    ]
  },
  "combined_diffs": {
    "raw_patch": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex ecae2566..26bd4e83 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -219,17 +219,23 @@ def _calc_concat_over(datasets, dim, dim_names, data_vars, coords, compat):\n             else:\n                 raise ValueError(\"unexpected value for %s: %s\" % (subset, opt))\n         else:\n-            invalid_vars = [k for k in opt if k not in getattr(datasets[0], subset)]\n+\n+            # Collect variables from all datasets instead of just the first\n+            all_vars_in_subset = set()\n+            for ds in datasets:\n+                all_vars_in_subset.update(getattr(ds, subset))\n+            \n+            invalid_vars = [k for k in opt if k not in all_vars_in_subset]\n             if invalid_vars:\n                 if subset == \"coords\":\n                     raise ValueError(\n                         \"some variables in coords are not coordinates on \"\n-                        \"the first dataset: %s\" % (invalid_vars,)\n+                        \"any dataset: %s\" % (invalid_vars,)\n                     )\n                 else:\n                     raise ValueError(\n                         \"some variables in data_vars are not data variables \"\n-                        \"on the first dataset: %s\" % (invalid_vars,)\n+                        \"on any dataset: %s\" % (invalid_vars,)\n                     )\n             concat_over.update(opt)\n \n@@ -312,12 +318,25 @@ def _dataset_concat(\n         to_merge = {var: [] for var in variables_to_merge}\n \n         for ds in datasets:\n+\n             absent_merge_vars = variables_to_merge - set(ds.variables)\n             if absent_merge_vars:\n-                raise ValueError(\n-                    \"variables %r are present in some datasets but not others. \"\n-                    % absent_merge_vars\n-                )\n+                # Create placeholder variables with fill_value for missing variables\n+                for var_name in absent_merge_vars:\n+                    # Find a reference variable from another dataset to get shape/dims\n+                    ref_var = None\n+                    for other_ds in datasets:\n+                        if var_name in other_ds.variables:\n+                            ref_var = other_ds.variables[var_name]\n+                            break\n+                    \n+                    if ref_var is not None:\n+                        # Create a variable filled with fill_value with same dims as reference\n+                        import numpy as np\n+                        fill_data = np.full(ref_var.shape, fill_value, dtype=ref_var.dtype)\n+                        placeholder_var = Variable(ref_var.dims, fill_data, ref_var.attrs)\n+                        # Add the placeholder to the current dataset's variables\n+                        ds.variables[var_name] = placeholder_var\n \n             for var in variables_to_merge:\n                 to_merge[var].append(ds.variables[var])\n@@ -359,9 +378,28 @@ def _dataset_concat(\n     for k in datasets[0].variables:\n         if k in concat_over:\n             try:\n-                vars = ensure_common_dims([ds.variables[k] for ds in datasets])\n-            except KeyError:\n-                raise ValueError(\"%r is not present in all datasets.\" % k)\n+\n+                # Safely collect variables, creating fill_value placeholders for missing ones\n+                vars_list = []\n+                for ds in datasets:\n+                    if k in ds.variables:\n+                        vars_list.append(ds.variables[k])\n+                    else:\n+                        # Find a reference variable from another dataset to get shape/dims\n+                        ref_var = None\n+                        for other_ds in datasets:\n+                            if k in other_ds.variables:\n+                                ref_var = other_ds.variables[k]\n+                                break\n+                        \n+                        if ref_var is not None:\n+                            # Create a variable filled with fill_value\n+                            import numpy as np\n+                            fill_data = np.full(ref_var.shape, fill_value, dtype=ref_var.dtype)\n+                            placeholder_var = Variable(ref_var.dims, fill_data, ref_var.attrs)\n+                            vars_list.append(placeholder_var)\n+                \n+                vars = ensure_common_dims(vars_list)\n             combined = concat_vars(vars, dim, positions)\n             assert isinstance(combined, Variable)\n             result_vars[k] = combined\n",
    "variant_0": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex ecae2566..f5b806a9 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -219,17 +219,23 @@ def _calc_concat_over(datasets, dim, dim_names, data_vars, coords, compat):\n             else:\n                 raise ValueError(\"unexpected value for %s: %s\" % (subset, opt))\n         else:\n-            invalid_vars = [k for k in opt if k not in getattr(datasets[0], subset)]\n+\n+            # Collect all variables from all datasets for validation\n+            all_vars = set()\n+            for ds in datasets:\n+                all_vars.update(getattr(ds, subset))\n+            \n+            invalid_vars = [k for k in opt if k not in all_vars]\n             if invalid_vars:\n                 if subset == \"coords\":\n                     raise ValueError(\n-                        \"some variables in coords are not coordinates on \"\n-                        \"the first dataset: %s\" % (invalid_vars,)\n+                        \"some variables in coords are not coordinates in \"\n+                        \"any dataset: %s\" % (invalid_vars,)\n                     )\n                 else:\n                     raise ValueError(\n                         \"some variables in data_vars are not data variables \"\n-                        \"on the first dataset: %s\" % (invalid_vars,)\n+                        \"in any dataset: %s\" % (invalid_vars,)\n                     )\n             concat_over.update(opt)\n \n@@ -312,12 +318,41 @@ def _dataset_concat(\n         to_merge = {var: [] for var in variables_to_merge}\n \n         for ds in datasets:\n-            absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n-                raise ValueError(\n-                    \"variables %r are present in some datasets but not others. \"\n-                    % absent_merge_vars\n-                )\n+\n+    # determine which variables to merge, and then merge them according to compat\n+    variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n+\n+    result_vars = {}\n+    if variables_to_merge:\n+        to_merge = {var: [] for var in variables_to_merge}\n+\n+        for ds in datasets:\n+            for var in variables_to_merge:\n+                if var in ds.variables:\n+                    to_merge[var].append(ds.variables[var])\n+                else:\n+                    # Create a placeholder variable with fill_value for missing variables\n+                    # Get the variable from a dataset that has it to determine shape and dtype\n+                    reference_var = None\n+                    for ref_ds in datasets:\n+                        if var in ref_ds.variables:\n+                            reference_var = ref_ds.variables[var]\n+                            break\n+                    \n+                    if reference_var is not None:\n+                        # Create a variable filled with fill_value matching the reference\n+                        import numpy as np\n+                        fill_val = fill_value if fill_value is not None else dtypes.get_fill_value(reference_var.dtype)\n+                        filled_data = np.full_like(reference_var.data, fill_val)\n+                        placeholder_var = Variable(reference_var.dims, filled_data, reference_var.attrs)\n+                        to_merge[var].append(placeholder_var)\n+\n+        for var in variables_to_merge:\n+            result_vars[var] = unique_variable(\n+                var, to_merge[var], compat=compat, equals=equals.get(var, None)\n+            )\n+    else:\n+        result_vars = {}\n \n             for var in variables_to_merge:\n                 to_merge[var].append(ds.variables[var])\n@@ -359,12 +394,34 @@ def _dataset_concat(\n     for k in datasets[0].variables:\n         if k in concat_over:\n             try:\n-                vars = ensure_common_dims([ds.variables[k] for ds in datasets])\n+\n+    # stack up each variable to fill-out the dataset (in order)\n+    # n.b. this loop preserves variable order, needed for groupby.\n+    for k in datasets[0].variables:\n+        if k in concat_over:\n+            try:\n+                # Safely collect variables, creating fill_value placeholders for missing ones\n+                vars_list = []\n+                for ds in datasets:\n+                    if k in ds.variables:\n+                        vars_list.append(ds.variables[k])\n+                    else:\n+                        # Create a placeholder variable with fill_value for missing data\n+                        # Use the shape and dims from the first dataset that has this variable\n+                        ref_var = next(d.variables[k] for d in datasets if k in d.variables)\n+                        fill_var = Variable(ref_var.dims, \n+                                          utils.full_like(ref_var.data, fill_value, ref_var.dtype),\n+                                          ref_var.attrs.copy())\n+                        vars_list.append(fill_var)\n+                vars = ensure_common_dims(vars_list)\n             except KeyError:\n                 raise ValueError(\"%r is not present in all datasets.\" % k)\n             combined = concat_vars(vars, dim, positions)\n             assert isinstance(combined, Variable)\n             result_vars[k] = combined\n+            combined = concat_vars(vars, dim, positions)\n+            assert isinstance(combined, Variable)\n+            result_vars[k] = combined\n \n     result = Dataset(result_vars, attrs=result_attrs)\n     absent_coord_names = coord_names - set(result.variables)\n",
    "variant_1": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex ecae2566..bd9a7ccf 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -219,17 +219,23 @@ def _calc_concat_over(datasets, dim, dim_names, data_vars, coords, compat):\n             else:\n                 raise ValueError(\"unexpected value for %s: %s\" % (subset, opt))\n         else:\n-            invalid_vars = [k for k in opt if k not in getattr(datasets[0], subset)]\n+\n+            # Collect variables from all datasets to support outer join behavior\n+            all_vars = set()\n+            for ds in datasets:\n+                all_vars.update(getattr(ds, subset))\n+            \n+            invalid_vars = [k for k in opt if k not in all_vars]\n             if invalid_vars:\n                 if subset == \"coords\":\n                     raise ValueError(\n                         \"some variables in coords are not coordinates on \"\n-                        \"the first dataset: %s\" % (invalid_vars,)\n+                        \"any dataset: %s\" % (invalid_vars,)\n                     )\n                 else:\n                     raise ValueError(\n                         \"some variables in data_vars are not data variables \"\n-                        \"on the first dataset: %s\" % (invalid_vars,)\n+                        \"on any dataset: %s\" % (invalid_vars,)\n                     )\n             concat_over.update(opt)\n \n@@ -312,12 +318,56 @@ def _dataset_concat(\n         to_merge = {var: [] for var in variables_to_merge}\n \n         for ds in datasets:\n-            absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n-                raise ValueError(\n-                    \"variables %r are present in some datasets but not others. \"\n-                    % absent_merge_vars\n-                )\n+\n+    # determine which variables to merge, and then merge them according to compat\n+    variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n+\n+    result_vars = {}\n+    if variables_to_merge:\n+        to_merge = {var: [] for var in variables_to_merge}\n+\n+        for ds in datasets:\n+            for var in variables_to_merge:\n+                if var in ds.variables:\n+                    to_merge[var].append(ds.variables[var])\n+                else:\n+                    # Create a placeholder variable with fill_value for missing variables\n+                    # Get shape from first available variable or use empty shape\n+                    if to_merge[var]:\n+                        template_var = to_merge[var][0]\n+                        shape = template_var.shape\n+                        dims = template_var.dims\n+                        dtype = template_var.dtype\n+                    else:\n+                        # Find any variable from any dataset to use as template\n+                        template_var = None\n+                        for other_ds in datasets:\n+                            if var in other_ds.variables:\n+                                template_var = other_ds.variables[var]\n+                                break\n+                        if template_var is not None:\n+                            shape = template_var.shape\n+                            dims = template_var.dims\n+                            dtype = template_var.dtype\n+                        else:\n+                            # Fallback if variable not found anywhere\n+                            shape = ()\n+                            dims = ()\n+                            dtype = object\n+                    \n+                    # Create fill_value variable\n+                    fill_val = fill_value if fill_value is not None else dtypes.NA\n+                    fill_data = utils.full_like(template_var.data if template_var else None, \n+                                              fill_val, shape=shape, dtype=dtype)\n+                    fill_var = Variable(dims, fill_data)\n+                    to_merge[var].append(fill_var)\n+\n+        for var in variables_to_merge:\n+            result_vars[var] = unique_variable(\n+                var, to_merge[var], compat=compat, equals=equals.get(var, None)\n+            )\n+    else:\n+        result_vars = {}\n \n             for var in variables_to_merge:\n                 to_merge[var].append(ds.variables[var])\n@@ -359,8 +409,26 @@ def _dataset_concat(\n     for k in datasets[0].variables:\n         if k in concat_over:\n             try:\n-                vars = ensure_common_dims([ds.variables[k] for ds in datasets])\n-            except KeyError:\n+\n+        if k in concat_over:\n+            try:\n+                # Safely collect variables, creating fill_value placeholders for missing ones\n+                vars_list = []\n+                for ds in datasets:\n+                    if k in ds.variables:\n+                        vars_list.append(ds.variables[k])\n+                    else:\n+                        # Create a compatible variable with fill_value for missing data\n+                        # Use the first available variable as template for dims and shape\n+                        template_var = next(ds.variables[k] for ds in datasets if k in ds.variables)\n+                        fill_var = Variable(template_var.dims, \n+                                           pd.core.arrays.masked.array(\n+                                               [fill_value] * template_var.size, \n+                                               mask=True).reshape(template_var.shape),\n+                                           template_var.attrs)\n+                        vars_list.append(fill_var)\n+                vars = ensure_common_dims(vars_list)\n+            except (KeyError, StopIteration):\n                 raise ValueError(\"%r is not present in all datasets.\" % k)\n             combined = concat_vars(vars, dim, positions)\n             assert isinstance(combined, Variable)\n",
    "variant_2": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex ecae2566..711116f1 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -219,17 +219,23 @@ def _calc_concat_over(datasets, dim, dim_names, data_vars, coords, compat):\n             else:\n                 raise ValueError(\"unexpected value for %s: %s\" % (subset, opt))\n         else:\n-            invalid_vars = [k for k in opt if k not in getattr(datasets[0], subset)]\n+\n+            # Collect variables from all datasets instead of just the first one\n+            all_vars_in_subset = set()\n+            for ds in datasets:\n+                all_vars_in_subset.update(getattr(ds, subset))\n+            \n+            invalid_vars = [k for k in opt if k not in all_vars_in_subset]\n             if invalid_vars:\n                 if subset == \"coords\":\n                     raise ValueError(\n                         \"some variables in coords are not coordinates on \"\n-                        \"the first dataset: %s\" % (invalid_vars,)\n+                        \"any dataset: %s\" % (invalid_vars,)\n                     )\n                 else:\n                     raise ValueError(\n                         \"some variables in data_vars are not data variables \"\n-                        \"on the first dataset: %s\" % (invalid_vars,)\n+                        \"on any dataset: %s\" % (invalid_vars,)\n                     )\n             concat_over.update(opt)\n \n@@ -312,12 +318,42 @@ def _dataset_concat(\n         to_merge = {var: [] for var in variables_to_merge}\n \n         for ds in datasets:\n-            absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n-                raise ValueError(\n-                    \"variables %r are present in some datasets but not others. \"\n-                    % absent_merge_vars\n-                )\n+\n+    # determine which variables to merge, and then merge them according to compat\n+    variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n+\n+    result_vars = {}\n+    if variables_to_merge:\n+        to_merge = {var: [] for var in variables_to_merge}\n+\n+        for ds in datasets:\n+            for var in variables_to_merge:\n+                if var in ds.variables:\n+                    to_merge[var].append(ds.variables[var])\n+                else:\n+                    # Create placeholder variable with fill_value for missing variables\n+                    # Get variable info from first dataset that has this variable\n+                    ref_var = None\n+                    for ref_ds in datasets:\n+                        if var in ref_ds.variables:\n+                            ref_var = ref_ds.variables[var]\n+                            break\n+                    \n+                    if ref_var is not None:\n+                        # Create a variable filled with fill_value matching the reference variable's shape and dims\n+                        fill_var = Variable(\n+                            ref_var.dims,\n+                            utils.full_like(ref_var.data, fill_value, dtype=ref_var.dtype),\n+                            ref_var.attrs\n+                        )\n+                        to_merge[var].append(fill_var)\n+\n+        for var in variables_to_merge:\n+            result_vars[var] = unique_variable(\n+                var, to_merge[var], compat=compat, equals=equals.get(var, None)\n+            )\n+    else:\n+        result_vars = {}\n \n             for var in variables_to_merge:\n                 to_merge[var].append(ds.variables[var])\n@@ -359,9 +395,32 @@ def _dataset_concat(\n     for k in datasets[0].variables:\n         if k in concat_over:\n             try:\n-                vars = ensure_common_dims([ds.variables[k] for ds in datasets])\n-            except KeyError:\n-                raise ValueError(\"%r is not present in all datasets.\" % k)\n+\n+        # stack up each variable to fill-out the dataset (in order)\n+        # n.b. this loop preserves variable order, needed for groupby.\n+        for k in datasets[0].variables:\n+            if k in concat_over:\n+                try:\n+                    # Safely collect variables, creating fill_value placeholders for missing ones\n+                    vars_list = []\n+                    for ds in datasets:\n+                        if k in ds.variables:\n+                            vars_list.append(ds.variables[k])\n+                        else:\n+                            # Create a placeholder variable with fill_value for missing variable\n+                            # Use the shape and dims from a reference variable in the same dataset\n+                            ref_var = next(iter(ds.data_vars.values())) if ds.data_vars else next(iter(ds.variables.values()))\n+                            placeholder_shape = tuple(dims_sizes.get(d, s) for d, s in zip(ref_var.dims, ref_var.shape))\n+                            placeholder = Variable(ref_var.dims, \n+                                                 utils.full_like(ref_var.data, fill_value, shape=placeholder_shape),\n+                                                 attrs={})\n+                            vars_list.append(placeholder)\n+                    vars = ensure_common_dims(vars_list)\n+                except KeyError:\n+                    raise ValueError(\"%r is not present in all datasets.\" % k)\n+                combined = concat_vars(vars, dim, positions)\n+                assert isinstance(combined, Variable)\n+                result_vars[k] = combined\n             combined = concat_vars(vars, dim, positions)\n             assert isinstance(combined, Variable)\n             result_vars[k] = combined\n",
    "variant_3": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex ecae2566..18fb664d 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -219,17 +219,23 @@ def _calc_concat_over(datasets, dim, dim_names, data_vars, coords, compat):\n             else:\n                 raise ValueError(\"unexpected value for %s: %s\" % (subset, opt))\n         else:\n-            invalid_vars = [k for k in opt if k not in getattr(datasets[0], subset)]\n+\n+            # Collect variables from all datasets to support outer join behavior\n+            all_vars = set()\n+            for ds in datasets:\n+                all_vars.update(getattr(ds, subset))\n+            \n+            invalid_vars = [k for k in opt if k not in all_vars]\n             if invalid_vars:\n                 if subset == \"coords\":\n                     raise ValueError(\n                         \"some variables in coords are not coordinates on \"\n-                        \"the first dataset: %s\" % (invalid_vars,)\n+                        \"any dataset: %s\" % (invalid_vars,)\n                     )\n                 else:\n                     raise ValueError(\n                         \"some variables in data_vars are not data variables \"\n-                        \"on the first dataset: %s\" % (invalid_vars,)\n+                        \"on any dataset: %s\" % (invalid_vars,)\n                     )\n             concat_over.update(opt)\n \n@@ -312,12 +318,36 @@ def _dataset_concat(\n         to_merge = {var: [] for var in variables_to_merge}\n \n         for ds in datasets:\n-            absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n-                raise ValueError(\n-                    \"variables %r are present in some datasets but not others. \"\n-                    % absent_merge_vars\n-                )\n+\n+    # determine which variables to merge, and then merge them according to compat\n+    variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n+\n+    result_vars = {}\n+    if variables_to_merge:\n+        to_merge = {var: [] for var in variables_to_merge}\n+\n+        for ds in datasets:\n+            for var in variables_to_merge:\n+                if var in ds.variables:\n+                    to_merge[var].append(ds.variables[var])\n+                else:\n+                    # Create a placeholder variable with fill_value for missing variables\n+                    # Get the first available variable to determine shape and dims\n+                    first_var = next((ds.variables[var] for ds in datasets if var in ds.variables), None)\n+                    if first_var is not None:\n+                        fill_var = Variable(\n+                            first_var.dims,\n+                            full(first_var.shape, fill_value, dtype=first_var.dtype),\n+                            attrs=first_var.attrs.copy()\n+                        )\n+                        to_merge[var].append(fill_var)\n+\n+        for var in variables_to_merge:\n+            result_vars[var] = unique_variable(\n+                var, to_merge[var], compat=compat, equals=equals.get(var, None)\n+            )\n+    else:\n+        result_vars = {}\n \n             for var in variables_to_merge:\n                 to_merge[var].append(ds.variables[var])\n@@ -359,9 +389,32 @@ def _dataset_concat(\n     for k in datasets[0].variables:\n         if k in concat_over:\n             try:\n-                vars = ensure_common_dims([ds.variables[k] for ds in datasets])\n-            except KeyError:\n-                raise ValueError(\"%r is not present in all datasets.\" % k)\n+\n+        # stack up each variable to fill-out the dataset (in order)\n+        # n.b. this loop preserves variable order, needed for groupby.\n+        for k in datasets[0].variables:\n+            if k in concat_over:\n+                try:\n+                    # Safely collect variables, creating fill_value placeholders for missing ones\n+                    vars_list = []\n+                    for ds in datasets:\n+                        if k in ds.variables:\n+                            vars_list.append(ds.variables[k])\n+                        else:\n+                            # Create a placeholder variable with fill_value for missing variable\n+                            # Use the shape and dims from a reference variable (first available)\n+                            ref_var = next(ds.variables[k] for ds in datasets if k in ds.variables)\n+                            placeholder_shape = tuple(dims_sizes.get(d, ref_var.sizes.get(d, 1)) for d in ref_var.dims)\n+                            placeholder_var = Variable(ref_var.dims, \n+                                                     utils.full_like(ref_var.data, fill_value, shape=placeholder_shape),\n+                                                     attrs=ref_var.attrs)\n+                            vars_list.append(placeholder_var)\n+                    vars = ensure_common_dims(vars_list)\n+                except KeyError:\n+                    raise ValueError(\"%r is not present in all datasets.\" % k)\n+                combined = concat_vars(vars, dim, positions)\n+                assert isinstance(combined, Variable)\n+                result_vars[k] = combined\n             combined = concat_vars(vars, dim, positions)\n             assert isinstance(combined, Variable)\n             result_vars[k] = combined\n",
    "variant_4": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex ecae2566..f45a05a1 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -219,19 +219,27 @@ def _calc_concat_over(datasets, dim, dim_names, data_vars, coords, compat):\n             else:\n                 raise ValueError(\"unexpected value for %s: %s\" % (subset, opt))\n         else:\n-            invalid_vars = [k for k in opt if k not in getattr(datasets[0], subset)]\n+\n+        else:\n+            # Collect variables from all datasets instead of just the first one\n+            all_vars_in_subset = set()\n+            for ds in datasets:\n+                all_vars_in_subset.update(getattr(ds, subset))\n+            \n+            invalid_vars = [k for k in opt if k not in all_vars_in_subset]\n             if invalid_vars:\n                 if subset == \"coords\":\n                     raise ValueError(\n                         \"some variables in coords are not coordinates on \"\n-                        \"the first dataset: %s\" % (invalid_vars,)\n+                        \"any dataset: %s\" % (invalid_vars,)\n                     )\n                 else:\n                     raise ValueError(\n                         \"some variables in data_vars are not data variables \"\n-                        \"on the first dataset: %s\" % (invalid_vars,)\n+                        \"on any dataset: %s\" % (invalid_vars,)\n                     )\n             concat_over.update(opt)\n+            concat_over.update(opt)\n \n     process_subset_opt(data_vars, \"data_vars\")\n     process_subset_opt(coords, \"coords\")\n@@ -312,12 +320,42 @@ def _dataset_concat(\n         to_merge = {var: [] for var in variables_to_merge}\n \n         for ds in datasets:\n-            absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n-                raise ValueError(\n-                    \"variables %r are present in some datasets but not others. \"\n-                    % absent_merge_vars\n-                )\n+\n+    # determine which variables to merge, and then merge them according to compat\n+    variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n+\n+    result_vars = {}\n+    if variables_to_merge:\n+        to_merge = {var: [] for var in variables_to_merge}\n+\n+        for ds in datasets:\n+            for var in variables_to_merge:\n+                if var in ds.variables:\n+                    to_merge[var].append(ds.variables[var])\n+                else:\n+                    # Create a placeholder variable with fill_value for missing variables\n+                    # Get the variable from a dataset that has it to determine shape/dims\n+                    reference_var = None\n+                    for ref_ds in datasets:\n+                        if var in ref_ds.variables:\n+                            reference_var = ref_ds.variables[var]\n+                            break\n+                    \n+                    if reference_var is not None:\n+                        # Create fill_value variable with same dims and dtype as reference\n+                        fill_var = Variable(\n+                            reference_var.dims,\n+                            dtypes.full_like(reference_var, fill_value, reference_var.dtype),\n+                            reference_var.attrs\n+                        )\n+                        to_merge[var].append(fill_var)\n+\n+        for var in variables_to_merge:\n+            result_vars[var] = unique_variable(\n+                var, to_merge[var], compat=compat, equals=equals.get(var, None)\n+            )\n+    else:\n+        result_vars = {}\n \n             for var in variables_to_merge:\n                 to_merge[var].append(ds.variables[var])\n@@ -359,7 +397,33 @@ def _dataset_concat(\n     for k in datasets[0].variables:\n         if k in concat_over:\n             try:\n-                vars = ensure_common_dims([ds.variables[k] for ds in datasets])\n+\n+        if k in concat_over:\n+            try:\n+                # Safely collect variables, using fill_value for missing ones\n+                vars_list = []\n+                for ds in datasets:\n+                    if k in ds.variables:\n+                        vars_list.append(ds.variables[k])\n+                    else:\n+                        # Create a compatible variable with fill_value for missing data\n+                        # Use the first available variable as template for dimensions and shape\n+                        template_var = None\n+                        for other_ds in datasets:\n+                            if k in other_ds.variables:\n+                                template_var = other_ds.variables[k]\n+                                break\n+                        \n+                        if template_var is not None:\n+                            # Create variable filled with fill_value\n+                            fill_data = utils.full_like(template_var.data, fill_value, template_var.dtype)\n+                            fill_var = Variable(template_var.dims, fill_data, template_var.attrs)\n+                            vars_list.append(fill_var)\n+                        else:\n+                            # This shouldn't happen if concat_over was calculated correctly\n+                            raise ValueError(f\"Variable {k!r} not found in any dataset\")\n+                \n+                vars = ensure_common_dims(vars_list)\n             except KeyError:\n                 raise ValueError(\"%r is not present in all datasets.\" % k)\n             combined = concat_vars(vars, dim, positions)\n",
    "variant_5": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex ecae2566..e5c5a347 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -219,17 +219,23 @@ def _calc_concat_over(datasets, dim, dim_names, data_vars, coords, compat):\n             else:\n                 raise ValueError(\"unexpected value for %s: %s\" % (subset, opt))\n         else:\n-            invalid_vars = [k for k in opt if k not in getattr(datasets[0], subset)]\n+\n+            # Collect all variables from all datasets for validation\n+            all_vars = set()\n+            for ds in datasets:\n+                all_vars.update(getattr(ds, subset))\n+            \n+            invalid_vars = [k for k in opt if k not in all_vars]\n             if invalid_vars:\n                 if subset == \"coords\":\n                     raise ValueError(\n                         \"some variables in coords are not coordinates on \"\n-                        \"the first dataset: %s\" % (invalid_vars,)\n+                        \"any dataset: %s\" % (invalid_vars,)\n                     )\n                 else:\n                     raise ValueError(\n                         \"some variables in data_vars are not data variables \"\n-                        \"on the first dataset: %s\" % (invalid_vars,)\n+                        \"on any dataset: %s\" % (invalid_vars,)\n                     )\n             concat_over.update(opt)\n \n@@ -312,12 +318,44 @@ def _dataset_concat(\n         to_merge = {var: [] for var in variables_to_merge}\n \n         for ds in datasets:\n-            absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n-                raise ValueError(\n-                    \"variables %r are present in some datasets but not others. \"\n-                    % absent_merge_vars\n-                )\n+\n+    # determine which variables to merge, and then merge them according to compat\n+    variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n+\n+    result_vars = {}\n+    if variables_to_merge:\n+        to_merge = {var: [] for var in variables_to_merge}\n+\n+        for ds in datasets:\n+            for var in variables_to_merge:\n+                if var in ds.variables:\n+                    to_merge[var].append(ds.variables[var])\n+                else:\n+                    # Create a placeholder variable with fill_value for missing variables\n+                    # Get the variable from a dataset that has it to determine shape/dims\n+                    template_var = None\n+                    for other_ds in datasets:\n+                        if var in other_ds.variables:\n+                            template_var = other_ds.variables[var]\n+                            break\n+                    \n+                    if template_var is not None:\n+                        # Create a variable filled with fill_value matching template structure\n+                        fill_var = template_var._constructor(\n+                            template_var.dims,\n+                            utils.full_like(template_var, fill_value, dtype=template_var.dtype),\n+                            template_var.attrs,\n+                            template_var.encoding,\n+                            fastpath=True\n+                        )\n+                        to_merge[var].append(fill_var)\n+\n+        for var in variables_to_merge:\n+            result_vars[var] = unique_variable(\n+                var, to_merge[var], compat=compat, equals=equals.get(var, None)\n+            )\n+    else:\n+        result_vars = {}\n \n             for var in variables_to_merge:\n                 to_merge[var].append(ds.variables[var])\n@@ -359,9 +397,29 @@ def _dataset_concat(\n     for k in datasets[0].variables:\n         if k in concat_over:\n             try:\n-                vars = ensure_common_dims([ds.variables[k] for ds in datasets])\n-            except KeyError:\n-                raise ValueError(\"%r is not present in all datasets.\" % k)\n+\n+        if k in concat_over:\n+            try:\n+                # Safely collect variables, creating fill_value placeholders for missing ones\n+                vars_list = []\n+                for ds in datasets:\n+                    if k in ds.variables:\n+                        vars_list.append(ds.variables[k])\n+                    else:\n+                        # Create a fill_value placeholder variable with compatible shape\n+                        template_var = next(ds.variables[k] for ds in datasets if k in ds.variables)\n+                        fill_var = template_var._constructor(\n+                            template_var.dims,\n+                            utils.full_like(template_var, fill_value, dtype=template_var.dtype),\n+                            template_var.attrs\n+                        )\n+                        vars_list.append(fill_var)\n+                vars = ensure_common_dims(vars_list)\n+            except (KeyError, StopIteration):\n+                raise ValueError(\"%r is not present in any datasets.\" % k)\n+            combined = concat_vars(vars, dim, positions)\n+            assert isinstance(combined, Variable)\n+            result_vars[k] = combined\n             combined = concat_vars(vars, dim, positions)\n             assert isinstance(combined, Variable)\n             result_vars[k] = combined\n",
    "variant_6": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex ecae2566..8dac6761 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -219,17 +219,23 @@ def _calc_concat_over(datasets, dim, dim_names, data_vars, coords, compat):\n             else:\n                 raise ValueError(\"unexpected value for %s: %s\" % (subset, opt))\n         else:\n-            invalid_vars = [k for k in opt if k not in getattr(datasets[0], subset)]\n+\n+            # Collect variables from all datasets for validation\n+            all_vars = set()\n+            for ds in datasets:\n+                all_vars.update(getattr(ds, subset))\n+            \n+            invalid_vars = [k for k in opt if k not in all_vars]\n             if invalid_vars:\n                 if subset == \"coords\":\n                     raise ValueError(\n                         \"some variables in coords are not coordinates on \"\n-                        \"the first dataset: %s\" % (invalid_vars,)\n+                        \"any dataset: %s\" % (invalid_vars,)\n                     )\n                 else:\n                     raise ValueError(\n                         \"some variables in data_vars are not data variables \"\n-                        \"on the first dataset: %s\" % (invalid_vars,)\n+                        \"on any dataset: %s\" % (invalid_vars,)\n                     )\n             concat_over.update(opt)\n \n@@ -312,12 +318,42 @@ def _dataset_concat(\n         to_merge = {var: [] for var in variables_to_merge}\n \n         for ds in datasets:\n-            absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n-                raise ValueError(\n-                    \"variables %r are present in some datasets but not others. \"\n-                    % absent_merge_vars\n-                )\n+\n+    # determine which variables to merge, and then merge them according to compat\n+    variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n+\n+    result_vars = {}\n+    if variables_to_merge:\n+        to_merge = {var: [] for var in variables_to_merge}\n+\n+        for ds in datasets:\n+            for var in variables_to_merge:\n+                if var in ds.variables:\n+                    to_merge[var].append(ds.variables[var])\n+                else:\n+                    # Create a placeholder variable with fill_value for missing variables\n+                    # Get the shape from a reference variable or use empty shape\n+                    ref_var = None\n+                    for other_ds in datasets:\n+                        if var in other_ds.variables:\n+                            ref_var = other_ds.variables[var]\n+                            break\n+                    \n+                    if ref_var is not None:\n+                        # Create compatible variable with fill_value\n+                        fill_var = Variable(\n+                            ref_var.dims,\n+                            utils.full_like(ref_var.data, fill_value, dtype=ref_var.dtype),\n+                            attrs=ref_var.attrs.copy()\n+                        )\n+                        to_merge[var].append(fill_var)\n+\n+        for var in variables_to_merge:\n+            result_vars[var] = unique_variable(\n+                var, to_merge[var], compat=compat, equals=equals.get(var, None)\n+            )\n+    else:\n+        result_vars = {}\n \n             for var in variables_to_merge:\n                 to_merge[var].append(ds.variables[var])\n@@ -359,9 +395,29 @@ def _dataset_concat(\n     for k in datasets[0].variables:\n         if k in concat_over:\n             try:\n-                vars = ensure_common_dims([ds.variables[k] for ds in datasets])\n-            except KeyError:\n-                raise ValueError(\"%r is not present in all datasets.\" % k)\n+\n+        if k in concat_over:\n+            try:\n+                # Safely collect variables, creating fill_value placeholders for missing ones\n+                vars_list = []\n+                for ds in datasets:\n+                    if k in ds.variables:\n+                        vars_list.append(ds.variables[k])\n+                    else:\n+                        # Create a fill_value placeholder variable with compatible shape\n+                        ref_var = next(ds.variables[k] for ds in datasets if k in ds.variables)\n+                        fill_var = ref_var._constructor(\n+                            ref_var.dims,\n+                            utils.full_like(ref_var, fill_value, dtype=ref_var.dtype),\n+                            ref_var.attrs.copy()\n+                        )\n+                        vars_list.append(fill_var)\n+                vars = ensure_common_dims(vars_list)\n+            except (KeyError, StopIteration):\n+                raise ValueError(\"%r is not present in any datasets.\" % k)\n+            combined = concat_vars(vars, dim, positions)\n+            assert isinstance(combined, Variable)\n+            result_vars[k] = combined\n             combined = concat_vars(vars, dim, positions)\n             assert isinstance(combined, Variable)\n             result_vars[k] = combined\n",
    "variant_7": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex ecae2566..906dc6a9 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -219,17 +219,23 @@ def _calc_concat_over(datasets, dim, dim_names, data_vars, coords, compat):\n             else:\n                 raise ValueError(\"unexpected value for %s: %s\" % (subset, opt))\n         else:\n-            invalid_vars = [k for k in opt if k not in getattr(datasets[0], subset)]\n+\n+            # Collect variables from all datasets for validation\n+            all_vars = set()\n+            for ds in datasets:\n+                all_vars.update(getattr(ds, subset))\n+            \n+            invalid_vars = [k for k in opt if k not in all_vars]\n             if invalid_vars:\n                 if subset == \"coords\":\n                     raise ValueError(\n                         \"some variables in coords are not coordinates on \"\n-                        \"the first dataset: %s\" % (invalid_vars,)\n+                        \"any dataset: %s\" % (invalid_vars,)\n                     )\n                 else:\n                     raise ValueError(\n                         \"some variables in data_vars are not data variables \"\n-                        \"on the first dataset: %s\" % (invalid_vars,)\n+                        \"on any dataset: %s\" % (invalid_vars,)\n                     )\n             concat_over.update(opt)\n \n@@ -312,12 +318,42 @@ def _dataset_concat(\n         to_merge = {var: [] for var in variables_to_merge}\n \n         for ds in datasets:\n-            absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n-                raise ValueError(\n-                    \"variables %r are present in some datasets but not others. \"\n-                    % absent_merge_vars\n-                )\n+\n+    # determine which variables to merge, and then merge them according to compat\n+    variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n+\n+    result_vars = {}\n+    if variables_to_merge:\n+        to_merge = {var: [] for var in variables_to_merge}\n+\n+        for ds in datasets:\n+            for var in variables_to_merge:\n+                if var in ds.variables:\n+                    to_merge[var].append(ds.variables[var])\n+                else:\n+                    # Create a fill_value variable for missing variables\n+                    # Use the first available variable as template for shape/dims\n+                    template_var = None\n+                    for other_ds in datasets:\n+                        if var in other_ds.variables:\n+                            template_var = other_ds.variables[var]\n+                            break\n+                    \n+                    if template_var is not None:\n+                        # Create variable with same dims/shape but filled with fill_value\n+                        fill_var = Variable(\n+                            template_var.dims,\n+                            dtypes.NA if fill_value is None else fill_value,\n+                            attrs=template_var.attrs.copy()\n+                        )\n+                        to_merge[var].append(fill_var)\n+\n+        for var in variables_to_merge:\n+            result_vars[var] = unique_variable(\n+                var, to_merge[var], compat=compat, equals=equals.get(var, None)\n+            )\n+    else:\n+        result_vars = {}\n \n             for var in variables_to_merge:\n                 to_merge[var].append(ds.variables[var])\n@@ -359,7 +395,31 @@ def _dataset_concat(\n     for k in datasets[0].variables:\n         if k in concat_over:\n             try:\n-                vars = ensure_common_dims([ds.variables[k] for ds in datasets])\n+\n+        if k in concat_over:\n+            try:\n+                # Collect variables from all datasets, handling missing ones with fill_value\n+                vars_list = []\n+                for ds in datasets:\n+                    if k in ds.variables:\n+                        vars_list.append(ds.variables[k])\n+                    else:\n+                        # Create a placeholder variable with fill_value for missing variable\n+                        # Use the first available variable as template for dimensions and shape\n+                        template_var = None\n+                        for other_ds in datasets:\n+                            if k in other_ds.variables:\n+                                template_var = other_ds.variables[k]\n+                                break\n+                        \n+                        if template_var is not None:\n+                            # Create variable filled with fill_value matching template structure\n+                            import numpy as np\n+                            fill_data = np.full(template_var.shape, fill_value, dtype=template_var.dtype)\n+                            fill_var = Variable(template_var.dims, fill_data, template_var.attrs)\n+                            vars_list.append(fill_var)\n+                \n+                vars = ensure_common_dims(vars_list)\n             except KeyError:\n                 raise ValueError(\"%r is not present in all datasets.\" % k)\n             combined = concat_vars(vars, dim, positions)\n",
    "variant_8": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex ecae2566..faa80b54 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -219,17 +219,23 @@ def _calc_concat_over(datasets, dim, dim_names, data_vars, coords, compat):\n             else:\n                 raise ValueError(\"unexpected value for %s: %s\" % (subset, opt))\n         else:\n-            invalid_vars = [k for k in opt if k not in getattr(datasets[0], subset)]\n+\n+            # Collect variables from all datasets instead of just the first one\n+            all_vars = set()\n+            for ds in datasets:\n+                all_vars.update(getattr(ds, subset))\n+            \n+            invalid_vars = [k for k in opt if k not in all_vars]\n             if invalid_vars:\n                 if subset == \"coords\":\n                     raise ValueError(\n                         \"some variables in coords are not coordinates on \"\n-                        \"the first dataset: %s\" % (invalid_vars,)\n+                        \"any dataset: %s\" % (invalid_vars,)\n                     )\n                 else:\n                     raise ValueError(\n                         \"some variables in data_vars are not data variables \"\n-                        \"on the first dataset: %s\" % (invalid_vars,)\n+                        \"on any dataset: %s\" % (invalid_vars,)\n                     )\n             concat_over.update(opt)\n \n@@ -312,12 +318,40 @@ def _dataset_concat(\n         to_merge = {var: [] for var in variables_to_merge}\n \n         for ds in datasets:\n-            absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n-                raise ValueError(\n-                    \"variables %r are present in some datasets but not others. \"\n-                    % absent_merge_vars\n-                )\n+\n+    # determine which variables to merge, and then merge them according to compat\n+    variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n+\n+    result_vars = {}\n+    if variables_to_merge:\n+        to_merge = {var: [] for var in variables_to_merge}\n+\n+        for ds in datasets:\n+            for var in variables_to_merge:\n+                if var in ds.variables:\n+                    to_merge[var].append(ds.variables[var])\n+                else:\n+                    # Create a placeholder variable with fill_value for missing variables\n+                    # Get a reference variable to match dimensions and attributes\n+                    ref_var = None\n+                    for other_ds in datasets:\n+                        if var in other_ds.variables:\n+                            ref_var = other_ds.variables[var]\n+                            break\n+                    \n+                    if ref_var is not None:\n+                        # Create a variable filled with fill_value that matches reference dimensions\n+                        import numpy as np\n+                        fill_data = np.full(ref_var.shape, fill_value, dtype=ref_var.dtype)\n+                        fill_var = Variable(ref_var.dims, fill_data, ref_var.attrs)\n+                        to_merge[var].append(fill_var)\n+\n+        for var in variables_to_merge:\n+            result_vars[var] = unique_variable(\n+                var, to_merge[var], compat=compat, equals=equals.get(var, None)\n+            )\n+    else:\n+        result_vars = {}\n \n             for var in variables_to_merge:\n                 to_merge[var].append(ds.variables[var])\n@@ -359,9 +393,31 @@ def _dataset_concat(\n     for k in datasets[0].variables:\n         if k in concat_over:\n             try:\n-                vars = ensure_common_dims([ds.variables[k] for ds in datasets])\n-            except KeyError:\n-                raise ValueError(\"%r is not present in all datasets.\" % k)\n+\n+    # stack up each variable to fill-out the dataset (in order)\n+    # n.b. this loop preserves variable order, needed for groupby.\n+    for k in datasets[0].variables:\n+        if k in concat_over:\n+            try:\n+                # Safely collect variables, creating fill_value placeholders for missing ones\n+                vars_list = []\n+                for ds in datasets:\n+                    if k in ds.variables:\n+                        vars_list.append(ds.variables[k])\n+                    else:\n+                        # Create a fill_value placeholder variable with compatible shape and dims\n+                        first_var = next(d.variables[k] for d in datasets if k in d.variables)\n+                        fill_var = Variable(first_var.dims, \n+                                          utils.full_like(first_var.data, fill_value, first_var.dtype),\n+                                          attrs=first_var.attrs)\n+                        vars_list.append(fill_var)\n+                vars = ensure_common_dims(vars_list)\n+            except StopIteration:\n+                # This should not happen if concat_over is properly calculated\n+                raise ValueError(\"%r is not present in any datasets.\" % k)\n+            combined = concat_vars(vars, dim, positions)\n+            assert isinstance(combined, Variable)\n+            result_vars[k] = combined\n             combined = concat_vars(vars, dim, positions)\n             assert isinstance(combined, Variable)\n             result_vars[k] = combined\n"
  }
}