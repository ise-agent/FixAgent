{
  "zero_patches": {
    "Location 1 (/root/hy/projects_3/scikit-learn/sklearn/model_selection/_split.py lines 1164-1166)": "\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n\n\n",
    "Location 2 (/root/hy/projects_3/scikit-learn/sklearn/model_selection/_split.py lines 1066-1165)": "\nclass _RepeatedSplits(metaclass=ABCMeta):\n    \"\"\"Repeated splits for an arbitrary randomized CV splitter.\n\n    Repeats splits for cross-validators n times with different randomization\n    in each repetition.\n\n    Parameters\n    ----------\n    cv : callable\n        Cross-validator class.\n\n    n_repeats : int, default=10\n        Number of times cross-validator needs to be repeated.\n\n    random_state : int, RandomState instance or None, optional, default=None\n        If int, random_state is the seed used by the random number generator;\n        If RandomState instance, random_state is the random number generator;\n        If None, the random number generator is the RandomState instance used\n        by `np.random`.\n\n    **cvargs : additional params\n        Constructor parameters for cv. Must not contain random_state\n        and shuffle.\n    \"\"\"\n    def __init__(self, cv, n_repeats=10, random_state=None, **cvargs):\n        if not isinstance(n_repeats, numbers.Integral):\n            raise ValueError(\"Number of repetitions must be of Integral type.\")\n\n        if n_repeats <= 0:\n            raise ValueError(\"Number of repetitions must be greater than 0.\")\n\n        if any(key in cvargs for key in ('random_state', 'shuffle')):\n            raise ValueError(\n                \"cvargs must not contain random_state or shuffle.\")\n\n        self.cv = cv\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        self.cvargs = cvargs\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generates indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y : array-like, of length n_samples\n            The target variable for supervised learning problems.\n\n        groups : array-like, with shape (n_samples,), optional\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        n_repeats = self.n_repeats\n        rng = check_random_state(self.random_state)\n\n        for idx in range(n_repeats):\n            cv = self.cv(random_state=rng, shuffle=True,\n                         **self.cvargs)\n            for train_index, test_index in cv.split(X, y, groups):\n                yield train_index, test_index\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n            ``np.zeros(n_samples)`` may be used as a placeholder.\n\n        y : object\n            Always ignored, exists for compatibility.\n            ``np.zeros(n_samples)`` may be used as a placeholder.\n\n        groups : array-like, with shape (n_samples,), optional\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, shuffle=True,\n                     **self.cvargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _pprint(self, {}, changed_only=True)\n",
    "Location 3 (/root/hy/projects_3/scikit-learn/sklearn/model_selection/_split.py lines 1167-1218)": "\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator.\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, shuffle=True,\n                     **self.cvargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n",
    "Location 4 (/root/hy/projects_3/scikit-learn/sklearn/model_selection/_split.py lines 1220-1270)": "\nclass _RepeatedSplits(metaclass=ABCMeta):\n    \"\"\"Base class for repeated cross-validators.\"\"\"\n\n    def __init__(self, cv, n_repeats, random_state, **cv_kwargs):\n        self.cv = cv\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        self.cv_kwargs = cv_kwargs\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generates indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y : array-like of shape (n_samples,), default=None\n            The target variable for supervised learning problems.\n\n        groups : array-like of shape (n_samples,), default=None\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        n_repeats = self.n_repeats\n        rng = check_random_state(self.random_state)\n\n        for idx in range(n_repeats):\n            cv = self.cv(random_state=rng, **self.cv_kwargs)\n            for train_index, test_index in cv.split(X, y, groups):\n                yield train_index, test_index\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator.\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, **self.cv_kwargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n",
    "Location 5 (/root/hy/projects_3/scikit-learn/sklearn/model_selection/_split.py lines 2138-2168)": "\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        return self.cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n"
  },
  "variant_patches": {
    "Location 1 (/root/hy/projects_3/scikit-learn/sklearn/model_selection/_split.py lines 1164-1166)": [
      "\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n\n\n",
      "\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n\n\n",
      "\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n\n\n",
      "\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n\n\n",
      "\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n\n\n",
      "\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n\n\n",
      "\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n\n\n",
      "\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n\n\n"
    ],
    "Location 2 (/root/hy/projects_3/scikit-learn/sklearn/model_selection/_split.py lines 1066-1165)": [
      "\nclass _RepeatedSplits(metaclass=ABCMeta):\n    \"\"\"Repeated splits for an arbitrary randomized CV splitter.\n\n    Repeats splits for cross-validators n times with different randomization\n    in each repetition.\n\n    Parameters\n    ----------\n    cv : callable\n        Cross-validator class.\n\n    n_repeats : int, default=10\n        Number of times cross-validator needs to be repeated.\n\n    random_state : int, RandomState instance or None, optional, default=None\n        If int, random_state is the seed used by the random number generator;\n        If RandomState instance, random_state is the random number generator;\n        If None, the random number generator is the RandomState instance used\n        by `np.random`.\n\n    **cvargs : additional params\n        Constructor parameters for cv. Must not contain random_state\n        and shuffle.\n    \"\"\"\n    def __init__(self, cv, n_repeats=10, random_state=None, **cvargs):\n        if not isinstance(n_repeats, numbers.Integral):\n            raise ValueError(\"Number of repetitions must be of Integral type.\")\n\n        if n_repeats <= 0:\n            raise ValueError(\"Number of repetitions must be greater than 0.\")\n\n        if any(key in cvargs for key in ('random_state', 'shuffle')):\n            raise ValueError(\n                \"cvargs must not contain random_state or shuffle.\")\n\n        self.cv = cv\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        self.cvargs = cvargs\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generates indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y : array-like, of length n_samples\n            The target variable for supervised learning problems.\n\n        groups : array-like, with shape (n_samples,), optional\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        n_repeats = self.n_repeats\n        rng = check_random_state(self.random_state)\n\n        for idx in range(n_repeats):\n            cv = self.cv(random_state=rng, shuffle=True,\n                         **self.cvargs)\n            for train_index, test_index in cv.split(X, y, groups):\n                yield train_index, test_index\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n            ``np.zeros(n_samples)`` may be used as a placeholder.\n\n        y : object\n            Always ignored, exists for compatibility.\n            ``np.zeros(n_samples)`` may be used as a placeholder.\n\n        groups : array-like, with shape (n_samples,), optional\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, shuffle=True,\n                     **self.cvargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _pprint(self, {}, self.__class__.__name__)\n",
      "\nclass _RepeatedSplits(metaclass=ABCMeta):\n    \"\"\"Repeated splits for an arbitrary randomized CV splitter.\n\n    Repeats splits for cross-validators n times with different randomization\n    in each repetition.\n\n    Parameters\n    ----------\n    cv : callable\n        Cross-validator class.\n\n    n_repeats : int, default=10\n        Number of times cross-validator needs to be repeated.\n\n    random_state : int, RandomState instance or None, optional, default=None\n        If int, random_state is the seed used by the random number generator;\n        If RandomState instance, random_state is the random number generator;\n        If None, the random number generator is the RandomState instance used\n        by `np.random`.\n\n    **cvargs : additional params\n        Constructor parameters for cv. Must not contain random_state\n        and shuffle.\n    \"\"\"\n    def __init__(self, cv, n_repeats=10, random_state=None, **cvargs):\n        if not isinstance(n_repeats, numbers.Integral):\n            raise ValueError(\"Number of repetitions must be of Integral type.\")\n\n        if n_repeats <= 0:\n            raise ValueError(\"Number of repetitions must be greater than 0.\")\n\n        if any(key in cvargs for key in ('random_state', 'shuffle')):\n            raise ValueError(\n                \"cvargs must not contain random_state or shuffle.\")\n\n        self.cv = cv\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        self.cvargs = cvargs\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generates indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y : array-like, of length n_samples\n            The target variable for supervised learning problems.\n\n        groups : array-like, with shape (n_samples,), optional\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        n_repeats = self.n_repeats\n        rng = check_random_state(self.random_state)\n\n        for idx in range(n_repeats):\n            cv = self.cv(random_state=rng, shuffle=True,\n                         **self.cvargs)\n            for train_index, test_index in cv.split(X, y, groups):\n                yield train_index, test_index\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n            ``np.zeros(n_samples)`` may be used as a placeholder.\n\n        y : object\n            Always ignored, exists for compatibility.\n            ``np.zeros(n_samples)`` may be used as a placeholder.\n\n        groups : array-like, with shape (n_samples,), optional\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, shuffle=True,\n                     **self.cvargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _pprint(self, {}, changed_only=True)\n",
      "\nclass _RepeatedSplits(metaclass=ABCMeta):\n    \"\"\"Repeated splits for an arbitrary randomized CV splitter.\n\n    Repeats splits for cross-validators n times with different randomization\n    in each repetition.\n\n    Parameters\n    ----------\n    cv : callable\n        Cross-validator class.\n\n    n_repeats : int, default=10\n        Number of times cross-validator needs to be repeated.\n\n    random_state : int, RandomState instance or None, optional, default=None\n        If int, random_state is the seed used by the random number generator;\n        If RandomState instance, random_state is the random number generator;\n        If None, the random number generator is the RandomState instance used\n        by `np.random`.\n\n    **cvargs : additional params\n        Constructor parameters for cv. Must not contain random_state\n        and shuffle.\n    \"\"\"\n    def __init__(self, cv, n_repeats=10, random_state=None, **cvargs):\n        if not isinstance(n_repeats, numbers.Integral):\n            raise ValueError(\"Number of repetitions must be of Integral type.\")\n\n        if n_repeats <= 0:\n            raise ValueError(\"Number of repetitions must be greater than 0.\")\n\n        if any(key in cvargs for key in ('random_state', 'shuffle')):\n            raise ValueError(\n                \"cvargs must not contain random_state or shuffle.\")\n\n        self.cv = cv\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        self.cvargs = cvargs\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generates indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y : array-like, of length n_samples\n            The target variable for supervised learning problems.\n\n        groups : array-like, with shape (n_samples,), optional\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        n_repeats = self.n_repeats\n        rng = check_random_state(self.random_state)\n\n        for idx in range(n_repeats):\n            cv = self.cv(random_state=rng, shuffle=True,\n                         **self.cvargs)\n            for train_index, test_index in cv.split(X, y, groups):\n                yield train_index, test_index\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n            ``np.zeros(n_samples)`` may be used as a placeholder.\n\n        y : object\n            Always ignored, exists for compatibility.\n            ``np.zeros(n_samples)`` may be used as a placeholder.\n\n        groups : array-like, with shape (n_samples,), optional\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, shuffle=True,\n                     **self.cvargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _pprint(self, {}, changed_only=True)\n",
      "\nclass _RepeatedSplits(metaclass=ABCMeta):\n    \"\"\"Repeated splits for an arbitrary randomized CV splitter.\n\n    Repeats splits for cross-validators n times with different randomization\n    in each repetition.\n\n    Parameters\n    ----------\n    cv : callable\n        Cross-validator class.\n\n    n_repeats : int, default=10\n        Number of times cross-validator needs to be repeated.\n\n    random_state : int, RandomState instance or None, optional, default=None\n        If int, random_state is the seed used by the random number generator;\n        If RandomState instance, random_state is the random number generator;\n        If None, the random number generator is the RandomState instance used\n        by `np.random`.\n\n    **cvargs : additional params\n        Constructor parameters for cv. Must not contain random_state\n        and shuffle.\n    \"\"\"\n    def __init__(self, cv, n_repeats=10, random_state=None, **cvargs):\n        if not isinstance(n_repeats, numbers.Integral):\n            raise ValueError(\"Number of repetitions must be of Integral type.\")\n\n        if n_repeats <= 0:\n            raise ValueError(\"Number of repetitions must be greater than 0.\")\n\n        if any(key in cvargs for key in ('random_state', 'shuffle')):\n            raise ValueError(\n                \"cvargs must not contain random_state or shuffle.\")\n\n        self.cv = cv\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        self.cvargs = cvargs\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generates indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y : array-like, of length n_samples\n            The target variable for supervised learning problems.\n\n        groups : array-like, with shape (n_samples,), optional\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        n_repeats = self.n_repeats\n        rng = check_random_state(self.random_state)\n\n        for idx in range(n_repeats):\n            cv = self.cv(random_state=rng, shuffle=True,\n                         **self.cvargs)\n            for train_index, test_index in cv.split(X, y, groups):\n                yield train_index, test_index\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n            ``np.zeros(n_samples)`` may be used as a placeholder.\n\n        y : object\n            Always ignored, exists for compatibility.\n            ``np.zeros(n_samples)`` may be used as a placeholder.\n\n        groups : array-like, with shape (n_samples,), optional\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, shuffle=True,\n                     **self.cvargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _pprint(self, {}, self.__class__.__name__)\n",
      "\nclass _RepeatedSplits(metaclass=ABCMeta):\n    \"\"\"Repeated splits for an arbitrary randomized CV splitter.\n\n    Repeats splits for cross-validators n times with different randomization\n    in each repetition.\n\n    Parameters\n    ----------\n    cv : callable\n        Cross-validator class.\n\n    n_repeats : int, default=10\n        Number of times cross-validator needs to be repeated.\n\n    random_state : int, RandomState instance or None, optional, default=None\n        If int, random_state is the seed used by the random number generator;\n        If RandomState instance, random_state is the random number generator;\n        If None, the random number generator is the RandomState instance used\n        by `np.random`.\n\n    **cvargs : additional params\n        Constructor parameters for cv. Must not contain random_state\n        and shuffle.\n    \"\"\"\n    def __init__(self, cv, n_repeats=10, random_state=None, **cvargs):\n        if not isinstance(n_repeats, numbers.Integral):\n            raise ValueError(\"Number of repetitions must be of Integral type.\")\n\n        if n_repeats <= 0:\n            raise ValueError(\"Number of repetitions must be greater than 0.\")\n\n        if any(key in cvargs for key in ('random_state', 'shuffle')):\n            raise ValueError(\n                \"cvargs must not contain random_state or shuffle.\")\n\n        self.cv = cv\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        self.cvargs = cvargs\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generates indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y : array-like, of length n_samples\n            The target variable for supervised learning problems.\n\n        groups : array-like, with shape (n_samples,), optional\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        n_repeats = self.n_repeats\n        rng = check_random_state(self.random_state)\n\n        for idx in range(n_repeats):\n            cv = self.cv(random_state=rng, shuffle=True,\n                         **self.cvargs)\n            for train_index, test_index in cv.split(X, y, groups):\n                yield train_index, test_index\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n            ``np.zeros(n_samples)`` may be used as a placeholder.\n\n        y : object\n            Always ignored, exists for compatibility.\n            ``np.zeros(n_samples)`` may be used as a placeholder.\n\n        groups : array-like, with shape (n_samples,), optional\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, shuffle=True,\n                     **self.cvargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _pprint(self, {}, changed_only=True)\n",
      "\nclass _RepeatedSplits(metaclass=ABCMeta):\n    \"\"\"Repeated splits for an arbitrary randomized CV splitter.\n\n    Repeats splits for cross-validators n times with different randomization\n    in each repetition.\n\n    Parameters\n    ----------\n    cv : callable\n        Cross-validator class.\n\n    n_repeats : int, default=10\n        Number of times cross-validator needs to be repeated.\n\n    random_state : int, RandomState instance or None, optional, default=None\n        If int, random_state is the seed used by the random number generator;\n        If RandomState instance, random_state is the random number generator;\n        If None, the random number generator is the RandomState instance used\n        by `np.random`.\n\n    **cvargs : additional params\n        Constructor parameters for cv. Must not contain random_state\n        and shuffle.\n    \"\"\"\n    def __init__(self, cv, n_repeats=10, random_state=None, **cvargs):\n        if not isinstance(n_repeats, numbers.Integral):\n            raise ValueError(\"Number of repetitions must be of Integral type.\")\n\n        if n_repeats <= 0:\n            raise ValueError(\"Number of repetitions must be greater than 0.\")\n\n        if any(key in cvargs for key in ('random_state', 'shuffle')):\n            raise ValueError(\n                \"cvargs must not contain random_state or shuffle.\")\n\n        self.cv = cv\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        self.cvargs = cvargs\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generates indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y : array-like, of length n_samples\n            The target variable for supervised learning problems.\n\n        groups : array-like, with shape (n_samples,), optional\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        n_repeats = self.n_repeats\n        rng = check_random_state(self.random_state)\n\n        for idx in range(n_repeats):\n            cv = self.cv(random_state=rng, shuffle=True,\n                         **self.cvargs)\n            for train_index, test_index in cv.split(X, y, groups):\n                yield train_index, test_index\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n            ``np.zeros(n_samples)`` may be used as a placeholder.\n\n        y : object\n            Always ignored, exists for compatibility.\n            ``np.zeros(n_samples)`` may be used as a placeholder.\n\n        groups : array-like, with shape (n_samples,), optional\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, shuffle=True,\n                     **self.cvargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _pprint(self, {}, changed_only=True)\n",
      "\nclass _RepeatedSplits(metaclass=ABCMeta):\n    \"\"\"Repeated splits for an arbitrary randomized CV splitter.\n\n    Repeats splits for cross-validators n times with different randomization\n    in each repetition.\n\n    Parameters\n    ----------\n    cv : callable\n        Cross-validator class.\n\n    n_repeats : int, default=10\n        Number of times cross-validator needs to be repeated.\n\n    random_state : int, RandomState instance or None, optional, default=None\n        If int, random_state is the seed used by the random number generator;\n        If RandomState instance, random_state is the random number generator;\n        If None, the random number generator is the RandomState instance used\n        by `np.random`.\n\n    **cvargs : additional params\n        Constructor parameters for cv. Must not contain random_state\n        and shuffle.\n    \"\"\"\n    def __init__(self, cv, n_repeats=10, random_state=None, **cvargs):\n        if not isinstance(n_repeats, numbers.Integral):\n            raise ValueError(\"Number of repetitions must be of Integral type.\")\n\n        if n_repeats <= 0:\n            raise ValueError(\"Number of repetitions must be greater than 0.\")\n\n        if any(key in cvargs for key in ('random_state', 'shuffle')):\n            raise ValueError(\n                \"cvargs must not contain random_state or shuffle.\")\n\n        self.cv = cv\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        self.cvargs = cvargs\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generates indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y : array-like, of length n_samples\n            The target variable for supervised learning problems.\n\n        groups : array-like, with shape (n_samples,), optional\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        n_repeats = self.n_repeats\n        rng = check_random_state(self.random_state)\n\n        for idx in range(n_repeats):\n            cv = self.cv(random_state=rng, shuffle=True,\n                         **self.cvargs)\n            for train_index, test_index in cv.split(X, y, groups):\n                yield train_index, test_index\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n            ``np.zeros(n_samples)`` may be used as a placeholder.\n\n        y : object\n            Always ignored, exists for compatibility.\n            ``np.zeros(n_samples)`` may be used as a placeholder.\n\n        groups : array-like, with shape (n_samples,), optional\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, shuffle=True,\n                     **self.cvargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _pprint(self, {}, changed_only=True)\n",
      "\nclass _RepeatedSplits(metaclass=ABCMeta):\n    \"\"\"Repeated splits for an arbitrary randomized CV splitter.\n\n    Repeats splits for cross-validators n times with different randomization\n    in each repetition.\n\n    Parameters\n    ----------\n    cv : callable\n        Cross-validator class.\n\n    n_repeats : int, default=10\n        Number of times cross-validator needs to be repeated.\n\n    random_state : int, RandomState instance or None, optional, default=None\n        If int, random_state is the seed used by the random number generator;\n        If RandomState instance, random_state is the random number generator;\n        If None, the random number generator is the RandomState instance used\n        by `np.random`.\n\n    **cvargs : additional params\n        Constructor parameters for cv. Must not contain random_state\n        and shuffle.\n    \"\"\"\n    def __init__(self, cv, n_repeats=10, random_state=None, **cvargs):\n        if not isinstance(n_repeats, numbers.Integral):\n            raise ValueError(\"Number of repetitions must be of Integral type.\")\n\n        if n_repeats <= 0:\n            raise ValueError(\"Number of repetitions must be greater than 0.\")\n\n        if any(key in cvargs for key in ('random_state', 'shuffle')):\n            raise ValueError(\n                \"cvargs must not contain random_state or shuffle.\")\n\n        self.cv = cv\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        self.cvargs = cvargs\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generates indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y : array-like, of length n_samples\n            The target variable for supervised learning problems.\n\n        groups : array-like, with shape (n_samples,), optional\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        n_repeats = self.n_repeats\n        rng = check_random_state(self.random_state)\n\n        for idx in range(n_repeats):\n            cv = self.cv(random_state=rng, shuffle=True,\n                         **self.cvargs)\n            for train_index, test_index in cv.split(X, y, groups):\n                yield train_index, test_index\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n            ``np.zeros(n_samples)`` may be used as a placeholder.\n\n        y : object\n            Always ignored, exists for compatibility.\n            ``np.zeros(n_samples)`` may be used as a placeholder.\n\n        groups : array-like, with shape (n_samples,), optional\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, shuffle=True,\n                     **self.cvargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _pprint(self, {}, changed_only=True)\n"
    ],
    "Location 3 (/root/hy/projects_3/scikit-learn/sklearn/model_selection/_split.py lines 1167-1218)": [
      "\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator.\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, shuffle=True,\n                     **self.cvargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _pprint(self, {}, changed_only=True)\n",
      "\nclass _RepeatedSplits(metaclass=ABCMeta):\n    \"\"\"Base class for repeated cross-validators.\"\"\"\n\n    def __init__(self, cv, n_repeats, random_state, **cvargs):\n        if not isinstance(n_repeats, numbers.Integral):\n            raise ValueError(\"n_repeats must be an integer.\")\n        if n_repeats <= 0:\n            raise ValueError(\"n_repeats must be a positive integer.\")\n        self.cv = cv\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        self.cvargs = cvargs\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generates indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y : array-like of shape (n_samples,), default=None\n            The target variable for supervised learning problems.\n\n        groups : array-like of shape (n_samples,), default=None\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        n_samples = _num_samples(X)\n        rng = check_random_state(self.random_state)\n        for idx in range(self.n_repeats):\n            cv = self.cv(random_state=rng, shuffle=True,\n                         **self.cvargs)\n            for train_index, test_index in cv.split(X, y, groups):\n                yield train_index, test_index\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator.\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, shuffle=True,\n                     **self.cvargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n",
      "\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator.\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, shuffle=True,\n                     **self.cvargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n",
      "\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator.\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, shuffle=True,\n                     **self.cvargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n",
      "\nclass _RepeatedSplits(metaclass=ABCMeta):\n    \"\"\"Base class for repeated cross-validators.\"\"\"\n\n    def __init__(self, cv, n_repeats, random_state, **cvargs):\n        self.cv = cv\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        self.cvargs = cvargs\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generates indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y : array-like of shape (n_samples,), default=None\n            The target variable for supervised learning problems.\n\n        groups : array-like of shape (n_samples,), default=None\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        n_repeats = self.n_repeats\n        rng = check_random_state(self.random_state)\n\n        for idx in range(n_repeats):\n            cv = self.cv(random_state=rng, shuffle=True,\n                         **self.cvargs)\n            for train_index, test_index in cv.split(X, y, groups):\n                yield train_index, test_index\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator.\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, shuffle=True,\n                     **self.cvargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n",
      "\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator.\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, shuffle=True,\n                     **self.cvargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n",
      "\nclass _RepeatedSplits(metaclass=ABCMeta):\n    \"\"\"Base class for repeated cross-validators.\"\"\"\n\n    def __init__(self, cv, n_repeats, random_state, **cvargs):\n        self.cv = cv\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        self.cvargs = cvargs\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generates indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y : array-like of shape (n_samples,), default=None\n            The target variable for supervised learning problems.\n\n        groups : array-like of shape (n_samples,), default=None\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        n_repeats = self.n_repeats\n        rng = check_random_state(self.random_state)\n\n        for idx in range(n_repeats):\n            cv = self.cv(random_state=rng, shuffle=True,\n                         **self.cvargs)\n            for train_index, test_index in cv.split(X, y, groups):\n                yield train_index, test_index\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator.\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, shuffle=True,\n                     **self.cvargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n",
      "\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator.\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, shuffle=True,\n                     **self.cvargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n"
    ],
    "Location 4 (/root/hy/projects_3/scikit-learn/sklearn/model_selection/_split.py lines 1220-1270)": [
      "\nclass _RepeatedSplits(metaclass=ABCMeta):\n    \"\"\"Base class for repeated cross-validators.\"\"\"\n\n    def __init__(self, cv, n_repeats, random_state, **cv_kwargs):\n        self.cv = cv\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        self.cv_kwargs = cv_kwargs\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generates indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y : array-like of shape (n_samples,)\n            The target variable for supervised learning problems.\n\n        groups : array-like of shape (n_samples,), default=None\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        n_repeats = self.n_repeats\n        rng = check_random_state(self.random_state)\n\n        for idx in range(n_repeats):\n            cv = self.cv(random_state=rng, **self.cv_kwargs)\n            for train_index, test_index in cv.split(X, y, groups):\n                yield train_index, test_index\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator.\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, **self.cv_kwargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n",
      "\nclass _RepeatedSplits(metaclass=ABCMeta):\n    \"\"\"Base class for repeated cross-validators.\"\"\"\n\n    def __init__(self, cv, n_repeats, random_state, **cv_kwargs):\n        self.cv = cv\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        self.cv_kwargs = cv_kwargs\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generates indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y : array-like of shape (n_samples,)\n            The target variable for supervised learning problems.\n\n        groups : array-like of shape (n_samples,), default=None\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        n_repeats = self.n_repeats\n        rng = check_random_state(self.random_state)\n\n        for idx in range(n_repeats):\n            cv = self.cv(random_state=rng, **self.cv_kwargs)\n            for train_index, test_index in cv.split(X, y, groups):\n                yield train_index, test_index\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator.\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, **self.cv_kwargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _pprint(self, {})\n",
      "\nclass RepeatedStratifiedKFold(_RepeatedSplits):\n    \"\"\"Repeated Stratified K-Fold cross validator.\n\n    Repeats Stratified K-Fold n times with different randomization in each\n    repetition.\n\n    Read more in the :ref:`User Guide <cross_validation>`.\n\n    Parameters\n    ----------\n    n_splits : int, default=5\n        Number of folds. Must be at least 2.\n\n    n_repeats : int, default=10\n        Number of times cross-validator needs to be repeated.\n\n    random_state : None, int or RandomState, default=None\n        Random state to be used to generate random state for each\n        repetition.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.model_selection import RepeatedStratifiedKFold\n    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n    >>> y = np.array([0, 0, 1, 1])\n    >>> rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=2,\n    ...     random_state=36851234)\n    >>> for train_index, test_index in rskf.split(X, y):\n    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    ...     X_train, X_test = X[train_index], X[test_index]\n    ...     y_train, y_test = y[train_index], y[test_index]\n    ...\n    TRAIN: [1 2] TEST: [0 3]\n    TRAIN: [0 3] TEST: [1 2]\n    TRAIN: [1 3] TEST: [0 2]\n    TRAIN: [0 2] TEST: [1 3]\n\n    Notes\n    -----\n    Randomized CV splitters may return different results for each call of\n    split. You can make the results identical by setting ``random_state``\n    to an integer.\n\n    See also\n    --------\n    RepeatedKFold: Repeats K-Fold n times.\n    \"\"\"\n    def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n        super().__init__(\n            StratifiedKFold, n_repeats, random_state, n_splits=n_splits)\n",
      "\nclass _RepeatedSplits(metaclass=ABCMeta):\n    \"\"\"Base class for repeated cross-validators.\"\"\"\n\n    def __init__(self, cv, n_repeats, random_state, **cv_kwargs):\n        self.cv = cv\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        self.cv_kwargs = cv_kwargs\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generates indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y : array-like of shape (n_samples,), default=None\n            The target variable for supervised learning problems.\n\n        groups : array-like of shape (n_samples,), default=None\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        n_repeats = self.n_repeats\n        rng = check_random_state(self.random_state)\n\n        for idx in range(n_repeats):\n            cv = self.cv(random_state=rng, **self.cv_kwargs)\n            for train_index, test_index in cv.split(X, y, groups):\n                yield train_index, test_index\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator.\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, **self.cv_kwargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _pprint(self, {})\n",
      "\nclass RepeatedStratifiedKFold(_RepeatedSplits):\n    \"\"\"Repeated Stratified K-Fold cross validator.\n\n    Repeats Stratified K-Fold n times with different randomization in each\n    repetition.\n\n    Read more in the :ref:`User Guide <cross_validation>`.\n\n    Parameters\n    ----------\n    n_splits : int, default=5\n        Number of folds. Must be at least 2.\n\n    n_repeats : int, default=10\n        Number of times cross-validator needs to be repeated.\n\n    random_state : None, int or RandomState, default=None\n        Random state to be used to generate random state for each\n        repetition.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.model_selection import RepeatedStratifiedKFold\n    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n    >>> y = np.array([0, 0, 1, 1])\n    >>> rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=2,\n    ...     random_state=36851234)\n    >>> for train_index, test_index in rskf.split(X, y):\n    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    ...     X_train, X_test = X[train_index], X[test_index]\n    ...     y_train, y_test = y[train_index], y[test_index]\n    ...\n    TRAIN: [1 2] TEST: [0 3]\n    TRAIN: [0 3] TEST: [1 2]\n    TRAIN: [1 3] TEST: [0 2]\n    TRAIN: [0 2] TEST: [1 3]\n\n    Notes\n    -----\n    Randomized CV splitters may return different results for each call of\n    split. You can make the results identical by setting ``random_state``\n    to an integer.\n\n    See also\n    --------\n    RepeatedKFold: Repeats K-Fold n times.\n    \"\"\"\n    def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n        super().__init__(\n            StratifiedKFold, n_repeats, random_state, n_splits=n_splits)\n",
      "\nclass _RepeatedSplits(metaclass=ABCMeta):\n    \"\"\"Base class for repeated cross-validators.\"\"\"\n\n    def __init__(self, cv, n_repeats, random_state, **cv_kwargs):\n        if not isinstance(n_repeats, numbers.Integral):\n            raise ValueError(\"n_repeats must be an integer.\")\n        if n_repeats <= 0:\n            raise ValueError(\"n_repeats must be a positive integer.\")\n        self.cv = cv\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        self.cv_kwargs = cv_kwargs\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generates indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y : array-like of shape (n_samples,), default=None\n            The target variable for supervised learning problems.\n\n        groups : array-like of shape (n_samples,), default=None\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        n_samples = _num_samples(X)\n        rng = check_random_state(self.random_state)\n        for idx in range(self.n_repeats):\n            cv = self.cv(random_state=rng, **self.cv_kwargs)\n            for train_index, test_index in cv.split(X, y, groups):\n                yield train_index, test_index\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator.\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, **self.cv_kwargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n",
      "\nclass _RepeatedSplits(metaclass=ABCMeta):\n    \"\"\"Base class for repeated cross-validators.\"\"\"\n\n    def __init__(self, cv, n_repeats, random_state, **cv_kwargs):\n        self.cv = cv\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        self.cv_kwargs = cv_kwargs\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generates indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y : array-like, shape (n_samples,)\n            The target variable for supervised learning problems.\n\n        groups : array-like, with shape (n_samples,), optional\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        n_repeats = self.n_repeats\n        rng = check_random_state(self.random_state)\n\n        for idx in range(n_repeats):\n            cv = self.cv(random_state=rng, **self.cv_kwargs)\n            for train_index, test_index in cv.split(X, y, groups):\n                yield train_index, test_index\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        rng = check_random_state(self.random_state)\n        cv = self.cv(random_state=rng, **self.cv_kwargs)\n        return cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n",
      "\nclass _RepeatedSplits(metaclass=ABCMeta):\n    \"\"\"Base class for repeated cross-validators.\"\"\"\n\n    def __init__(self, cv, n_repeats, random_state, **cv_kwargs):\n        if not isinstance(n_repeats, numbers.Integral):\n            raise ValueError(\"n_repeats must be an integer.\")\n        if n_repeats <= 0:\n            raise ValueError(\"n_repeats must be a positive integer.\")\n\n        if isinstance(cv, type):\n            cv = cv(**cv_kwargs)\n        else:\n            for key, value in cv_kwargs.items():\n                setattr(cv, key, value)\n\n        self.cv = cv\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generates indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        y : array-like, shape (n_samples,)\n            The target variable for supervised learning problems.\n\n        groups : array-like, with shape (n_samples,), optional\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        n_samples = _num_samples(X)\n        rng = check_random_state(self.random_state)\n        for idx in range(self.n_repeats):\n            cv = clone(self.cv)\n            if hasattr(cv, 'random_state'):\n                cv.random_state = rng.randint(0, np.iinfo(np.int32).max)\n            for train_index, test_index in cv.split(X, y, groups):\n                yield train_index, test_index\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        return self.cv.get_n_splits(X, y, groups) * self.n_repeats\n\n    def __repr__(self):\n        return _build_repr(self)\n"
    ],
    "Location 5 (/root/hy/projects_3/scikit-learn/sklearn/model_selection/_split.py lines 2138-2168)": [
      "\ndef _build_repr(self):\n    # XXX This is copied from BaseEstimator's get_params\n    cls = self.__class__\n    init = getattr(cls.__init__, 'deprecated_original', cls.__init__)\n    # Ignore varargs, kw and default values and pop self\n    init_signature = signature(init)\n    # Consider the constructor parameters excluding 'self'\n    if init is object.__init__:\n        args = []\n    else:\n        args = sorted([p.name for p in init_signature.parameters.values()\n                       if p.name != 'self' and p.kind != p.VAR_KEYWORD])\n    class_name = self.__class__.__name__\n    params = dict()\n    for key in args:\n        # We need deprecation warnings to always be on in order to\n        # catch deprecated param values.\n        # This is set in utils/__init__.py but it gets overwritten\n        # when running under python3 somehow.\n        warnings.simplefilter(\"always\", DeprecationWarning)\n        try:\n            with warnings.catch_warnings(record=True) as w:\n                value = getattr(self, key, None)\n            if len(w) and w[0].category == DeprecationWarning:\n                # if the parameter is deprecated, don't show it\n                continue\n        finally:\n            warnings.filters.pop(0)\n        params[key] = value\n\n    return '%s(%s)' % (class_name, _pprint(params, offset=len(class_name)))\n",
      "\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        return self.n_repeats * self.cv.get_n_splits(X, y, groups)\n\n    def __repr__(self):\n        return _build_repr(self)\n",
      "\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        return self.n_repeats * self.cv.get_n_splits(X, y, groups)\n\n    def __repr__(self):\n        return _build_repr(self)\n",
      "\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator.\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        return self.n_repeats * self.cv.get_n_splits(X, y, groups)\n\n    def __repr__(self):\n        return _build_repr(self)\n",
      "\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator.\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        return self.n_repeats * self.cv.get_n_splits(X, y, groups)\n\n    def __repr__(self):\n        return _build_repr(self)\n",
      "\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator.\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        return self.n_repeats * self.cv.get_n_splits(X, y, groups)\n\n    def __repr__(self):\n        return _build_repr(self)\n",
      "\ndef _build_repr(self):\n    # XXX This is copied from BaseEstimator's get_params\n    cls = self.__class__\n    init = getattr(cls.__init__, 'deprecated_original', cls.__init__)\n    # Ignore varargs, kw and default values and pop self\n    init_signature = signature(init)\n    # Consider the constructor parameters excluding 'self'\n    if init is object.__init__:\n        args = []\n    else:\n        args = sorted([p.name for p in init_signature.parameters.values()\n                       if p.name != 'self' and p.kind != p.VAR_KEYWORD])\n    class_name = self.__class__.__name__\n    params = dict()\n    for key in args:\n        # We need deprecation warnings to always be on in order to\n        # catch deprecated param values.\n        # This is set in utils/__init__.py but it gets overwritten\n        # when running under python3 somehow.\n        warnings.simplefilter(\"always\", DeprecationWarning)\n        try:\n            with warnings.catch_warnings(record=True) as w:\n                value = getattr(self, key, None)\n            if len(w) and w[0].category == DeprecationWarning:\n                # if the parameter is deprecated, don't show it\n                continue\n        finally:\n            warnings.filters.pop(0)\n        params[key] = value\n\n    return '%s(%s)' % (class_name, _pprint(params, offset=len(class_name)))\n",
      "\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator\n\n        Parameters\n        ----------\n        X : object\n            Always ignored, exists for compatibility.\n\n        y : object\n            Always ignored, exists for compatibility.\n\n        groups : object\n            Always ignored, exists for compatibility.\n\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        return self.n_repeats * self.cv.get_n_splits(X, y, groups)\n\n    def __repr__(self):\n        return _build_repr(self)\n"
    ]
  },
  "combined_diffs": {
    "raw_patch": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex c49a3ce6a..299cd9587 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -1063,6 +1063,7 @@ class LeavePGroupsOut(BaseCrossValidator):\n         return super().split(X, y, groups)\n \n \n+\n class _RepeatedSplits(metaclass=ABCMeta):\n     \"\"\"Repeated splits for an arbitrary randomized CV splitter.\n \n@@ -1163,6 +1164,13 @@ class _RepeatedSplits(metaclass=ABCMeta):\n                      **self.cvargs)\n         return cv.get_n_splits(X, y, groups) * self.n_repeats\n \n+    def __repr__(self):\n+        return _build_repr(self)\n+\n+    def __repr__(self):\n+        return _build_repr(self)\n+\n+\n \n class RepeatedKFold(_RepeatedSplits):\n     \"\"\"Repeated K-Fold cross validator.\n@@ -2135,6 +2143,7 @@ def train_test_split(*arrays, **options):\n train_test_split.__test__ = False\n \n \n+\n def _build_repr(self):\n     # XXX This is copied from BaseEstimator's get_params\n     cls = self.__class__\n",
    "variant_0": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex c49a3ce6a..aab3ec5fd 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -1063,6 +1063,7 @@ class LeavePGroupsOut(BaseCrossValidator):\n         return super().split(X, y, groups)\n \n \n+\n class _RepeatedSplits(metaclass=ABCMeta):\n     \"\"\"Repeated splits for an arbitrary randomized CV splitter.\n \n@@ -1163,111 +1164,108 @@ class _RepeatedSplits(metaclass=ABCMeta):\n                      **self.cvargs)\n         return cv.get_n_splits(X, y, groups) * self.n_repeats\n \n+    def __repr__(self):\n+        return _pprint(self, {}, changed_only=True)\n \n-class RepeatedKFold(_RepeatedSplits):\n-    \"\"\"Repeated K-Fold cross validator.\n+    def __repr__(self):\n+        return _build_repr(self)\n \n-    Repeats K-Fold n times with different randomization in each repetition.\n \n-    Read more in the :ref:`User Guide <cross_validation>`.\n \n-    Parameters\n-    ----------\n-    n_splits : int, default=5\n-        Number of folds. Must be at least 2.\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator.\n \n-    n_repeats : int, default=10\n-        Number of times cross-validator needs to be repeated.\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n \n-    random_state : int, RandomState instance or None, optional, default=None\n-        If int, random_state is the seed used by the random number generator;\n-        If RandomState instance, random_state is the random number generator;\n-        If None, the random number generator is the RandomState instance used\n-        by `np.random`.\n+        y : object\n+            Always ignored, exists for compatibility.\n \n-    Examples\n-    --------\n-    >>> import numpy as np\n-    >>> from sklearn.model_selection import RepeatedKFold\n-    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n-    >>> y = np.array([0, 0, 1, 1])\n-    >>> rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=2652124)\n-    >>> for train_index, test_index in rkf.split(X):\n-    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n-    ...     X_train, X_test = X[train_index], X[test_index]\n-    ...     y_train, y_test = y[train_index], y[test_index]\n-    ...\n-    TRAIN: [0 1] TEST: [2 3]\n-    TRAIN: [2 3] TEST: [0 1]\n-    TRAIN: [1 2] TEST: [0 3]\n-    TRAIN: [0 3] TEST: [1 2]\n+        groups : object\n+            Always ignored, exists for compatibility.\n \n-    Notes\n-    -----\n-    Randomized CV splitters may return different results for each call of\n-    split. You can make the results identical by setting ``random_state``\n-    to an integer.\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        rng = check_random_state(self.random_state)\n+        cv = self.cv(random_state=rng, shuffle=True,\n+                     **self.cvargs)\n+        return cv.get_n_splits(X, y, groups) * self.n_repeats\n \n-    See also\n-    --------\n-    RepeatedStratifiedKFold: Repeats Stratified K-Fold n times.\n-    \"\"\"\n-    def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n-        super().__init__(\n-            KFold, n_repeats, random_state, n_splits=n_splits)\n+    def __repr__(self):\n+        return _build_repr(self)\n \n \n-class RepeatedStratifiedKFold(_RepeatedSplits):\n-    \"\"\"Repeated Stratified K-Fold cross validator.\n+class _RepeatedSplits(metaclass=ABCMeta):\n+    \"\"\"Base class for repeated cross-validators.\"\"\"\n \n-    Repeats Stratified K-Fold n times with different randomization in each\n-    repetition.\n+    def __init__(self, cv, n_repeats, random_state, **cv_kwargs):\n+        self.cv = cv\n+        self.n_repeats = n_repeats\n+        self.random_state = random_state\n+        self.cv_kwargs = cv_kwargs\n \n-    Read more in the :ref:`User Guide <cross_validation>`.\n+    def split(self, X, y=None, groups=None):\n+        \"\"\"Generates indices to split data into training and test set.\n \n-    Parameters\n-    ----------\n-    n_splits : int, default=5\n-        Number of folds. Must be at least 2.\n+        Parameters\n+        ----------\n+        X : array-like of shape (n_samples, n_features)\n+            Training data, where n_samples is the number of samples\n+            and n_features is the number of features.\n \n-    n_repeats : int, default=10\n-        Number of times cross-validator needs to be repeated.\n+        y : array-like of shape (n_samples,), default=None\n+            The target variable for supervised learning problems.\n \n-    random_state : None, int or RandomState, default=None\n-        Random state to be used to generate random state for each\n-        repetition.\n+        groups : array-like of shape (n_samples,), default=None\n+            Group labels for the samples used while splitting the dataset into\n+            train/test set.\n \n-    Examples\n-    --------\n-    >>> import numpy as np\n-    >>> from sklearn.model_selection import RepeatedStratifiedKFold\n-    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n-    >>> y = np.array([0, 0, 1, 1])\n-    >>> rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=2,\n-    ...     random_state=36851234)\n-    >>> for train_index, test_index in rskf.split(X, y):\n-    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n-    ...     X_train, X_test = X[train_index], X[test_index]\n-    ...     y_train, y_test = y[train_index], y[test_index]\n-    ...\n-    TRAIN: [1 2] TEST: [0 3]\n-    TRAIN: [0 3] TEST: [1 2]\n-    TRAIN: [1 3] TEST: [0 2]\n-    TRAIN: [0 2] TEST: [1 3]\n+        Yields\n+        ------\n+        train : ndarray\n+            The training set indices for that split.\n \n-    Notes\n-    -----\n-    Randomized CV splitters may return different results for each call of\n-    split. You can make the results identical by setting ``random_state``\n-    to an integer.\n+        test : ndarray\n+            The testing set indices for that split.\n+        \"\"\"\n+        n_repeats = self.n_repeats\n+        rng = check_random_state(self.random_state)\n \n-    See also\n-    --------\n-    RepeatedKFold: Repeats K-Fold n times.\n-    \"\"\"\n-    def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n-        super().__init__(\n-            StratifiedKFold, n_repeats, random_state, n_splits=n_splits)\n+        for idx in range(n_repeats):\n+            cv = self.cv(random_state=rng, **self.cv_kwargs)\n+            for train_index, test_index in cv.split(X, y, groups):\n+                yield train_index, test_index\n+\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator.\n+\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n+\n+        y : object\n+            Always ignored, exists for compatibility.\n+\n+        groups : object\n+            Always ignored, exists for compatibility.\n+\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        rng = check_random_state(self.random_state)\n+        cv = self.cv(random_state=rng, **self.cv_kwargs)\n+        return cv.get_n_splits(X, y, groups) * self.n_repeats\n+\n+    def __repr__(self):\n+        return _build_repr(self)\n \n \n class BaseShuffleSplit(metaclass=ABCMeta):\n@@ -2135,34 +2133,27 @@ def train_test_split(*arrays, **options):\n train_test_split.__test__ = False\n \n \n-def _build_repr(self):\n-    # XXX This is copied from BaseEstimator's get_params\n-    cls = self.__class__\n-    init = getattr(cls.__init__, 'deprecated_original', cls.__init__)\n-    # Ignore varargs, kw and default values and pop self\n-    init_signature = signature(init)\n-    # Consider the constructor parameters excluding 'self'\n-    if init is object.__init__:\n-        args = []\n-    else:\n-        args = sorted([p.name for p in init_signature.parameters.values()\n-                       if p.name != 'self' and p.kind != p.VAR_KEYWORD])\n-    class_name = self.__class__.__name__\n-    params = dict()\n-    for key in args:\n-        # We need deprecation warnings to always be on in order to\n-        # catch deprecated param values.\n-        # This is set in utils/__init__.py but it gets overwritten\n-        # when running under python3 somehow.\n-        warnings.simplefilter(\"always\", DeprecationWarning)\n-        try:\n-            with warnings.catch_warnings(record=True) as w:\n-                value = getattr(self, key, None)\n-            if len(w) and w[0].category == DeprecationWarning:\n-                # if the parameter is deprecated, don't show it\n-                continue\n-        finally:\n-            warnings.filters.pop(0)\n-        params[key] = value\n-\n-    return '%s(%s)' % (class_name, _pprint(params, offset=len(class_name)))\n+\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator\n+\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n+\n+        y : object\n+            Always ignored, exists for compatibility.\n+\n+        groups : object\n+            Always ignored, exists for compatibility.\n+\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        return self.cv.get_n_splits(X, y, groups) * self.n_repeats\n+\n+    def __repr__(self):\n+        return _build_repr(self)\n",
    "variant_1": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex c49a3ce6a..b13534cdd 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -1063,6 +1063,7 @@ class LeavePGroupsOut(BaseCrossValidator):\n         return super().split(X, y, groups)\n \n \n+\n class _RepeatedSplits(metaclass=ABCMeta):\n     \"\"\"Repeated splits for an arbitrary randomized CV splitter.\n \n@@ -1163,111 +1164,108 @@ class _RepeatedSplits(metaclass=ABCMeta):\n                      **self.cvargs)\n         return cv.get_n_splits(X, y, groups) * self.n_repeats\n \n+    def __repr__(self):\n+        return _pprint(self, {}, self.__class__.__name__)\n \n-class RepeatedKFold(_RepeatedSplits):\n-    \"\"\"Repeated K-Fold cross validator.\n+    def __repr__(self):\n+        return _build_repr(self)\n \n-    Repeats K-Fold n times with different randomization in each repetition.\n \n-    Read more in the :ref:`User Guide <cross_validation>`.\n \n-    Parameters\n-    ----------\n-    n_splits : int, default=5\n-        Number of folds. Must be at least 2.\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator.\n \n-    n_repeats : int, default=10\n-        Number of times cross-validator needs to be repeated.\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n \n-    random_state : int, RandomState instance or None, optional, default=None\n-        If int, random_state is the seed used by the random number generator;\n-        If RandomState instance, random_state is the random number generator;\n-        If None, the random number generator is the RandomState instance used\n-        by `np.random`.\n+        y : object\n+            Always ignored, exists for compatibility.\n \n-    Examples\n-    --------\n-    >>> import numpy as np\n-    >>> from sklearn.model_selection import RepeatedKFold\n-    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n-    >>> y = np.array([0, 0, 1, 1])\n-    >>> rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=2652124)\n-    >>> for train_index, test_index in rkf.split(X):\n-    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n-    ...     X_train, X_test = X[train_index], X[test_index]\n-    ...     y_train, y_test = y[train_index], y[test_index]\n-    ...\n-    TRAIN: [0 1] TEST: [2 3]\n-    TRAIN: [2 3] TEST: [0 1]\n-    TRAIN: [1 2] TEST: [0 3]\n-    TRAIN: [0 3] TEST: [1 2]\n+        groups : object\n+            Always ignored, exists for compatibility.\n \n-    Notes\n-    -----\n-    Randomized CV splitters may return different results for each call of\n-    split. You can make the results identical by setting ``random_state``\n-    to an integer.\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        rng = check_random_state(self.random_state)\n+        cv = self.cv(random_state=rng, shuffle=True,\n+                     **self.cvargs)\n+        return cv.get_n_splits(X, y, groups) * self.n_repeats\n \n-    See also\n-    --------\n-    RepeatedStratifiedKFold: Repeats Stratified K-Fold n times.\n-    \"\"\"\n-    def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n-        super().__init__(\n-            KFold, n_repeats, random_state, n_splits=n_splits)\n+    def __repr__(self):\n+        return _pprint(self, {}, changed_only=True)\n \n \n-class RepeatedStratifiedKFold(_RepeatedSplits):\n-    \"\"\"Repeated Stratified K-Fold cross validator.\n+class _RepeatedSplits(metaclass=ABCMeta):\n+    \"\"\"Base class for repeated cross-validators.\"\"\"\n \n-    Repeats Stratified K-Fold n times with different randomization in each\n-    repetition.\n+    def __init__(self, cv, n_repeats, random_state, **cv_kwargs):\n+        self.cv = cv\n+        self.n_repeats = n_repeats\n+        self.random_state = random_state\n+        self.cv_kwargs = cv_kwargs\n \n-    Read more in the :ref:`User Guide <cross_validation>`.\n+    def split(self, X, y=None, groups=None):\n+        \"\"\"Generates indices to split data into training and test set.\n \n-    Parameters\n-    ----------\n-    n_splits : int, default=5\n-        Number of folds. Must be at least 2.\n+        Parameters\n+        ----------\n+        X : array-like of shape (n_samples, n_features)\n+            Training data, where n_samples is the number of samples\n+            and n_features is the number of features.\n \n-    n_repeats : int, default=10\n-        Number of times cross-validator needs to be repeated.\n+        y : array-like of shape (n_samples,)\n+            The target variable for supervised learning problems.\n \n-    random_state : None, int or RandomState, default=None\n-        Random state to be used to generate random state for each\n-        repetition.\n+        groups : array-like of shape (n_samples,), default=None\n+            Group labels for the samples used while splitting the dataset into\n+            train/test set.\n \n-    Examples\n-    --------\n-    >>> import numpy as np\n-    >>> from sklearn.model_selection import RepeatedStratifiedKFold\n-    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n-    >>> y = np.array([0, 0, 1, 1])\n-    >>> rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=2,\n-    ...     random_state=36851234)\n-    >>> for train_index, test_index in rskf.split(X, y):\n-    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n-    ...     X_train, X_test = X[train_index], X[test_index]\n-    ...     y_train, y_test = y[train_index], y[test_index]\n-    ...\n-    TRAIN: [1 2] TEST: [0 3]\n-    TRAIN: [0 3] TEST: [1 2]\n-    TRAIN: [1 3] TEST: [0 2]\n-    TRAIN: [0 2] TEST: [1 3]\n+        Yields\n+        ------\n+        train : ndarray\n+            The training set indices for that split.\n \n-    Notes\n-    -----\n-    Randomized CV splitters may return different results for each call of\n-    split. You can make the results identical by setting ``random_state``\n-    to an integer.\n+        test : ndarray\n+            The testing set indices for that split.\n+        \"\"\"\n+        n_repeats = self.n_repeats\n+        rng = check_random_state(self.random_state)\n \n-    See also\n-    --------\n-    RepeatedKFold: Repeats K-Fold n times.\n-    \"\"\"\n-    def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n-        super().__init__(\n-            StratifiedKFold, n_repeats, random_state, n_splits=n_splits)\n+        for idx in range(n_repeats):\n+            cv = self.cv(random_state=rng, **self.cv_kwargs)\n+            for train_index, test_index in cv.split(X, y, groups):\n+                yield train_index, test_index\n+\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator.\n+\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n+\n+        y : object\n+            Always ignored, exists for compatibility.\n+\n+        groups : object\n+            Always ignored, exists for compatibility.\n+\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        rng = check_random_state(self.random_state)\n+        cv = self.cv(random_state=rng, **self.cv_kwargs)\n+        return cv.get_n_splits(X, y, groups) * self.n_repeats\n+\n+    def __repr__(self):\n+        return _build_repr(self)\n \n \n class BaseShuffleSplit(metaclass=ABCMeta):\n@@ -2135,6 +2133,7 @@ def train_test_split(*arrays, **options):\n train_test_split.__test__ = False\n \n \n+\n def _build_repr(self):\n     # XXX This is copied from BaseEstimator's get_params\n     cls = self.__class__\n",
    "variant_2": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex c49a3ce6a..bce23ca7c 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -1063,6 +1063,7 @@ class LeavePGroupsOut(BaseCrossValidator):\n         return super().split(X, y, groups)\n \n \n+\n class _RepeatedSplits(metaclass=ABCMeta):\n     \"\"\"Repeated splits for an arbitrary randomized CV splitter.\n \n@@ -1163,111 +1164,153 @@ class _RepeatedSplits(metaclass=ABCMeta):\n                      **self.cvargs)\n         return cv.get_n_splits(X, y, groups) * self.n_repeats\n \n+    def __repr__(self):\n+        return _pprint(self, {}, changed_only=True)\n \n-class RepeatedKFold(_RepeatedSplits):\n-    \"\"\"Repeated K-Fold cross validator.\n+    def __repr__(self):\n+        return _build_repr(self)\n \n-    Repeats K-Fold n times with different randomization in each repetition.\n \n-    Read more in the :ref:`User Guide <cross_validation>`.\n \n-    Parameters\n-    ----------\n-    n_splits : int, default=5\n-        Number of folds. Must be at least 2.\n+class _RepeatedSplits(metaclass=ABCMeta):\n+    \"\"\"Base class for repeated cross-validators.\"\"\"\n \n-    n_repeats : int, default=10\n-        Number of times cross-validator needs to be repeated.\n+    def __init__(self, cv, n_repeats, random_state, **cvargs):\n+        if not isinstance(n_repeats, numbers.Integral):\n+            raise ValueError(\"n_repeats must be an integer.\")\n+        if n_repeats <= 0:\n+            raise ValueError(\"n_repeats must be a positive integer.\")\n+        self.cv = cv\n+        self.n_repeats = n_repeats\n+        self.random_state = random_state\n+        self.cvargs = cvargs\n \n-    random_state : int, RandomState instance or None, optional, default=None\n-        If int, random_state is the seed used by the random number generator;\n-        If RandomState instance, random_state is the random number generator;\n-        If None, the random number generator is the RandomState instance used\n-        by `np.random`.\n+    def split(self, X, y=None, groups=None):\n+        \"\"\"Generates indices to split data into training and test set.\n \n-    Examples\n-    --------\n-    >>> import numpy as np\n-    >>> from sklearn.model_selection import RepeatedKFold\n-    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n-    >>> y = np.array([0, 0, 1, 1])\n-    >>> rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=2652124)\n-    >>> for train_index, test_index in rkf.split(X):\n-    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n-    ...     X_train, X_test = X[train_index], X[test_index]\n-    ...     y_train, y_test = y[train_index], y[test_index]\n-    ...\n-    TRAIN: [0 1] TEST: [2 3]\n-    TRAIN: [2 3] TEST: [0 1]\n-    TRAIN: [1 2] TEST: [0 3]\n-    TRAIN: [0 3] TEST: [1 2]\n+        Parameters\n+        ----------\n+        X : array-like of shape (n_samples, n_features)\n+            Training data, where n_samples is the number of samples\n+            and n_features is the number of features.\n \n-    Notes\n-    -----\n-    Randomized CV splitters may return different results for each call of\n-    split. You can make the results identical by setting ``random_state``\n-    to an integer.\n+        y : array-like of shape (n_samples,), default=None\n+            The target variable for supervised learning problems.\n \n-    See also\n-    --------\n-    RepeatedStratifiedKFold: Repeats Stratified K-Fold n times.\n-    \"\"\"\n-    def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n-        super().__init__(\n-            KFold, n_repeats, random_state, n_splits=n_splits)\n+        groups : array-like of shape (n_samples,), default=None\n+            Group labels for the samples used while splitting the dataset into\n+            train/test set.\n \n+        Yields\n+        ------\n+        train : ndarray\n+            The training set indices for that split.\n \n-class RepeatedStratifiedKFold(_RepeatedSplits):\n-    \"\"\"Repeated Stratified K-Fold cross validator.\n+        test : ndarray\n+            The testing set indices for that split.\n+        \"\"\"\n+        n_samples = _num_samples(X)\n+        rng = check_random_state(self.random_state)\n+        for idx in range(self.n_repeats):\n+            cv = self.cv(random_state=rng, shuffle=True,\n+                         **self.cvargs)\n+            for train_index, test_index in cv.split(X, y, groups):\n+                yield train_index, test_index\n \n-    Repeats Stratified K-Fold n times with different randomization in each\n-    repetition.\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator.\n \n-    Read more in the :ref:`User Guide <cross_validation>`.\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n \n-    Parameters\n-    ----------\n-    n_splits : int, default=5\n-        Number of folds. Must be at least 2.\n+        y : object\n+            Always ignored, exists for compatibility.\n \n-    n_repeats : int, default=10\n-        Number of times cross-validator needs to be repeated.\n+        groups : object\n+            Always ignored, exists for compatibility.\n \n-    random_state : None, int or RandomState, default=None\n-        Random state to be used to generate random state for each\n-        repetition.\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        rng = check_random_state(self.random_state)\n+        cv = self.cv(random_state=rng, shuffle=True,\n+                     **self.cvargs)\n+        return cv.get_n_splits(X, y, groups) * self.n_repeats\n \n-    Examples\n-    --------\n-    >>> import numpy as np\n-    >>> from sklearn.model_selection import RepeatedStratifiedKFold\n-    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n-    >>> y = np.array([0, 0, 1, 1])\n-    >>> rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=2,\n-    ...     random_state=36851234)\n-    >>> for train_index, test_index in rskf.split(X, y):\n-    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n-    ...     X_train, X_test = X[train_index], X[test_index]\n-    ...     y_train, y_test = y[train_index], y[test_index]\n-    ...\n-    TRAIN: [1 2] TEST: [0 3]\n-    TRAIN: [0 3] TEST: [1 2]\n-    TRAIN: [1 3] TEST: [0 2]\n-    TRAIN: [0 2] TEST: [1 3]\n+    def __repr__(self):\n+        return _build_repr(self)\n \n-    Notes\n-    -----\n-    Randomized CV splitters may return different results for each call of\n-    split. You can make the results identical by setting ``random_state``\n-    to an integer.\n \n-    See also\n-    --------\n-    RepeatedKFold: Repeats K-Fold n times.\n-    \"\"\"\n-    def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n-        super().__init__(\n-            StratifiedKFold, n_repeats, random_state, n_splits=n_splits)\n+class _RepeatedSplits(metaclass=ABCMeta):\n+    \"\"\"Base class for repeated cross-validators.\"\"\"\n+\n+    def __init__(self, cv, n_repeats, random_state, **cv_kwargs):\n+        self.cv = cv\n+        self.n_repeats = n_repeats\n+        self.random_state = random_state\n+        self.cv_kwargs = cv_kwargs\n+\n+    def split(self, X, y=None, groups=None):\n+        \"\"\"Generates indices to split data into training and test set.\n+\n+        Parameters\n+        ----------\n+        X : array-like of shape (n_samples, n_features)\n+            Training data, where n_samples is the number of samples\n+            and n_features is the number of features.\n+\n+        y : array-like of shape (n_samples,)\n+            The target variable for supervised learning problems.\n+\n+        groups : array-like of shape (n_samples,), default=None\n+            Group labels for the samples used while splitting the dataset into\n+            train/test set.\n+\n+        Yields\n+        ------\n+        train : ndarray\n+            The training set indices for that split.\n+\n+        test : ndarray\n+            The testing set indices for that split.\n+        \"\"\"\n+        n_repeats = self.n_repeats\n+        rng = check_random_state(self.random_state)\n+\n+        for idx in range(n_repeats):\n+            cv = self.cv(random_state=rng, **self.cv_kwargs)\n+            for train_index, test_index in cv.split(X, y, groups):\n+                yield train_index, test_index\n+\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator.\n+\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n+\n+        y : object\n+            Always ignored, exists for compatibility.\n+\n+        groups : object\n+            Always ignored, exists for compatibility.\n+\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        rng = check_random_state(self.random_state)\n+        cv = self.cv(random_state=rng, **self.cv_kwargs)\n+        return cv.get_n_splits(X, y, groups) * self.n_repeats\n+\n+    def __repr__(self):\n+        return _pprint(self, {})\n \n \n class BaseShuffleSplit(metaclass=ABCMeta):\n@@ -2135,34 +2178,27 @@ def train_test_split(*arrays, **options):\n train_test_split.__test__ = False\n \n \n-def _build_repr(self):\n-    # XXX This is copied from BaseEstimator's get_params\n-    cls = self.__class__\n-    init = getattr(cls.__init__, 'deprecated_original', cls.__init__)\n-    # Ignore varargs, kw and default values and pop self\n-    init_signature = signature(init)\n-    # Consider the constructor parameters excluding 'self'\n-    if init is object.__init__:\n-        args = []\n-    else:\n-        args = sorted([p.name for p in init_signature.parameters.values()\n-                       if p.name != 'self' and p.kind != p.VAR_KEYWORD])\n-    class_name = self.__class__.__name__\n-    params = dict()\n-    for key in args:\n-        # We need deprecation warnings to always be on in order to\n-        # catch deprecated param values.\n-        # This is set in utils/__init__.py but it gets overwritten\n-        # when running under python3 somehow.\n-        warnings.simplefilter(\"always\", DeprecationWarning)\n-        try:\n-            with warnings.catch_warnings(record=True) as w:\n-                value = getattr(self, key, None)\n-            if len(w) and w[0].category == DeprecationWarning:\n-                # if the parameter is deprecated, don't show it\n-                continue\n-        finally:\n-            warnings.filters.pop(0)\n-        params[key] = value\n-\n-    return '%s(%s)' % (class_name, _pprint(params, offset=len(class_name)))\n+\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator\n+\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n+\n+        y : object\n+            Always ignored, exists for compatibility.\n+\n+        groups : object\n+            Always ignored, exists for compatibility.\n+\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        return self.n_repeats * self.cv.get_n_splits(X, y, groups)\n+\n+    def __repr__(self):\n+        return _build_repr(self)\n",
    "variant_3": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex c49a3ce6a..11dec8f90 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -1063,6 +1063,7 @@ class LeavePGroupsOut(BaseCrossValidator):\n         return super().split(X, y, groups)\n \n \n+\n class _RepeatedSplits(metaclass=ABCMeta):\n     \"\"\"Repeated splits for an arbitrary randomized CV splitter.\n \n@@ -1163,58 +1164,40 @@ class _RepeatedSplits(metaclass=ABCMeta):\n                      **self.cvargs)\n         return cv.get_n_splits(X, y, groups) * self.n_repeats\n \n+    def __repr__(self):\n+        return _pprint(self, {}, changed_only=True)\n \n-class RepeatedKFold(_RepeatedSplits):\n-    \"\"\"Repeated K-Fold cross validator.\n+    def __repr__(self):\n+        return _build_repr(self)\n \n-    Repeats K-Fold n times with different randomization in each repetition.\n \n-    Read more in the :ref:`User Guide <cross_validation>`.\n \n-    Parameters\n-    ----------\n-    n_splits : int, default=5\n-        Number of folds. Must be at least 2.\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator.\n \n-    n_repeats : int, default=10\n-        Number of times cross-validator needs to be repeated.\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n \n-    random_state : int, RandomState instance or None, optional, default=None\n-        If int, random_state is the seed used by the random number generator;\n-        If RandomState instance, random_state is the random number generator;\n-        If None, the random number generator is the RandomState instance used\n-        by `np.random`.\n+        y : object\n+            Always ignored, exists for compatibility.\n \n-    Examples\n-    --------\n-    >>> import numpy as np\n-    >>> from sklearn.model_selection import RepeatedKFold\n-    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n-    >>> y = np.array([0, 0, 1, 1])\n-    >>> rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=2652124)\n-    >>> for train_index, test_index in rkf.split(X):\n-    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n-    ...     X_train, X_test = X[train_index], X[test_index]\n-    ...     y_train, y_test = y[train_index], y[test_index]\n-    ...\n-    TRAIN: [0 1] TEST: [2 3]\n-    TRAIN: [2 3] TEST: [0 1]\n-    TRAIN: [1 2] TEST: [0 3]\n-    TRAIN: [0 3] TEST: [1 2]\n+        groups : object\n+            Always ignored, exists for compatibility.\n \n-    Notes\n-    -----\n-    Randomized CV splitters may return different results for each call of\n-    split. You can make the results identical by setting ``random_state``\n-    to an integer.\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        rng = check_random_state(self.random_state)\n+        cv = self.cv(random_state=rng, shuffle=True,\n+                     **self.cvargs)\n+        return cv.get_n_splits(X, y, groups) * self.n_repeats\n \n-    See also\n-    --------\n-    RepeatedStratifiedKFold: Repeats Stratified K-Fold n times.\n-    \"\"\"\n-    def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n-        super().__init__(\n-            KFold, n_repeats, random_state, n_splits=n_splits)\n+    def __repr__(self):\n+        return _build_repr(self)\n \n \n class RepeatedStratifiedKFold(_RepeatedSplits):\n@@ -2135,34 +2118,27 @@ def train_test_split(*arrays, **options):\n train_test_split.__test__ = False\n \n \n-def _build_repr(self):\n-    # XXX This is copied from BaseEstimator's get_params\n-    cls = self.__class__\n-    init = getattr(cls.__init__, 'deprecated_original', cls.__init__)\n-    # Ignore varargs, kw and default values and pop self\n-    init_signature = signature(init)\n-    # Consider the constructor parameters excluding 'self'\n-    if init is object.__init__:\n-        args = []\n-    else:\n-        args = sorted([p.name for p in init_signature.parameters.values()\n-                       if p.name != 'self' and p.kind != p.VAR_KEYWORD])\n-    class_name = self.__class__.__name__\n-    params = dict()\n-    for key in args:\n-        # We need deprecation warnings to always be on in order to\n-        # catch deprecated param values.\n-        # This is set in utils/__init__.py but it gets overwritten\n-        # when running under python3 somehow.\n-        warnings.simplefilter(\"always\", DeprecationWarning)\n-        try:\n-            with warnings.catch_warnings(record=True) as w:\n-                value = getattr(self, key, None)\n-            if len(w) and w[0].category == DeprecationWarning:\n-                # if the parameter is deprecated, don't show it\n-                continue\n-        finally:\n-            warnings.filters.pop(0)\n-        params[key] = value\n-\n-    return '%s(%s)' % (class_name, _pprint(params, offset=len(class_name)))\n+\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator\n+\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n+\n+        y : object\n+            Always ignored, exists for compatibility.\n+\n+        groups : object\n+            Always ignored, exists for compatibility.\n+\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        return self.n_repeats * self.cv.get_n_splits(X, y, groups)\n+\n+    def __repr__(self):\n+        return _build_repr(self)\n",
    "variant_4": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex c49a3ce6a..8f089f011 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -1063,6 +1063,7 @@ class LeavePGroupsOut(BaseCrossValidator):\n         return super().split(X, y, groups)\n \n \n+\n class _RepeatedSplits(metaclass=ABCMeta):\n     \"\"\"Repeated splits for an arbitrary randomized CV splitter.\n \n@@ -1163,111 +1164,108 @@ class _RepeatedSplits(metaclass=ABCMeta):\n                      **self.cvargs)\n         return cv.get_n_splits(X, y, groups) * self.n_repeats\n \n+    def __repr__(self):\n+        return _pprint(self, {}, self.__class__.__name__)\n \n-class RepeatedKFold(_RepeatedSplits):\n-    \"\"\"Repeated K-Fold cross validator.\n+    def __repr__(self):\n+        return _build_repr(self)\n \n-    Repeats K-Fold n times with different randomization in each repetition.\n \n-    Read more in the :ref:`User Guide <cross_validation>`.\n \n-    Parameters\n-    ----------\n-    n_splits : int, default=5\n-        Number of folds. Must be at least 2.\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator.\n \n-    n_repeats : int, default=10\n-        Number of times cross-validator needs to be repeated.\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n \n-    random_state : int, RandomState instance or None, optional, default=None\n-        If int, random_state is the seed used by the random number generator;\n-        If RandomState instance, random_state is the random number generator;\n-        If None, the random number generator is the RandomState instance used\n-        by `np.random`.\n+        y : object\n+            Always ignored, exists for compatibility.\n \n-    Examples\n-    --------\n-    >>> import numpy as np\n-    >>> from sklearn.model_selection import RepeatedKFold\n-    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n-    >>> y = np.array([0, 0, 1, 1])\n-    >>> rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=2652124)\n-    >>> for train_index, test_index in rkf.split(X):\n-    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n-    ...     X_train, X_test = X[train_index], X[test_index]\n-    ...     y_train, y_test = y[train_index], y[test_index]\n-    ...\n-    TRAIN: [0 1] TEST: [2 3]\n-    TRAIN: [2 3] TEST: [0 1]\n-    TRAIN: [1 2] TEST: [0 3]\n-    TRAIN: [0 3] TEST: [1 2]\n+        groups : object\n+            Always ignored, exists for compatibility.\n \n-    Notes\n-    -----\n-    Randomized CV splitters may return different results for each call of\n-    split. You can make the results identical by setting ``random_state``\n-    to an integer.\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        rng = check_random_state(self.random_state)\n+        cv = self.cv(random_state=rng, shuffle=True,\n+                     **self.cvargs)\n+        return cv.get_n_splits(X, y, groups) * self.n_repeats\n \n-    See also\n-    --------\n-    RepeatedStratifiedKFold: Repeats Stratified K-Fold n times.\n-    \"\"\"\n-    def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n-        super().__init__(\n-            KFold, n_repeats, random_state, n_splits=n_splits)\n+    def __repr__(self):\n+        return _build_repr(self)\n \n \n-class RepeatedStratifiedKFold(_RepeatedSplits):\n-    \"\"\"Repeated Stratified K-Fold cross validator.\n+class _RepeatedSplits(metaclass=ABCMeta):\n+    \"\"\"Base class for repeated cross-validators.\"\"\"\n \n-    Repeats Stratified K-Fold n times with different randomization in each\n-    repetition.\n+    def __init__(self, cv, n_repeats, random_state, **cv_kwargs):\n+        self.cv = cv\n+        self.n_repeats = n_repeats\n+        self.random_state = random_state\n+        self.cv_kwargs = cv_kwargs\n \n-    Read more in the :ref:`User Guide <cross_validation>`.\n+    def split(self, X, y=None, groups=None):\n+        \"\"\"Generates indices to split data into training and test set.\n \n-    Parameters\n-    ----------\n-    n_splits : int, default=5\n-        Number of folds. Must be at least 2.\n+        Parameters\n+        ----------\n+        X : array-like of shape (n_samples, n_features)\n+            Training data, where n_samples is the number of samples\n+            and n_features is the number of features.\n \n-    n_repeats : int, default=10\n-        Number of times cross-validator needs to be repeated.\n+        y : array-like of shape (n_samples,), default=None\n+            The target variable for supervised learning problems.\n \n-    random_state : None, int or RandomState, default=None\n-        Random state to be used to generate random state for each\n-        repetition.\n+        groups : array-like of shape (n_samples,), default=None\n+            Group labels for the samples used while splitting the dataset into\n+            train/test set.\n \n-    Examples\n-    --------\n-    >>> import numpy as np\n-    >>> from sklearn.model_selection import RepeatedStratifiedKFold\n-    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n-    >>> y = np.array([0, 0, 1, 1])\n-    >>> rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=2,\n-    ...     random_state=36851234)\n-    >>> for train_index, test_index in rskf.split(X, y):\n-    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n-    ...     X_train, X_test = X[train_index], X[test_index]\n-    ...     y_train, y_test = y[train_index], y[test_index]\n-    ...\n-    TRAIN: [1 2] TEST: [0 3]\n-    TRAIN: [0 3] TEST: [1 2]\n-    TRAIN: [1 3] TEST: [0 2]\n-    TRAIN: [0 2] TEST: [1 3]\n+        Yields\n+        ------\n+        train : ndarray\n+            The training set indices for that split.\n \n-    Notes\n-    -----\n-    Randomized CV splitters may return different results for each call of\n-    split. You can make the results identical by setting ``random_state``\n-    to an integer.\n+        test : ndarray\n+            The testing set indices for that split.\n+        \"\"\"\n+        n_repeats = self.n_repeats\n+        rng = check_random_state(self.random_state)\n \n-    See also\n-    --------\n-    RepeatedKFold: Repeats K-Fold n times.\n-    \"\"\"\n-    def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n-        super().__init__(\n-            StratifiedKFold, n_repeats, random_state, n_splits=n_splits)\n+        for idx in range(n_repeats):\n+            cv = self.cv(random_state=rng, **self.cv_kwargs)\n+            for train_index, test_index in cv.split(X, y, groups):\n+                yield train_index, test_index\n+\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator.\n+\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n+\n+        y : object\n+            Always ignored, exists for compatibility.\n+\n+        groups : object\n+            Always ignored, exists for compatibility.\n+\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        rng = check_random_state(self.random_state)\n+        cv = self.cv(random_state=rng, **self.cv_kwargs)\n+        return cv.get_n_splits(X, y, groups) * self.n_repeats\n+\n+    def __repr__(self):\n+        return _pprint(self, {})\n \n \n class BaseShuffleSplit(metaclass=ABCMeta):\n@@ -2135,34 +2133,27 @@ def train_test_split(*arrays, **options):\n train_test_split.__test__ = False\n \n \n-def _build_repr(self):\n-    # XXX This is copied from BaseEstimator's get_params\n-    cls = self.__class__\n-    init = getattr(cls.__init__, 'deprecated_original', cls.__init__)\n-    # Ignore varargs, kw and default values and pop self\n-    init_signature = signature(init)\n-    # Consider the constructor parameters excluding 'self'\n-    if init is object.__init__:\n-        args = []\n-    else:\n-        args = sorted([p.name for p in init_signature.parameters.values()\n-                       if p.name != 'self' and p.kind != p.VAR_KEYWORD])\n-    class_name = self.__class__.__name__\n-    params = dict()\n-    for key in args:\n-        # We need deprecation warnings to always be on in order to\n-        # catch deprecated param values.\n-        # This is set in utils/__init__.py but it gets overwritten\n-        # when running under python3 somehow.\n-        warnings.simplefilter(\"always\", DeprecationWarning)\n-        try:\n-            with warnings.catch_warnings(record=True) as w:\n-                value = getattr(self, key, None)\n-            if len(w) and w[0].category == DeprecationWarning:\n-                # if the parameter is deprecated, don't show it\n-                continue\n-        finally:\n-            warnings.filters.pop(0)\n-        params[key] = value\n-\n-    return '%s(%s)' % (class_name, _pprint(params, offset=len(class_name)))\n+\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator.\n+\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n+\n+        y : object\n+            Always ignored, exists for compatibility.\n+\n+        groups : object\n+            Always ignored, exists for compatibility.\n+\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        return self.n_repeats * self.cv.get_n_splits(X, y, groups)\n+\n+    def __repr__(self):\n+        return _build_repr(self)\n",
    "variant_5": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex c49a3ce6a..21d4ea707 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -1063,6 +1063,7 @@ class LeavePGroupsOut(BaseCrossValidator):\n         return super().split(X, y, groups)\n \n \n+\n class _RepeatedSplits(metaclass=ABCMeta):\n     \"\"\"Repeated splits for an arbitrary randomized CV splitter.\n \n@@ -1163,58 +1164,82 @@ class _RepeatedSplits(metaclass=ABCMeta):\n                      **self.cvargs)\n         return cv.get_n_splits(X, y, groups) * self.n_repeats\n \n+    def __repr__(self):\n+        return _pprint(self, {}, changed_only=True)\n \n-class RepeatedKFold(_RepeatedSplits):\n-    \"\"\"Repeated K-Fold cross validator.\n+    def __repr__(self):\n+        return _build_repr(self)\n \n-    Repeats K-Fold n times with different randomization in each repetition.\n \n-    Read more in the :ref:`User Guide <cross_validation>`.\n \n-    Parameters\n-    ----------\n-    n_splits : int, default=5\n-        Number of folds. Must be at least 2.\n+class _RepeatedSplits(metaclass=ABCMeta):\n+    \"\"\"Base class for repeated cross-validators.\"\"\"\n \n-    n_repeats : int, default=10\n-        Number of times cross-validator needs to be repeated.\n+    def __init__(self, cv, n_repeats, random_state, **cvargs):\n+        self.cv = cv\n+        self.n_repeats = n_repeats\n+        self.random_state = random_state\n+        self.cvargs = cvargs\n \n-    random_state : int, RandomState instance or None, optional, default=None\n-        If int, random_state is the seed used by the random number generator;\n-        If RandomState instance, random_state is the random number generator;\n-        If None, the random number generator is the RandomState instance used\n-        by `np.random`.\n+    def split(self, X, y=None, groups=None):\n+        \"\"\"Generates indices to split data into training and test set.\n \n-    Examples\n-    --------\n-    >>> import numpy as np\n-    >>> from sklearn.model_selection import RepeatedKFold\n-    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n-    >>> y = np.array([0, 0, 1, 1])\n-    >>> rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=2652124)\n-    >>> for train_index, test_index in rkf.split(X):\n-    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n-    ...     X_train, X_test = X[train_index], X[test_index]\n-    ...     y_train, y_test = y[train_index], y[test_index]\n-    ...\n-    TRAIN: [0 1] TEST: [2 3]\n-    TRAIN: [2 3] TEST: [0 1]\n-    TRAIN: [1 2] TEST: [0 3]\n-    TRAIN: [0 3] TEST: [1 2]\n+        Parameters\n+        ----------\n+        X : array-like of shape (n_samples, n_features)\n+            Training data, where n_samples is the number of samples\n+            and n_features is the number of features.\n \n-    Notes\n-    -----\n-    Randomized CV splitters may return different results for each call of\n-    split. You can make the results identical by setting ``random_state``\n-    to an integer.\n+        y : array-like of shape (n_samples,), default=None\n+            The target variable for supervised learning problems.\n \n-    See also\n-    --------\n-    RepeatedStratifiedKFold: Repeats Stratified K-Fold n times.\n-    \"\"\"\n-    def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n-        super().__init__(\n-            KFold, n_repeats, random_state, n_splits=n_splits)\n+        groups : array-like of shape (n_samples,), default=None\n+            Group labels for the samples used while splitting the dataset into\n+            train/test set.\n+\n+        Yields\n+        ------\n+        train : ndarray\n+            The training set indices for that split.\n+\n+        test : ndarray\n+            The testing set indices for that split.\n+        \"\"\"\n+        n_repeats = self.n_repeats\n+        rng = check_random_state(self.random_state)\n+\n+        for idx in range(n_repeats):\n+            cv = self.cv(random_state=rng, shuffle=True,\n+                         **self.cvargs)\n+            for train_index, test_index in cv.split(X, y, groups):\n+                yield train_index, test_index\n+\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator.\n+\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n+\n+        y : object\n+            Always ignored, exists for compatibility.\n+\n+        groups : object\n+            Always ignored, exists for compatibility.\n+\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        rng = check_random_state(self.random_state)\n+        cv = self.cv(random_state=rng, shuffle=True,\n+                     **self.cvargs)\n+        return cv.get_n_splits(X, y, groups) * self.n_repeats\n+\n+    def __repr__(self):\n+        return _build_repr(self)\n \n \n class RepeatedStratifiedKFold(_RepeatedSplits):\n@@ -2135,34 +2160,27 @@ def train_test_split(*arrays, **options):\n train_test_split.__test__ = False\n \n \n-def _build_repr(self):\n-    # XXX This is copied from BaseEstimator's get_params\n-    cls = self.__class__\n-    init = getattr(cls.__init__, 'deprecated_original', cls.__init__)\n-    # Ignore varargs, kw and default values and pop self\n-    init_signature = signature(init)\n-    # Consider the constructor parameters excluding 'self'\n-    if init is object.__init__:\n-        args = []\n-    else:\n-        args = sorted([p.name for p in init_signature.parameters.values()\n-                       if p.name != 'self' and p.kind != p.VAR_KEYWORD])\n-    class_name = self.__class__.__name__\n-    params = dict()\n-    for key in args:\n-        # We need deprecation warnings to always be on in order to\n-        # catch deprecated param values.\n-        # This is set in utils/__init__.py but it gets overwritten\n-        # when running under python3 somehow.\n-        warnings.simplefilter(\"always\", DeprecationWarning)\n-        try:\n-            with warnings.catch_warnings(record=True) as w:\n-                value = getattr(self, key, None)\n-            if len(w) and w[0].category == DeprecationWarning:\n-                # if the parameter is deprecated, don't show it\n-                continue\n-        finally:\n-            warnings.filters.pop(0)\n-        params[key] = value\n-\n-    return '%s(%s)' % (class_name, _pprint(params, offset=len(class_name)))\n+\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator.\n+\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n+\n+        y : object\n+            Always ignored, exists for compatibility.\n+\n+        groups : object\n+            Always ignored, exists for compatibility.\n+\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        return self.n_repeats * self.cv.get_n_splits(X, y, groups)\n+\n+    def __repr__(self):\n+        return _build_repr(self)\n",
    "variant_6": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex c49a3ce6a..acb1f2db9 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -1063,6 +1063,7 @@ class LeavePGroupsOut(BaseCrossValidator):\n         return super().split(X, y, groups)\n \n \n+\n class _RepeatedSplits(metaclass=ABCMeta):\n     \"\"\"Repeated splits for an arbitrary randomized CV splitter.\n \n@@ -1163,111 +1164,111 @@ class _RepeatedSplits(metaclass=ABCMeta):\n                      **self.cvargs)\n         return cv.get_n_splits(X, y, groups) * self.n_repeats\n \n+    def __repr__(self):\n+        return _pprint(self, {}, changed_only=True)\n \n-class RepeatedKFold(_RepeatedSplits):\n-    \"\"\"Repeated K-Fold cross validator.\n+    def __repr__(self):\n+        return _build_repr(self)\n \n-    Repeats K-Fold n times with different randomization in each repetition.\n \n-    Read more in the :ref:`User Guide <cross_validation>`.\n \n-    Parameters\n-    ----------\n-    n_splits : int, default=5\n-        Number of folds. Must be at least 2.\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator.\n \n-    n_repeats : int, default=10\n-        Number of times cross-validator needs to be repeated.\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n \n-    random_state : int, RandomState instance or None, optional, default=None\n-        If int, random_state is the seed used by the random number generator;\n-        If RandomState instance, random_state is the random number generator;\n-        If None, the random number generator is the RandomState instance used\n-        by `np.random`.\n+        y : object\n+            Always ignored, exists for compatibility.\n \n-    Examples\n-    --------\n-    >>> import numpy as np\n-    >>> from sklearn.model_selection import RepeatedKFold\n-    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n-    >>> y = np.array([0, 0, 1, 1])\n-    >>> rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=2652124)\n-    >>> for train_index, test_index in rkf.split(X):\n-    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n-    ...     X_train, X_test = X[train_index], X[test_index]\n-    ...     y_train, y_test = y[train_index], y[test_index]\n-    ...\n-    TRAIN: [0 1] TEST: [2 3]\n-    TRAIN: [2 3] TEST: [0 1]\n-    TRAIN: [1 2] TEST: [0 3]\n-    TRAIN: [0 3] TEST: [1 2]\n+        groups : object\n+            Always ignored, exists for compatibility.\n \n-    Notes\n-    -----\n-    Randomized CV splitters may return different results for each call of\n-    split. You can make the results identical by setting ``random_state``\n-    to an integer.\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        rng = check_random_state(self.random_state)\n+        cv = self.cv(random_state=rng, shuffle=True,\n+                     **self.cvargs)\n+        return cv.get_n_splits(X, y, groups) * self.n_repeats\n \n-    See also\n-    --------\n-    RepeatedStratifiedKFold: Repeats Stratified K-Fold n times.\n-    \"\"\"\n-    def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n-        super().__init__(\n-            KFold, n_repeats, random_state, n_splits=n_splits)\n+    def __repr__(self):\n+        return _build_repr(self)\n \n \n-class RepeatedStratifiedKFold(_RepeatedSplits):\n-    \"\"\"Repeated Stratified K-Fold cross validator.\n+class _RepeatedSplits(metaclass=ABCMeta):\n+    \"\"\"Base class for repeated cross-validators.\"\"\"\n \n-    Repeats Stratified K-Fold n times with different randomization in each\n-    repetition.\n+    def __init__(self, cv, n_repeats, random_state, **cv_kwargs):\n+        if not isinstance(n_repeats, numbers.Integral):\n+            raise ValueError(\"n_repeats must be an integer.\")\n+        if n_repeats <= 0:\n+            raise ValueError(\"n_repeats must be a positive integer.\")\n+        self.cv = cv\n+        self.n_repeats = n_repeats\n+        self.random_state = random_state\n+        self.cv_kwargs = cv_kwargs\n \n-    Read more in the :ref:`User Guide <cross_validation>`.\n+    def split(self, X, y=None, groups=None):\n+        \"\"\"Generates indices to split data into training and test set.\n \n-    Parameters\n-    ----------\n-    n_splits : int, default=5\n-        Number of folds. Must be at least 2.\n+        Parameters\n+        ----------\n+        X : array-like of shape (n_samples, n_features)\n+            Training data, where n_samples is the number of samples\n+            and n_features is the number of features.\n \n-    n_repeats : int, default=10\n-        Number of times cross-validator needs to be repeated.\n+        y : array-like of shape (n_samples,), default=None\n+            The target variable for supervised learning problems.\n \n-    random_state : None, int or RandomState, default=None\n-        Random state to be used to generate random state for each\n-        repetition.\n+        groups : array-like of shape (n_samples,), default=None\n+            Group labels for the samples used while splitting the dataset into\n+            train/test set.\n \n-    Examples\n-    --------\n-    >>> import numpy as np\n-    >>> from sklearn.model_selection import RepeatedStratifiedKFold\n-    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n-    >>> y = np.array([0, 0, 1, 1])\n-    >>> rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=2,\n-    ...     random_state=36851234)\n-    >>> for train_index, test_index in rskf.split(X, y):\n-    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n-    ...     X_train, X_test = X[train_index], X[test_index]\n-    ...     y_train, y_test = y[train_index], y[test_index]\n-    ...\n-    TRAIN: [1 2] TEST: [0 3]\n-    TRAIN: [0 3] TEST: [1 2]\n-    TRAIN: [1 3] TEST: [0 2]\n-    TRAIN: [0 2] TEST: [1 3]\n+        Yields\n+        ------\n+        train : ndarray\n+            The training set indices for that split.\n \n-    Notes\n-    -----\n-    Randomized CV splitters may return different results for each call of\n-    split. You can make the results identical by setting ``random_state``\n-    to an integer.\n+        test : ndarray\n+            The testing set indices for that split.\n+        \"\"\"\n+        n_samples = _num_samples(X)\n+        rng = check_random_state(self.random_state)\n+        for idx in range(self.n_repeats):\n+            cv = self.cv(random_state=rng, **self.cv_kwargs)\n+            for train_index, test_index in cv.split(X, y, groups):\n+                yield train_index, test_index\n \n-    See also\n-    --------\n-    RepeatedKFold: Repeats K-Fold n times.\n-    \"\"\"\n-    def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n-        super().__init__(\n-            StratifiedKFold, n_repeats, random_state, n_splits=n_splits)\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator.\n+\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n+\n+        y : object\n+            Always ignored, exists for compatibility.\n+\n+        groups : object\n+            Always ignored, exists for compatibility.\n+\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        rng = check_random_state(self.random_state)\n+        cv = self.cv(random_state=rng, **self.cv_kwargs)\n+        return cv.get_n_splits(X, y, groups) * self.n_repeats\n+\n+    def __repr__(self):\n+        return _build_repr(self)\n \n \n class BaseShuffleSplit(metaclass=ABCMeta):\n@@ -2135,34 +2136,27 @@ def train_test_split(*arrays, **options):\n train_test_split.__test__ = False\n \n \n-def _build_repr(self):\n-    # XXX This is copied from BaseEstimator's get_params\n-    cls = self.__class__\n-    init = getattr(cls.__init__, 'deprecated_original', cls.__init__)\n-    # Ignore varargs, kw and default values and pop self\n-    init_signature = signature(init)\n-    # Consider the constructor parameters excluding 'self'\n-    if init is object.__init__:\n-        args = []\n-    else:\n-        args = sorted([p.name for p in init_signature.parameters.values()\n-                       if p.name != 'self' and p.kind != p.VAR_KEYWORD])\n-    class_name = self.__class__.__name__\n-    params = dict()\n-    for key in args:\n-        # We need deprecation warnings to always be on in order to\n-        # catch deprecated param values.\n-        # This is set in utils/__init__.py but it gets overwritten\n-        # when running under python3 somehow.\n-        warnings.simplefilter(\"always\", DeprecationWarning)\n-        try:\n-            with warnings.catch_warnings(record=True) as w:\n-                value = getattr(self, key, None)\n-            if len(w) and w[0].category == DeprecationWarning:\n-                # if the parameter is deprecated, don't show it\n-                continue\n-        finally:\n-            warnings.filters.pop(0)\n-        params[key] = value\n-\n-    return '%s(%s)' % (class_name, _pprint(params, offset=len(class_name)))\n+\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator.\n+\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n+\n+        y : object\n+            Always ignored, exists for compatibility.\n+\n+        groups : object\n+            Always ignored, exists for compatibility.\n+\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        return self.n_repeats * self.cv.get_n_splits(X, y, groups)\n+\n+    def __repr__(self):\n+        return _build_repr(self)\n",
    "variant_7": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex c49a3ce6a..d364eb872 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -1063,6 +1063,7 @@ class LeavePGroupsOut(BaseCrossValidator):\n         return super().split(X, y, groups)\n \n \n+\n class _RepeatedSplits(metaclass=ABCMeta):\n     \"\"\"Repeated splits for an arbitrary randomized CV splitter.\n \n@@ -1163,111 +1164,150 @@ class _RepeatedSplits(metaclass=ABCMeta):\n                      **self.cvargs)\n         return cv.get_n_splits(X, y, groups) * self.n_repeats\n \n+    def __repr__(self):\n+        return _pprint(self, {}, changed_only=True)\n \n-class RepeatedKFold(_RepeatedSplits):\n-    \"\"\"Repeated K-Fold cross validator.\n+    def __repr__(self):\n+        return _build_repr(self)\n \n-    Repeats K-Fold n times with different randomization in each repetition.\n \n-    Read more in the :ref:`User Guide <cross_validation>`.\n \n-    Parameters\n-    ----------\n-    n_splits : int, default=5\n-        Number of folds. Must be at least 2.\n+class _RepeatedSplits(metaclass=ABCMeta):\n+    \"\"\"Base class for repeated cross-validators.\"\"\"\n \n-    n_repeats : int, default=10\n-        Number of times cross-validator needs to be repeated.\n+    def __init__(self, cv, n_repeats, random_state, **cvargs):\n+        self.cv = cv\n+        self.n_repeats = n_repeats\n+        self.random_state = random_state\n+        self.cvargs = cvargs\n \n-    random_state : int, RandomState instance or None, optional, default=None\n-        If int, random_state is the seed used by the random number generator;\n-        If RandomState instance, random_state is the random number generator;\n-        If None, the random number generator is the RandomState instance used\n-        by `np.random`.\n+    def split(self, X, y=None, groups=None):\n+        \"\"\"Generates indices to split data into training and test set.\n \n-    Examples\n-    --------\n-    >>> import numpy as np\n-    >>> from sklearn.model_selection import RepeatedKFold\n-    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n-    >>> y = np.array([0, 0, 1, 1])\n-    >>> rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=2652124)\n-    >>> for train_index, test_index in rkf.split(X):\n-    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n-    ...     X_train, X_test = X[train_index], X[test_index]\n-    ...     y_train, y_test = y[train_index], y[test_index]\n-    ...\n-    TRAIN: [0 1] TEST: [2 3]\n-    TRAIN: [2 3] TEST: [0 1]\n-    TRAIN: [1 2] TEST: [0 3]\n-    TRAIN: [0 3] TEST: [1 2]\n+        Parameters\n+        ----------\n+        X : array-like of shape (n_samples, n_features)\n+            Training data, where n_samples is the number of samples\n+            and n_features is the number of features.\n \n-    Notes\n-    -----\n-    Randomized CV splitters may return different results for each call of\n-    split. You can make the results identical by setting ``random_state``\n-    to an integer.\n+        y : array-like of shape (n_samples,), default=None\n+            The target variable for supervised learning problems.\n \n-    See also\n-    --------\n-    RepeatedStratifiedKFold: Repeats Stratified K-Fold n times.\n-    \"\"\"\n-    def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n-        super().__init__(\n-            KFold, n_repeats, random_state, n_splits=n_splits)\n+        groups : array-like of shape (n_samples,), default=None\n+            Group labels for the samples used while splitting the dataset into\n+            train/test set.\n \n+        Yields\n+        ------\n+        train : ndarray\n+            The training set indices for that split.\n \n-class RepeatedStratifiedKFold(_RepeatedSplits):\n-    \"\"\"Repeated Stratified K-Fold cross validator.\n+        test : ndarray\n+            The testing set indices for that split.\n+        \"\"\"\n+        n_repeats = self.n_repeats\n+        rng = check_random_state(self.random_state)\n \n-    Repeats Stratified K-Fold n times with different randomization in each\n-    repetition.\n+        for idx in range(n_repeats):\n+            cv = self.cv(random_state=rng, shuffle=True,\n+                         **self.cvargs)\n+            for train_index, test_index in cv.split(X, y, groups):\n+                yield train_index, test_index\n \n-    Read more in the :ref:`User Guide <cross_validation>`.\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator.\n \n-    Parameters\n-    ----------\n-    n_splits : int, default=5\n-        Number of folds. Must be at least 2.\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n \n-    n_repeats : int, default=10\n-        Number of times cross-validator needs to be repeated.\n+        y : object\n+            Always ignored, exists for compatibility.\n \n-    random_state : None, int or RandomState, default=None\n-        Random state to be used to generate random state for each\n-        repetition.\n+        groups : object\n+            Always ignored, exists for compatibility.\n \n-    Examples\n-    --------\n-    >>> import numpy as np\n-    >>> from sklearn.model_selection import RepeatedStratifiedKFold\n-    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n-    >>> y = np.array([0, 0, 1, 1])\n-    >>> rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=2,\n-    ...     random_state=36851234)\n-    >>> for train_index, test_index in rskf.split(X, y):\n-    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n-    ...     X_train, X_test = X[train_index], X[test_index]\n-    ...     y_train, y_test = y[train_index], y[test_index]\n-    ...\n-    TRAIN: [1 2] TEST: [0 3]\n-    TRAIN: [0 3] TEST: [1 2]\n-    TRAIN: [1 3] TEST: [0 2]\n-    TRAIN: [0 2] TEST: [1 3]\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        rng = check_random_state(self.random_state)\n+        cv = self.cv(random_state=rng, shuffle=True,\n+                     **self.cvargs)\n+        return cv.get_n_splits(X, y, groups) * self.n_repeats\n \n-    Notes\n-    -----\n-    Randomized CV splitters may return different results for each call of\n-    split. You can make the results identical by setting ``random_state``\n-    to an integer.\n+    def __repr__(self):\n+        return _build_repr(self)\n \n-    See also\n-    --------\n-    RepeatedKFold: Repeats K-Fold n times.\n-    \"\"\"\n-    def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n-        super().__init__(\n-            StratifiedKFold, n_repeats, random_state, n_splits=n_splits)\n+\n+class _RepeatedSplits(metaclass=ABCMeta):\n+    \"\"\"Base class for repeated cross-validators.\"\"\"\n+\n+    def __init__(self, cv, n_repeats, random_state, **cv_kwargs):\n+        self.cv = cv\n+        self.n_repeats = n_repeats\n+        self.random_state = random_state\n+        self.cv_kwargs = cv_kwargs\n+\n+    def split(self, X, y=None, groups=None):\n+        \"\"\"Generates indices to split data into training and test set.\n+\n+        Parameters\n+        ----------\n+        X : array-like, shape (n_samples, n_features)\n+            Training data, where n_samples is the number of samples\n+            and n_features is the number of features.\n+\n+        y : array-like, shape (n_samples,)\n+            The target variable for supervised learning problems.\n+\n+        groups : array-like, with shape (n_samples,), optional\n+            Group labels for the samples used while splitting the dataset into\n+            train/test set.\n+\n+        Yields\n+        ------\n+        train : ndarray\n+            The training set indices for that split.\n+\n+        test : ndarray\n+            The testing set indices for that split.\n+        \"\"\"\n+        n_repeats = self.n_repeats\n+        rng = check_random_state(self.random_state)\n+\n+        for idx in range(n_repeats):\n+            cv = self.cv(random_state=rng, **self.cv_kwargs)\n+            for train_index, test_index in cv.split(X, y, groups):\n+                yield train_index, test_index\n+\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator\n+\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n+\n+        y : object\n+            Always ignored, exists for compatibility.\n+\n+        groups : object\n+            Always ignored, exists for compatibility.\n+\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        rng = check_random_state(self.random_state)\n+        cv = self.cv(random_state=rng, **self.cv_kwargs)\n+        return cv.get_n_splits(X, y, groups) * self.n_repeats\n+\n+    def __repr__(self):\n+        return _build_repr(self)\n \n \n class BaseShuffleSplit(metaclass=ABCMeta):\n@@ -2135,6 +2175,7 @@ def train_test_split(*arrays, **options):\n train_test_split.__test__ = False\n \n \n+\n def _build_repr(self):\n     # XXX This is copied from BaseEstimator's get_params\n     cls = self.__class__\n",
    "variant_8": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex c49a3ce6a..0bfc9405c 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -1063,6 +1063,7 @@ class LeavePGroupsOut(BaseCrossValidator):\n         return super().split(X, y, groups)\n \n \n+\n class _RepeatedSplits(metaclass=ABCMeta):\n     \"\"\"Repeated splits for an arbitrary randomized CV splitter.\n \n@@ -1163,111 +1164,117 @@ class _RepeatedSplits(metaclass=ABCMeta):\n                      **self.cvargs)\n         return cv.get_n_splits(X, y, groups) * self.n_repeats\n \n+    def __repr__(self):\n+        return _pprint(self, {}, changed_only=True)\n \n-class RepeatedKFold(_RepeatedSplits):\n-    \"\"\"Repeated K-Fold cross validator.\n+    def __repr__(self):\n+        return _build_repr(self)\n \n-    Repeats K-Fold n times with different randomization in each repetition.\n \n-    Read more in the :ref:`User Guide <cross_validation>`.\n \n-    Parameters\n-    ----------\n-    n_splits : int, default=5\n-        Number of folds. Must be at least 2.\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator.\n \n-    n_repeats : int, default=10\n-        Number of times cross-validator needs to be repeated.\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n \n-    random_state : int, RandomState instance or None, optional, default=None\n-        If int, random_state is the seed used by the random number generator;\n-        If RandomState instance, random_state is the random number generator;\n-        If None, the random number generator is the RandomState instance used\n-        by `np.random`.\n+        y : object\n+            Always ignored, exists for compatibility.\n \n-    Examples\n-    --------\n-    >>> import numpy as np\n-    >>> from sklearn.model_selection import RepeatedKFold\n-    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n-    >>> y = np.array([0, 0, 1, 1])\n-    >>> rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=2652124)\n-    >>> for train_index, test_index in rkf.split(X):\n-    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n-    ...     X_train, X_test = X[train_index], X[test_index]\n-    ...     y_train, y_test = y[train_index], y[test_index]\n-    ...\n-    TRAIN: [0 1] TEST: [2 3]\n-    TRAIN: [2 3] TEST: [0 1]\n-    TRAIN: [1 2] TEST: [0 3]\n-    TRAIN: [0 3] TEST: [1 2]\n+        groups : object\n+            Always ignored, exists for compatibility.\n \n-    Notes\n-    -----\n-    Randomized CV splitters may return different results for each call of\n-    split. You can make the results identical by setting ``random_state``\n-    to an integer.\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        rng = check_random_state(self.random_state)\n+        cv = self.cv(random_state=rng, shuffle=True,\n+                     **self.cvargs)\n+        return cv.get_n_splits(X, y, groups) * self.n_repeats\n \n-    See also\n-    --------\n-    RepeatedStratifiedKFold: Repeats Stratified K-Fold n times.\n-    \"\"\"\n-    def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n-        super().__init__(\n-            KFold, n_repeats, random_state, n_splits=n_splits)\n+    def __repr__(self):\n+        return _build_repr(self)\n \n \n-class RepeatedStratifiedKFold(_RepeatedSplits):\n-    \"\"\"Repeated Stratified K-Fold cross validator.\n+class _RepeatedSplits(metaclass=ABCMeta):\n+    \"\"\"Base class for repeated cross-validators.\"\"\"\n \n-    Repeats Stratified K-Fold n times with different randomization in each\n-    repetition.\n+    def __init__(self, cv, n_repeats, random_state, **cv_kwargs):\n+        if not isinstance(n_repeats, numbers.Integral):\n+            raise ValueError(\"n_repeats must be an integer.\")\n+        if n_repeats <= 0:\n+            raise ValueError(\"n_repeats must be a positive integer.\")\n \n-    Read more in the :ref:`User Guide <cross_validation>`.\n+        if isinstance(cv, type):\n+            cv = cv(**cv_kwargs)\n+        else:\n+            for key, value in cv_kwargs.items():\n+                setattr(cv, key, value)\n \n-    Parameters\n-    ----------\n-    n_splits : int, default=5\n-        Number of folds. Must be at least 2.\n+        self.cv = cv\n+        self.n_repeats = n_repeats\n+        self.random_state = random_state\n \n-    n_repeats : int, default=10\n-        Number of times cross-validator needs to be repeated.\n+    def split(self, X, y=None, groups=None):\n+        \"\"\"Generates indices to split data into training and test set.\n \n-    random_state : None, int or RandomState, default=None\n-        Random state to be used to generate random state for each\n-        repetition.\n+        Parameters\n+        ----------\n+        X : array-like, shape (n_samples, n_features)\n+            Training data, where n_samples is the number of samples\n+            and n_features is the number of features.\n \n-    Examples\n-    --------\n-    >>> import numpy as np\n-    >>> from sklearn.model_selection import RepeatedStratifiedKFold\n-    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n-    >>> y = np.array([0, 0, 1, 1])\n-    >>> rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=2,\n-    ...     random_state=36851234)\n-    >>> for train_index, test_index in rskf.split(X, y):\n-    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n-    ...     X_train, X_test = X[train_index], X[test_index]\n-    ...     y_train, y_test = y[train_index], y[test_index]\n-    ...\n-    TRAIN: [1 2] TEST: [0 3]\n-    TRAIN: [0 3] TEST: [1 2]\n-    TRAIN: [1 3] TEST: [0 2]\n-    TRAIN: [0 2] TEST: [1 3]\n+        y : array-like, shape (n_samples,)\n+            The target variable for supervised learning problems.\n \n-    Notes\n-    -----\n-    Randomized CV splitters may return different results for each call of\n-    split. You can make the results identical by setting ``random_state``\n-    to an integer.\n+        groups : array-like, with shape (n_samples,), optional\n+            Group labels for the samples used while splitting the dataset into\n+            train/test set.\n \n-    See also\n-    --------\n-    RepeatedKFold: Repeats K-Fold n times.\n-    \"\"\"\n-    def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n-        super().__init__(\n-            StratifiedKFold, n_repeats, random_state, n_splits=n_splits)\n+        Yields\n+        ------\n+        train : ndarray\n+            The training set indices for that split.\n+\n+        test : ndarray\n+            The testing set indices for that split.\n+        \"\"\"\n+        n_samples = _num_samples(X)\n+        rng = check_random_state(self.random_state)\n+        for idx in range(self.n_repeats):\n+            cv = clone(self.cv)\n+            if hasattr(cv, 'random_state'):\n+                cv.random_state = rng.randint(0, np.iinfo(np.int32).max)\n+            for train_index, test_index in cv.split(X, y, groups):\n+                yield train_index, test_index\n+\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator\n+\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n+\n+        y : object\n+            Always ignored, exists for compatibility.\n+\n+        groups : object\n+            Always ignored, exists for compatibility.\n+\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        return self.cv.get_n_splits(X, y, groups) * self.n_repeats\n+\n+    def __repr__(self):\n+        return _build_repr(self)\n \n \n class BaseShuffleSplit(metaclass=ABCMeta):\n@@ -2135,34 +2142,27 @@ def train_test_split(*arrays, **options):\n train_test_split.__test__ = False\n \n \n-def _build_repr(self):\n-    # XXX This is copied from BaseEstimator's get_params\n-    cls = self.__class__\n-    init = getattr(cls.__init__, 'deprecated_original', cls.__init__)\n-    # Ignore varargs, kw and default values and pop self\n-    init_signature = signature(init)\n-    # Consider the constructor parameters excluding 'self'\n-    if init is object.__init__:\n-        args = []\n-    else:\n-        args = sorted([p.name for p in init_signature.parameters.values()\n-                       if p.name != 'self' and p.kind != p.VAR_KEYWORD])\n-    class_name = self.__class__.__name__\n-    params = dict()\n-    for key in args:\n-        # We need deprecation warnings to always be on in order to\n-        # catch deprecated param values.\n-        # This is set in utils/__init__.py but it gets overwritten\n-        # when running under python3 somehow.\n-        warnings.simplefilter(\"always\", DeprecationWarning)\n-        try:\n-            with warnings.catch_warnings(record=True) as w:\n-                value = getattr(self, key, None)\n-            if len(w) and w[0].category == DeprecationWarning:\n-                # if the parameter is deprecated, don't show it\n-                continue\n-        finally:\n-            warnings.filters.pop(0)\n-        params[key] = value\n-\n-    return '%s(%s)' % (class_name, _pprint(params, offset=len(class_name)))\n+\n+    def get_n_splits(self, X=None, y=None, groups=None):\n+        \"\"\"Returns the number of splitting iterations in the cross-validator\n+\n+        Parameters\n+        ----------\n+        X : object\n+            Always ignored, exists for compatibility.\n+\n+        y : object\n+            Always ignored, exists for compatibility.\n+\n+        groups : object\n+            Always ignored, exists for compatibility.\n+\n+        Returns\n+        -------\n+        n_splits : int\n+            Returns the number of splitting iterations in the cross-validator.\n+        \"\"\"\n+        return self.n_repeats * self.cv.get_n_splits(X, y, groups)\n+\n+    def __repr__(self):\n+        return _build_repr(self)\n"
  }
}