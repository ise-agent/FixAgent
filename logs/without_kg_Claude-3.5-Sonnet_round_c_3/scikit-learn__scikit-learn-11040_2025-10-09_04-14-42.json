{
  "zero_patches": {
    "Location 1 (/root/hy/projects_3/scikit-learn/sklearn/neighbors/base.py lines 106-118)": "\n    @abstractmethod\n    def __init__(self, n_neighbors=None, radius=None,\n                 algorithm='auto', leaf_size=30, metric='minkowski',\n                 p=2, metric_params=None, n_jobs=1):\n\n        self.n_neighbors = n_neighbors\n        self.radius = radius\n        self.algorithm = algorithm\n        self.leaf_size = leaf_size\n        self.metric = metric\n        self.metric_params = metric_params\n        self.p = p\n        self.n_jobs = n_jobs\n        self._check_algorithm_metric()\n        self._check_n_neighbors()\n\n    def _check_n_neighbors(self):\n        if self.n_neighbors is not None:\n            if not isinstance(self.n_neighbors, int):\n                raise ValueError(\"n_neighbors must be a positive integer, \"\n                               \"got %s %r\" % (type(self.n_neighbors).__name__, \n                                             self.n_neighbors))\n            if self.n_neighbors <= 0:\n                raise ValueError(\"n_neighbors must be a positive integer, \"\n                               \"got %d\" % self.n_neighbors)\n",
    "Location 2 (/root/hy/projects_3/scikit-learn/sklearn/neighbors/base.py lines 120-130)": "\n    def _check_algorithm_metric(self):\n        if self.algorithm not in ['auto', 'brute',\n                                  'kd_tree', 'ball_tree']:\n            raise ValueError(\"unrecognized algorithm: '%s'\" % self.algorithm)\n\n        if self.algorithm == 'auto':\n            if self.metric == 'precomputed':\n                alg_check = 'brute'\n            elif (callable(self.metric) or\n                  self.metric in VALID_METRICS['ball_tree']):\n                alg_check = 'ball_tree'\n            else:\n                alg_check = 'brute'\n        else:\n            alg_check = self.algorithm\n\n        if callable(self.metric):\n            if self.algorithm == 'kd_tree':\n                # callable metric is only valid for brute force and ball_tree\n                raise ValueError(\n                    \"kd_tree algorithm does not support callable metric '%s'\"\n                    % self.metric)\n            elif alg_check == 'kd_tree':\n                # callable metric is only valid for brute force and ball_tree\n                raise ValueError(\n                    \"kd_tree algorithm does not support callable metric '%s'\"\n                    % self.metric)\n\n        if self.metric not in VALID_METRICS[alg_check]:\n            raise ValueError(\"Metric '%s' not valid for algorithm '%s'\"\n                             % (self.metric, self.algorithm))\n\n        if self.metric_params is not None and 'p' in self.metric_params:\n            warnings.warn(\"Parameter p is found in metric_params. \"\n                          \"The corresponding parameter from __init__ \"\n                          \"is ignored.\", SyntaxWarning, stacklevel=3)\n            effective_p = self.metric_params['p']\n        else:\n            effective_p = self.p\n\n        if self.metric in ['wminkowski', 'minkowski'] and effective_p < 1:\n            raise ValueError(\"p must be greater than one for minkowski metric\")\n\n    def _check_n_neighbors(self):\n        \"\"\"Validate n_neighbors parameter.\"\"\"\n        if self.n_neighbors is not None:\n            if not isinstance(self.n_neighbors, int):\n                raise ValueError(\"n_neighbors must be a positive integer, got %s %r\"\n                               % (type(self.n_neighbors).__name__, self.n_neighbors))\n            if self.n_neighbors <= 0:\n                raise ValueError(\"n_neighbors must be a positive integer, got %r\"\n                               % self.n_neighbors)\n",
    "Location 3 (/root/hy/projects_3/scikit-learn/sklearn/neighbors/base.py lines 328-340)": "\n        if n_neighbors is None:\n            n_neighbors = self.n_neighbors\n        \n        # Validate n_neighbors parameter\n        if not isinstance(n_neighbors, (int, np.integer)) or n_neighbors <= 0:\n            raise ValueError(\"n_neighbors must be a positive integer, \"\n                           \"got {}: {}\".format(type(n_neighbors).__name__, n_neighbors))\n\n        if X is not None:\n            query_is_train = False\n            X = check_array(X, accept_sparse='csr')\n        else:\n            query_is_train = True\n            X = self._fit_X\n            # Include an extra neighbor to account for the sample itself being\n            # returned, which is removed later\n            n_neighbors += 1\n",
    "Location 4 (/root/hy/projects_3/scikit-learn/sklearn/neighbors/base.py lines 360-365)": "\n            neigh_ind = np.argpartition(dist, int(n_neighbors) - 1, axis=1)\n            neigh_ind = neigh_ind[:, :int(n_neighbors)]\n            # argpartition doesn't guarantee sorted order, so we sort again\n            neigh_ind = neigh_ind[\n"
  },
  "variant_patches": {
    "Location 1 (/root/hy/projects_3/scikit-learn/sklearn/neighbors/base.py lines 106-118)": [
      "\n    @abstractmethod\n    def __init__(self, n_neighbors=None, radius=None,\n                 algorithm='auto', leaf_size=30, metric='minkowski',\n                 p=2, metric_params=None, n_jobs=1):\n\n        self.n_neighbors = n_neighbors\n        self.radius = radius\n        self.algorithm = algorithm\n        self.leaf_size = leaf_size\n        self.metric = metric\n        self.metric_params = metric_params\n        self.p = p\n        self.n_jobs = n_jobs\n        self._check_algorithm_metric()\n        self._check_n_neighbors()\n",
      "\n    @abstractmethod\n    def __init__(self, n_neighbors=None, radius=None,\n                 algorithm='auto', leaf_size=30, metric='minkowski',\n                 p=2, metric_params=None, n_jobs=1):\n\n        self.n_neighbors = n_neighbors\n        self.radius = radius\n        self.algorithm = algorithm\n        self.leaf_size = leaf_size\n        self.metric = metric\n        self.metric_params = metric_params\n        self.p = p\n        self.n_jobs = n_jobs\n        self._check_algorithm_metric()\n        self._check_n_neighbors()\n\n    def _check_n_neighbors(self):\n        if self.n_neighbors is not None:\n            if not isinstance(self.n_neighbors, int) or self.n_neighbors <= 0:\n                if isinstance(self.n_neighbors, float) and self.n_neighbors.is_integer():\n                    raise ValueError(\"n_neighbors must be a positive integer, \"\n                                   \"got float {:.1f}. Please use integer {} instead.\"\n                                   .format(self.n_neighbors, int(self.n_neighbors)))\n                else:\n                    raise ValueError(\"n_neighbors must be a positive integer, \"\n                                   \"got {} {!r}\".format(type(self.n_neighbors).__name__, \n                                                       self.n_neighbors))\n",
      "\n    @abstractmethod\n    def __init__(self, n_neighbors=None, radius=None,\n                 algorithm='auto', leaf_size=30, metric='minkowski',\n                 p=2, metric_params=None, n_jobs=1):\n\n        self.n_neighbors = n_neighbors\n        self.radius = radius\n        self.algorithm = algorithm\n        self.leaf_size = leaf_size\n        self.metric = metric\n        self.metric_params = metric_params\n        self.p = p\n        self.n_jobs = n_jobs\n        self._check_algorithm_metric()\n        self._check_n_neighbors()\n\n    def _check_n_neighbors(self):\n        if self.n_neighbors is not None:\n            if not isinstance(self.n_neighbors, int):\n                raise ValueError(\"n_neighbors must be a positive integer, \"\n                               \"got %s %r\" % (type(self.n_neighbors).__name__, \n                                            self.n_neighbors))\n            if self.n_neighbors <= 0:\n                raise ValueError(\"n_neighbors must be a positive integer, \"\n                               \"got %d\" % self.n_neighbors)\n",
      "\n    @abstractmethod\n    def __init__(self, n_neighbors=None, radius=None,\n                 algorithm='auto', leaf_size=30, metric='minkowski',\n                 p=2, metric_params=None, n_jobs=1):\n\n        self.n_neighbors = n_neighbors\n        self.radius = radius\n        self.algorithm = algorithm\n        self.leaf_size = leaf_size\n        self.metric = metric\n        self.metric_params = metric_params\n        self.p = p\n        self.n_jobs = n_jobs\n        self._check_algorithm_metric()\n        self._check_n_neighbors()\n",
      "\n    @abstractmethod\n    def __init__(self, n_neighbors=None, radius=None,\n                 algorithm='auto', leaf_size=30, metric='minkowski',\n                 p=2, metric_params=None, n_jobs=1):\n\n        self.n_neighbors = n_neighbors\n        self.radius = radius\n        self.algorithm = algorithm\n        self.leaf_size = leaf_size\n        self.metric = metric\n        self.metric_params = metric_params\n        self.p = p\n        self.n_jobs = n_jobs\n        self._check_algorithm_metric()\n        self._check_n_neighbors()\n\n    def _check_n_neighbors(self):\n        if self.n_neighbors is not None:\n            if not isinstance(self.n_neighbors, int) or self.n_neighbors <= 0:\n                raise ValueError(\"n_neighbors must be a positive integer, \"\n                               \"got %s %r\" % (type(self.n_neighbors).__name__, \n                                             self.n_neighbors))\n",
      "\n    @abstractmethod\n    def __init__(self, n_neighbors=None, radius=None,\n                 algorithm='auto', leaf_size=30, metric='minkowski',\n                 p=2, metric_params=None, n_jobs=1):\n\n        self.n_neighbors = n_neighbors\n        self.radius = radius\n        self.algorithm = algorithm\n        self.leaf_size = leaf_size\n        self.metric = metric\n        self.metric_params = metric_params\n        self.p = p\n        self.n_jobs = n_jobs\n        self._check_algorithm_metric()\n        self._check_n_neighbors()\n\n    def _check_n_neighbors(self):\n        if self.n_neighbors is not None:\n            if not isinstance(self.n_neighbors, int) or self.n_neighbors <= 0:\n                raise ValueError(\"n_neighbors must be a positive integer, \"\n                               \"got {} {}\".format(type(self.n_neighbors).__name__, \n                                                self.n_neighbors))\n",
      "\n    @abstractmethod\n    def __init__(self, n_neighbors=None, radius=None,\n                 algorithm='auto', leaf_size=30, metric='minkowski',\n                 p=2, metric_params=None, n_jobs=1):\n\n        self.n_neighbors = n_neighbors\n        self.radius = radius\n        self.algorithm = algorithm\n        self.leaf_size = leaf_size\n        self.metric = metric\n        self.metric_params = metric_params\n        self.p = p\n        self.n_jobs = n_jobs\n        self._check_algorithm_metric()\n        self._check_n_neighbors()\n\n    def _check_n_neighbors(self):\n        if self.n_neighbors is not None:\n            if not isinstance(self.n_neighbors, int) or self.n_neighbors <= 0:\n                raise ValueError(\"n_neighbors must be a positive integer, \"\n                               \"got %s %r\" % (type(self.n_neighbors).__name__, \n                                            self.n_neighbors))\n",
      "\n    @abstractmethod\n    def __init__(self, n_neighbors=None, radius=None,\n                 algorithm='auto', leaf_size=30, metric='minkowski',\n                 p=2, metric_params=None, n_jobs=1):\n\n        self.n_neighbors = n_neighbors\n        self.radius = radius\n        self.algorithm = algorithm\n        self.leaf_size = leaf_size\n        self.metric = metric\n        self.metric_params = metric_params\n        self.p = p\n        self.n_jobs = n_jobs\n        self._check_algorithm_metric()\n        self._check_n_neighbors()\n\n    def _check_n_neighbors(self):\n        if self.n_neighbors is not None:\n            if not isinstance(self.n_neighbors, int) or self.n_neighbors <= 0:\n                raise ValueError(\"n_neighbors must be a positive integer, got %s %r\" \n                               % (type(self.n_neighbors).__name__, self.n_neighbors))\n"
    ],
    "Location 2 (/root/hy/projects_3/scikit-learn/sklearn/neighbors/base.py lines 120-130)": [
      "\n    def _check_algorithm_metric(self):\n        if self.algorithm not in ['auto', 'brute',\n                                  'kd_tree', 'ball_tree']:\n            raise ValueError(\"unrecognized algorithm: '%s'\" % self.algorithm)\n\n        if self.algorithm == 'auto':\n            if self.metric == 'precomputed':\n                alg_check = 'brute'\n            elif (callable(self.metric) or\n                  self.metric in VALID_METRICS['ball_tree']):\n                alg_check = 'ball_tree'\n            else:\n                alg_check = 'brute'\n        else:\n            alg_check = self.algorithm\n\n        if callable(self.metric):\n            if self.algorithm == 'kd_tree':\n                # callable metric is only valid for brute force and ball_tree\n                raise ValueError(\n                    \"kd_tree algorithm does not support callable metric '%s'\"\n                    % self.metric)\n            elif self.algorithm == 'ball_tree':\n                if self.metric not in VALID_METRICS['ball_tree']:\n                    raise ValueError(\n                        \"ball_tree algorithm does not support callable \"\n                        \"metric '%s'\" % self.metric)\n        else:\n            # Check if metric is valid for the chosen algorithm\n            if alg_check not in VALID_METRICS:\n                raise ValueError(\"unrecognized algorithm: '%s'\" % alg_check)\n            if self.metric not in VALID_METRICS[alg_check]:\n                raise ValueError(\"Metric '%s' not valid for algorithm '%s'\" %\n                                 (self.metric, alg_check))\n\n    def _check_n_neighbors(self):\n        \"\"\"Check that n_neighbors is a positive integer.\"\"\"\n        if self.n_neighbors is not None:\n            if not isinstance(self.n_neighbors, int):\n                if isinstance(self.n_neighbors, float) and self.n_neighbors.is_integer():\n                    # Convert float that represents an integer (e.g., 3.0 -> 3)\n                    self.n_neighbors = int(self.n_neighbors)\n                else:\n                    raise ValueError(\"n_neighbors must be a positive integer, \"\n                                   \"got %s %r\" % (type(self.n_neighbors).__name__, \n                                                  self.n_neighbors))\n            if self.n_neighbors <= 0:\n                raise ValueError(\"n_neighbors must be a positive integer, \"\n                               \"got %d\" % self.n_neighbors)\n",
      "\n    def _check_algorithm_metric(self):\n        if self.algorithm not in ['auto', 'brute',\n                                  'kd_tree', 'ball_tree']:\n            raise ValueError(\"unrecognized algorithm: '%s'\" % self.algorithm)\n\n        if self.algorithm == 'auto':\n            if self.metric == 'precomputed':\n                alg_check = 'brute'\n            elif (callable(self.metric) or\n                  self.metric in VALID_METRICS['ball_tree']):\n                alg_check = 'ball_tree'\n            else:\n                alg_check = 'brute'\n        else:\n            alg_check = self.algorithm\n\n        if callable(self.metric):\n            if self.algorithm == 'kd_tree':\n                # callable metric is only valid for brute force and ball_tree\n                raise ValueError(\n                    \"kd_tree algorithm does not support callable metric '%s'\"\n                    % self.metric)\n            elif alg_check == 'kd_tree':\n                # callable metric is only valid for brute force and ball_tree\n                raise ValueError(\n                    \"kd_tree algorithm does not support callable metric '%s'\"\n                    % self.metric)\n\n        if self.metric in VALID_METRICS[alg_check]:\n            return\n\n        if getattr(self, '_fit_method', None) is None:\n            return\n\n        if isinstance(self.metric_params, dict):\n            kwds = self.metric_params.copy()\n        else:\n            kwds = {}\n\n        if self.metric in PAIRWISE_DISTANCE_FUNCTIONS:\n            func = PAIRWISE_DISTANCE_FUNCTIONS[self.metric]\n        elif callable(self.metric):\n            func = self.metric\n        else:\n            raise ValueError(\"Unrecognized metric '%s'\" % self.metric)\n\n        # Check if the metric works with the given metric_params\n        try:\n            func(np.array([[0]]), np.array([[0]]), **kwds)\n        except Exception as e:\n            raise ValueError(\"metric %s with parameters %s is not \"\n                             \"valid for algorithm %s. \"\n                             \"Reason: %s\" % (self.metric,\n                                             self.metric_params,\n                                             alg_check, e))\n\n    def _check_n_neighbors(self):\n        if self.n_neighbors is not None:\n            if not isinstance(self.n_neighbors, int):\n                raise ValueError(\n                    \"n_neighbors must be a positive integer, got %s %r\"\n                    % (type(self.n_neighbors).__name__, self.n_neighbors))\n            if self.n_neighbors <= 0:\n                raise ValueError(\n                    \"n_neighbors must be a positive integer, got %d\"\n                    % self.n_neighbors)\n",
      "\n    def _check_algorithm_metric(self):\n        if self.algorithm not in ['auto', 'brute',\n                                  'kd_tree', 'ball_tree']:\n            raise ValueError(\"unrecognized algorithm: '%s'\" % self.algorithm)\n\n        if self.algorithm == 'auto':\n            if self.metric == 'precomputed':\n                alg_check = 'brute'\n            elif (callable(self.metric) or\n                  self.metric in VALID_METRICS['ball_tree']):\n                alg_check = 'ball_tree'\n            else:\n                alg_check = 'brute'\n        else:\n            alg_check = self.algorithm\n\n        if callable(self.metric):\n            if self.algorithm == 'kd_tree':\n                # callable metric is only valid for brute force and ball_tree\n                raise ValueError(\n                    \"kd_tree algorithm does not support callable metric '%s'\"\n                    % self.metric)\n            elif alg_check not in VALID_METRICS_SPARSE['brute'] \\\n                    and not callable(self.metric):\n                raise ValueError(\"Metric '%s' not valid for algorithm '%s'\"\n                                 % (self.metric, self.algorithm))\n        else:\n            if self.metric not in VALID_METRICS[alg_check]:\n                raise ValueError(\"Metric '%s' not valid for algorithm '%s'\"\n                                 % (self.metric, self.algorithm))\n\n        if self.metric_params is not None and 'p' in self.metric_params:\n            warnings.warn(\"Parameter p is found in metric_params. \"\n                          \"The corresponding parameter from __init__ \"\n                          \"is ignored.\", SyntaxWarning, stacklevel=3)\n            effective_p = self.metric_params['p']\n        else:\n            effective_p = self.p\n\n        if self.metric in ['wminkowski', 'minkowski'] and effective_p < 1:\n            raise ValueError(\"p must be greater than one for minkowski metric\")\n\n    def _check_n_neighbors(self):\n        if self.n_neighbors is not None:\n            if not isinstance(self.n_neighbors, int):\n                raise ValueError(\"n_neighbors must be a positive integer, \"\n                                 \"got %s %r\" % (type(self.n_neighbors).__name__, \n                                                self.n_neighbors))\n            if self.n_neighbors <= 0:\n                raise ValueError(\"n_neighbors must be a positive integer, \"\n                                 \"got %d\" % self.n_neighbors)\n",
      "\n    def _check_algorithm_metric(self):\n        if self.algorithm not in ['auto', 'brute',\n                                  'kd_tree', 'ball_tree']:\n            raise ValueError(\"unrecognized algorithm: '%s'\" % self.algorithm)\n\n        if self.algorithm == 'auto':\n            if self.metric == 'precomputed':\n                alg_check = 'brute'\n            elif (callable(self.metric) or\n                  self.metric in VALID_METRICS['ball_tree']):\n                alg_check = 'ball_tree'\n            else:\n                alg_check = 'brute'\n        else:\n            alg_check = self.algorithm\n\n        if callable(self.metric):\n            if self.algorithm == 'kd_tree':\n                # callable metric is only valid for brute force and ball_tree\n                raise ValueError(\n                    \"kd_tree algorithm does not support callable metric '%s'\"\n                    % self.metric)\n            elif alg_check == 'kd_tree':\n                # callable metric is only valid for brute force and ball_tree\n                raise ValueError(\n                    \"kd_tree algorithm does not support callable metric '%s'\"\n                    % self.metric)\n\n        if self.metric not in VALID_METRICS[alg_check]:\n            raise ValueError(\"Metric '%s' not valid for algorithm '%s'\"\n                             % (self.metric, self.algorithm))\n\n        if self.metric_params is not None and 'p' in self.metric_params:\n            warnings.warn(\"Parameter p is found in metric_params. \"\n                          \"The corresponding parameter from __init__ \"\n                          \"is ignored.\", SyntaxWarning, stacklevel=3)\n\n        if self.metric in ['wminkowski', 'minkowski'] and self.p < 1:\n            raise ValueError(\"p must be greater than one for minkowski metric\")\n\n    def _check_n_neighbors(self):\n        if self.n_neighbors is not None:\n            if not isinstance(self.n_neighbors, int):\n                if isinstance(self.n_neighbors, float) and self.n_neighbors.is_integer():\n                    # Convert float that is actually an integer (e.g., 3.0 -> 3)\n                    self.n_neighbors = int(self.n_neighbors)\n                else:\n                    raise ValueError(\"n_neighbors must be a positive integer, \"\n                                   \"got %s %r\" % (type(self.n_neighbors).__name__, \n                                                 self.n_neighbors))\n            if self.n_neighbors <= 0:\n                raise ValueError(\"n_neighbors must be a positive integer, \"\n                               \"got %d\" % self.n_neighbors)\n",
      "\n    def _check_algorithm_metric(self):\n        if self.algorithm not in ['auto', 'brute',\n                                  'kd_tree', 'ball_tree']:\n            raise ValueError(\"unrecognized algorithm: '%s'\" % self.algorithm)\n\n        if self.algorithm == 'auto':\n            if self.metric == 'precomputed':\n                alg_check = 'brute'\n            elif (callable(self.metric) or\n                  self.metric in VALID_METRICS['ball_tree']):\n                alg_check = 'ball_tree'\n            else:\n                alg_check = 'brute'\n        else:\n            alg_check = self.algorithm\n\n        if callable(self.metric):\n            if self.algorithm == 'kd_tree':\n                # callable metric is only valid for brute force and ball_tree\n                raise ValueError(\n                    \"kd_tree algorithm does not support callable metric '%s'\"\n                    % self.metric)\n            elif alg_check == 'kd_tree':\n                # callable metric is only valid for brute force and ball_tree\n                raise ValueError(\n                    \"kd_tree algorithm does not support callable metric '%s'\"\n                    % self.metric)\n\n        if self.metric not in VALID_METRICS[alg_check]:\n            raise ValueError(\"Metric '%s' not valid for algorithm '%s'\"\n                             % (self.metric, self.algorithm))\n\n        if self.metric_params is not None and 'p' in self.metric_params:\n            warnings.warn(\"Parameter p is found in metric_params. \"\n                          \"The corresponding parameter from __init__ \"\n                          \"is ignored.\", SyntaxWarning, stacklevel=3)\n            effective_p = self.metric_params['p']\n        else:\n            effective_p = self.p\n\n        if self.metric in ['wminkowski', 'minkowski'] and effective_p < 1:\n            raise ValueError(\"p must be greater than one for minkowski metric\")\n\n    def _check_n_neighbors(self):\n        \"\"\"Check that n_neighbors is a valid positive integer.\"\"\"\n        if self.n_neighbors is not None:\n            if not isinstance(self.n_neighbors, (int, np.integer)):\n                raise ValueError(\"n_neighbors must be a positive integer, \"\n                                 \"got %s %r\" % (type(self.n_neighbors).__name__, \n                                                self.n_neighbors))\n            if self.n_neighbors <= 0:\n                raise ValueError(\"n_neighbors must be a positive integer, \"\n                                 \"got %r\" % self.n_neighbors)\n",
      "\n    def _check_algorithm_metric(self):\n        if self.algorithm not in ['auto', 'brute',\n                                  'kd_tree', 'ball_tree']:\n            raise ValueError(\"unrecognized algorithm: '%s'\" % self.algorithm)\n\n        if self.algorithm == 'auto':\n            if self.metric == 'precomputed':\n                alg_check = 'brute'\n            elif (callable(self.metric) or\n                  self.metric in VALID_METRICS['ball_tree']):\n                alg_check = 'ball_tree'\n            else:\n                alg_check = 'brute'\n        else:\n            alg_check = self.algorithm\n\n        if callable(self.metric):\n            if self.algorithm == 'kd_tree':\n                # callable metric is only valid for brute force and ball_tree\n                raise ValueError(\n                    \"kd_tree algorithm does not support callable metric '%s'\"\n                    % self.metric)\n            elif alg_check == 'kd_tree':\n                # callable metric is only valid for brute force and ball_tree\n                raise ValueError(\n                    \"kd_tree algorithm does not support callable metric '%s'\"\n                    % self.metric)\n\n        if self.metric in VALID_METRICS[alg_check]:\n            return\n\n        if callable(self.metric):\n            return\n\n        raise ValueError(\"metric '%s' not valid for algorithm '%s'\"\n                         % (self.metric, self.algorithm))\n\n    def _check_n_neighbors(self):\n        if self.n_neighbors is not None:\n            if not isinstance(self.n_neighbors, int) or isinstance(self.n_neighbors, bool):\n                raise ValueError(\"n_neighbors must be a positive integer, got %s %r\" % \n                               (type(self.n_neighbors).__name__, self.n_neighbors))\n            if self.n_neighbors <= 0:\n                raise ValueError(\"n_neighbors must be a positive integer, got %d\" % \n                               self.n_neighbors)\n",
      "\n    def _check_algorithm_metric(self):\n        if self.algorithm not in ['auto', 'brute',\n                                  'kd_tree', 'ball_tree']:\n            raise ValueError(\"unrecognized algorithm: '%s'\" % self.algorithm)\n\n        if self.algorithm == 'auto':\n            if self.metric == 'precomputed':\n                alg_check = 'brute'\n            elif (callable(self.metric) or\n                  self.metric in VALID_METRICS['ball_tree']):\n                alg_check = 'ball_tree'\n            else:\n                alg_check = 'brute'\n        else:\n            alg_check = self.algorithm\n\n        if callable(self.metric):\n            if self.algorithm == 'kd_tree':\n                # callable metric is only valid for brute force and ball_tree\n                raise ValueError(\n                    \"kd_tree algorithm does not support callable metric '%s'\"\n\n    def _check_n_neighbors(self):\n        if self.n_neighbors is not None:\n            if not isinstance(self.n_neighbors, int) or self.n_neighbors <= 0:\n                raise ValueError(\"n_neighbors must be a positive integer, \"\n                               \"got %s %r\" % (type(self.n_neighbors).__name__, \n                                            self.n_neighbors))\n",
      "\n    def _check_algorithm_metric(self):\n        if self.algorithm not in ['auto', 'brute',\n                                  'kd_tree', 'ball_tree']:\n            raise ValueError(\"unrecognized algorithm: '%s'\" % self.algorithm)\n\n        if self.algorithm == 'auto':\n            if self.metric == 'precomputed':\n                alg_check = 'brute'\n            elif (callable(self.metric) or\n                  self.metric in VALID_METRICS['ball_tree']):\n                alg_check = 'ball_tree'\n            else:\n                alg_check = 'brute'\n        else:\n            alg_check = self.algorithm\n\n        if callable(self.metric):\n            if self.algorithm == 'kd_tree':\n                # callable metric is only valid for brute force and ball_tree\n                raise ValueError(\n                    \"kd_tree algorithm does not support callable metric '%s'\"\n                    % self.metric)\n            if alg_check not in VALID_METRICS_SPARSE[self.metric]:\n                raise ValueError(\"metric '%s' not valid for algorithm '%s'\"\n                                 % (self.metric, self.algorithm))\n        else:\n            if self.metric not in VALID_METRICS[alg_check]:\n                raise ValueError(\"metric '%s' not valid for algorithm '%s'\"\n                                 % (self.metric, self.algorithm))\n\n        if self.metric_params is not None and 'p' in self.metric_params:\n            warnings.warn(\"Parameter p is found in metric_params. \"\n                          \"The corresponding parameter from __init__ \"\n                          \"is ignored.\", SyntaxWarning, stacklevel=3)\n            effective_p = self.metric_params['p']\n        else:\n            effective_p = self.p\n\n        if self.metric in ['wminkowski', 'minkowski'] and effective_p < 1:\n            raise ValueError(\"p must be greater than one for minkowski metric\")\n\n    def _check_n_neighbors(self):\n        \"\"\"Check that n_neighbors is a positive integer.\"\"\"\n        if self.n_neighbors is not None:\n            if not isinstance(self.n_neighbors, int) or isinstance(self.n_neighbors, bool):\n                raise ValueError(\"n_neighbors must be a positive integer, got %s %r\"\n                                 % (type(self.n_neighbors).__name__, self.n_neighbors))\n            if self.n_neighbors <= 0:\n                raise ValueError(\"n_neighbors must be a positive integer, got %d\"\n                                 % self.n_neighbors)\n"
    ],
    "Location 3 (/root/hy/projects_3/scikit-learn/sklearn/neighbors/base.py lines 328-340)": [
      "\n        if n_neighbors is None:\n            n_neighbors = self.n_neighbors\n        \n        # Validate n_neighbors is a positive integer\n        if not isinstance(n_neighbors, (int, np.integer)) or n_neighbors <= 0:\n            raise ValueError(\"n_neighbors must be a positive integer, got %s %r\" % \n                           (type(n_neighbors).__name__, n_neighbors))\n\n        if X is not None:\n            query_is_train = False\n            X = check_array(X, accept_sparse='csr')\n        else:\n            query_is_train = True\n            X = self._fit_X\n            # Include an extra neighbor to account for the sample itself being\n            # returned, which is removed later\n            n_neighbors += 1\n",
      "\n        if n_neighbors is None:\n            n_neighbors = self.n_neighbors\n        \n        # Validate n_neighbors is a positive integer\n        if not isinstance(n_neighbors, (int, np.integer)):\n            raise ValueError(\"n_neighbors must be a positive integer, got {} {}\".format(\n                type(n_neighbors).__name__, n_neighbors))\n        if n_neighbors <= 0:\n            raise ValueError(\"n_neighbors must be a positive integer, got {}\".format(\n                n_neighbors))\n\n        if X is not None:\n            query_is_train = False\n            X = check_array(X, accept_sparse='csr')\n        else:\n            query_is_train = True\n            X = self._fit_X\n            # Include an extra neighbor to account for the sample itself being\n            # returned, which is removed later\n            n_neighbors += 1\n",
      "\n        if n_neighbors is None:\n            n_neighbors = self.n_neighbors\n        \n        # Validate n_neighbors is an integer\n        if not isinstance(n_neighbors, int):\n            raise ValueError(\n                \"n_neighbors must be a positive integer, got %s %r\" %\n                (type(n_neighbors).__name__, n_neighbors)\n            )\n\n        if X is not None:\n            query_is_train = False\n            X = check_array(X, accept_sparse='csr')\n        else:\n            query_is_train = True\n            X = self._fit_X\n            # Include an extra neighbor to account for the sample itself being\n            # returned, which is removed later\n            n_neighbors += 1\n",
      "\n        check_is_fitted(self, \"_fit_method\")\n\n        if n_neighbors is None:\n            n_neighbors = self.n_neighbors\n        \n        # Validate n_neighbors is a positive integer\n        if not isinstance(n_neighbors, (int, np.integer)):\n            raise ValueError(\"n_neighbors must be a positive integer, \"\n                           \"got {}: {}\".format(type(n_neighbors).__name__, n_neighbors))\n        if n_neighbors <= 0:\n            raise ValueError(\"n_neighbors must be a positive integer, \"\n                           \"got {}\".format(n_neighbors))\n\n        if X is not None:\n            query_is_train = False\n            X = check_array(X, accept_sparse='csr')\n        else:\n            query_is_train = True\n            X = self._fit_X\n            # Include an extra neighbor to account for the sample itself being\n            # returned, which is removed later\n            n_neighbors += 1\n",
      "\n        if n_neighbors is None:\n            n_neighbors = self.n_neighbors\n        \n        # Validate n_neighbors is a positive integer\n        if not isinstance(n_neighbors, (int, np.integer)) or n_neighbors <= 0:\n            raise ValueError(\"n_neighbors must be a positive integer, got {} {}\".format(\n                type(n_neighbors).__name__, n_neighbors))\n\n        if X is not None:\n            query_is_train = False\n            X = check_array(X, accept_sparse='csr')\n        else:\n            query_is_train = True\n            X = self._fit_X\n            # Include an extra neighbor to account for the sample itself being\n            # returned, which is removed later\n            n_neighbors += 1\n",
      "\n        if n_neighbors is None:\n            n_neighbors = self.n_neighbors\n        \n        # Validate n_neighbors is a positive integer\n        if not isinstance(n_neighbors, (int, np.integer)) or n_neighbors <= 0:\n            raise ValueError(\n                \"n_neighbors must be a positive integer, got %s %r\" %\n                (type(n_neighbors).__name__, n_neighbors)\n            )\n\n        if X is not None:\n            query_is_train = False\n            X = check_array(X, accept_sparse='csr')\n        else:\n            query_is_train = True\n            X = self._fit_X\n            # Include an extra neighbor to account for the sample itself being\n            # returned, which is removed later\n            n_neighbors += 1\n",
      "\n        if n_neighbors is None:\n            n_neighbors = self.n_neighbors\n        \n        # Validate n_neighbors is a positive integer\n        if not isinstance(n_neighbors, (int, np.integer)) or n_neighbors <= 0:\n            raise ValueError(\n                \"n_neighbors must be a positive integer, got {} {}\".format(\n                    type(n_neighbors).__name__, n_neighbors\n                )\n            )\n\n        if X is not None:\n            query_is_train = False\n            X = check_array(X, accept_sparse='csr')\n        else:\n            query_is_train = True\n            X = self._fit_X\n            # Include an extra neighbor to account for the sample itself being\n            # returned, which is removed later\n            n_neighbors += 1\n",
      "\n        if n_neighbors is None:\n            n_neighbors = self.n_neighbors\n        \n        # Validate n_neighbors is a positive integer\n        if not isinstance(n_neighbors, (int, np.integer)) or n_neighbors <= 0:\n            raise ValueError(\"n_neighbors must be a positive integer, got %s %r\" \n                           % (type(n_neighbors).__name__, n_neighbors))\n\n        if X is not None:\n            query_is_train = False\n            X = check_array(X, accept_sparse='csr')\n        else:\n            query_is_train = True\n            X = self._fit_X\n            # Include an extra neighbor to account for the sample itself being\n            # returned, which is removed later\n            n_neighbors += 1\n"
    ],
    "Location 4 (/root/hy/projects_3/scikit-learn/sklearn/neighbors/base.py lines 360-365)": [
      "\n            neigh_ind = np.argpartition(dist, int(n_neighbors) - 1, axis=1)\n            neigh_ind = neigh_ind[:, :int(n_neighbors)]\n            # argpartition doesn't guarantee sorted order, so we sort again\n            neigh_ind = neigh_ind[\n",
      "\n            neigh_ind = np.argpartition(dist, n_neighbors - 1, axis=1)\n            neigh_ind = neigh_ind[:, :n_neighbors]\n            # argpartition doesn't guarantee sorted order, so we sort again\n            neigh_ind = neigh_ind[\n",
      "\n            neigh_ind = np.argpartition(dist, int(n_neighbors) - 1, axis=1)\n            neigh_ind = neigh_ind[:, :int(n_neighbors)]\n            # argpartition doesn't guarantee sorted order, so we sort again\n            neigh_ind = neigh_ind[\n",
      "\n        n_jobs = _get_n_jobs(self.n_jobs)\n        if self._fit_method == 'brute':\n            # for efficiency, use squared euclidean distances\n            if self.effective_metric_ == 'euclidean':\n                dist = pairwise_distances(X, self._fit_X, 'euclidean',\n                                          n_jobs=n_jobs, squared=True)\n            else:\n                dist = pairwise_distances(\n                    X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n                    **self.effective_metric_params_)\n\n            neigh_ind = np.argpartition(dist, int(n_neighbors) - 1, axis=1)\n            neigh_ind = neigh_ind[:, :int(n_neighbors)]\n            # argpartition doesn't guarantee sorted order, so we sort again\n            neigh_ind = neigh_ind[\n",
      "\n        n_jobs = _get_n_jobs(self.n_jobs)\n        if self._fit_method == 'brute':\n            # for efficiency, use squared euclidean distances\n            if self.effective_metric_ == 'euclidean':\n                dist = pairwise_distances(X, self._fit_X, 'euclidean',\n                                          n_jobs=n_jobs, squared=True)\n            else:\n                dist = pairwise_distances(\n                    X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n                    **self.effective_metric_params_)\n\n            # Validate n_neighbors is an integer before using in numpy operations\n            if not isinstance(n_neighbors, (int, np.integer)):\n                raise ValueError(\"n_neighbors must be a positive integer, \"\n                               \"got {} {}\".format(type(n_neighbors).__name__, \n                                                n_neighbors))\n\n            neigh_ind = np.argpartition(dist, n_neighbors - 1, axis=1)\n            neigh_ind = neigh_ind[:, :n_neighbors]\n            # argpartition doesn't guarantee sorted order, so we sort again\n            neigh_ind = neigh_ind[\n",
      "\n        n_jobs = _get_n_jobs(self.n_jobs)\n        if self._fit_method == 'brute':\n            # for efficiency, use squared euclidean distances\n            if self.effective_metric_ == 'euclidean':\n                dist = pairwise_distances(X, self._fit_X, 'euclidean',\n                                          n_jobs=n_jobs, squared=True)\n            else:\n                dist = pairwise_distances(\n                    X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n                    **self.effective_metric_params_)\n\n            neigh_ind = np.argpartition(dist, int(n_neighbors) - 1, axis=1)\n            neigh_ind = neigh_ind[:, :int(n_neighbors)]\n            # argpartition doesn't guarantee sorted order, so we sort again\n            neigh_ind = neigh_ind[\n",
      "\n            neigh_ind = np.argpartition(dist, int(n_neighbors) - 1, axis=1)\n            neigh_ind = neigh_ind[:, :int(n_neighbors)]\n            # argpartition doesn't guarantee sorted order, so we sort again\n            neigh_ind = neigh_ind[\n",
      "\ndef _check_n_neighbors(self):\n    \"\"\"Check the n_neighbors parameter.\"\"\"\n    if self.n_neighbors is not None:\n        if not isinstance(self.n_neighbors, (int, np.integer)):\n            raise ValueError(\"n_neighbors must be a positive integer, \"\n                           \"got {} {}\".format(type(self.n_neighbors).__name__, \n                                            self.n_neighbors))\n        if self.n_neighbors <= 0:\n            raise ValueError(\"n_neighbors must be a positive integer, \"\n                           \"got {}\".format(self.n_neighbors))\n\ndef _check_algorithm_metric(self):\n    if self.algorithm not in ['auto', 'brute',\n                              'kd_tree', 'ball_tree']:\n        raise ValueError(\"unrecognized algorithm: '%s'\" % self.algorithm)\n\n    if self.algorithm == 'auto':\n        if self.metric == 'precomputed':\n            alg_check = 'brute'\n        elif (self.metric in VALID_METRICS['ball_tree'] and\n              self.metric in VALID_METRICS['kd_tree']):\n            alg_check = 'kd_tree'\n        else:\n            alg_check = 'brute'\n    else:\n        alg_check = self.algorithm\n\n    if callable(self.metric):\n        if self.algorithm == 'kd_tree':\n            # callable metric is only valid for brute force and ball_tree\n            raise ValueError(\n                \"kd_tree algorithm does not support callable metric '%s'\"\n                % self.metric)\n    elif self.metric not in VALID_METRICS[alg_check]:\n        raise ValueError(\"Metric '%s' not valid for algorithm '%s'\"\n                         % (self.metric, self.algorithm))\n\n    if self.metric_params is not None and 'p' in self.metric_params:\n        warnings.warn(\"Parameter p is found in metric_params. \"\n                      \"The corresponding parameter from __init__ \"\n                      \"is ignored.\", SyntaxWarning, stacklevel=3)\n\n    effective_p = self.metric_params.get('p', self.p)\n    if self.metric in ['wminkowski', 'minkowski'] and effective_p < 1:\n        raise ValueError(\"p must be greater than one for minkowski metric\")\n"
    ]
  },
  "combined_diffs": {
    "raw_patch": "diff --git a/sklearn/neighbors/base.py b/sklearn/neighbors/base.py\nindex 3e5e729c2..85bc39b21 100644\n--- a/sklearn/neighbors/base.py\n+++ b/sklearn/neighbors/base.py\n@@ -103,6 +103,7 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n     \"\"\"Base class for nearest neighbors estimators.\"\"\"\n \n     @abstractmethod\n+\n     def __init__(self, n_neighbors=None, radius=None,\n                  algorithm='auto', leaf_size=30, metric='minkowski',\n                  p=2, metric_params=None, n_jobs=1):\n@@ -116,6 +117,8 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n         self.p = p\n         self.n_jobs = n_jobs\n         self._check_algorithm_metric()\n+        self._check_n_neighbors()\n+\n \n     def _check_algorithm_metric(self):\n         if self.algorithm not in ['auto', 'brute',\n@@ -128,6 +131,13 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n             elif (callable(self.metric) or\n                   self.metric in VALID_METRICS['ball_tree']):\n                 alg_check = 'ball_tree'\n+\n+    def _check_n_neighbors(self):\n+        if self.n_neighbors is not None:\n+            if not isinstance(self.n_neighbors, int) or self.n_neighbors <= 0:\n+                raise ValueError(\"n_neighbors must be a positive integer, \"\n+                               \"got %s with value %r\" % \n+                               (type(self.n_neighbors).__name__, self.n_neighbors))\n             else:\n                 alg_check = 'brute'\n         else:\n@@ -325,9 +335,17 @@ class KNeighborsMixin(object):\n         \"\"\"\n         check_is_fitted(self, \"_fit_method\")\n \n+\n         if n_neighbors is None:\n             n_neighbors = self.n_neighbors\n \n+        # Validate n_neighbors parameter\n+        if n_neighbors is not None:\n+            if not isinstance(n_neighbors, int) or n_neighbors <= 0:\n+                raise ValueError(\"n_neighbors must be a positive integer, \"\n+                               \"got %s with value %r\" % \n+                               (type(n_neighbors).__name__, n_neighbors))\n+\n         if X is not None:\n             query_is_train = False\n             X = check_array(X, accept_sparse='csr')\n@@ -337,7 +355,6 @@ class KNeighborsMixin(object):\n             # Include an extra neighbor to account for the sample itself being\n             # returned, which is removed later\n             n_neighbors += 1\n-\n         train_size = self._fit_X.shape[0]\n         if n_neighbors > train_size:\n             raise ValueError(\n@@ -357,6 +374,7 @@ class KNeighborsMixin(object):\n             else:\n                 dist = pairwise_distances(\n                     X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n+\n                     **self.effective_metric_params_)\n \n             neigh_ind = np.argpartition(dist, n_neighbors - 1, axis=1)\n",
    "variant_0": "diff --git a/sklearn/neighbors/base.py b/sklearn/neighbors/base.py\nindex 3e5e729c2..546d23e78 100644\n--- a/sklearn/neighbors/base.py\n+++ b/sklearn/neighbors/base.py\n@@ -102,6 +102,8 @@ def _get_weights(dist, weights):\n class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n     \"\"\"Base class for nearest neighbors estimators.\"\"\"\n \n+    @abstractmethod\n+\n     @abstractmethod\n     def __init__(self, n_neighbors=None, radius=None,\n                  algorithm='auto', leaf_size=30, metric='minkowski',\n@@ -116,6 +118,18 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n         self.p = p\n         self.n_jobs = n_jobs\n         self._check_algorithm_metric()\n+        self._check_n_neighbors()\n+\n+    def _check_n_neighbors(self):\n+        if self.n_neighbors is not None:\n+            if not isinstance(self.n_neighbors, int):\n+                raise ValueError(\"n_neighbors must be a positive integer, \"\n+                               \"got %s %r\" % (type(self.n_neighbors).__name__, \n+                                             self.n_neighbors))\n+            if self.n_neighbors <= 0:\n+                raise ValueError(\"n_neighbors must be a positive integer, \"\n+                               \"got %d\" % self.n_neighbors)\n+\n \n     def _check_algorithm_metric(self):\n         if self.algorithm not in ['auto', 'brute',\n@@ -133,6 +147,47 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n         else:\n             alg_check = self.algorithm\n \n+        if callable(self.metric):\n+            if self.algorithm == 'kd_tree':\n+                # callable metric is only valid for brute force and ball_tree\n+                raise ValueError(\n+                    \"kd_tree algorithm does not support callable metric '%s'\"\n+                    % self.metric)\n+            elif alg_check == 'kd_tree':\n+                # callable metric is only valid for brute force and ball_tree\n+                raise ValueError(\n+                    \"kd_tree algorithm does not support callable metric '%s'\"\n+                    % self.metric)\n+\n+        if self.metric not in VALID_METRICS[alg_check]:\n+            raise ValueError(\"Metric '%s' not valid for algorithm '%s'\"\n+                             % (self.metric, self.algorithm))\n+\n+        if self.metric_params is not None and 'p' in self.metric_params:\n+            warnings.warn(\"Parameter p is found in metric_params. \"\n+                          \"The corresponding parameter from __init__ \"\n+                          \"is ignored.\", SyntaxWarning, stacklevel=3)\n+            effective_p = self.metric_params['p']\n+        else:\n+            effective_p = self.p\n+\n+        if self.metric in ['wminkowski', 'minkowski'] and effective_p < 1:\n+            raise ValueError(\"p must be greater than one for minkowski metric\")\n+\n+    def _check_n_neighbors(self):\n+        \"\"\"Validate n_neighbors parameter.\"\"\"\n+        if self.n_neighbors is not None:\n+            if not isinstance(self.n_neighbors, int):\n+                raise ValueError(\"n_neighbors must be a positive integer, got %s %r\"\n+                               % (type(self.n_neighbors).__name__, self.n_neighbors))\n+            if self.n_neighbors <= 0:\n+                raise ValueError(\"n_neighbors must be a positive integer, got %r\"\n+                               % self.n_neighbors)\n+            else:\n+                alg_check = 'brute'\n+        else:\n+            alg_check = self.algorithm\n+\n         if callable(self.metric):\n             if self.algorithm == 'kd_tree':\n                 # callable metric is only valid for brute force and ball_tree\n@@ -325,8 +380,14 @@ class KNeighborsMixin(object):\n         \"\"\"\n         check_is_fitted(self, \"_fit_method\")\n \n+\n         if n_neighbors is None:\n             n_neighbors = self.n_neighbors\n+        \n+        # Validate n_neighbors parameter\n+        if not isinstance(n_neighbors, (int, np.integer)) or n_neighbors <= 0:\n+            raise ValueError(\"n_neighbors must be a positive integer, \"\n+                           \"got {}: {}\".format(type(n_neighbors).__name__, n_neighbors))\n \n         if X is not None:\n             query_is_train = False\n@@ -337,7 +398,6 @@ class KNeighborsMixin(object):\n             # Include an extra neighbor to account for the sample itself being\n             # returned, which is removed later\n             n_neighbors += 1\n-\n         train_size = self._fit_X.shape[0]\n         if n_neighbors > train_size:\n             raise ValueError(\n@@ -357,10 +417,9 @@ class KNeighborsMixin(object):\n             else:\n                 dist = pairwise_distances(\n                     X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n-                    **self.effective_metric_params_)\n \n-            neigh_ind = np.argpartition(dist, n_neighbors - 1, axis=1)\n-            neigh_ind = neigh_ind[:, :n_neighbors]\n+            neigh_ind = np.argpartition(dist, int(n_neighbors) - 1, axis=1)\n+            neigh_ind = neigh_ind[:, :int(n_neighbors)]\n             # argpartition doesn't guarantee sorted order, so we sort again\n             neigh_ind = neigh_ind[\n                 sample_range, np.argsort(dist[sample_range, neigh_ind])]\n",
    "variant_1": "diff --git a/sklearn/neighbors/base.py b/sklearn/neighbors/base.py\nindex 3e5e729c2..0f8442619 100644\n--- a/sklearn/neighbors/base.py\n+++ b/sklearn/neighbors/base.py\n@@ -102,6 +102,8 @@ def _get_weights(dist, weights):\n class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n     \"\"\"Base class for nearest neighbors estimators.\"\"\"\n \n+    @abstractmethod\n+\n     @abstractmethod\n     def __init__(self, n_neighbors=None, radius=None,\n                  algorithm='auto', leaf_size=30, metric='minkowski',\n@@ -116,6 +118,8 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n         self.p = p\n         self.n_jobs = n_jobs\n         self._check_algorithm_metric()\n+        self._check_n_neighbors()\n+\n \n     def _check_algorithm_metric(self):\n         if self.algorithm not in ['auto', 'brute',\n@@ -133,6 +137,44 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n         else:\n             alg_check = self.algorithm\n \n+        if callable(self.metric):\n+            if self.algorithm == 'kd_tree':\n+                # callable metric is only valid for brute force and ball_tree\n+                raise ValueError(\n+                    \"kd_tree algorithm does not support callable metric '%s'\"\n+                    % self.metric)\n+            elif self.algorithm == 'ball_tree':\n+                if self.metric not in VALID_METRICS['ball_tree']:\n+                    raise ValueError(\n+                        \"ball_tree algorithm does not support callable \"\n+                        \"metric '%s'\" % self.metric)\n+        else:\n+            # Check if metric is valid for the chosen algorithm\n+            if alg_check not in VALID_METRICS:\n+                raise ValueError(\"unrecognized algorithm: '%s'\" % alg_check)\n+            if self.metric not in VALID_METRICS[alg_check]:\n+                raise ValueError(\"Metric '%s' not valid for algorithm '%s'\" %\n+                                 (self.metric, alg_check))\n+\n+    def _check_n_neighbors(self):\n+        \"\"\"Check that n_neighbors is a positive integer.\"\"\"\n+        if self.n_neighbors is not None:\n+            if not isinstance(self.n_neighbors, int):\n+                if isinstance(self.n_neighbors, float) and self.n_neighbors.is_integer():\n+                    # Convert float that represents an integer (e.g., 3.0 -> 3)\n+                    self.n_neighbors = int(self.n_neighbors)\n+                else:\n+                    raise ValueError(\"n_neighbors must be a positive integer, \"\n+                                   \"got %s %r\" % (type(self.n_neighbors).__name__, \n+                                                  self.n_neighbors))\n+            if self.n_neighbors <= 0:\n+                raise ValueError(\"n_neighbors must be a positive integer, \"\n+                               \"got %d\" % self.n_neighbors)\n+            else:\n+                alg_check = 'brute'\n+        else:\n+            alg_check = self.algorithm\n+\n         if callable(self.metric):\n             if self.algorithm == 'kd_tree':\n                 # callable metric is only valid for brute force and ball_tree\n@@ -325,8 +367,14 @@ class KNeighborsMixin(object):\n         \"\"\"\n         check_is_fitted(self, \"_fit_method\")\n \n+\n         if n_neighbors is None:\n             n_neighbors = self.n_neighbors\n+        \n+        # Validate n_neighbors is a positive integer\n+        if not isinstance(n_neighbors, (int, np.integer)) or n_neighbors <= 0:\n+            raise ValueError(\"n_neighbors must be a positive integer, got %s %r\" % \n+                           (type(n_neighbors).__name__, n_neighbors))\n \n         if X is not None:\n             query_is_train = False\n@@ -337,7 +385,6 @@ class KNeighborsMixin(object):\n             # Include an extra neighbor to account for the sample itself being\n             # returned, which is removed later\n             n_neighbors += 1\n-\n         train_size = self._fit_X.shape[0]\n         if n_neighbors > train_size:\n             raise ValueError(\n@@ -357,10 +404,9 @@ class KNeighborsMixin(object):\n             else:\n                 dist = pairwise_distances(\n                     X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n-                    **self.effective_metric_params_)\n \n-            neigh_ind = np.argpartition(dist, n_neighbors - 1, axis=1)\n-            neigh_ind = neigh_ind[:, :n_neighbors]\n+            neigh_ind = np.argpartition(dist, int(n_neighbors) - 1, axis=1)\n+            neigh_ind = neigh_ind[:, :int(n_neighbors)]\n             # argpartition doesn't guarantee sorted order, so we sort again\n             neigh_ind = neigh_ind[\n                 sample_range, np.argsort(dist[sample_range, neigh_ind])]\n",
    "variant_2": "diff --git a/sklearn/neighbors/base.py b/sklearn/neighbors/base.py\nindex 3e5e729c2..a91f883f1 100644\n--- a/sklearn/neighbors/base.py\n+++ b/sklearn/neighbors/base.py\n@@ -102,6 +102,8 @@ def _get_weights(dist, weights):\n class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n     \"\"\"Base class for nearest neighbors estimators.\"\"\"\n \n+    @abstractmethod\n+\n     @abstractmethod\n     def __init__(self, n_neighbors=None, radius=None,\n                  algorithm='auto', leaf_size=30, metric='minkowski',\n@@ -116,6 +118,20 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n         self.p = p\n         self.n_jobs = n_jobs\n         self._check_algorithm_metric()\n+        self._check_n_neighbors()\n+\n+    def _check_n_neighbors(self):\n+        if self.n_neighbors is not None:\n+            if not isinstance(self.n_neighbors, int) or self.n_neighbors <= 0:\n+                if isinstance(self.n_neighbors, float) and self.n_neighbors.is_integer():\n+                    raise ValueError(\"n_neighbors must be a positive integer, \"\n+                                   \"got float {:.1f}. Please use integer {} instead.\"\n+                                   .format(self.n_neighbors, int(self.n_neighbors)))\n+                else:\n+                    raise ValueError(\"n_neighbors must be a positive integer, \"\n+                                   \"got {} {!r}\".format(type(self.n_neighbors).__name__, \n+                                                       self.n_neighbors))\n+\n \n     def _check_algorithm_metric(self):\n         if self.algorithm not in ['auto', 'brute',\n@@ -133,6 +149,61 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n         else:\n             alg_check = self.algorithm\n \n+        if callable(self.metric):\n+            if self.algorithm == 'kd_tree':\n+                # callable metric is only valid for brute force and ball_tree\n+                raise ValueError(\n+                    \"kd_tree algorithm does not support callable metric '%s'\"\n+                    % self.metric)\n+            elif alg_check == 'kd_tree':\n+                # callable metric is only valid for brute force and ball_tree\n+                raise ValueError(\n+                    \"kd_tree algorithm does not support callable metric '%s'\"\n+                    % self.metric)\n+\n+        if self.metric in VALID_METRICS[alg_check]:\n+            return\n+\n+        if getattr(self, '_fit_method', None) is None:\n+            return\n+\n+        if isinstance(self.metric_params, dict):\n+            kwds = self.metric_params.copy()\n+        else:\n+            kwds = {}\n+\n+        if self.metric in PAIRWISE_DISTANCE_FUNCTIONS:\n+            func = PAIRWISE_DISTANCE_FUNCTIONS[self.metric]\n+        elif callable(self.metric):\n+            func = self.metric\n+        else:\n+            raise ValueError(\"Unrecognized metric '%s'\" % self.metric)\n+\n+        # Check if the metric works with the given metric_params\n+        try:\n+            func(np.array([[0]]), np.array([[0]]), **kwds)\n+        except Exception as e:\n+            raise ValueError(\"metric %s with parameters %s is not \"\n+                             \"valid for algorithm %s. \"\n+                             \"Reason: %s\" % (self.metric,\n+                                             self.metric_params,\n+                                             alg_check, e))\n+\n+    def _check_n_neighbors(self):\n+        if self.n_neighbors is not None:\n+            if not isinstance(self.n_neighbors, int):\n+                raise ValueError(\n+                    \"n_neighbors must be a positive integer, got %s %r\"\n+                    % (type(self.n_neighbors).__name__, self.n_neighbors))\n+            if self.n_neighbors <= 0:\n+                raise ValueError(\n+                    \"n_neighbors must be a positive integer, got %d\"\n+                    % self.n_neighbors)\n+            else:\n+                alg_check = 'brute'\n+        else:\n+            alg_check = self.algorithm\n+\n         if callable(self.metric):\n             if self.algorithm == 'kd_tree':\n                 # callable metric is only valid for brute force and ball_tree\n@@ -325,8 +396,17 @@ class KNeighborsMixin(object):\n         \"\"\"\n         check_is_fitted(self, \"_fit_method\")\n \n+\n         if n_neighbors is None:\n             n_neighbors = self.n_neighbors\n+        \n+        # Validate n_neighbors is a positive integer\n+        if not isinstance(n_neighbors, (int, np.integer)):\n+            raise ValueError(\"n_neighbors must be a positive integer, got {} {}\".format(\n+                type(n_neighbors).__name__, n_neighbors))\n+        if n_neighbors <= 0:\n+            raise ValueError(\"n_neighbors must be a positive integer, got {}\".format(\n+                n_neighbors))\n \n         if X is not None:\n             query_is_train = False\n@@ -337,7 +417,6 @@ class KNeighborsMixin(object):\n             # Include an extra neighbor to account for the sample itself being\n             # returned, which is removed later\n             n_neighbors += 1\n-\n         train_size = self._fit_X.shape[0]\n         if n_neighbors > train_size:\n             raise ValueError(\n@@ -357,7 +436,6 @@ class KNeighborsMixin(object):\n             else:\n                 dist = pairwise_distances(\n                     X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n-                    **self.effective_metric_params_)\n \n             neigh_ind = np.argpartition(dist, n_neighbors - 1, axis=1)\n             neigh_ind = neigh_ind[:, :n_neighbors]\n",
    "variant_3": "diff --git a/sklearn/neighbors/base.py b/sklearn/neighbors/base.py\nindex 3e5e729c2..58008dac2 100644\n--- a/sklearn/neighbors/base.py\n+++ b/sklearn/neighbors/base.py\n@@ -102,6 +102,8 @@ def _get_weights(dist, weights):\n class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n     \"\"\"Base class for nearest neighbors estimators.\"\"\"\n \n+    @abstractmethod\n+\n     @abstractmethod\n     def __init__(self, n_neighbors=None, radius=None,\n                  algorithm='auto', leaf_size=30, metric='minkowski',\n@@ -116,6 +118,18 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n         self.p = p\n         self.n_jobs = n_jobs\n         self._check_algorithm_metric()\n+        self._check_n_neighbors()\n+\n+    def _check_n_neighbors(self):\n+        if self.n_neighbors is not None:\n+            if not isinstance(self.n_neighbors, int):\n+                raise ValueError(\"n_neighbors must be a positive integer, \"\n+                               \"got %s %r\" % (type(self.n_neighbors).__name__, \n+                                            self.n_neighbors))\n+            if self.n_neighbors <= 0:\n+                raise ValueError(\"n_neighbors must be a positive integer, \"\n+                               \"got %d\" % self.n_neighbors)\n+\n \n     def _check_algorithm_metric(self):\n         if self.algorithm not in ['auto', 'brute',\n@@ -133,6 +147,46 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n         else:\n             alg_check = self.algorithm\n \n+        if callable(self.metric):\n+            if self.algorithm == 'kd_tree':\n+                # callable metric is only valid for brute force and ball_tree\n+                raise ValueError(\n+                    \"kd_tree algorithm does not support callable metric '%s'\"\n+                    % self.metric)\n+            elif alg_check not in VALID_METRICS_SPARSE['brute'] \\\n+                    and not callable(self.metric):\n+                raise ValueError(\"Metric '%s' not valid for algorithm '%s'\"\n+                                 % (self.metric, self.algorithm))\n+        else:\n+            if self.metric not in VALID_METRICS[alg_check]:\n+                raise ValueError(\"Metric '%s' not valid for algorithm '%s'\"\n+                                 % (self.metric, self.algorithm))\n+\n+        if self.metric_params is not None and 'p' in self.metric_params:\n+            warnings.warn(\"Parameter p is found in metric_params. \"\n+                          \"The corresponding parameter from __init__ \"\n+                          \"is ignored.\", SyntaxWarning, stacklevel=3)\n+            effective_p = self.metric_params['p']\n+        else:\n+            effective_p = self.p\n+\n+        if self.metric in ['wminkowski', 'minkowski'] and effective_p < 1:\n+            raise ValueError(\"p must be greater than one for minkowski metric\")\n+\n+    def _check_n_neighbors(self):\n+        if self.n_neighbors is not None:\n+            if not isinstance(self.n_neighbors, int):\n+                raise ValueError(\"n_neighbors must be a positive integer, \"\n+                                 \"got %s %r\" % (type(self.n_neighbors).__name__, \n+                                                self.n_neighbors))\n+            if self.n_neighbors <= 0:\n+                raise ValueError(\"n_neighbors must be a positive integer, \"\n+                                 \"got %d\" % self.n_neighbors)\n+            else:\n+                alg_check = 'brute'\n+        else:\n+            alg_check = self.algorithm\n+\n         if callable(self.metric):\n             if self.algorithm == 'kd_tree':\n                 # callable metric is only valid for brute force and ball_tree\n@@ -325,8 +379,16 @@ class KNeighborsMixin(object):\n         \"\"\"\n         check_is_fitted(self, \"_fit_method\")\n \n+\n         if n_neighbors is None:\n             n_neighbors = self.n_neighbors\n+        \n+        # Validate n_neighbors is an integer\n+        if not isinstance(n_neighbors, int):\n+            raise ValueError(\n+                \"n_neighbors must be a positive integer, got %s %r\" %\n+                (type(n_neighbors).__name__, n_neighbors)\n+            )\n \n         if X is not None:\n             query_is_train = False\n@@ -337,7 +399,6 @@ class KNeighborsMixin(object):\n             # Include an extra neighbor to account for the sample itself being\n             # returned, which is removed later\n             n_neighbors += 1\n-\n         train_size = self._fit_X.shape[0]\n         if n_neighbors > train_size:\n             raise ValueError(\n@@ -357,10 +418,9 @@ class KNeighborsMixin(object):\n             else:\n                 dist = pairwise_distances(\n                     X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n-                    **self.effective_metric_params_)\n \n-            neigh_ind = np.argpartition(dist, n_neighbors - 1, axis=1)\n-            neigh_ind = neigh_ind[:, :n_neighbors]\n+            neigh_ind = np.argpartition(dist, int(n_neighbors) - 1, axis=1)\n+            neigh_ind = neigh_ind[:, :int(n_neighbors)]\n             # argpartition doesn't guarantee sorted order, so we sort again\n             neigh_ind = neigh_ind[\n                 sample_range, np.argsort(dist[sample_range, neigh_ind])]\n",
    "variant_4": "diff --git a/sklearn/neighbors/base.py b/sklearn/neighbors/base.py\nindex 3e5e729c2..7a603873c 100644\n--- a/sklearn/neighbors/base.py\n+++ b/sklearn/neighbors/base.py\n@@ -102,6 +102,8 @@ def _get_weights(dist, weights):\n class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n     \"\"\"Base class for nearest neighbors estimators.\"\"\"\n \n+    @abstractmethod\n+\n     @abstractmethod\n     def __init__(self, n_neighbors=None, radius=None,\n                  algorithm='auto', leaf_size=30, metric='minkowski',\n@@ -116,6 +118,8 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n         self.p = p\n         self.n_jobs = n_jobs\n         self._check_algorithm_metric()\n+        self._check_n_neighbors()\n+\n \n     def _check_algorithm_metric(self):\n         if self.algorithm not in ['auto', 'brute',\n@@ -133,6 +137,48 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n         else:\n             alg_check = self.algorithm\n \n+        if callable(self.metric):\n+            if self.algorithm == 'kd_tree':\n+                # callable metric is only valid for brute force and ball_tree\n+                raise ValueError(\n+                    \"kd_tree algorithm does not support callable metric '%s'\"\n+                    % self.metric)\n+            elif alg_check == 'kd_tree':\n+                # callable metric is only valid for brute force and ball_tree\n+                raise ValueError(\n+                    \"kd_tree algorithm does not support callable metric '%s'\"\n+                    % self.metric)\n+\n+        if self.metric not in VALID_METRICS[alg_check]:\n+            raise ValueError(\"Metric '%s' not valid for algorithm '%s'\"\n+                             % (self.metric, self.algorithm))\n+\n+        if self.metric_params is not None and 'p' in self.metric_params:\n+            warnings.warn(\"Parameter p is found in metric_params. \"\n+                          \"The corresponding parameter from __init__ \"\n+                          \"is ignored.\", SyntaxWarning, stacklevel=3)\n+\n+        if self.metric in ['wminkowski', 'minkowski'] and self.p < 1:\n+            raise ValueError(\"p must be greater than one for minkowski metric\")\n+\n+    def _check_n_neighbors(self):\n+        if self.n_neighbors is not None:\n+            if not isinstance(self.n_neighbors, int):\n+                if isinstance(self.n_neighbors, float) and self.n_neighbors.is_integer():\n+                    # Convert float that is actually an integer (e.g., 3.0 -> 3)\n+                    self.n_neighbors = int(self.n_neighbors)\n+                else:\n+                    raise ValueError(\"n_neighbors must be a positive integer, \"\n+                                   \"got %s %r\" % (type(self.n_neighbors).__name__, \n+                                                 self.n_neighbors))\n+            if self.n_neighbors <= 0:\n+                raise ValueError(\"n_neighbors must be a positive integer, \"\n+                               \"got %d\" % self.n_neighbors)\n+            else:\n+                alg_check = 'brute'\n+        else:\n+            alg_check = self.algorithm\n+\n         if callable(self.metric):\n             if self.algorithm == 'kd_tree':\n                 # callable metric is only valid for brute force and ball_tree\n@@ -325,8 +371,19 @@ class KNeighborsMixin(object):\n         \"\"\"\n         check_is_fitted(self, \"_fit_method\")\n \n+\n+        check_is_fitted(self, \"_fit_method\")\n+\n         if n_neighbors is None:\n             n_neighbors = self.n_neighbors\n+        \n+        # Validate n_neighbors is a positive integer\n+        if not isinstance(n_neighbors, (int, np.integer)):\n+            raise ValueError(\"n_neighbors must be a positive integer, \"\n+                           \"got {}: {}\".format(type(n_neighbors).__name__, n_neighbors))\n+        if n_neighbors <= 0:\n+            raise ValueError(\"n_neighbors must be a positive integer, \"\n+                           \"got {}\".format(n_neighbors))\n \n         if X is not None:\n             query_is_train = False\n@@ -337,7 +394,6 @@ class KNeighborsMixin(object):\n             # Include an extra neighbor to account for the sample itself being\n             # returned, which is removed later\n             n_neighbors += 1\n-\n         train_size = self._fit_X.shape[0]\n         if n_neighbors > train_size:\n             raise ValueError(\n@@ -348,6 +404,16 @@ class KNeighborsMixin(object):\n         n_samples, _ = X.shape\n         sample_range = np.arange(n_samples)[:, None]\n \n+        n_jobs = _get_n_jobs(self.n_jobs)\n+        if self._fit_method == 'brute':\n+            # for efficiency, use squared euclidean distances\n+            if self.effective_metric_ == 'euclidean':\n+                dist = pairwise_distances(X, self._fit_X, 'euclidean',\n+                                          n_jobs=n_jobs, squared=True)\n+            else:\n+                dist = pairwise_distances(\n+                    X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n+\n         n_jobs = _get_n_jobs(self.n_jobs)\n         if self._fit_method == 'brute':\n             # for efficiency, use squared euclidean distances\n@@ -359,8 +425,8 @@ class KNeighborsMixin(object):\n                     X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n                     **self.effective_metric_params_)\n \n-            neigh_ind = np.argpartition(dist, n_neighbors - 1, axis=1)\n-            neigh_ind = neigh_ind[:, :n_neighbors]\n+            neigh_ind = np.argpartition(dist, int(n_neighbors) - 1, axis=1)\n+            neigh_ind = neigh_ind[:, :int(n_neighbors)]\n             # argpartition doesn't guarantee sorted order, so we sort again\n             neigh_ind = neigh_ind[\n                 sample_range, np.argsort(dist[sample_range, neigh_ind])]\n",
    "variant_5": "diff --git a/sklearn/neighbors/base.py b/sklearn/neighbors/base.py\nindex 3e5e729c2..fddcf58b1 100644\n--- a/sklearn/neighbors/base.py\n+++ b/sklearn/neighbors/base.py\n@@ -102,6 +102,8 @@ def _get_weights(dist, weights):\n class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n     \"\"\"Base class for nearest neighbors estimators.\"\"\"\n \n+    @abstractmethod\n+\n     @abstractmethod\n     def __init__(self, n_neighbors=None, radius=None,\n                  algorithm='auto', leaf_size=30, metric='minkowski',\n@@ -116,6 +118,15 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n         self.p = p\n         self.n_jobs = n_jobs\n         self._check_algorithm_metric()\n+        self._check_n_neighbors()\n+\n+    def _check_n_neighbors(self):\n+        if self.n_neighbors is not None:\n+            if not isinstance(self.n_neighbors, int) or self.n_neighbors <= 0:\n+                raise ValueError(\"n_neighbors must be a positive integer, \"\n+                               \"got %s %r\" % (type(self.n_neighbors).__name__, \n+                                             self.n_neighbors))\n+\n \n     def _check_algorithm_metric(self):\n         if self.algorithm not in ['auto', 'brute',\n@@ -133,6 +144,48 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n         else:\n             alg_check = self.algorithm\n \n+        if callable(self.metric):\n+            if self.algorithm == 'kd_tree':\n+                # callable metric is only valid for brute force and ball_tree\n+                raise ValueError(\n+                    \"kd_tree algorithm does not support callable metric '%s'\"\n+                    % self.metric)\n+            elif alg_check == 'kd_tree':\n+                # callable metric is only valid for brute force and ball_tree\n+                raise ValueError(\n+                    \"kd_tree algorithm does not support callable metric '%s'\"\n+                    % self.metric)\n+\n+        if self.metric not in VALID_METRICS[alg_check]:\n+            raise ValueError(\"Metric '%s' not valid for algorithm '%s'\"\n+                             % (self.metric, self.algorithm))\n+\n+        if self.metric_params is not None and 'p' in self.metric_params:\n+            warnings.warn(\"Parameter p is found in metric_params. \"\n+                          \"The corresponding parameter from __init__ \"\n+                          \"is ignored.\", SyntaxWarning, stacklevel=3)\n+            effective_p = self.metric_params['p']\n+        else:\n+            effective_p = self.p\n+\n+        if self.metric in ['wminkowski', 'minkowski'] and effective_p < 1:\n+            raise ValueError(\"p must be greater than one for minkowski metric\")\n+\n+    def _check_n_neighbors(self):\n+        \"\"\"Check that n_neighbors is a valid positive integer.\"\"\"\n+        if self.n_neighbors is not None:\n+            if not isinstance(self.n_neighbors, (int, np.integer)):\n+                raise ValueError(\"n_neighbors must be a positive integer, \"\n+                                 \"got %s %r\" % (type(self.n_neighbors).__name__, \n+                                                self.n_neighbors))\n+            if self.n_neighbors <= 0:\n+                raise ValueError(\"n_neighbors must be a positive integer, \"\n+                                 \"got %r\" % self.n_neighbors)\n+            else:\n+                alg_check = 'brute'\n+        else:\n+            alg_check = self.algorithm\n+\n         if callable(self.metric):\n             if self.algorithm == 'kd_tree':\n                 # callable metric is only valid for brute force and ball_tree\n@@ -325,8 +378,14 @@ class KNeighborsMixin(object):\n         \"\"\"\n         check_is_fitted(self, \"_fit_method\")\n \n+\n         if n_neighbors is None:\n             n_neighbors = self.n_neighbors\n+        \n+        # Validate n_neighbors is a positive integer\n+        if not isinstance(n_neighbors, (int, np.integer)) or n_neighbors <= 0:\n+            raise ValueError(\"n_neighbors must be a positive integer, got {} {}\".format(\n+                type(n_neighbors).__name__, n_neighbors))\n \n         if X is not None:\n             query_is_train = False\n@@ -337,7 +396,6 @@ class KNeighborsMixin(object):\n             # Include an extra neighbor to account for the sample itself being\n             # returned, which is removed later\n             n_neighbors += 1\n-\n         train_size = self._fit_X.shape[0]\n         if n_neighbors > train_size:\n             raise ValueError(\n@@ -348,6 +406,16 @@ class KNeighborsMixin(object):\n         n_samples, _ = X.shape\n         sample_range = np.arange(n_samples)[:, None]\n \n+        n_jobs = _get_n_jobs(self.n_jobs)\n+        if self._fit_method == 'brute':\n+            # for efficiency, use squared euclidean distances\n+            if self.effective_metric_ == 'euclidean':\n+                dist = pairwise_distances(X, self._fit_X, 'euclidean',\n+                                          n_jobs=n_jobs, squared=True)\n+            else:\n+                dist = pairwise_distances(\n+                    X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n+\n         n_jobs = _get_n_jobs(self.n_jobs)\n         if self._fit_method == 'brute':\n             # for efficiency, use squared euclidean distances\n@@ -359,6 +427,12 @@ class KNeighborsMixin(object):\n                     X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n                     **self.effective_metric_params_)\n \n+            # Validate n_neighbors is an integer before using in numpy operations\n+            if not isinstance(n_neighbors, (int, np.integer)):\n+                raise ValueError(\"n_neighbors must be a positive integer, \"\n+                               \"got {} {}\".format(type(n_neighbors).__name__, \n+                                                n_neighbors))\n+\n             neigh_ind = np.argpartition(dist, n_neighbors - 1, axis=1)\n             neigh_ind = neigh_ind[:, :n_neighbors]\n             # argpartition doesn't guarantee sorted order, so we sort again\n",
    "variant_6": "diff --git a/sklearn/neighbors/base.py b/sklearn/neighbors/base.py\nindex 3e5e729c2..6ffe45761 100644\n--- a/sklearn/neighbors/base.py\n+++ b/sklearn/neighbors/base.py\n@@ -102,6 +102,8 @@ def _get_weights(dist, weights):\n class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n     \"\"\"Base class for nearest neighbors estimators.\"\"\"\n \n+    @abstractmethod\n+\n     @abstractmethod\n     def __init__(self, n_neighbors=None, radius=None,\n                  algorithm='auto', leaf_size=30, metric='minkowski',\n@@ -116,6 +118,15 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n         self.p = p\n         self.n_jobs = n_jobs\n         self._check_algorithm_metric()\n+        self._check_n_neighbors()\n+\n+    def _check_n_neighbors(self):\n+        if self.n_neighbors is not None:\n+            if not isinstance(self.n_neighbors, int) or self.n_neighbors <= 0:\n+                raise ValueError(\"n_neighbors must be a positive integer, \"\n+                               \"got {} {}\".format(type(self.n_neighbors).__name__, \n+                                                self.n_neighbors))\n+\n \n     def _check_algorithm_metric(self):\n         if self.algorithm not in ['auto', 'brute',\n@@ -133,6 +144,40 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n         else:\n             alg_check = self.algorithm\n \n+        if callable(self.metric):\n+            if self.algorithm == 'kd_tree':\n+                # callable metric is only valid for brute force and ball_tree\n+                raise ValueError(\n+                    \"kd_tree algorithm does not support callable metric '%s'\"\n+                    % self.metric)\n+            elif alg_check == 'kd_tree':\n+                # callable metric is only valid for brute force and ball_tree\n+                raise ValueError(\n+                    \"kd_tree algorithm does not support callable metric '%s'\"\n+                    % self.metric)\n+\n+        if self.metric in VALID_METRICS[alg_check]:\n+            return\n+\n+        if callable(self.metric):\n+            return\n+\n+        raise ValueError(\"metric '%s' not valid for algorithm '%s'\"\n+                         % (self.metric, self.algorithm))\n+\n+    def _check_n_neighbors(self):\n+        if self.n_neighbors is not None:\n+            if not isinstance(self.n_neighbors, int) or isinstance(self.n_neighbors, bool):\n+                raise ValueError(\"n_neighbors must be a positive integer, got %s %r\" % \n+                               (type(self.n_neighbors).__name__, self.n_neighbors))\n+            if self.n_neighbors <= 0:\n+                raise ValueError(\"n_neighbors must be a positive integer, got %d\" % \n+                               self.n_neighbors)\n+            else:\n+                alg_check = 'brute'\n+        else:\n+            alg_check = self.algorithm\n+\n         if callable(self.metric):\n             if self.algorithm == 'kd_tree':\n                 # callable metric is only valid for brute force and ball_tree\n@@ -325,8 +370,16 @@ class KNeighborsMixin(object):\n         \"\"\"\n         check_is_fitted(self, \"_fit_method\")\n \n+\n         if n_neighbors is None:\n             n_neighbors = self.n_neighbors\n+        \n+        # Validate n_neighbors is a positive integer\n+        if not isinstance(n_neighbors, (int, np.integer)) or n_neighbors <= 0:\n+            raise ValueError(\n+                \"n_neighbors must be a positive integer, got %s %r\" %\n+                (type(n_neighbors).__name__, n_neighbors)\n+            )\n \n         if X is not None:\n             query_is_train = False\n@@ -337,7 +390,6 @@ class KNeighborsMixin(object):\n             # Include an extra neighbor to account for the sample itself being\n             # returned, which is removed later\n             n_neighbors += 1\n-\n         train_size = self._fit_X.shape[0]\n         if n_neighbors > train_size:\n             raise ValueError(\n@@ -348,6 +400,16 @@ class KNeighborsMixin(object):\n         n_samples, _ = X.shape\n         sample_range = np.arange(n_samples)[:, None]\n \n+        n_jobs = _get_n_jobs(self.n_jobs)\n+        if self._fit_method == 'brute':\n+            # for efficiency, use squared euclidean distances\n+            if self.effective_metric_ == 'euclidean':\n+                dist = pairwise_distances(X, self._fit_X, 'euclidean',\n+                                          n_jobs=n_jobs, squared=True)\n+            else:\n+                dist = pairwise_distances(\n+                    X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n+\n         n_jobs = _get_n_jobs(self.n_jobs)\n         if self._fit_method == 'brute':\n             # for efficiency, use squared euclidean distances\n@@ -359,8 +421,8 @@ class KNeighborsMixin(object):\n                     X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n                     **self.effective_metric_params_)\n \n-            neigh_ind = np.argpartition(dist, n_neighbors - 1, axis=1)\n-            neigh_ind = neigh_ind[:, :n_neighbors]\n+            neigh_ind = np.argpartition(dist, int(n_neighbors) - 1, axis=1)\n+            neigh_ind = neigh_ind[:, :int(n_neighbors)]\n             # argpartition doesn't guarantee sorted order, so we sort again\n             neigh_ind = neigh_ind[\n                 sample_range, np.argsort(dist[sample_range, neigh_ind])]\n",
    "variant_7": "diff --git a/sklearn/neighbors/base.py b/sklearn/neighbors/base.py\nindex 3e5e729c2..2f6602cbd 100644\n--- a/sklearn/neighbors/base.py\n+++ b/sklearn/neighbors/base.py\n@@ -102,6 +102,8 @@ def _get_weights(dist, weights):\n class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n     \"\"\"Base class for nearest neighbors estimators.\"\"\"\n \n+    @abstractmethod\n+\n     @abstractmethod\n     def __init__(self, n_neighbors=None, radius=None,\n                  algorithm='auto', leaf_size=30, metric='minkowski',\n@@ -116,6 +118,15 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n         self.p = p\n         self.n_jobs = n_jobs\n         self._check_algorithm_metric()\n+        self._check_n_neighbors()\n+\n+    def _check_n_neighbors(self):\n+        if self.n_neighbors is not None:\n+            if not isinstance(self.n_neighbors, int) or self.n_neighbors <= 0:\n+                raise ValueError(\"n_neighbors must be a positive integer, \"\n+                               \"got %s %r\" % (type(self.n_neighbors).__name__, \n+                                            self.n_neighbors))\n+\n \n     def _check_algorithm_metric(self):\n         if self.algorithm not in ['auto', 'brute',\n@@ -133,6 +144,23 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n         else:\n             alg_check = self.algorithm\n \n+        if callable(self.metric):\n+            if self.algorithm == 'kd_tree':\n+                # callable metric is only valid for brute force and ball_tree\n+                raise ValueError(\n+                    \"kd_tree algorithm does not support callable metric '%s'\"\n+\n+    def _check_n_neighbors(self):\n+        if self.n_neighbors is not None:\n+            if not isinstance(self.n_neighbors, int) or self.n_neighbors <= 0:\n+                raise ValueError(\"n_neighbors must be a positive integer, \"\n+                               \"got %s %r\" % (type(self.n_neighbors).__name__, \n+                                            self.n_neighbors))\n+            else:\n+                alg_check = 'brute'\n+        else:\n+            alg_check = self.algorithm\n+\n         if callable(self.metric):\n             if self.algorithm == 'kd_tree':\n                 # callable metric is only valid for brute force and ball_tree\n@@ -325,8 +353,17 @@ class KNeighborsMixin(object):\n         \"\"\"\n         check_is_fitted(self, \"_fit_method\")\n \n+\n         if n_neighbors is None:\n             n_neighbors = self.n_neighbors\n+        \n+        # Validate n_neighbors is a positive integer\n+        if not isinstance(n_neighbors, (int, np.integer)) or n_neighbors <= 0:\n+            raise ValueError(\n+                \"n_neighbors must be a positive integer, got {} {}\".format(\n+                    type(n_neighbors).__name__, n_neighbors\n+                )\n+            )\n \n         if X is not None:\n             query_is_train = False\n@@ -337,7 +374,6 @@ class KNeighborsMixin(object):\n             # Include an extra neighbor to account for the sample itself being\n             # returned, which is removed later\n             n_neighbors += 1\n-\n         train_size = self._fit_X.shape[0]\n         if n_neighbors > train_size:\n             raise ValueError(\n@@ -357,10 +393,9 @@ class KNeighborsMixin(object):\n             else:\n                 dist = pairwise_distances(\n                     X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n-                    **self.effective_metric_params_)\n \n-            neigh_ind = np.argpartition(dist, n_neighbors - 1, axis=1)\n-            neigh_ind = neigh_ind[:, :n_neighbors]\n+            neigh_ind = np.argpartition(dist, int(n_neighbors) - 1, axis=1)\n+            neigh_ind = neigh_ind[:, :int(n_neighbors)]\n             # argpartition doesn't guarantee sorted order, so we sort again\n             neigh_ind = neigh_ind[\n                 sample_range, np.argsort(dist[sample_range, neigh_ind])]\n",
    "variant_8": "diff --git a/sklearn/neighbors/base.py b/sklearn/neighbors/base.py\nindex 3e5e729c2..f0d4d6f41 100644\n--- a/sklearn/neighbors/base.py\n+++ b/sklearn/neighbors/base.py\n@@ -102,6 +102,8 @@ def _get_weights(dist, weights):\n class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n     \"\"\"Base class for nearest neighbors estimators.\"\"\"\n \n+    @abstractmethod\n+\n     @abstractmethod\n     def __init__(self, n_neighbors=None, radius=None,\n                  algorithm='auto', leaf_size=30, metric='minkowski',\n@@ -116,6 +118,14 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n         self.p = p\n         self.n_jobs = n_jobs\n         self._check_algorithm_metric()\n+        self._check_n_neighbors()\n+\n+    def _check_n_neighbors(self):\n+        if self.n_neighbors is not None:\n+            if not isinstance(self.n_neighbors, int) or self.n_neighbors <= 0:\n+                raise ValueError(\"n_neighbors must be a positive integer, got %s %r\" \n+                               % (type(self.n_neighbors).__name__, self.n_neighbors))\n+\n \n     def _check_algorithm_metric(self):\n         if self.algorithm not in ['auto', 'brute',\n@@ -133,6 +143,45 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n         else:\n             alg_check = self.algorithm\n \n+        if callable(self.metric):\n+            if self.algorithm == 'kd_tree':\n+                # callable metric is only valid for brute force and ball_tree\n+                raise ValueError(\n+                    \"kd_tree algorithm does not support callable metric '%s'\"\n+                    % self.metric)\n+            if alg_check not in VALID_METRICS_SPARSE[self.metric]:\n+                raise ValueError(\"metric '%s' not valid for algorithm '%s'\"\n+                                 % (self.metric, self.algorithm))\n+        else:\n+            if self.metric not in VALID_METRICS[alg_check]:\n+                raise ValueError(\"metric '%s' not valid for algorithm '%s'\"\n+                                 % (self.metric, self.algorithm))\n+\n+        if self.metric_params is not None and 'p' in self.metric_params:\n+            warnings.warn(\"Parameter p is found in metric_params. \"\n+                          \"The corresponding parameter from __init__ \"\n+                          \"is ignored.\", SyntaxWarning, stacklevel=3)\n+            effective_p = self.metric_params['p']\n+        else:\n+            effective_p = self.p\n+\n+        if self.metric in ['wminkowski', 'minkowski'] and effective_p < 1:\n+            raise ValueError(\"p must be greater than one for minkowski metric\")\n+\n+    def _check_n_neighbors(self):\n+        \"\"\"Check that n_neighbors is a positive integer.\"\"\"\n+        if self.n_neighbors is not None:\n+            if not isinstance(self.n_neighbors, int) or isinstance(self.n_neighbors, bool):\n+                raise ValueError(\"n_neighbors must be a positive integer, got %s %r\"\n+                                 % (type(self.n_neighbors).__name__, self.n_neighbors))\n+            if self.n_neighbors <= 0:\n+                raise ValueError(\"n_neighbors must be a positive integer, got %d\"\n+                                 % self.n_neighbors)\n+            else:\n+                alg_check = 'brute'\n+        else:\n+            alg_check = self.algorithm\n+\n         if callable(self.metric):\n             if self.algorithm == 'kd_tree':\n                 # callable metric is only valid for brute force and ball_tree\n@@ -325,8 +374,14 @@ class KNeighborsMixin(object):\n         \"\"\"\n         check_is_fitted(self, \"_fit_method\")\n \n+\n         if n_neighbors is None:\n             n_neighbors = self.n_neighbors\n+        \n+        # Validate n_neighbors is a positive integer\n+        if not isinstance(n_neighbors, (int, np.integer)) or n_neighbors <= 0:\n+            raise ValueError(\"n_neighbors must be a positive integer, got %s %r\" \n+                           % (type(n_neighbors).__name__, n_neighbors))\n \n         if X is not None:\n             query_is_train = False\n@@ -337,7 +392,6 @@ class KNeighborsMixin(object):\n             # Include an extra neighbor to account for the sample itself being\n             # returned, which is removed later\n             n_neighbors += 1\n-\n         train_size = self._fit_X.shape[0]\n         if n_neighbors > train_size:\n             raise ValueError(\n@@ -357,12 +411,52 @@ class KNeighborsMixin(object):\n             else:\n                 dist = pairwise_distances(\n                     X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n-                    **self.effective_metric_params_)\n \n-            neigh_ind = np.argpartition(dist, n_neighbors - 1, axis=1)\n-            neigh_ind = neigh_ind[:, :n_neighbors]\n-            # argpartition doesn't guarantee sorted order, so we sort again\n-            neigh_ind = neigh_ind[\n+def _check_n_neighbors(self):\n+    \"\"\"Check the n_neighbors parameter.\"\"\"\n+    if self.n_neighbors is not None:\n+        if not isinstance(self.n_neighbors, (int, np.integer)):\n+            raise ValueError(\"n_neighbors must be a positive integer, \"\n+                           \"got {} {}\".format(type(self.n_neighbors).__name__, \n+                                            self.n_neighbors))\n+        if self.n_neighbors <= 0:\n+            raise ValueError(\"n_neighbors must be a positive integer, \"\n+                           \"got {}\".format(self.n_neighbors))\n+\n+def _check_algorithm_metric(self):\n+    if self.algorithm not in ['auto', 'brute',\n+                              'kd_tree', 'ball_tree']:\n+        raise ValueError(\"unrecognized algorithm: '%s'\" % self.algorithm)\n+\n+    if self.algorithm == 'auto':\n+        if self.metric == 'precomputed':\n+            alg_check = 'brute'\n+        elif (self.metric in VALID_METRICS['ball_tree'] and\n+              self.metric in VALID_METRICS['kd_tree']):\n+            alg_check = 'kd_tree'\n+        else:\n+            alg_check = 'brute'\n+    else:\n+        alg_check = self.algorithm\n+\n+    if callable(self.metric):\n+        if self.algorithm == 'kd_tree':\n+            # callable metric is only valid for brute force and ball_tree\n+            raise ValueError(\n+                \"kd_tree algorithm does not support callable metric '%s'\"\n+                % self.metric)\n+    elif self.metric not in VALID_METRICS[alg_check]:\n+        raise ValueError(\"Metric '%s' not valid for algorithm '%s'\"\n+                         % (self.metric, self.algorithm))\n+\n+    if self.metric_params is not None and 'p' in self.metric_params:\n+        warnings.warn(\"Parameter p is found in metric_params. \"\n+                      \"The corresponding parameter from __init__ \"\n+                      \"is ignored.\", SyntaxWarning, stacklevel=3)\n+\n+    effective_p = self.metric_params.get('p', self.p)\n+    if self.metric in ['wminkowski', 'minkowski'] and effective_p < 1:\n+        raise ValueError(\"p must be greater than one for minkowski metric\")\n                 sample_range, np.argsort(dist[sample_range, neigh_ind])]\n \n             if return_distance:\n"
  }
}