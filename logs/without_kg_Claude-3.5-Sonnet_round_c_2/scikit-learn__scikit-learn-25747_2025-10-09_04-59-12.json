{
  "zero_patches": {
    "Location 1 (/root/hy/projects_2/scikit-learn/sklearn/utils/_set_output.py lines 55-60)": "\n    if isinstance(data_to_wrap, pd.DataFrame):\n        if columns is not None:\n            data_to_wrap.columns = columns\n        if index is not None:\n            # Check if index length matches data length to avoid ValueError\n            if len(index) == len(data_to_wrap):\n                data_to_wrap.index = index\n            # If lengths don't match, keep the existing index (don't assign)\n        return data_to_wrap\n",
    "Location 2 (/root/hy/projects_2/scikit-learn/sklearn/utils/_set_output.py lines 127-134)": "\ndef _wrap_data_with_container(\n    method, data_to_wrap, original_input, estimator, *, index=None\n):\n    \"\"\"Wrap output with container based on an estimator's or global config.\n\n    Parameters\n    ----------\n    method : {\"transform\"}\n        Estimator's method to get container output for.\n\n    data_to_wrap : {ndarray, dataframe}\n        Data to wrap with container.\n\n    original_input : {ndarray, dataframe}\n        Original input of function.\n\n    estimator : estimator instance\n        Estimator with to get the output configuration from.\n\n    index : array-like, default=None\n        Index for output data. Only used when `data_to_wrap` has 1 or 2\n        dimensions. If `None`, then the index of `original_input` is used.\n\n    Returns\n    -------\n    output : {ndarray, dataframe}\n        If the output config is \"default\" or the estimator is not configured\n        for wrapping return `data_to_wrap` unchanged.\n        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n        DataFrame.\n    \"\"\"\n    output_config = _get_output_config(method, estimator)\n\n    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n        return data_to_wrap\n\n    # dense_config == \"pandas\"\n    # Check if dimensions changed (e.g., due to aggregation) and reset index if needed\n    original_index = getattr(original_input, \"index\", None)\n    if (original_index is not None and \n        hasattr(data_to_wrap, 'shape') and \n        len(data_to_wrap.shape) >= 1 and \n        len(original_index) != data_to_wrap.shape[0]):\n        original_index = None\n    \n    return _wrap_in_pandas_container(\n        data_to_wrap=data_to_wrap,\n        index=original_index,\n        columns=estimator.get_feature_names_out,\n    )\n",
    "Location 3 (/root/hy/projects_2/scikit-learn/sklearn/utils/_set_output.py lines 141-150)": "\ndef _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        \n        # Check if data dimensions changed (e.g., due to aggregation)\n        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape'):\n            if isinstance(data_to_wrap, tuple):\n                # For tuple outputs, check the first element\n                input_rows = X.shape[0] if len(X.shape) > 0 else 0\n                output_rows = data_to_wrap[0].shape[0] if len(data_to_wrap[0].shape) > 0 else 0\n            else:\n                input_rows = X.shape[0] if len(X.shape) > 0 else 0\n                output_rows = data_to_wrap.shape[0] if len(data_to_wrap.shape) > 0 else 0\n            \n            # If dimensions changed, we can't preserve the original index\n            if input_rows != output_rows:\n                # Create a copy of X without index for wrapping\n                X_for_wrapping = X\n                if hasattr(X, 'index'):\n                    import pandas as pd\n                    if isinstance(X, pd.DataFrame):\n                        X_for_wrapping = X.reset_index(drop=True)\n                    elif isinstance(X, pd.Series):\n                        X_for_wrapping = X.reset_index(drop=True)\n        else:\n            X_for_wrapping = X\n        \n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            return (\n                _wrap_data_with_container(method, data_to_wrap[0], X_for_wrapping, self),\n                *data_to_wrap[1:],\n            )\n\n        return _wrap_data_with_container(method, data_to_wrap, X_for_wrapping, self)\n",
    "Location 4 (/root/hy/projects_2/scikit-learn/sklearn/pipeline.py lines 1279-1289)": "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            # Reset index for each DataFrame to avoid conflicts during concatenation\n            # This handles cases where transformers change the number of rows (e.g., aggregation)\n            Xs_reset = [X.reset_index(drop=True) for X in Xs]\n            return pd.concat(Xs_reset, axis=1)\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n            Xs = np.hstack(Xs)\n        return Xs\n"
  },
  "variant_patches": {
    "Location 1 (/root/hy/projects_2/scikit-learn/sklearn/utils/_set_output.py lines 55-60)": [
      "\n    if isinstance(data_to_wrap, pd.DataFrame):\n        if columns is not None:\n            data_to_wrap.columns = columns\n        if index is not None:\n            # Check if index length matches data length to avoid ValueError\n            if len(index) == len(data_to_wrap):\n                data_to_wrap.index = index\n            # If lengths don't match, keep the existing index or reset to default\n        return data_to_wrap\n",
      "\n    if isinstance(data_to_wrap, pd.DataFrame):\n        if columns is not None:\n            data_to_wrap.columns = columns\n        if index is not None:\n            # Check if index length matches data length to avoid ValueError\n            if len(index) == len(data_to_wrap):\n                data_to_wrap.index = index\n            # If lengths don't match, keep the existing index (don't assign)\n        return data_to_wrap\n",
      "\n    if isinstance(data_to_wrap, pd.DataFrame):\n        if columns is not None:\n            data_to_wrap.columns = columns\n        if index is not None:\n            # Check if index length matches data length to avoid ValueError\n            if len(index) == len(data_to_wrap):\n                data_to_wrap.index = index\n            # If lengths don't match, keep the existing index (don't assign)\n        return data_to_wrap\n",
      "\n    if isinstance(data_to_wrap, pd.DataFrame):\n        if columns is not None:\n            data_to_wrap.columns = columns\n        if index is not None:\n            # Check if index length matches data length to avoid ValueError\n            if len(index) == len(data_to_wrap):\n                data_to_wrap.index = index\n            # If lengths don't match, keep the existing index or reset to default\n        return data_to_wrap\n",
      "\n    if isinstance(data_to_wrap, pd.DataFrame):\n        if columns is not None:\n            data_to_wrap.columns = columns\n        if index is not None:\n            # Check if index length matches data length to avoid ValueError\n            if len(index) == len(data_to_wrap):\n                data_to_wrap.index = index\n            # If lengths don't match, keep the original index or reset it\n        return data_to_wrap\n",
      "\n    if isinstance(data_to_wrap, pd.DataFrame):\n        if columns is not None:\n            data_to_wrap.columns = columns\n        if index is not None:\n            # Check if index length matches data length to avoid ValueError\n            if len(index) == len(data_to_wrap):\n                data_to_wrap.index = index\n            # If lengths don't match, keep the existing index (don't assign)\n        return data_to_wrap\n",
      "\n    if isinstance(data_to_wrap, pd.DataFrame):\n        if columns is not None:\n            data_to_wrap.columns = columns\n        if index is not None:\n            # Check if index length matches data length to avoid ValueError\n            if len(index) == len(data_to_wrap):\n                data_to_wrap.index = index\n            # If lengths don't match, keep the existing index or reset to default\n        return data_to_wrap\n",
      "\n    if isinstance(data_to_wrap, pd.DataFrame):\n        if columns is not None:\n            data_to_wrap.columns = columns\n        if index is not None:\n            # Check if index length matches DataFrame length to avoid ValueError\n            if len(index) == len(data_to_wrap):\n                data_to_wrap.index = index\n            # If lengths don't match (e.g., due to aggregation), keep original index\n        return data_to_wrap\n"
    ],
    "Location 2 (/root/hy/projects_2/scikit-learn/sklearn/utils/_set_output.py lines 127-134)": [
      "\ndef _wrap_data_with_container(\n    method, data_to_wrap, original_input, estimator, *, index=None\n):\n    \"\"\"Wrap output with container based on an estimator's or global config.\n\n    Parameters\n    ----------\n    method : {\"transform\"}\n        Estimator's method to get container output for.\n\n    data_to_wrap : {ndarray, dataframe}\n        Data to wrap with container.\n\n    original_input : {ndarray, dataframe}\n        Original input of function.\n\n    estimator : estimator instance\n        Estimator with to get the output configuration from.\n\n    index : array-like, default=None\n        Index for output.\n\n    Returns\n    -------\n    output : {ndarray, dataframe}\n        If the output config is \"default\" or the estimator is not configured\n        for wrapping return `data_to_wrap` unchanged.\n        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n        DataFrame.\n    \"\"\"\n    output_config = _get_output_config(method, estimator)\n\n    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n        return data_to_wrap\n\n    # dense_config == \"pandas\"\n    # Check if dimensions changed (e.g., due to aggregation)\n    original_index = getattr(original_input, \"index\", None)\n    if original_index is not None and hasattr(data_to_wrap, 'shape') and len(original_index) != data_to_wrap.shape[0]:\n        original_index = None\n    \n    return _wrap_in_pandas_container(\n        data_to_wrap=data_to_wrap,\n        index=original_index,\n        columns=estimator.get_feature_names_out,\n    )\n",
      "\ndef _wrap_data_with_container(\n    method, data_to_wrap, original_input, estimator, *, index=None\n):\n    \"\"\"Wrap output with container based on an estimator's or global config.\n\n    Parameters\n    ----------\n    method : {\"transform\"}\n        Estimator's method to get container output for.\n\n    data_to_wrap : {ndarray, dataframe}\n        Data to wrap with container.\n\n    original_input : {ndarray, dataframe}\n        Original input of function.\n\n    estimator : estimator instance\n        Estimator with to get the output configuration from.\n\n    index : array-like, default=None\n        Index for data_to_wrap. If None and output config is \"pandas\",\n        then `original_input.index` is used.\n\n    Returns\n    -------\n    output : {ndarray, dataframe}\n        If the output config is \"default\" or the estimator is not configured\n        for wrapping return `data_to_wrap` unchanged.\n        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n        DataFrame.\n    \"\"\"\n    output_config = _get_output_config(method, estimator)\n\n    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n        return data_to_wrap\n\n    # dense_config == \"pandas\"\n    # Check if dimensions match between input and output\n    original_index = getattr(original_input, \"index\", None)\n    if original_index is not None and hasattr(data_to_wrap, 'shape') and len(data_to_wrap.shape) > 0:\n        if len(original_index) != data_to_wrap.shape[0]:\n            # Dimensions don't match, likely due to aggregation - don't preserve index\n            original_index = None\n    \n    return _wrap_in_pandas_container(\n        data_to_wrap=data_to_wrap,\n        index=original_index,\n        columns=estimator.get_feature_names_out,\n    )\n",
      "\ndef _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n    \"\"\"Wrap output with container based on an estimator's or global config.\n\n    Parameters\n    ----------\n    method : {\"transform\"}\n        Estimator's method to get container output for.\n\n    data_to_wrap : {ndarray, dataframe}\n        Data to wrap with container.\n\n    original_input : {ndarray, dataframe}\n        Original input of function.\n\n    estimator : estimator instance\n        Estimator with to get the output configuration from.\n\n    Returns\n    -------\n    output : {ndarray, dataframe}\n        If the output config is \"default\" or the estimator is not configured\n        for wrapping return `data_to_wrap` unchanged.\n        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n        DataFrame.\n    \"\"\"\n    output_config = _get_output_config(method, estimator)\n\n    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n        return data_to_wrap\n\n    # dense_config == \"pandas\"\n    original_index = getattr(original_input, \"index\", None)\n    # Check if dimensions match to handle aggregation transformers\n    if original_index is not None and len(original_index) != data_to_wrap.shape[0]:\n        original_index = None\n    \n    return _wrap_in_pandas_container(\n        data_to_wrap=data_to_wrap,\n        index=original_index,\n        columns=estimator.get_feature_names_out,\n    )\n",
      "\ndef _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n    \"\"\"Wrap output with container based on an estimator's or global config.\n\n    Parameters\n    ----------\n    method : {\"transform\"}\n        Estimator's method to get container output for.\n\n    data_to_wrap : {ndarray, dataframe}\n        Data to wrap with container.\n\n    original_input : {ndarray, dataframe}\n        Original input of function.\n\n    estimator : estimator instance\n        Estimator with to get the output configuration from.\n\n    Returns\n    -------\n    output : {ndarray, dataframe}\n        If the output config is \"default\" or the estimator is not configured\n        for wrapping return `data_to_wrap` unchanged.\n        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n        DataFrame.\n    \"\"\"\n    output_config = _get_output_config(method, estimator)\n\n    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n        return data_to_wrap\n\n    # dense_config == \"pandas\"\n    # Check if dimensions match to handle aggregation cases\n    original_index = getattr(original_input, \"index\", None)\n    if original_index is not None and hasattr(data_to_wrap, 'shape') and len(original_index) != data_to_wrap.shape[0]:\n        # Dimensions don't match, likely due to aggregation - don't preserve index\n        original_index = None\n    \n    return _wrap_in_pandas_container(\n        data_to_wrap=data_to_wrap,\n        index=original_index,\n        columns=estimator.get_feature_names_out,\n    )\n",
      "\ndef _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n    \"\"\"Wrap output with container based on an estimator's or global config.\n\n    Parameters\n    ----------\n    method : {\"transform\"}\n        Estimator's method to get container output for.\n\n    data_to_wrap : {ndarray, dataframe}\n        Data to wrap with container.\n\n    original_input : {ndarray, dataframe}\n        Original input of function.\n\n    estimator : estimator instance\n        Estimator with to get the output configuration from.\n\n    Returns\n    -------\n    output : {ndarray, dataframe}\n        If the output config is \"default\" or the estimator is not configured\n        for wrapping return `data_to_wrap` unchanged.\n        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n        DataFrame.\n    \"\"\"\n    output_config = _get_output_config(method, estimator)\n\n    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n        return data_to_wrap\n\n    # dense_config == \"pandas\"\n    # Check if dimensions match before preserving index\n    original_index = getattr(original_input, \"index\", None)\n    if original_index is not None and hasattr(data_to_wrap, 'shape') and len(original_index) != data_to_wrap.shape[0]:\n        # Dimensions don't match (e.g., due to aggregation), don't preserve index\n        original_index = None\n    \n    return _wrap_in_pandas_container(\n        data_to_wrap=data_to_wrap,\n        index=original_index,\n        columns=estimator.get_feature_names_out,\n    )\n",
      "\ndef _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n    \"\"\"Wrap output with container based on an estimator's or global config.\n\n    Parameters\n    ----------\n    method : {\"transform\"}\n        Estimator's method to get container output for.\n\n    data_to_wrap : {ndarray, dataframe}\n        Data to wrap with container.\n\n    original_input : {ndarray, dataframe}\n        Original input of function.\n\n    estimator : estimator instance\n        Estimator with to get the output configuration from.\n\n    Returns\n    -------\n    output : {ndarray, dataframe}\n        If the output config is \"default\" or the estimator is not configured\n        for wrapping return `data_to_wrap` unchanged.\n        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n        DataFrame.\n    \"\"\"\n    output_config = _get_output_config(method, estimator)\n\n    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n        return data_to_wrap\n\n    # dense_config == \"pandas\"\n    # Check if dimensions changed (e.g., aggregation occurred)\n    original_index = getattr(original_input, \"index\", None)\n    if original_index is not None and hasattr(data_to_wrap, '__len__'):\n        if len(original_index) != len(data_to_wrap):\n            original_index = None\n    \n    return _wrap_in_pandas_container(\n        data_to_wrap=data_to_wrap,\n        index=original_index,\n        columns=estimator.get_feature_names_out,\n    )\n",
      "\ndef _wrap_data_with_container(\n    method, data_to_wrap, original_input, estimator, *, index=None\n):\n    \"\"\"Wrap output with container based on an estimator's or global config.\n\n    Parameters\n    ----------\n    method : {\"transform\"}\n        Estimator's method to get container output for.\n\n    data_to_wrap : {ndarray, dataframe}\n        Data to wrap with container.\n\n    original_input : {ndarray, dataframe}\n        Original input of function.\n\n    estimator : estimator instance\n        Estimator with to get the output configuration from.\n\n    index : array-like, default=None\n        Index for output.\n\n    Returns\n    -------\n    output : {ndarray, dataframe}\n        If the output config is \"default\" or the estimator is not configured\n        for wrapping return `data_to_wrap` unchanged.\n        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n        DataFrame.\n    \"\"\"\n    output_config = _get_output_config(method, estimator)\n\n    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n        return data_to_wrap\n\n    # dense_config == \"pandas\"\n    # Check if dimensions match to handle aggregation transformers\n    original_index = getattr(original_input, \"index\", None)\n    if original_index is not None and hasattr(data_to_wrap, 'shape') and len(original_index) != data_to_wrap.shape[0]:\n        original_index = None\n    \n    return _wrap_in_pandas_container(\n        data_to_wrap=data_to_wrap,\n        index=original_index,\n        columns=estimator.get_feature_names_out,\n    )\n",
      "\ndef _wrap_data_with_container(\n    method, data_to_wrap, original_input, estimator, *, index=None\n):\n    \"\"\"Wrap output with container based on an estimator's or global config.\n\n    Parameters\n    ----------\n    method : {\"transform\"}\n        Estimator's method to get container output for.\n\n    data_to_wrap : {ndarray, dataframe}\n        Data to wrap with container.\n\n    original_input : {ndarray, dataframe}\n        Original input of function.\n\n    estimator : estimator instance\n        Estimator with to get the output configuration from.\n\n    index : array-like, default=None\n        Index for output data. If `None`, then the index of `original_input`\n        is used.\n\n    Returns\n    -------\n    output : {ndarray, dataframe}\n        If the output config is \"default\" or the estimator is not configured\n        for wrapping return `data_to_wrap` unchanged.\n        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n        DataFrame.\n    \"\"\"\n    output_config = _get_output_config(method, estimator)\n\n    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n        return data_to_wrap\n\n    # dense_config == \"pandas\"\n    # Check if data dimensions match original input for index compatibility\n    original_index = getattr(original_input, \"index\", None)\n    if (original_index is not None and \n        hasattr(data_to_wrap, 'shape') and \n        len(original_index) != data_to_wrap.shape[0]):\n        # Data has been aggregated/transformed to different dimensions\n        # Don't preserve original index to avoid length mismatch\n        original_index = None\n    \n    return _wrap_in_pandas_container(\n        data_to_wrap=data_to_wrap,\n        index=original_index,\n        columns=estimator.get_feature_names_out,\n    )\n"
    ],
    "Location 3 (/root/hy/projects_2/scikit-learn/sklearn/utils/_set_output.py lines 141-150)": [
      "\ndef _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        \n        # Check if data dimensions changed (e.g., due to aggregation)\n        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape'):\n            if isinstance(data_to_wrap, tuple):\n                # For tuple outputs, check the first element\n                if data_to_wrap[0].shape[0] != X.shape[0]:\n                    # Dimensions changed, use None as X to reset index\n                    return (\n                        _wrap_data_with_container(method, data_to_wrap[0], None, self),\n                        *data_to_wrap[1:],\n                    )\n            elif data_to_wrap.shape[0] != X.shape[0]:\n                # Dimensions changed, use None as X to reset index\n                return _wrap_data_with_container(method, data_to_wrap, None, self)\n        \n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            return (\n                _wrap_data_with_container(method, data_to_wrap[0], X, self),\n                *data_to_wrap[1:],\n            )\n\n        return _wrap_data_with_container(method, data_to_wrap, X, self)\n",
      "\ndef _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        \n        # Check if data dimensions changed (e.g., due to aggregation)\n        def _has_compatible_dimensions(original, transformed):\n            if hasattr(original, 'shape') and hasattr(transformed, 'shape'):\n                return original.shape[0] == transformed.shape[0]\n            return True\n        \n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            if _has_compatible_dimensions(X, data_to_wrap[0]):\n                return (\n                    _wrap_data_with_container(method, data_to_wrap[0], X, self),\n                    *data_to_wrap[1:],\n                )\n            else:\n                # Reset input reference for incompatible dimensions\n                return (\n                    _wrap_data_with_container(method, data_to_wrap[0], None, self),\n                    *data_to_wrap[1:],\n                )\n\n        if _has_compatible_dimensions(X, data_to_wrap):\n            return _wrap_data_with_container(method, data_to_wrap, X, self)\n        else:\n            # Reset input reference for incompatible dimensions\n            return _wrap_data_with_container(method, data_to_wrap, None, self)\n",
      "\ndef _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            # Check if dimensions are compatible before wrapping\n            if hasattr(X, 'shape') and hasattr(data_to_wrap[0], 'shape'):\n                if len(data_to_wrap[0].shape) > 0 and len(X.shape) > 0:\n                    if data_to_wrap[0].shape[0] != X.shape[0]:\n                        # Dimensions changed, likely due to aggregation\n                        return data_to_wrap\n            return (\n                _wrap_data_with_container(method, data_to_wrap[0], X, self),\n                *data_to_wrap[1:],\n            )\n\n        # Check if dimensions are compatible before wrapping\n        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape'):\n            if len(data_to_wrap.shape) > 0 and len(X.shape) > 0:\n                if data_to_wrap.shape[0] != X.shape[0]:\n                    # Dimensions changed, likely due to aggregation\n                    return data_to_wrap\n\n        return _wrap_data_with_container(method, data_to_wrap, X, self)\n",
      "\ndef _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        \n        # Check if data dimensions changed (indicating aggregation/filtering)\n        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape'):\n            if isinstance(data_to_wrap, tuple):\n                # For tuple output, check the first element\n                if data_to_wrap[0].shape[0] != X.shape[0]:\n                    # Dimensions changed, avoid using original index\n                    return (\n                        _wrap_data_with_container(method, data_to_wrap[0], None, self),\n                        *data_to_wrap[1:],\n                    )\n            elif data_to_wrap.shape[0] != X.shape[0]:\n                # Dimensions changed, avoid using original index\n                return _wrap_data_with_container(method, data_to_wrap, None, self)\n        \n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            return (\n                _wrap_data_with_container(method, data_to_wrap[0], X, self),\n                *data_to_wrap[1:],\n            )\n\n        return _wrap_data_with_container(method, data_to_wrap, X, self)\n\n    return wrapped\n",
      "\ndef _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        \n        # Check if input has pandas index and validate dimensions for output wrapping\n        original_index = getattr(X, \"index\", None)\n        if original_index is not None:\n            if isinstance(data_to_wrap, tuple):\n                # For tuple outputs, check the first element's dimensions\n                first_output = data_to_wrap[0]\n                if hasattr(first_output, 'shape') and len(first_output) != len(original_index):\n                    # Dimensions changed - likely aggregation, avoid index mismatch\n                    X_for_wrapping = getattr(X, 'values', X) if hasattr(X, 'values') else X\n                    return (\n                        _wrap_data_with_container(method, first_output, X_for_wrapping, self),\n                        *data_to_wrap[1:],\n                    )\n            else:\n                # For single output, check dimensions\n                if hasattr(data_to_wrap, 'shape') and len(data_to_wrap) != len(original_index):\n                    # Dimensions changed - likely aggregation, avoid index mismatch\n                    X_for_wrapping = getattr(X, 'values', X) if hasattr(X, 'values') else X\n                    return _wrap_data_with_container(method, data_to_wrap, X_for_wrapping, self)\n        \n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            return (\n                _wrap_data_with_container(method, data_to_wrap[0], X, self),\n                *data_to_wrap[1:],\n            )\n\n        return _wrap_data_with_container(method, data_to_wrap, X, self)\n",
      "\ndef _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        \n        # Check if data dimensions changed (e.g., due to aggregation)\n        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape'):\n            if isinstance(data_to_wrap, tuple):\n                # For tuple outputs, check the first element\n                output_shape = data_to_wrap[0].shape if hasattr(data_to_wrap[0], 'shape') else None\n            else:\n                output_shape = data_to_wrap.shape\n            \n            # If dimensions changed significantly, it indicates aggregation\n            if output_shape is not None and len(output_shape) >= 1 and len(X.shape) >= 1:\n                if output_shape[0] != X.shape[0]:\n                    # Dimensions changed, likely due to aggregation - handle carefully\n                    if isinstance(data_to_wrap, tuple):\n                        return (\n                            _wrap_data_with_container(method, data_to_wrap[0], None, self),\n                            *data_to_wrap[1:],\n                        )\n                    return _wrap_data_with_container(method, data_to_wrap, None, self)\n        \n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            return (\n                _wrap_data_with_container(method, data_to_wrap[0], X, self),\n                *data_to_wrap[1:],\n            )\n\n        return _wrap_data_with_container(method, data_to_wrap, X, self)\n",
      "\ndef _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        \n        # Check if data dimensions changed (indicating aggregation/reduction)\n        def _has_compatible_dimensions(original, transformed):\n            if hasattr(original, 'shape') and hasattr(transformed, 'shape'):\n                return original.shape[0] == transformed.shape[0]\n            elif hasattr(original, '__len__') and hasattr(transformed, '__len__'):\n                return len(original) == len(transformed)\n            return True\n        \n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            first_output = data_to_wrap[0]\n            if _has_compatible_dimensions(X, first_output):\n                wrapped_first = _wrap_data_with_container(method, first_output, X, self)\n            else:\n                # Reset original input to None to avoid dimension mismatch\n                wrapped_first = _wrap_data_with_container(method, first_output, None, self)\n            return (wrapped_first, *data_to_wrap[1:])\n\n        if _has_compatible_dimensions(X, data_to_wrap):\n            return _wrap_data_with_container(method, data_to_wrap, X, self)\n        else:\n            # Reset original input to None to avoid dimension mismatch\n            return _wrap_data_with_container(method, data_to_wrap, None, self)\n",
      "\ndef _wrap_method_output(f, method):\n    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n\n    @wraps(f)\n    def wrapped(self, X, *args, **kwargs):\n        data_to_wrap = f(self, X, *args, **kwargs)\n        if isinstance(data_to_wrap, tuple):\n            # only wrap the first output for cross decomposition\n            # Check if dimensions are compatible for index preservation\n            first_output = data_to_wrap[0]\n            if hasattr(X, 'shape') and hasattr(first_output, 'shape'):\n                if len(first_output.shape) > 0 and len(X.shape) > 0 and first_output.shape[0] != X.shape[0]:\n                    # Dimensions changed, create new wrapper without original index\n                    wrapped_first = _wrap_data_with_container(method, first_output, None, self)\n                else:\n                    wrapped_first = _wrap_data_with_container(method, first_output, X, self)\n            else:\n                wrapped_first = _wrap_data_with_container(method, first_output, X, self)\n            return (wrapped_first, *data_to_wrap[1:])\n\n        # Check if dimensions are compatible for index preservation\n        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape'):\n            if len(data_to_wrap.shape) > 0 and len(X.shape) > 0 and data_to_wrap.shape[0] != X.shape[0]:\n                # Dimensions changed, create new wrapper without original index\n                return _wrap_data_with_container(method, data_to_wrap, None, self)\n        \n        return _wrap_data_with_container(method, data_to_wrap, X, self)\n"
    ],
    "Location 4 (/root/hy/projects_2/scikit-learn/sklearn/pipeline.py lines 1279-1289)": [
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            # Reset indices before concatenation to avoid length mismatch errors\n            # This handles cases where transformers aggregate data and change dimensions\n            Xs_reset = [X.reset_index(drop=True) for X in Xs]\n            return pd.concat(Xs_reset, axis=1)\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n            Xs = np.hstack(Xs)\n        return Xs\n",
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            # Reset index for each DataFrame to avoid conflicts when concatenating\n            # transformed data that may have different dimensions than input\n            Xs_reset = [X.reset_index(drop=True) for X in Xs]\n            return pd.concat(Xs_reset, axis=1)\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n            Xs = np.hstack(Xs)\n        return Xs\n",
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            # Reset index for each DataFrame to avoid conflicts when concatenating\n            # DataFrames with different row counts (e.g., from aggregation transformers)\n            Xs_reset = [X.reset_index(drop=True) for X in Xs]\n            return pd.concat(Xs_reset, axis=1)\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n            Xs = np.hstack(Xs)\n        return Xs\n",
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            # Reset index for each DataFrame to avoid length mismatches during concatenation\n            # This handles cases where transformers aggregate data and change dimensions\n            Xs_reset = [X.reset_index(drop=True) for X in Xs]\n            return pd.concat(Xs_reset, axis=1)\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n            Xs = np.hstack(Xs)\n        return Xs\n",
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            # Reset index for each DataFrame to avoid index conflicts during concatenation\n            # This is especially important when transformers aggregate data and change dimensions\n            Xs_reset = [X.reset_index(drop=True) for X in Xs]\n            return pd.concat(Xs_reset, axis=1)\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n            Xs = np.hstack(Xs)\n        return Xs\n",
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            # Reset index for all DataFrames to avoid length mismatches\n            # that can occur when transformers aggregate data\n            Xs_reset = [X.reset_index(drop=True) for X in Xs]\n            return pd.concat(Xs_reset, axis=1)\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n            Xs = np.hstack(Xs)\n        return Xs\n",
      "\n    def _hstack(self, Xs):\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            # Reset indices to avoid length mismatch when transformers aggregate data\n            Xs_reset = [X.reset_index(drop=True) for X in Xs]\n            return pd.concat(Xs_reset, axis=1)\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n            Xs = np.hstack(Xs)\n        return Xs\n",
      "\ndef _hstack(self, Xs):\n    config = _get_output_config(\"transform\", self)\n    if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n        pd = check_pandas_support(\"transform\")\n        # Reset index for each DataFrame to avoid index conflicts during concatenation\n        # This handles cases where transformers change the number of rows (e.g., aggregation)\n        Xs_reset = [X.reset_index(drop=True) for X in Xs]\n        return pd.concat(Xs_reset, axis=1)\n\n    if any(sparse.issparse(f) for f in Xs):\n        Xs = sparse.hstack(Xs).tocsr()\n    else:\n        Xs = np.hstack(Xs)\n    return Xs\n"
    ]
  },
  "combined_diffs": {
    "raw_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..b48c259d8 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1276,11 +1276,16 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n \n         return self._hstack(Xs)\n \n+\n     def _hstack(self, Xs):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            result = pd.concat(Xs, axis=1)\n+            # Reset index to avoid issues with automatic pandas wrapping\n+            # when the concatenated result has different dimensions\n+            result.reset_index(drop=True, inplace=True)\n+            return result\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..27050a895 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -52,11 +52,15 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n+\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n         if index is not None:\n-            data_to_wrap.index = index\n+            # Check if index length matches data length to avoid ValueError\n+            if len(index) == len(data_to_wrap):\n+                data_to_wrap.index = index\n+            # If lengths don't match, keep the existing index (don't assign)\n         return data_to_wrap\n \n     return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n@@ -124,12 +128,22 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     output_config = _get_output_config(method, estimator)\n \n     if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n+\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    original_index = getattr(original_input, \"index\", None)\n+    \n+    # Check if the transformed data has different dimensions than the original input\n+    # If so, don't pass the original index to avoid length mismatch errors\n+    if (original_index is not None and \n+        hasattr(data_to_wrap, '__len__') and \n+        len(original_index) != len(data_to_wrap)):\n+        original_index = None\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n+        index=original_index,\n         columns=estimator.get_feature_names_out,\n     )\n \n@@ -138,6 +152,7 @@ def _wrap_method_output(f, method):\n     \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n \n     @wraps(f)\n+\n     def wrapped(self, X, *args, **kwargs):\n         data_to_wrap = f(self, X, *args, **kwargs)\n         if isinstance(data_to_wrap, tuple):\n",
    "variant_0": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..5b85cae6e 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1276,11 +1276,15 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n \n         return self._hstack(Xs)\n \n+\n     def _hstack(self, Xs):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            # Reset index for each DataFrame to avoid conflicts during concatenation\n+            # This handles cases where transformers change the number of rows (e.g., aggregation)\n+            Xs_reset = [X.reset_index(drop=True) for X in Xs]\n+            return pd.concat(Xs_reset, axis=1)\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..ff4b93a39 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -52,11 +52,15 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n+\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n         if index is not None:\n-            data_to_wrap.index = index\n+            # Check if index length matches data length to avoid ValueError\n+            if len(index) == len(data_to_wrap):\n+                data_to_wrap.index = index\n+            # If lengths don't match, keep the existing index (don't assign)\n         return data_to_wrap\n \n     return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n@@ -123,31 +127,103 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     \"\"\"\n     output_config = _get_output_config(method, estimator)\n \n+    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n+\n+def _wrap_data_with_container(\n+    method, data_to_wrap, original_input, estimator, *, index=None\n+):\n+    \"\"\"Wrap output with container based on an estimator's or global config.\n+\n+    Parameters\n+    ----------\n+    method : {\"transform\"}\n+        Estimator's method to get container output for.\n+\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to wrap with container.\n+\n+    original_input : {ndarray, dataframe}\n+        Original input of function.\n+\n+    estimator : estimator instance\n+        Estimator with to get the output configuration from.\n+\n+    index : array-like, default=None\n+        Index for output data. Only used when `data_to_wrap` has 1 or 2\n+        dimensions. If `None`, then the index of `original_input` is used.\n+\n+    Returns\n+    -------\n+    output : {ndarray, dataframe}\n+        If the output config is \"default\" or the estimator is not configured\n+        for wrapping return `data_to_wrap` unchanged.\n+        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n+        DataFrame.\n+    \"\"\"\n+    output_config = _get_output_config(method, estimator)\n+\n     if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    # Check if dimensions changed (e.g., due to aggregation) and reset index if needed\n+    original_index = getattr(original_input, \"index\", None)\n+    if (original_index is not None and \n+        hasattr(data_to_wrap, 'shape') and \n+        len(data_to_wrap.shape) >= 1 and \n+        len(original_index) != data_to_wrap.shape[0]):\n+        original_index = None\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n+        index=original_index,\n         columns=estimator.get_feature_names_out,\n     )\n \n \n+def _wrap_method_output(f, method):\n+    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n+\n+    @wraps(f)\n+\n def _wrap_method_output(f, method):\n     \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n \n     @wraps(f)\n     def wrapped(self, X, *args, **kwargs):\n         data_to_wrap = f(self, X, *args, **kwargs)\n+        \n+        # Check if data dimensions changed (e.g., due to aggregation)\n+        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape'):\n+            if isinstance(data_to_wrap, tuple):\n+                # For tuple outputs, check the first element\n+                input_rows = X.shape[0] if len(X.shape) > 0 else 0\n+                output_rows = data_to_wrap[0].shape[0] if len(data_to_wrap[0].shape) > 0 else 0\n+            else:\n+                input_rows = X.shape[0] if len(X.shape) > 0 else 0\n+                output_rows = data_to_wrap.shape[0] if len(data_to_wrap.shape) > 0 else 0\n+            \n+            # If dimensions changed, we can't preserve the original index\n+            if input_rows != output_rows:\n+                # Create a copy of X without index for wrapping\n+                X_for_wrapping = X\n+                if hasattr(X, 'index'):\n+                    import pandas as pd\n+                    if isinstance(X, pd.DataFrame):\n+                        X_for_wrapping = X.reset_index(drop=True)\n+                    elif isinstance(X, pd.Series):\n+                        X_for_wrapping = X.reset_index(drop=True)\n+        else:\n+            X_for_wrapping = X\n+        \n         if isinstance(data_to_wrap, tuple):\n             # only wrap the first output for cross decomposition\n             return (\n-                _wrap_data_with_container(method, data_to_wrap[0], X, self),\n+                _wrap_data_with_container(method, data_to_wrap[0], X_for_wrapping, self),\n                 *data_to_wrap[1:],\n             )\n \n-        return _wrap_data_with_container(method, data_to_wrap, X, self)\n+        return _wrap_data_with_container(method, data_to_wrap, X_for_wrapping, self)\n \n     return wrapped\n \n",
    "variant_1": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..4307b60f9 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1276,11 +1276,15 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n \n         return self._hstack(Xs)\n \n+\n     def _hstack(self, Xs):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            # Reset indices before concatenation to avoid length mismatch errors\n+            # This handles cases where transformers aggregate data and change dimensions\n+            Xs_reset = [X.reset_index(drop=True) for X in Xs]\n+            return pd.concat(Xs_reset, axis=1)\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..eadbb8c80 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -52,11 +52,15 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n+\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n         if index is not None:\n-            data_to_wrap.index = index\n+            # Check if index length matches data length to avoid ValueError\n+            if len(index) == len(data_to_wrap):\n+                data_to_wrap.index = index\n+            # If lengths don't match, keep the existing index or reset to default\n         return data_to_wrap\n \n     return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n@@ -123,23 +127,82 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     \"\"\"\n     output_config = _get_output_config(method, estimator)\n \n+    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n+\n+def _wrap_data_with_container(\n+    method, data_to_wrap, original_input, estimator, *, index=None\n+):\n+    \"\"\"Wrap output with container based on an estimator's or global config.\n+\n+    Parameters\n+    ----------\n+    method : {\"transform\"}\n+        Estimator's method to get container output for.\n+\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to wrap with container.\n+\n+    original_input : {ndarray, dataframe}\n+        Original input of function.\n+\n+    estimator : estimator instance\n+        Estimator with to get the output configuration from.\n+\n+    index : array-like, default=None\n+        Index for output.\n+\n+    Returns\n+    -------\n+    output : {ndarray, dataframe}\n+        If the output config is \"default\" or the estimator is not configured\n+        for wrapping return `data_to_wrap` unchanged.\n+        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n+        DataFrame.\n+    \"\"\"\n+    output_config = _get_output_config(method, estimator)\n+\n     if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    # Check if dimensions changed (e.g., due to aggregation)\n+    original_index = getattr(original_input, \"index\", None)\n+    if original_index is not None and hasattr(data_to_wrap, 'shape') and len(original_index) != data_to_wrap.shape[0]:\n+        original_index = None\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n+        index=original_index,\n         columns=estimator.get_feature_names_out,\n     )\n \n \n+def _wrap_method_output(f, method):\n+    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n+\n+    @wraps(f)\n+\n def _wrap_method_output(f, method):\n     \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n \n     @wraps(f)\n     def wrapped(self, X, *args, **kwargs):\n         data_to_wrap = f(self, X, *args, **kwargs)\n+        \n+        # Check if data dimensions changed (e.g., due to aggregation)\n+        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape'):\n+            if isinstance(data_to_wrap, tuple):\n+                # For tuple outputs, check the first element\n+                if data_to_wrap[0].shape[0] != X.shape[0]:\n+                    # Dimensions changed, use None as X to reset index\n+                    return (\n+                        _wrap_data_with_container(method, data_to_wrap[0], None, self),\n+                        *data_to_wrap[1:],\n+                    )\n+            elif data_to_wrap.shape[0] != X.shape[0]:\n+                # Dimensions changed, use None as X to reset index\n+                return _wrap_data_with_container(method, data_to_wrap, None, self)\n+        \n         if isinstance(data_to_wrap, tuple):\n             # only wrap the first output for cross decomposition\n             return (\n",
    "variant_2": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..115da6950 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1276,11 +1276,15 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n \n         return self._hstack(Xs)\n \n+\n     def _hstack(self, Xs):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            # Reset index for each DataFrame to avoid conflicts when concatenating\n+            # transformed data that may have different dimensions than input\n+            Xs_reset = [X.reset_index(drop=True) for X in Xs]\n+            return pd.concat(Xs_reset, axis=1)\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..3bbb6c2ad 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -52,11 +52,15 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n+\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n         if index is not None:\n-            data_to_wrap.index = index\n+            # Check if index length matches data length to avoid ValueError\n+            if len(index) == len(data_to_wrap):\n+                data_to_wrap.index = index\n+            # If lengths don't match, keep the existing index (don't assign)\n         return data_to_wrap\n \n     return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n@@ -123,31 +127,96 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     \"\"\"\n     output_config = _get_output_config(method, estimator)\n \n+    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n+\n+def _wrap_data_with_container(\n+    method, data_to_wrap, original_input, estimator, *, index=None\n+):\n+    \"\"\"Wrap output with container based on an estimator's or global config.\n+\n+    Parameters\n+    ----------\n+    method : {\"transform\"}\n+        Estimator's method to get container output for.\n+\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to wrap with container.\n+\n+    original_input : {ndarray, dataframe}\n+        Original input of function.\n+\n+    estimator : estimator instance\n+        Estimator with to get the output configuration from.\n+\n+    index : array-like, default=None\n+        Index for data_to_wrap. If None and output config is \"pandas\",\n+        then `original_input.index` is used.\n+\n+    Returns\n+    -------\n+    output : {ndarray, dataframe}\n+        If the output config is \"default\" or the estimator is not configured\n+        for wrapping return `data_to_wrap` unchanged.\n+        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n+        DataFrame.\n+    \"\"\"\n+    output_config = _get_output_config(method, estimator)\n+\n     if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    # Check if dimensions match between input and output\n+    original_index = getattr(original_input, \"index\", None)\n+    if original_index is not None and hasattr(data_to_wrap, 'shape') and len(data_to_wrap.shape) > 0:\n+        if len(original_index) != data_to_wrap.shape[0]:\n+            # Dimensions don't match, likely due to aggregation - don't preserve index\n+            original_index = None\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n+        index=original_index,\n         columns=estimator.get_feature_names_out,\n     )\n \n \n+def _wrap_method_output(f, method):\n+    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n+\n+    @wraps(f)\n+\n def _wrap_method_output(f, method):\n     \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n \n     @wraps(f)\n     def wrapped(self, X, *args, **kwargs):\n         data_to_wrap = f(self, X, *args, **kwargs)\n+        \n+        # Check if data dimensions changed (e.g., due to aggregation)\n+        def _has_compatible_dimensions(original, transformed):\n+            if hasattr(original, 'shape') and hasattr(transformed, 'shape'):\n+                return original.shape[0] == transformed.shape[0]\n+            return True\n+        \n         if isinstance(data_to_wrap, tuple):\n             # only wrap the first output for cross decomposition\n-            return (\n-                _wrap_data_with_container(method, data_to_wrap[0], X, self),\n-                *data_to_wrap[1:],\n-            )\n-\n-        return _wrap_data_with_container(method, data_to_wrap, X, self)\n+            if _has_compatible_dimensions(X, data_to_wrap[0]):\n+                return (\n+                    _wrap_data_with_container(method, data_to_wrap[0], X, self),\n+                    *data_to_wrap[1:],\n+                )\n+            else:\n+                # Reset input reference for incompatible dimensions\n+                return (\n+                    _wrap_data_with_container(method, data_to_wrap[0], None, self),\n+                    *data_to_wrap[1:],\n+                )\n+\n+        if _has_compatible_dimensions(X, data_to_wrap):\n+            return _wrap_data_with_container(method, data_to_wrap, X, self)\n+        else:\n+            # Reset input reference for incompatible dimensions\n+            return _wrap_data_with_container(method, data_to_wrap, None, self)\n \n     return wrapped\n \n",
    "variant_3": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..a4c3c7802 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1276,11 +1276,15 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n \n         return self._hstack(Xs)\n \n+\n     def _hstack(self, Xs):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            # Reset index for each DataFrame to avoid conflicts when concatenating\n+            # DataFrames with different row counts (e.g., from aggregation transformers)\n+            Xs_reset = [X.reset_index(drop=True) for X in Xs]\n+            return pd.concat(Xs_reset, axis=1)\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..93e5f075a 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -52,11 +52,15 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n+\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n         if index is not None:\n-            data_to_wrap.index = index\n+            # Check if index length matches data length to avoid ValueError\n+            if len(index) == len(data_to_wrap):\n+                data_to_wrap.index = index\n+            # If lengths don't match, keep the existing index (don't assign)\n         return data_to_wrap\n \n     return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n@@ -96,6 +100,35 @@ def _get_output_config(method, estimator=None):\n     return {\"dense\": dense_config}\n \n \n+def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n+    \"\"\"Wrap output with container based on an estimator's or global config.\n+\n+    Parameters\n+    ----------\n+    method : {\"transform\"}\n+        Estimator's method to get container output for.\n+\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to wrap with container.\n+\n+    original_input : {ndarray, dataframe}\n+        Original input of function.\n+\n+    estimator : estimator instance\n+        Estimator with to get the output configuration from.\n+\n+    Returns\n+    -------\n+    output : {ndarray, dataframe}\n+        If the output config is \"default\" or the estimator is not configured\n+        for wrapping return `data_to_wrap` unchanged.\n+        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n+        DataFrame.\n+    \"\"\"\n+    output_config = _get_output_config(method, estimator)\n+\n+    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n+\n def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     \"\"\"Wrap output with container based on an estimator's or global config.\n \n@@ -127,13 +160,23 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    original_index = getattr(original_input, \"index\", None)\n+    # Check if dimensions match to handle aggregation transformers\n+    if original_index is not None and len(original_index) != data_to_wrap.shape[0]:\n+        original_index = None\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n+        index=original_index,\n         columns=estimator.get_feature_names_out,\n     )\n \n \n+def _wrap_method_output(f, method):\n+    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n+\n+    @wraps(f)\n+\n def _wrap_method_output(f, method):\n     \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n \n@@ -142,11 +185,24 @@ def _wrap_method_output(f, method):\n         data_to_wrap = f(self, X, *args, **kwargs)\n         if isinstance(data_to_wrap, tuple):\n             # only wrap the first output for cross decomposition\n+            # Check if dimensions are compatible before wrapping\n+            if hasattr(X, 'shape') and hasattr(data_to_wrap[0], 'shape'):\n+                if len(data_to_wrap[0].shape) > 0 and len(X.shape) > 0:\n+                    if data_to_wrap[0].shape[0] != X.shape[0]:\n+                        # Dimensions changed, likely due to aggregation\n+                        return data_to_wrap\n             return (\n                 _wrap_data_with_container(method, data_to_wrap[0], X, self),\n                 *data_to_wrap[1:],\n             )\n \n+        # Check if dimensions are compatible before wrapping\n+        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape'):\n+            if len(data_to_wrap.shape) > 0 and len(X.shape) > 0:\n+                if data_to_wrap.shape[0] != X.shape[0]:\n+                    # Dimensions changed, likely due to aggregation\n+                    return data_to_wrap\n+\n         return _wrap_data_with_container(method, data_to_wrap, X, self)\n \n     return wrapped\n",
    "variant_4": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..1584edafb 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1276,11 +1276,15 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n \n         return self._hstack(Xs)\n \n+\n     def _hstack(self, Xs):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            # Reset index for each DataFrame to avoid length mismatches during concatenation\n+            # This handles cases where transformers aggregate data and change dimensions\n+            Xs_reset = [X.reset_index(drop=True) for X in Xs]\n+            return pd.concat(Xs_reset, axis=1)\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..3d34518c0 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -52,11 +52,15 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n+\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n         if index is not None:\n-            data_to_wrap.index = index\n+            # Check if index length matches data length to avoid ValueError\n+            if len(index) == len(data_to_wrap):\n+                data_to_wrap.index = index\n+            # If lengths don't match, keep the existing index or reset to default\n         return data_to_wrap\n \n     return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n@@ -96,6 +100,35 @@ def _get_output_config(method, estimator=None):\n     return {\"dense\": dense_config}\n \n \n+def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n+    \"\"\"Wrap output with container based on an estimator's or global config.\n+\n+    Parameters\n+    ----------\n+    method : {\"transform\"}\n+        Estimator's method to get container output for.\n+\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to wrap with container.\n+\n+    original_input : {ndarray, dataframe}\n+        Original input of function.\n+\n+    estimator : estimator instance\n+        Estimator with to get the output configuration from.\n+\n+    Returns\n+    -------\n+    output : {ndarray, dataframe}\n+        If the output config is \"default\" or the estimator is not configured\n+        for wrapping return `data_to_wrap` unchanged.\n+        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n+        DataFrame.\n+    \"\"\"\n+    output_config = _get_output_config(method, estimator)\n+\n+    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n+\n def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     \"\"\"Wrap output with container based on an estimator's or global config.\n \n@@ -127,19 +160,45 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    # Check if dimensions match to handle aggregation cases\n+    original_index = getattr(original_input, \"index\", None)\n+    if original_index is not None and hasattr(data_to_wrap, 'shape') and len(original_index) != data_to_wrap.shape[0]:\n+        # Dimensions don't match, likely due to aggregation - don't preserve index\n+        original_index = None\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n+        index=original_index,\n         columns=estimator.get_feature_names_out,\n     )\n \n \n+def _wrap_method_output(f, method):\n+    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n+\n+    @wraps(f)\n+\n def _wrap_method_output(f, method):\n     \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n \n     @wraps(f)\n     def wrapped(self, X, *args, **kwargs):\n         data_to_wrap = f(self, X, *args, **kwargs)\n+        \n+        # Check if data dimensions changed (indicating aggregation/filtering)\n+        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape'):\n+            if isinstance(data_to_wrap, tuple):\n+                # For tuple output, check the first element\n+                if data_to_wrap[0].shape[0] != X.shape[0]:\n+                    # Dimensions changed, avoid using original index\n+                    return (\n+                        _wrap_data_with_container(method, data_to_wrap[0], None, self),\n+                        *data_to_wrap[1:],\n+                    )\n+            elif data_to_wrap.shape[0] != X.shape[0]:\n+                # Dimensions changed, avoid using original index\n+                return _wrap_data_with_container(method, data_to_wrap, None, self)\n+        \n         if isinstance(data_to_wrap, tuple):\n             # only wrap the first output for cross decomposition\n             return (\n@@ -151,6 +210,8 @@ def _wrap_method_output(f, method):\n \n     return wrapped\n \n+    return wrapped\n+\n \n def _auto_wrap_is_configured(estimator):\n     \"\"\"Return True if estimator is configured for auto-wrapping the transform method.\n",
    "variant_5": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..6bd6acf5f 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1276,11 +1276,15 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n \n         return self._hstack(Xs)\n \n+\n     def _hstack(self, Xs):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            # Reset index for each DataFrame to avoid index conflicts during concatenation\n+            # This is especially important when transformers aggregate data and change dimensions\n+            Xs_reset = [X.reset_index(drop=True) for X in Xs]\n+            return pd.concat(Xs_reset, axis=1)\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..76cc0e82a 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -52,11 +52,15 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n+\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n         if index is not None:\n-            data_to_wrap.index = index\n+            # Check if index length matches data length to avoid ValueError\n+            if len(index) == len(data_to_wrap):\n+                data_to_wrap.index = index\n+            # If lengths don't match, keep the original index or reset it\n         return data_to_wrap\n \n     return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n@@ -96,6 +100,35 @@ def _get_output_config(method, estimator=None):\n     return {\"dense\": dense_config}\n \n \n+def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n+    \"\"\"Wrap output with container based on an estimator's or global config.\n+\n+    Parameters\n+    ----------\n+    method : {\"transform\"}\n+        Estimator's method to get container output for.\n+\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to wrap with container.\n+\n+    original_input : {ndarray, dataframe}\n+        Original input of function.\n+\n+    estimator : estimator instance\n+        Estimator with to get the output configuration from.\n+\n+    Returns\n+    -------\n+    output : {ndarray, dataframe}\n+        If the output config is \"default\" or the estimator is not configured\n+        for wrapping return `data_to_wrap` unchanged.\n+        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n+        DataFrame.\n+    \"\"\"\n+    output_config = _get_output_config(method, estimator)\n+\n+    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n+\n def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     \"\"\"Wrap output with container based on an estimator's or global config.\n \n@@ -127,19 +160,51 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    # Check if dimensions match before preserving index\n+    original_index = getattr(original_input, \"index\", None)\n+    if original_index is not None and hasattr(data_to_wrap, 'shape') and len(original_index) != data_to_wrap.shape[0]:\n+        # Dimensions don't match (e.g., due to aggregation), don't preserve index\n+        original_index = None\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n+        index=original_index,\n         columns=estimator.get_feature_names_out,\n     )\n \n \n+def _wrap_method_output(f, method):\n+    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n+\n+    @wraps(f)\n+\n def _wrap_method_output(f, method):\n     \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n \n     @wraps(f)\n     def wrapped(self, X, *args, **kwargs):\n         data_to_wrap = f(self, X, *args, **kwargs)\n+        \n+        # Check if input has pandas index and validate dimensions for output wrapping\n+        original_index = getattr(X, \"index\", None)\n+        if original_index is not None:\n+            if isinstance(data_to_wrap, tuple):\n+                # For tuple outputs, check the first element's dimensions\n+                first_output = data_to_wrap[0]\n+                if hasattr(first_output, 'shape') and len(first_output) != len(original_index):\n+                    # Dimensions changed - likely aggregation, avoid index mismatch\n+                    X_for_wrapping = getattr(X, 'values', X) if hasattr(X, 'values') else X\n+                    return (\n+                        _wrap_data_with_container(method, first_output, X_for_wrapping, self),\n+                        *data_to_wrap[1:],\n+                    )\n+            else:\n+                # For single output, check dimensions\n+                if hasattr(data_to_wrap, 'shape') and len(data_to_wrap) != len(original_index):\n+                    # Dimensions changed - likely aggregation, avoid index mismatch\n+                    X_for_wrapping = getattr(X, 'values', X) if hasattr(X, 'values') else X\n+                    return _wrap_data_with_container(method, data_to_wrap, X_for_wrapping, self)\n+        \n         if isinstance(data_to_wrap, tuple):\n             # only wrap the first output for cross decomposition\n             return (\n",
    "variant_6": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..0ff42ef5f 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1276,11 +1276,15 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n \n         return self._hstack(Xs)\n \n+\n     def _hstack(self, Xs):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            # Reset index for all DataFrames to avoid length mismatches\n+            # that can occur when transformers aggregate data\n+            Xs_reset = [X.reset_index(drop=True) for X in Xs]\n+            return pd.concat(Xs_reset, axis=1)\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..251777744 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -52,11 +52,15 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n+\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n         if index is not None:\n-            data_to_wrap.index = index\n+            # Check if index length matches data length to avoid ValueError\n+            if len(index) == len(data_to_wrap):\n+                data_to_wrap.index = index\n+            # If lengths don't match, keep the existing index (don't assign)\n         return data_to_wrap\n \n     return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n@@ -96,6 +100,35 @@ def _get_output_config(method, estimator=None):\n     return {\"dense\": dense_config}\n \n \n+def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n+    \"\"\"Wrap output with container based on an estimator's or global config.\n+\n+    Parameters\n+    ----------\n+    method : {\"transform\"}\n+        Estimator's method to get container output for.\n+\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to wrap with container.\n+\n+    original_input : {ndarray, dataframe}\n+        Original input of function.\n+\n+    estimator : estimator instance\n+        Estimator with to get the output configuration from.\n+\n+    Returns\n+    -------\n+    output : {ndarray, dataframe}\n+        If the output config is \"default\" or the estimator is not configured\n+        for wrapping return `data_to_wrap` unchanged.\n+        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n+        DataFrame.\n+    \"\"\"\n+    output_config = _get_output_config(method, estimator)\n+\n+    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n+\n def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     \"\"\"Wrap output with container based on an estimator's or global config.\n \n@@ -127,19 +160,50 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    # Check if dimensions changed (e.g., aggregation occurred)\n+    original_index = getattr(original_input, \"index\", None)\n+    if original_index is not None and hasattr(data_to_wrap, '__len__'):\n+        if len(original_index) != len(data_to_wrap):\n+            original_index = None\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n+        index=original_index,\n         columns=estimator.get_feature_names_out,\n     )\n \n \n+def _wrap_method_output(f, method):\n+    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n+\n+    @wraps(f)\n+\n def _wrap_method_output(f, method):\n     \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n \n     @wraps(f)\n     def wrapped(self, X, *args, **kwargs):\n         data_to_wrap = f(self, X, *args, **kwargs)\n+        \n+        # Check if data dimensions changed (e.g., due to aggregation)\n+        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape'):\n+            if isinstance(data_to_wrap, tuple):\n+                # For tuple outputs, check the first element\n+                output_shape = data_to_wrap[0].shape if hasattr(data_to_wrap[0], 'shape') else None\n+            else:\n+                output_shape = data_to_wrap.shape\n+            \n+            # If dimensions changed significantly, it indicates aggregation\n+            if output_shape is not None and len(output_shape) >= 1 and len(X.shape) >= 1:\n+                if output_shape[0] != X.shape[0]:\n+                    # Dimensions changed, likely due to aggregation - handle carefully\n+                    if isinstance(data_to_wrap, tuple):\n+                        return (\n+                            _wrap_data_with_container(method, data_to_wrap[0], None, self),\n+                            *data_to_wrap[1:],\n+                        )\n+                    return _wrap_data_with_container(method, data_to_wrap, None, self)\n+        \n         if isinstance(data_to_wrap, tuple):\n             # only wrap the first output for cross decomposition\n             return (\n",
    "variant_7": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..c9a467c48 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1276,11 +1276,14 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n \n         return self._hstack(Xs)\n \n+\n     def _hstack(self, Xs):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            # Reset indices to avoid length mismatch when transformers aggregate data\n+            Xs_reset = [X.reset_index(drop=True) for X in Xs]\n+            return pd.concat(Xs_reset, axis=1)\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..2c9c97032 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -52,11 +52,15 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n+\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n         if index is not None:\n-            data_to_wrap.index = index\n+            # Check if index length matches data length to avoid ValueError\n+            if len(index) == len(data_to_wrap):\n+                data_to_wrap.index = index\n+            # If lengths don't match, keep the existing index or reset to default\n         return data_to_wrap\n \n     return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n@@ -123,31 +127,91 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     \"\"\"\n     output_config = _get_output_config(method, estimator)\n \n+    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n+\n+def _wrap_data_with_container(\n+    method, data_to_wrap, original_input, estimator, *, index=None\n+):\n+    \"\"\"Wrap output with container based on an estimator's or global config.\n+\n+    Parameters\n+    ----------\n+    method : {\"transform\"}\n+        Estimator's method to get container output for.\n+\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to wrap with container.\n+\n+    original_input : {ndarray, dataframe}\n+        Original input of function.\n+\n+    estimator : estimator instance\n+        Estimator with to get the output configuration from.\n+\n+    index : array-like, default=None\n+        Index for output.\n+\n+    Returns\n+    -------\n+    output : {ndarray, dataframe}\n+        If the output config is \"default\" or the estimator is not configured\n+        for wrapping return `data_to_wrap` unchanged.\n+        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n+        DataFrame.\n+    \"\"\"\n+    output_config = _get_output_config(method, estimator)\n+\n     if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    # Check if dimensions match to handle aggregation transformers\n+    original_index = getattr(original_input, \"index\", None)\n+    if original_index is not None and hasattr(data_to_wrap, 'shape') and len(original_index) != data_to_wrap.shape[0]:\n+        original_index = None\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n+        index=original_index,\n         columns=estimator.get_feature_names_out,\n     )\n \n \n+def _wrap_method_output(f, method):\n+    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n+\n+    @wraps(f)\n+\n def _wrap_method_output(f, method):\n     \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n \n     @wraps(f)\n     def wrapped(self, X, *args, **kwargs):\n         data_to_wrap = f(self, X, *args, **kwargs)\n+        \n+        # Check if data dimensions changed (indicating aggregation/reduction)\n+        def _has_compatible_dimensions(original, transformed):\n+            if hasattr(original, 'shape') and hasattr(transformed, 'shape'):\n+                return original.shape[0] == transformed.shape[0]\n+            elif hasattr(original, '__len__') and hasattr(transformed, '__len__'):\n+                return len(original) == len(transformed)\n+            return True\n+        \n         if isinstance(data_to_wrap, tuple):\n             # only wrap the first output for cross decomposition\n-            return (\n-                _wrap_data_with_container(method, data_to_wrap[0], X, self),\n-                *data_to_wrap[1:],\n-            )\n-\n-        return _wrap_data_with_container(method, data_to_wrap, X, self)\n+            first_output = data_to_wrap[0]\n+            if _has_compatible_dimensions(X, first_output):\n+                wrapped_first = _wrap_data_with_container(method, first_output, X, self)\n+            else:\n+                # Reset original input to None to avoid dimension mismatch\n+                wrapped_first = _wrap_data_with_container(method, first_output, None, self)\n+            return (wrapped_first, *data_to_wrap[1:])\n+\n+        if _has_compatible_dimensions(X, data_to_wrap):\n+            return _wrap_data_with_container(method, data_to_wrap, X, self)\n+        else:\n+            # Reset original input to None to avoid dimension mismatch\n+            return _wrap_data_with_container(method, data_to_wrap, None, self)\n \n     return wrapped\n \n",
    "variant_8": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..8abbc0fa4 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1276,17 +1276,21 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n \n         return self._hstack(Xs)\n \n-    def _hstack(self, Xs):\n-        config = _get_output_config(\"transform\", self)\n-        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n-            pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n-\n-        if any(sparse.issparse(f) for f in Xs):\n-            Xs = sparse.hstack(Xs).tocsr()\n-        else:\n-            Xs = np.hstack(Xs)\n-        return Xs\n+\n+def _hstack(self, Xs):\n+    config = _get_output_config(\"transform\", self)\n+    if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n+        pd = check_pandas_support(\"transform\")\n+        # Reset index for each DataFrame to avoid index conflicts during concatenation\n+        # This handles cases where transformers change the number of rows (e.g., aggregation)\n+        Xs_reset = [X.reset_index(drop=True) for X in Xs]\n+        return pd.concat(Xs_reset, axis=1)\n+\n+    if any(sparse.issparse(f) for f in Xs):\n+        Xs = sparse.hstack(Xs).tocsr()\n+    else:\n+        Xs = np.hstack(Xs)\n+    return Xs\n \n     def _update_transformer_list(self, transformers):\n         transformers = iter(transformers)\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..ccab23b35 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -52,11 +52,15 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n+\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n         if index is not None:\n-            data_to_wrap.index = index\n+            # Check if index length matches DataFrame length to avoid ValueError\n+            if len(index) == len(data_to_wrap):\n+                data_to_wrap.index = index\n+            # If lengths don't match (e.g., due to aggregation), keep original index\n         return data_to_wrap\n \n     return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n@@ -123,17 +127,66 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     \"\"\"\n     output_config = _get_output_config(method, estimator)\n \n+    if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n+\n+def _wrap_data_with_container(\n+    method, data_to_wrap, original_input, estimator, *, index=None\n+):\n+    \"\"\"Wrap output with container based on an estimator's or global config.\n+\n+    Parameters\n+    ----------\n+    method : {\"transform\"}\n+        Estimator's method to get container output for.\n+\n+    data_to_wrap : {ndarray, dataframe}\n+        Data to wrap with container.\n+\n+    original_input : {ndarray, dataframe}\n+        Original input of function.\n+\n+    estimator : estimator instance\n+        Estimator with to get the output configuration from.\n+\n+    index : array-like, default=None\n+        Index for output data. If `None`, then the index of `original_input`\n+        is used.\n+\n+    Returns\n+    -------\n+    output : {ndarray, dataframe}\n+        If the output config is \"default\" or the estimator is not configured\n+        for wrapping return `data_to_wrap` unchanged.\n+        If the output config is \"pandas\", return `data_to_wrap` as a pandas\n+        DataFrame.\n+    \"\"\"\n+    output_config = _get_output_config(method, estimator)\n+\n     if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    # Check if data dimensions match original input for index compatibility\n+    original_index = getattr(original_input, \"index\", None)\n+    if (original_index is not None and \n+        hasattr(data_to_wrap, 'shape') and \n+        len(original_index) != data_to_wrap.shape[0]):\n+        # Data has been aggregated/transformed to different dimensions\n+        # Don't preserve original index to avoid length mismatch\n+        original_index = None\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n+        index=original_index,\n         columns=estimator.get_feature_names_out,\n     )\n \n \n+def _wrap_method_output(f, method):\n+    \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n+\n+    @wraps(f)\n+\n def _wrap_method_output(f, method):\n     \"\"\"Wrapper used by `_SetOutputMixin` to automatically wrap methods.\"\"\"\n \n@@ -142,11 +195,24 @@ def _wrap_method_output(f, method):\n         data_to_wrap = f(self, X, *args, **kwargs)\n         if isinstance(data_to_wrap, tuple):\n             # only wrap the first output for cross decomposition\n-            return (\n-                _wrap_data_with_container(method, data_to_wrap[0], X, self),\n-                *data_to_wrap[1:],\n-            )\n-\n+            # Check if dimensions are compatible for index preservation\n+            first_output = data_to_wrap[0]\n+            if hasattr(X, 'shape') and hasattr(first_output, 'shape'):\n+                if len(first_output.shape) > 0 and len(X.shape) > 0 and first_output.shape[0] != X.shape[0]:\n+                    # Dimensions changed, create new wrapper without original index\n+                    wrapped_first = _wrap_data_with_container(method, first_output, None, self)\n+                else:\n+                    wrapped_first = _wrap_data_with_container(method, first_output, X, self)\n+            else:\n+                wrapped_first = _wrap_data_with_container(method, first_output, X, self)\n+            return (wrapped_first, *data_to_wrap[1:])\n+\n+        # Check if dimensions are compatible for index preservation\n+        if hasattr(X, 'shape') and hasattr(data_to_wrap, 'shape'):\n+            if len(data_to_wrap.shape) > 0 and len(X.shape) > 0 and data_to_wrap.shape[0] != X.shape[0]:\n+                # Dimensions changed, create new wrapper without original index\n+                return _wrap_data_with_container(method, data_to_wrap, None, self)\n+        \n         return _wrap_data_with_container(method, data_to_wrap, X, self)\n \n     return wrapped\n"
  }
}