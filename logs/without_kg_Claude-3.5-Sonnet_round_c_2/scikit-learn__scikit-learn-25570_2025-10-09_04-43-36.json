{
  "zero_patches": {
    "Location 1 (/root/hy/projects_2/scikit-learn/sklearn/compose/_column_transformer.py lines 865-872)": "\n                transformer_names = []\n                feature_names_outs = []\n                for i, (name, transformer, columns) in enumerate(self._iter(fitted=True, replace_strings=True)):\n                    if i < len(Xs) and hasattr(Xs[i], 'columns') and len(Xs[i].columns) > 0:\n                        transformer_names.append(name)\n                        feature_names_outs.append(Xs[i].columns)\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
    "Location 2 (/root/hy/projects_2/scikit-learn/sklearn/compose/_column_transformer.py lines 394-395)": "\n                # List of tuples (name, fitted_transformer, column) for\n                # transformers that actually produced output\n                non_empty_transformers = []\n                for name, fitted_transformer, column in self._iter(fitted=True, replace_strings=True):\n                    if not _is_empty_column_selection(column):\n                        non_empty_transformers.append((name, fitted_transformer, column))\n                \n                transformer_names = [name for name, _, _ in non_empty_transformers]\n",
    "Location 3 (/root/hy/projects_2/scikit-learn/sklearn/compose/_column_transformer.py lines 533-554)": "\n    def _hstack(self, Xs):\n        \"\"\"Stacks Xs horizontally.\n\n        This allows subclasses to control the stacking behavior, while reusing\n        everything else from ColumnTransformer.\n\n        Parameters\n        ----------\n        Xs : list of {array-like, sparse matrix, dataframe}\n        \"\"\"\n        if self._n_features == 0:\n            # No columns were selected\n            if hasattr(Xs[0], \"iloc\"):\n                return Xs[0].iloc[:, :0]\n            else:\n                return np.empty((Xs[0].shape[0], 0))\n\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            output = pd.concat(Xs, axis=1)\n\n            # `output` is a pd.DataFrame. When `self.verbose_feature_names_out=True`,\n            # we need to update the column names from the fitted transformers\n            if not self._feature_names_out_uses_transformer_names:\n                output.columns = self.get_feature_names_out()\n            else:\n                # Filter transformer names to match non-empty outputs in Xs\n                transformer_names = []\n                for name, transformer, columns in self._iter(fitted=True, replace_strings=True):\n                    if not _is_empty_column_selection(columns):\n                        transformer_names.append(name)\n                \n                # Only proceed if we have transformer names that match the outputs\n                if len(transformer_names) == len(Xs):\n                    transformer_with_feature_names_out = []\n                    for i, (name, transformer, columns) in enumerate(self._iter(fitted=True, replace_strings=True)):\n                        if not _is_empty_column_selection(columns):\n                            feature_names_out = transformer.get_feature_names_out()\n                            transformer_with_feature_names_out.append((name, feature_names_out))\n\n                    if transformer_with_feature_names_out:\n                        feature_names = self._add_prefix_for_feature_names_out(\n                            transformer_with_feature_names_out\n                        )\n                        output.columns = feature_names\n\n            return output\n\n        return np.hstack(Xs)\n",
    "Location 4 (/root/hy/projects_2/scikit-learn/sklearn/compose/_column_transformer.py lines 856-862)": "\n                if not self.verbose_feature_names_out:\n                    return output\n\n                # Get transformer names and feature names, filtering to match actual outputs\n                transformer_info = list(self._iter(fitted=True, replace_strings=True))\n                transformer_names = []\n                feature_names_outs = []\n                \n                # Only include transformers that produced non-empty outputs\n                for i, (name, transformer, columns) in enumerate(transformer_info):\n                    if i < len(Xs) and hasattr(Xs[i], 'columns') and len(Xs[i].columns) > 0:\n                        transformer_names.append(name)\n                        feature_names_outs.append(Xs[i].columns)\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
    "Location 5 (/root/hy/projects_2/scikit-learn/sklearn/compose/_column_transformer.py lines 907-920)": "\ndef _hstack(self, Xs):\n    \"\"\"\n    Stacks Xs horizontally.\n\n    This allows subclasses to control the stacking behavior, while reusing\n    everything else from ColumnTransformer.\n\n    Parameters\n    ----------\n    Xs : list of {array-like, sparse matrix, dataframe}\n    \"\"\"\n    config = _get_output_config(\"transform\", self)\n    if config[\"dense\"] == \"pandas\":\n        pd = check_pandas_support(\"transform\")\n        output = pd.concat(Xs, axis=1)\n        # `pd.concat` ignores the index so, we set it here\n        if hasattr(self, \"_df_columns\") and hasattr(self._df_columns, \"index\"):\n            output.index = self._df_columns.index\n        output.columns = self.get_feature_names_out()\n    elif sparse.issparse(Xs[0]):\n        output = sparse.hstack(Xs).tocsr()\n    else:\n        output = np.hstack(Xs)\n    return output\n"
  },
  "variant_patches": {
    "Location 1 (/root/hy/projects_2/scikit-learn/sklearn/compose/_column_transformer.py lines 865-872)": [
      "\n                transformer_names = []\n                feature_names_outs = []\n                for i, (name, transformer, columns) in enumerate(self._iter(fitted=True, replace_strings=True)):\n                    if i < len(Xs) and hasattr(Xs[i], 'columns') and len(Xs[i].columns) > 0:\n                        transformer_names.append(name)\n                        feature_names_outs.append(Xs[i].columns)\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
      "\n                transformer_names = []\n                feature_names_outs = []\n                for i, (name, transformer, columns) in enumerate(self._iter(fitted=True, replace_strings=True)):\n                    if i < len(Xs) and hasattr(Xs[i], 'columns') and len(Xs[i].columns) > 0:\n                        transformer_names.append(name)\n                        feature_names_outs.append(Xs[i].columns)\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
      "\n                transformer_names = []\n                feature_names_outs = []\n                for i, (name, transformer, columns) in enumerate(self._iter(fitted=True, replace_strings=True)):\n                    if i < len(Xs) and hasattr(Xs[i], 'columns') and len(Xs[i].columns) > 0:\n                        transformer_names.append(name)\n                        feature_names_outs.append(Xs[i].columns)\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
      "\n                transformer_names = []\n                feature_names_outs = []\n                \n                # Only include transformers that actually produced output\n                transformer_iter = self._iter(fitted=True, replace_strings=True)\n                for i, (name, transformer, columns) in enumerate(transformer_iter):\n                    if i < len(Xs) and not Xs[i].empty:\n                        transformer_names.append(name)\n                        feature_names_outs.append(Xs[i].columns)\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
      "\n                transformer_names = []\n                feature_names_outs = []\n                for i, (name, transformer, columns) in enumerate(self._iter(fitted=True, replace_strings=True)):\n                    if i < len(Xs) and hasattr(Xs[i], 'columns') and len(Xs[i].columns) > 0:\n                        transformer_names.append(name)\n                        feature_names_outs.append(Xs[i].columns)\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
      "\n                transformer_names = []\n                feature_names_outs = []\n                for i, (name, transformer, columns) in enumerate(self._iter(fitted=True, replace_strings=True)):\n                    if i < len(Xs) and len(Xs[i].columns) > 0:\n                        transformer_names.append(name)\n                        feature_names_outs.append(Xs[i].columns)\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
      "\n                transformer_names = []\n                feature_names_outs = []\n                for i, (name, transformer, columns) in enumerate(self._iter(fitted=True, replace_strings=True)):\n                    if i < len(Xs) and hasattr(Xs[i], 'columns') and len(Xs[i].columns) > 0:\n                        transformer_names.append(name)\n                        feature_names_outs.append(Xs[i].columns)\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
      "\n                transformer_names = []\n                feature_names_outs = []\n                for i, (name, transformer, columns) in enumerate(self._iter(fitted=True, replace_strings=True)):\n                    if i < len(Xs) and hasattr(Xs[i], 'columns') and len(Xs[i].columns) > 0:\n                        transformer_names.append(name)\n                        feature_names_outs.append(Xs[i].columns)\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n"
    ],
    "Location 2 (/root/hy/projects_2/scikit-learn/sklearn/compose/_column_transformer.py lines 394-395)": [
      "\n                # Get transformer names that actually produced output\n                transformer_names = []\n                for name, trans, columns in self._iter(fitted=True, replace_strings=True):\n                    if not _is_empty_column_selection(columns):\n                        transformer_names.append(name)\n                \n                # Ensure we have matching number of names and outputs\n                if len(transformer_names) != len(Xs):\n                    # Fallback: create generic names if mismatch persists\n                    transformer_names = [f\"transformer_{i}\" for i in range(len(Xs))]\n                \n                output_config = _get_output_config(\"transform\", self)\n                if output_config[\"dense\"] == \"pandas\":\n                    pd = check_pandas_support(\"transform\")\n                    feature_names = self._add_prefix_for_feature_names_out(\n                        list(\n                            chain.from_iterable(\n                                (X.columns for X in Xs if hasattr(X, \"columns\"))\n                            )\n                        ),\n                        transformer_names,\n                    )\n",
      "\n                # Create feature names for the concatenated output\n                transformer_names = []\n                non_empty_indices = []\n                \n                # Only include transformers that produced non-empty output\n                for i, (name, trans, columns, weight) in enumerate(\n                    self._iter(fitted=True, replace_strings=True)\n                ):\n                    if i < len(Xs) and Xs[i].shape[1] > 0:\n                        transformer_names.append(name)\n                        non_empty_indices.append(i)\n                \n                # Filter Xs to only include non-empty outputs\n                Xs = [Xs[i] for i in non_empty_indices]\n                \n                feature_names_outs = [X.columns for X in Xs]\n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n",
      "\n                # Get transformer names that actually produced output\n                transformer_names = []\n                for i, (name, trans, columns) in enumerate(self._iter(fitted=True, replace_strings=True)):\n                    # Only include transformers that have corresponding output in Xs\n                    if i < len(Xs):\n                        transformer_names.append(name)\n                \n                feature_names_outs = [\n                    X.columns for X in Xs if hasattr(X, \"columns\")\n                ]\n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n",
      "\n                # Get transformer names that actually produced output\n                transformer_names = []\n                for (name, trans, columns), X in zip(\n                    self._iter(fitted=True, replace_strings=True), Xs\n                ):\n                    if X.shape[1] > 0:  # Only include transformers with non-empty output\n                        transformer_names.append(name)\n                \n                # Get feature names for transformers that produced output\n                feature_names_outs = [\n                    self._add_prefix_for_feature_names_out(\n                        list(X.columns), transformer_names[i]\n                    )\n                    for i, X in enumerate(Xs)\n                    if X.shape[1] > 0\n                ]\n",
      "\n                # Get transformer names that actually produced output\n                transformer_names = []\n                for name, trans, columns in self._iter(fitted=True, replace_strings=True):\n                    if trans == \"passthrough\":\n                        trans = FunctionTransformer(\n                            accept_sparse=True,\n                            check_inverse=False,\n                            feature_names_out=\"one-to-one\",\n                        ).set_output(transform=output_config[\"dense\"])\n                    elif trans == \"drop\":\n                        continue\n                    elif _is_empty_column_selection(columns):\n                        continue\n                    transformer_names.append(name)\n                \n                # Only proceed if we have matching transformers and outputs\n                if len(transformer_names) == len(Xs):\n                    feature_names_outs = [\n                        X.columns if hasattr(X, \"columns\") else None for X in Xs\n                    ]\n                    feature_names_out = self._add_prefix_for_feature_names_out(\n                        list(zip(transformer_names, feature_names_outs))\n                    )\n",
      "\n                # List of feature names for each transformer.\n                if hasattr(self, 'feature_names_in_'):\n                    # Filter out transformers that produced empty outputs\n                    # to align with the actual Xs list\n                    non_empty_transformers = []\n                    transformer_idx = 0\n                    for name, trans, columns in self._iter(fitted=True, replace_strings=True):\n                        if not _is_empty_column_selection(columns):\n                            non_empty_transformers.append((name, trans, columns))\n                            transformer_idx += 1\n                    \n                    feature_names_outs = [X.columns for name, trans, columns in non_empty_transformers]\n                else:\n                    feature_names_outs = [\n                        _get_feature_names_out_with_prefix(name, trans)\n                        for name, trans, columns in self._iter(fitted=True, replace_strings=True)\n                        if not _is_empty_column_selection(columns)\n                    ]\n",
      "\n                # Get transformer names and outputs, filtering out empty outputs\n                transformer_names = []\n                filtered_Xs = []\n                \n                for name, trans, columns, _ in self._iter(fitted=True, replace_strings=True):\n                    # Find the corresponding output in Xs\n                    transformer_idx = [t[0] for t in self.transformers_].index(name)\n                    if transformer_idx < len(Xs) and Xs[transformer_idx].shape[1] > 0:\n                        transformer_names.append(name)\n                        filtered_Xs.append(Xs[transformer_idx])\n                \n                # Use filtered lists for feature naming\n                Xs = filtered_Xs\n                transformer_names = transformer_names\n",
      "\n                # List of tuples (name, fitted_transformer, column) for\n                # transformers that actually produced output\n                output_transformers = []\n                for (name, fitted_transformer, column), X in zip(\n                    self._iter(fitted=True, replace_strings=True), Xs\n                ):\n                    if X.shape[1] > 0:  # Only include transformers with non-empty output\n                        output_transformers.append((name, fitted_transformer, column))\n                \n                transformer_names = [name for name, _, _ in output_transformers]\n"
    ],
    "Location 3 (/root/hy/projects_2/scikit-learn/sklearn/compose/_column_transformer.py lines 533-554)": [
      "\n    def _hstack(self, Xs):\n        \"\"\"\n        Stacks Xs horizontally.\n\n        This allows subclasses to control the stacking behavior, while reusing\n        everything else from ColumnTransformer.\n\n        Parameters\n        ----------\n        Xs : list of {array-like, sparse matrix, dataframe}\n        \"\"\"\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            output = pd.concat(Xs, axis=1)\n            # `pd.concat` adds a redundant level to the column MultiIndex\n            output.columns = output.columns.droplevel(0)\n            return output\n\n        if any(sparse.issparse(X) for X in Xs):\n            return sparse.hstack(Xs).tocsr()\n        else:\n            Xs = [X for X in Xs if X.shape[1] > 0]\n            if not Xs:\n                # All transformers produced empty outputs\n                return np.empty((self._n_features, 0))\n            return np.hstack(Xs)\n",
      "\n    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n        \"\"\"Add prefix for feature names out that includes the transformer names.\n\n        Parameters\n        ----------\n        transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n            The tuple consistent of the transformer's name and its feature names out.\n\n        Returns\n        -------\n        feature_names_out : ndarray of shape (n_features,), dtype=str\n            Transformed feature names.\n        \"\"\"\n        if self.verbose_feature_names_out:\n            # Prefix the feature names out with the transformers name\n            names = list(\n                chain.from_iterable(\n                    (f\"{name}__{i}\" for i in feature_names_out)\n                    for name, feature_names_out in transformer_with_feature_names_out\n                )\n            )\n            return np.asarray(names, dtype=object)\n",
      "\n    def _hstack(self, Xs):\n        \"\"\"\n        Stacks Xs horizontally.\n\n        This allows subclasses to control the stacking behavior, while reusing\n        everything else from ColumnTransformer.\n\n        Parameters\n        ----------\n        Xs : list of {array-like, sparse matrix, dataframe}\n        \"\"\"\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            output = pd.concat(Xs, axis=1)\n            # `pd.concat` adds a `0` suffix to columns with the same name;\n            # we remove the suffix here.\n            if len(Xs) > 1:\n                output.columns = output.columns.str.removesuffix(\"_0\")\n            output.index = Xs[0].index\n            return output\n\n        if any(sparse.issparse(X) for X in Xs):\n            return sparse.hstack(Xs).tocsr()\n        else:\n            return np.hstack(Xs)\n",
      "\n    def _hstack(self, Xs):\n        \"\"\"Stacks Xs horizontally.\n\n        This allows subclasses to control the stacking behavior, while reusing\n        everything else from ColumnTransformer.\n\n        Parameters\n        ----------\n        Xs : list of {array-like, sparse matrix, dataframe}\n        \"\"\"\n        if self._n_features == 0:\n            # No columns were selected\n            if hasattr(Xs[0], \"iloc\"):\n                return Xs[0].iloc[:, :0]\n            else:\n                return np.empty((Xs[0].shape[0], 0))\n\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            output = pd.concat(Xs, axis=1)\n\n            # `pd.concat` adds a integer suffix when concat'ing transformers\n            # with identical feature names\n            if not output.columns.is_unique:\n                output.columns = self.get_feature_names_out()\n\n        elif sparse.issparse(Xs[0]):\n            output = sparse.hstack(Xs).tocsr()\n        else:\n            output = np.hstack(Xs)\n        return output\n",
      "\n    def _hstack(self, Xs):\n        \"\"\"\n        Stacks Xs horizontally.\n\n        This allows subclasses to control the stacking behavior, while reusing\n        everything else from ColumnTransformer.\n\n        Parameters\n        ----------\n        Xs : list of {array-like, sparse matrix, dataframe}\n        \"\"\"\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            output = pd.concat(Xs, axis=1)\n            # `pd.concat` adds a keys level to the columns, remove it\n            if isinstance(output.columns, pd.MultiIndex):\n                output.columns = output.columns.get_level_values(-1)\n            output.index = Xs[0].index\n            return output\n\n        if any(sparse.issparse(f) for f in Xs):\n            Xs = sparse.hstack(Xs).tocsr()\n        else:\n            Xs = np.hstack(Xs)\n        return Xs\n",
      "\n    def _hstack(self, Xs):\n        \"\"\"Stacks Xs horizontally.\n\n        This allows subclasses to control the stacking behavior, while reusing\n        everything else from ColumnTransformer.\n\n        Parameters\n        ----------\n        Xs : list of {array-like, sparse matrix, dataframe}\n        \"\"\"\n        if self._n_features == 0:\n            # No columns were selected\n            if hasattr(Xs[0], \"iloc\"):\n                return Xs[0].iloc[:, :0]\n            else:\n                return np.empty((Xs[0].shape[0], 0))\n\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            output = pd.concat(Xs, axis=1)\n\n            # `pd.concat` adds a `RangeIndex` for the columns, we want to\n            # use the feature names that we generate.\n            output.columns = self.get_feature_names_out()\n            return output\n\n        return sparse.hstack(Xs).tocsr()\n",
      "\n    def _hstack(self, Xs):\n        \"\"\"\n        Stacks Xs horizontally.\n\n        This allows subclasses to control the stacking behavior, while reusing\n        everything else from ColumnTransformer.\n\n        Parameters\n        ----------\n        Xs : list of {array-like, sparse matrix, dataframe}\n        \"\"\"\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            output = pd.concat(Xs, axis=1)\n            # `pd.concat` adds a `RangeIndex` which is unused\n            output.index = Xs[0].index\n            return output\n\n        if any(sparse.issparse(X) for X in Xs):\n            return sparse.hstack(Xs).tocsr()\n        else:\n            Xs = [X for X in Xs if X.shape[1] > 0]\n            if not Xs:\n                # All transformers produced empty outputs\n                return np.zeros((self._n_features, 0))\n            return np.hstack(Xs)\n",
      "\n    def _hstack(self, Xs):\n        \"\"\"Stacks Xs horizontally.\n\n        This allows subclasses to control the stacking behavior, while reusing\n        everything else from ColumnTransformer.\n\n        Parameters\n        ----------\n        Xs : list of {array-like, sparse matrix, dataframe}\n        \"\"\"\n        config = _get_output_config(\"transform\", self)\n        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n            pd = check_pandas_support(\"transform\")\n            output = pd.concat(Xs, axis=1)\n            # `pd.concat` adds a redundant level to the column MultiIndex\n            output.columns = output.columns.droplevel(0)\n            return output\n\n        if any(sparse.issparse(X) for X in Xs):\n            return sparse.hstack(Xs).tocsr()\n        else:\n            Xs = [X for X in Xs if X.shape[1] > 0]\n            if not Xs:\n                # All transformers produced empty output\n                return np.empty((self.n_features_in_, 0))\n            return np.hstack(Xs)\n"
    ],
    "Location 4 (/root/hy/projects_2/scikit-learn/sklearn/compose/_column_transformer.py lines 856-862)": [
      "\n                if not self.verbose_feature_names_out:\n                    return output\n\n                # Get transformer names and feature names, but only for transformers\n                # that actually produced output (non-empty Xs)\n                all_transformers = [\n                    t for t in self._iter(fitted=True, replace_strings=True)\n                ]\n                transformer_names = []\n                feature_names_outs = []\n                \n                # Only include transformers that produced non-empty output\n                transformer_idx = 0\n                for i, X in enumerate(Xs):\n                    if X.shape[1] > 0:  # Only include non-empty outputs\n                        # Find the corresponding transformer for this output\n                        while transformer_idx < len(all_transformers):\n                            transformer_name, transformer, columns = all_transformers[transformer_idx]\n                            transformer_idx += 1\n                            if not _is_empty_column_selection(columns):\n                                transformer_names.append(transformer_name)\n                                feature_names_outs.append(X.columns)\n                                break\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
      "\n                if not self.verbose_feature_names_out:\n                    return output\n\n                # Get transformer names and feature names, but only for transformers\n                # that actually produced output (non-empty Xs)\n                all_transformers = list(self._iter(fitted=True, replace_strings=True))\n                transformer_names = []\n                feature_names_outs = []\n                \n                # Only include transformers that have corresponding non-empty outputs\n                transformer_idx = 0\n                for X in Xs:\n                    if hasattr(X, 'shape') and X.shape[1] > 0:\n                        # Find the corresponding transformer for this output\n                        while transformer_idx < len(all_transformers):\n                            transformer_name = all_transformers[transformer_idx][0]\n                            transformer_idx += 1\n                            # Skip transformers with empty column selections\n                            if not _is_empty_column_selection(all_transformers[transformer_idx - 1][2]):\n                                transformer_names.append(transformer_name)\n                                feature_names_outs.append(X.columns)\n                                break\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
      "\n                if not self.verbose_feature_names_out:\n                    return output\n\n                # Get transformer names and outputs, filtering to match non-empty outputs\n                transformer_info = list(self._iter(fitted=True, replace_strings=True))\n                feature_names_outs = [X.columns for X in Xs]\n                \n                # Filter transformer names to match the actual outputs in Xs\n                # by excluding transformers that produced empty outputs\n                filtered_transformer_names = []\n                for i, (name, transformer, columns) in enumerate(transformer_info):\n                    if i < len(Xs) and len(Xs[i].columns) > 0:\n                        filtered_transformer_names.append(name)\n                \n                # Ensure we have matching lengths\n                if len(filtered_transformer_names) == len(feature_names_outs):\n                    names_out = self._add_prefix_for_feature_names_out(\n                        list(zip(filtered_transformer_names, feature_names_outs))\n                    )\n                    output.columns = names_out\n",
      "\n                if not self.verbose_feature_names_out:\n                    return output\n\n                # Get transformer names and feature names, but only for transformers\n                # that actually produced output (non-empty Xs)\n                all_transformers = list(self._iter(fitted=True, replace_strings=True))\n                transformer_names = []\n                feature_names_outs = []\n                \n                # Only include transformers that have corresponding non-empty outputs\n                transformer_idx = 0\n                for i, X in enumerate(Xs):\n                    if X.shape[1] > 0:  # Only include transformers with actual output columns\n                        # Find the corresponding transformer name\n                        while transformer_idx < len(all_transformers):\n                            transformer_name, transformer, columns = all_transformers[transformer_idx]\n                            transformer_idx += 1\n                            if not _is_empty_column_selection(columns):\n                                transformer_names.append(transformer_name)\n                                feature_names_outs.append(X.columns)\n                                break\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
      "\n                if not self.verbose_feature_names_out:\n                    return output\n\n                # Get transformer names and feature names for non-empty outputs only\n                transformer_info = [\n                    (name, X.columns) for (name, _, _), X in zip(\n                        self._iter(fitted=True, replace_strings=True), Xs\n                    ) if len(X.columns) > 0\n                ]\n                \n                if transformer_info:\n                    names_out = self._add_prefix_for_feature_names_out(transformer_info)\n                    output.columns = names_out\n",
      "\n                if not self.verbose_feature_names_out:\n                    return output\n\n                # Get transformer names and outputs, filtering to match actual outputs\n                transformer_info = list(self._iter(fitted=True, replace_strings=True))\n                transformer_names = []\n                feature_names_outs = []\n                \n                # Only include transformers that produced non-empty outputs\n                for i, (name, transformer, columns) in enumerate(transformer_info):\n                    if i < len(Xs) and hasattr(Xs[i], 'columns') and len(Xs[i].columns) > 0:\n                        transformer_names.append(name)\n                        feature_names_outs.append(Xs[i].columns)\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
      "\n                if not self.verbose_feature_names_out:\n                    return output\n\n                # Get transformer names and outputs, filtering to match actual outputs\n                transformer_info = list(self._iter(fitted=True, replace_strings=True))\n                transformer_names = []\n                feature_names_outs = []\n                \n                # Only include transformers that produced non-empty outputs\n                xs_index = 0\n                for name, transformer, columns in transformer_info:\n                    if not _is_empty_column_selection(columns):\n                        if xs_index < len(Xs) and len(Xs[xs_index].columns) > 0:\n                            transformer_names.append(name)\n                            feature_names_outs.append(Xs[xs_index].columns)\n                        xs_index += 1\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n",
      "\n                if not self.verbose_feature_names_out:\n                    return output\n\n                # Get transformer names and feature names, but only for transformers\n                # that actually produced output (non-empty Xs)\n                all_transformers = [\n                    t for t in self._iter(fitted=True, replace_strings=True)\n                ]\n                \n                # Filter to only include transformers that produced non-empty output\n                transformer_names = []\n                feature_names_outs = []\n                \n                transformer_idx = 0\n                for i, X in enumerate(Xs):\n                    if X.shape[1] > 0:  # Only include transformers with actual output\n                        # Find the corresponding transformer name\n                        while transformer_idx < len(all_transformers):\n                            transformer_name, transformer, columns = all_transformers[transformer_idx]\n                            transformer_idx += 1\n                            if not _is_empty_column_selection(columns):\n                                transformer_names.append(transformer_name)\n                                feature_names_outs.append(X.columns)\n                                break\n                \n                names_out = self._add_prefix_for_feature_names_out(\n                    list(zip(transformer_names, feature_names_outs))\n                )\n                output.columns = names_out\n"
    ],
    "Location 5 (/root/hy/projects_2/scikit-learn/sklearn/compose/_column_transformer.py lines 907-920)": [
      "\ndef _is_empty_column_selection(column):\n    \"\"\"\n    Return True if the column selection is empty (empty list or all-False\n    boolean array).\n\n    \"\"\"\n    if hasattr(column, \"dtype\") and np.issubdtype(column.dtype, np.bool_):\n        return not column.any()\n    elif hasattr(column, \"__len__\"):\n        return (\n            len(column) == 0\n            or (all(isinstance(col, bool) for col in column)\n            and not any(column))\n        )\n    else:\n        return False\n",
      "\ndef _is_empty_column_selection(column):\n    \"\"\"\n    Return True if the column selection is empty (empty list or all-False\n    boolean array).\n\n    \"\"\"\n    if hasattr(column, \"dtype\") and np.issubdtype(column.dtype, np.bool_):\n        return not column.any()\n    elif hasattr(column, \"__len__\"):\n        return (\n            len(column) == 0\n            or (all(isinstance(col, bool) for col in column)\n            and not any(column))\n        )\n    else:\n        return False\n",
      "\ndef _is_empty_column_selection(column):\n    \"\"\"\n    Return True if the column selection is empty (empty list or all-False\n    boolean array).\n\n    \"\"\"\n    if hasattr(column, \"dtype\") and np.issubdtype(column.dtype, np.bool_):\n        return not column.any()\n    elif hasattr(column, \"__len__\"):\n        return (\n            len(column) == 0\n            or (all(isinstance(col, bool) for col in column)\n            and not any(column))\n        )\n    else:\n        return False\n",
      "\ndef _is_empty_column_selection(column):\n    \"\"\"\n    Return True if the column selection is empty (empty list or all-False\n    boolean array).\n\n    \"\"\"\n    if hasattr(column, \"dtype\") and np.issubdtype(column.dtype, np.bool_):\n        return not column.any()\n    elif hasattr(column, \"__len__\"):\n        return (\n            len(column) == 0\n            or (all(isinstance(col, bool) for col in column)\n            and not any(column))\n        )\n    else:\n        return False\n",
      "\ndef _is_empty_column_selection(column):\n    \"\"\"\n    Return True if the column selection is empty (empty list or all-False\n    boolean array).\n\n    \"\"\"\n    if hasattr(column, \"dtype\") and np.issubdtype(column.dtype, np.bool_):\n        return not column.any()\n    elif hasattr(column, \"__len__\"):\n        return (\n            len(column) == 0\n            or (all(isinstance(col, bool) for col in column)\n            and not any(column))\n        )\n    else:\n        return False\n",
      "\ndef _is_empty_column_selection(column):\n    \"\"\"\n    Return True if the column selection is empty (empty list or all-False\n    boolean array).\n\n    \"\"\"\n    if hasattr(column, \"dtype\") and np.issubdtype(column.dtype, np.bool_):\n        return not column.any()\n    elif hasattr(column, \"__len__\"):\n        return (\n            len(column) == 0\n            or (all(isinstance(col, bool) for col in column)\n            and not any(column))\n        )\n    else:\n        return False\n",
      "\ndef _is_empty_column_selection(column):\n    \"\"\"\n    Return True if the column selection is empty (empty list or all-False\n    boolean array).\n\n    \"\"\"\n    if hasattr(column, \"dtype\") and np.issubdtype(column.dtype, np.bool_):\n        return not column.any()\n    elif hasattr(column, \"__len__\"):\n        return (\n            len(column) == 0\n            or (all(isinstance(col, bool) for col in column)\n            and not any(column))\n        )\n    else:\n        return False\n",
      "\ndef _is_empty_column_selection(column):\n    \"\"\"\n    Return True if the column selection is empty (empty list or all-False\n    boolean array).\n\n    \"\"\"\n    if hasattr(column, \"dtype\") and np.issubdtype(column.dtype, np.bool_):\n        return not column.any()\n    elif hasattr(column, \"__len__\"):\n        return (\n            len(column) == 0\n            or (all(isinstance(col, bool) for col in column)\n            and not any(column))\n        )\n    else:\n        return False\n"
    ]
  },
  "combined_diffs": {
    "raw_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..1d6da891f 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -391,6 +391,7 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     ).set_output(transform=output_config[\"dense\"])\n                 elif trans == \"drop\":\n                     continue\n+\n                 elif _is_empty_column_selection(columns):\n                     continue\n \n@@ -530,6 +531,7 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             transformer_with_feature_names_out\n         )\n \n+\n     def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n         \"\"\"Add prefix for feature names out that includes the transformer names.\n \n@@ -854,6 +856,7 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 pd = check_pandas_support(\"transform\")\n                 output = pd.concat(Xs, axis=1)\n \n+\n                 # If all transformers define `get_feature_names_out`, then transform\n                 # will adjust the column names to be consistent with\n                 # verbose_feature_names_out. Here we prefix the feature names if\n@@ -862,12 +865,23 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 if not self.verbose_feature_names_out:\n                     return output\n \n-                transformer_names = [\n-                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n-                ]\n+\n+                # Get all transformers including those with empty columns\n+                all_transformers = list(self._iter(fitted=True, replace_strings=True, \n+                                                 skip_empty=False))\n                 feature_names_outs = [X.columns for X in Xs]\n+                \n+                # Filter to only include transformers that actually produced output\n+                transformer_names = []\n+                filtered_feature_names_outs = []\n+                \n+                for i, (name, trans, columns) in enumerate(all_transformers):\n+                    if i < len(Xs) and len(Xs[i].columns) > 0:\n+                        transformer_names.append(name)\n+                        filtered_feature_names_outs.append(feature_names_outs[i])\n+                \n                 names_out = self._add_prefix_for_feature_names_out(\n-                    list(zip(transformer_names, feature_names_outs))\n+                    list(zip(transformer_names, filtered_feature_names_outs))\n                 )\n                 output.columns = names_out\n                 return output\n@@ -904,6 +918,7 @@ def _check_X(X):\n     return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n \n \n+\n def _is_empty_column_selection(column):\n     \"\"\"\n     Return True if the column selection is empty (empty list or all-False\n",
    "variant_0": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..00a8eca04 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -391,8 +391,15 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     ).set_output(transform=output_config[\"dense\"])\n                 elif trans == \"drop\":\n                     continue\n-                elif _is_empty_column_selection(columns):\n-                    continue\n+\n+                # List of tuples (name, fitted_transformer, column) for\n+                # transformers that actually produced output\n+                non_empty_transformers = []\n+                for name, fitted_transformer, column in self._iter(fitted=True, replace_strings=True):\n+                    if not _is_empty_column_selection(column):\n+                        non_empty_transformers.append((name, fitted_transformer, column))\n+                \n+                transformer_names = [name for name, _, _ in non_empty_transformers]\n \n             if column_as_strings:\n                 # Convert all columns to using their string labels\n@@ -530,28 +537,57 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             transformer_with_feature_names_out\n         )\n \n-    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n-        \"\"\"Add prefix for feature names out that includes the transformer names.\n+\n+    def _hstack(self, Xs):\n+        \"\"\"Stacks Xs horizontally.\n+\n+        This allows subclasses to control the stacking behavior, while reusing\n+        everything else from ColumnTransformer.\n \n         Parameters\n         ----------\n-        transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n-            The tuple consistent of the transformer's name and its feature names out.\n-\n-        Returns\n-        -------\n-        feature_names_out : ndarray of shape (n_features,), dtype=str\n-            Transformed feature names.\n+        Xs : list of {array-like, sparse matrix, dataframe}\n         \"\"\"\n-        if self.verbose_feature_names_out:\n-            # Prefix the feature names out with the transformers name\n-            names = list(\n-                chain.from_iterable(\n-                    (f\"{name}__{i}\" for i in feature_names_out)\n-                    for name, feature_names_out in transformer_with_feature_names_out\n-                )\n-            )\n-            return np.asarray(names, dtype=object)\n+        if self._n_features == 0:\n+            # No columns were selected\n+            if hasattr(Xs[0], \"iloc\"):\n+                return Xs[0].iloc[:, :0]\n+            else:\n+                return np.empty((Xs[0].shape[0], 0))\n+\n+        config = _get_output_config(\"transform\", self)\n+        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n+            pd = check_pandas_support(\"transform\")\n+            output = pd.concat(Xs, axis=1)\n+\n+            # `output` is a pd.DataFrame. When `self.verbose_feature_names_out=True`,\n+            # we need to update the column names from the fitted transformers\n+            if not self._feature_names_out_uses_transformer_names:\n+                output.columns = self.get_feature_names_out()\n+            else:\n+                # Filter transformer names to match non-empty outputs in Xs\n+                transformer_names = []\n+                for name, transformer, columns in self._iter(fitted=True, replace_strings=True):\n+                    if not _is_empty_column_selection(columns):\n+                        transformer_names.append(name)\n+                \n+                # Only proceed if we have transformer names that match the outputs\n+                if len(transformer_names) == len(Xs):\n+                    transformer_with_feature_names_out = []\n+                    for i, (name, transformer, columns) in enumerate(self._iter(fitted=True, replace_strings=True)):\n+                        if not _is_empty_column_selection(columns):\n+                            feature_names_out = transformer.get_feature_names_out()\n+                            transformer_with_feature_names_out.append((name, feature_names_out))\n+\n+                    if transformer_with_feature_names_out:\n+                        feature_names = self._add_prefix_for_feature_names_out(\n+                            transformer_with_feature_names_out\n+                        )\n+                        output.columns = feature_names\n+\n+            return output\n+\n+        return np.hstack(Xs)\n \n         # verbose_feature_names_out is False\n         # Check that names are all unique without a prefix\n@@ -854,18 +890,34 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 pd = check_pandas_support(\"transform\")\n                 output = pd.concat(Xs, axis=1)\n \n-                # If all transformers define `get_feature_names_out`, then transform\n-                # will adjust the column names to be consistent with\n-                # verbose_feature_names_out. Here we prefix the feature names if\n-                # verbose_feature_names_out=True.\n-\n                 if not self.verbose_feature_names_out:\n                     return output\n \n-                transformer_names = [\n-                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n-                ]\n-                feature_names_outs = [X.columns for X in Xs]\n+                # Get transformer names and feature names, filtering to match actual outputs\n+                transformer_info = list(self._iter(fitted=True, replace_strings=True))\n+                transformer_names = []\n+                feature_names_outs = []\n+                \n+                # Only include transformers that produced non-empty outputs\n+                for i, (name, transformer, columns) in enumerate(transformer_info):\n+                    if i < len(Xs) and hasattr(Xs[i], 'columns') and len(Xs[i].columns) > 0:\n+                        transformer_names.append(name)\n+                        feature_names_outs.append(Xs[i].columns)\n+                \n+                names_out = self._add_prefix_for_feature_names_out(\n+                    list(zip(transformer_names, feature_names_outs))\n+                )\n+                output.columns = names_out\n+                    return output\n+\n+\n+                transformer_names = []\n+                feature_names_outs = []\n+                for i, (name, transformer, columns) in enumerate(self._iter(fitted=True, replace_strings=True)):\n+                    if i < len(Xs) and hasattr(Xs[i], 'columns') and len(Xs[i].columns) > 0:\n+                        transformer_names.append(name)\n+                        feature_names_outs.append(Xs[i].columns)\n+                \n                 names_out = self._add_prefix_for_feature_names_out(\n                     list(zip(transformer_names, feature_names_outs))\n                 )\n@@ -904,20 +956,31 @@ def _check_X(X):\n     return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n \n \n-def _is_empty_column_selection(column):\n+\n+def _hstack(self, Xs):\n     \"\"\"\n-    Return True if the column selection is empty (empty list or all-False\n-    boolean array).\n+    Stacks Xs horizontally.\n+\n+    This allows subclasses to control the stacking behavior, while reusing\n+    everything else from ColumnTransformer.\n \n+    Parameters\n+    ----------\n+    Xs : list of {array-like, sparse matrix, dataframe}\n     \"\"\"\n-    if hasattr(column, \"dtype\") and np.issubdtype(column.dtype, np.bool_):\n-        return not column.any()\n-    elif hasattr(column, \"__len__\"):\n-        return (\n-            len(column) == 0\n-            or all(isinstance(col, bool) for col in column)\n-            and not any(column)\n-        )\n+    config = _get_output_config(\"transform\", self)\n+    if config[\"dense\"] == \"pandas\":\n+        pd = check_pandas_support(\"transform\")\n+        output = pd.concat(Xs, axis=1)\n+        # `pd.concat` ignores the index so, we set it here\n+        if hasattr(self, \"_df_columns\") and hasattr(self._df_columns, \"index\"):\n+            output.index = self._df_columns.index\n+        output.columns = self.get_feature_names_out()\n+    elif sparse.issparse(Xs[0]):\n+        output = sparse.hstack(Xs).tocsr()\n+    else:\n+        output = np.hstack(Xs)\n+    return output\n     else:\n         return False\n \n",
    "variant_1": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..28c96b923 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -391,8 +391,29 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     ).set_output(transform=output_config[\"dense\"])\n                 elif trans == \"drop\":\n                     continue\n-                elif _is_empty_column_selection(columns):\n-                    continue\n+\n+                # Get transformer names that actually produced output\n+                transformer_names = []\n+                for name, trans, columns in self._iter(fitted=True, replace_strings=True):\n+                    if not _is_empty_column_selection(columns):\n+                        transformer_names.append(name)\n+                \n+                # Ensure we have matching number of names and outputs\n+                if len(transformer_names) != len(Xs):\n+                    # Fallback: create generic names if mismatch persists\n+                    transformer_names = [f\"transformer_{i}\" for i in range(len(Xs))]\n+                \n+                output_config = _get_output_config(\"transform\", self)\n+                if output_config[\"dense\"] == \"pandas\":\n+                    pd = check_pandas_support(\"transform\")\n+                    feature_names = self._add_prefix_for_feature_names_out(\n+                        list(\n+                            chain.from_iterable(\n+                                (X.columns for X in Xs if hasattr(X, \"columns\"))\n+                            )\n+                        ),\n+                        transformer_names,\n+                    )\n \n             if column_as_strings:\n                 # Convert all columns to using their string labels\n@@ -530,28 +551,34 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             transformer_with_feature_names_out\n         )\n \n-    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n-        \"\"\"Add prefix for feature names out that includes the transformer names.\n+\n+    def _hstack(self, Xs):\n+        \"\"\"\n+        Stacks Xs horizontally.\n+\n+        This allows subclasses to control the stacking behavior, while reusing\n+        everything else from ColumnTransformer.\n \n         Parameters\n         ----------\n-        transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n-            The tuple consistent of the transformer's name and its feature names out.\n-\n-        Returns\n-        -------\n-        feature_names_out : ndarray of shape (n_features,), dtype=str\n-            Transformed feature names.\n+        Xs : list of {array-like, sparse matrix, dataframe}\n         \"\"\"\n-        if self.verbose_feature_names_out:\n-            # Prefix the feature names out with the transformers name\n-            names = list(\n-                chain.from_iterable(\n-                    (f\"{name}__{i}\" for i in feature_names_out)\n-                    for name, feature_names_out in transformer_with_feature_names_out\n-                )\n-            )\n-            return np.asarray(names, dtype=object)\n+        config = _get_output_config(\"transform\", self)\n+        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n+            pd = check_pandas_support(\"transform\")\n+            output = pd.concat(Xs, axis=1)\n+            # `pd.concat` adds a redundant level to the column MultiIndex\n+            output.columns = output.columns.droplevel(0)\n+            return output\n+\n+        if any(sparse.issparse(X) for X in Xs):\n+            return sparse.hstack(Xs).tocsr()\n+        else:\n+            Xs = [X for X in Xs if X.shape[1] > 0]\n+            if not Xs:\n+                # All transformers produced empty outputs\n+                return np.empty((self._n_features, 0))\n+            return np.hstack(Xs)\n \n         # verbose_feature_names_out is False\n         # Check that names are all unique without a prefix\n@@ -854,18 +881,44 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 pd = check_pandas_support(\"transform\")\n                 output = pd.concat(Xs, axis=1)\n \n-                # If all transformers define `get_feature_names_out`, then transform\n-                # will adjust the column names to be consistent with\n-                # verbose_feature_names_out. Here we prefix the feature names if\n-                # verbose_feature_names_out=True.\n-\n                 if not self.verbose_feature_names_out:\n                     return output\n \n-                transformer_names = [\n-                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n+                # Get transformer names and feature names, but only for transformers\n+                # that actually produced output (non-empty Xs)\n+                all_transformers = [\n+                    t for t in self._iter(fitted=True, replace_strings=True)\n                 ]\n-                feature_names_outs = [X.columns for X in Xs]\n+                transformer_names = []\n+                feature_names_outs = []\n+                \n+                # Only include transformers that produced non-empty output\n+                transformer_idx = 0\n+                for i, X in enumerate(Xs):\n+                    if X.shape[1] > 0:  # Only include non-empty outputs\n+                        # Find the corresponding transformer for this output\n+                        while transformer_idx < len(all_transformers):\n+                            transformer_name, transformer, columns = all_transformers[transformer_idx]\n+                            transformer_idx += 1\n+                            if not _is_empty_column_selection(columns):\n+                                transformer_names.append(transformer_name)\n+                                feature_names_outs.append(X.columns)\n+                                break\n+                \n+                names_out = self._add_prefix_for_feature_names_out(\n+                    list(zip(transformer_names, feature_names_outs))\n+                )\n+                output.columns = names_out\n+                    return output\n+\n+\n+                transformer_names = []\n+                feature_names_outs = []\n+                for i, (name, transformer, columns) in enumerate(self._iter(fitted=True, replace_strings=True)):\n+                    if i < len(Xs) and hasattr(Xs[i], 'columns') and len(Xs[i].columns) > 0:\n+                        transformer_names.append(name)\n+                        feature_names_outs.append(Xs[i].columns)\n+                \n                 names_out = self._add_prefix_for_feature_names_out(\n                     list(zip(transformer_names, feature_names_outs))\n                 )\n@@ -904,6 +957,7 @@ def _check_X(X):\n     return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n \n \n+\n def _is_empty_column_selection(column):\n     \"\"\"\n     Return True if the column selection is empty (empty list or all-False\n@@ -915,11 +969,13 @@ def _is_empty_column_selection(column):\n     elif hasattr(column, \"__len__\"):\n         return (\n             len(column) == 0\n-            or all(isinstance(col, bool) for col in column)\n-            and not any(column)\n+            or (all(isinstance(col, bool) for col in column)\n+            and not any(column))\n         )\n     else:\n         return False\n+    else:\n+        return False\n \n \n def _get_transformer_list(estimators):\n",
    "variant_2": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..69c7346e0 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -391,8 +391,26 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     ).set_output(transform=output_config[\"dense\"])\n                 elif trans == \"drop\":\n                     continue\n-                elif _is_empty_column_selection(columns):\n-                    continue\n+\n+                # Create feature names for the concatenated output\n+                transformer_names = []\n+                non_empty_indices = []\n+                \n+                # Only include transformers that produced non-empty output\n+                for i, (name, trans, columns, weight) in enumerate(\n+                    self._iter(fitted=True, replace_strings=True)\n+                ):\n+                    if i < len(Xs) and Xs[i].shape[1] > 0:\n+                        transformer_names.append(name)\n+                        non_empty_indices.append(i)\n+                \n+                # Filter Xs to only include non-empty outputs\n+                Xs = [Xs[i] for i in non_empty_indices]\n+                \n+                feature_names_outs = [X.columns for X in Xs]\n+                names_out = self._add_prefix_for_feature_names_out(\n+                    list(zip(transformer_names, feature_names_outs))\n+                )\n \n             if column_as_strings:\n                 # Convert all columns to using their string labels\n@@ -530,6 +548,7 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             transformer_with_feature_names_out\n         )\n \n+\n     def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n         \"\"\"Add prefix for feature names out that includes the transformer names.\n \n@@ -854,18 +873,43 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 pd = check_pandas_support(\"transform\")\n                 output = pd.concat(Xs, axis=1)\n \n-                # If all transformers define `get_feature_names_out`, then transform\n-                # will adjust the column names to be consistent with\n-                # verbose_feature_names_out. Here we prefix the feature names if\n-                # verbose_feature_names_out=True.\n-\n                 if not self.verbose_feature_names_out:\n                     return output\n \n-                transformer_names = [\n-                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n-                ]\n-                feature_names_outs = [X.columns for X in Xs]\n+                # Get transformer names and feature names, but only for transformers\n+                # that actually produced output (non-empty Xs)\n+                all_transformers = list(self._iter(fitted=True, replace_strings=True))\n+                transformer_names = []\n+                feature_names_outs = []\n+                \n+                # Only include transformers that have corresponding non-empty outputs\n+                transformer_idx = 0\n+                for X in Xs:\n+                    if hasattr(X, 'shape') and X.shape[1] > 0:\n+                        # Find the corresponding transformer for this output\n+                        while transformer_idx < len(all_transformers):\n+                            transformer_name = all_transformers[transformer_idx][0]\n+                            transformer_idx += 1\n+                            # Skip transformers with empty column selections\n+                            if not _is_empty_column_selection(all_transformers[transformer_idx - 1][2]):\n+                                transformer_names.append(transformer_name)\n+                                feature_names_outs.append(X.columns)\n+                                break\n+                \n+                names_out = self._add_prefix_for_feature_names_out(\n+                    list(zip(transformer_names, feature_names_outs))\n+                )\n+                output.columns = names_out\n+                    return output\n+\n+\n+                transformer_names = []\n+                feature_names_outs = []\n+                for i, (name, transformer, columns) in enumerate(self._iter(fitted=True, replace_strings=True)):\n+                    if i < len(Xs) and hasattr(Xs[i], 'columns') and len(Xs[i].columns) > 0:\n+                        transformer_names.append(name)\n+                        feature_names_outs.append(Xs[i].columns)\n+                \n                 names_out = self._add_prefix_for_feature_names_out(\n                     list(zip(transformer_names, feature_names_outs))\n                 )\n@@ -904,6 +948,7 @@ def _check_X(X):\n     return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n \n \n+\n def _is_empty_column_selection(column):\n     \"\"\"\n     Return True if the column selection is empty (empty list or all-False\n@@ -915,11 +960,13 @@ def _is_empty_column_selection(column):\n     elif hasattr(column, \"__len__\"):\n         return (\n             len(column) == 0\n-            or all(isinstance(col, bool) for col in column)\n-            and not any(column)\n+            or (all(isinstance(col, bool) for col in column)\n+            and not any(column))\n         )\n     else:\n         return False\n+    else:\n+        return False\n \n \n def _get_transformer_list(estimators):\n",
    "variant_3": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..295a79773 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -391,8 +391,20 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     ).set_output(transform=output_config[\"dense\"])\n                 elif trans == \"drop\":\n                     continue\n-                elif _is_empty_column_selection(columns):\n-                    continue\n+\n+                # Get transformer names that actually produced output\n+                transformer_names = []\n+                for i, (name, trans, columns) in enumerate(self._iter(fitted=True, replace_strings=True)):\n+                    # Only include transformers that have corresponding output in Xs\n+                    if i < len(Xs):\n+                        transformer_names.append(name)\n+                \n+                feature_names_outs = [\n+                    X.columns for X in Xs if hasattr(X, \"columns\")\n+                ]\n+                names_out = self._add_prefix_for_feature_names_out(\n+                    list(zip(transformer_names, feature_names_outs))\n+                )\n \n             if column_as_strings:\n                 # Convert all columns to using their string labels\n@@ -530,28 +542,33 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             transformer_with_feature_names_out\n         )\n \n-    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n-        \"\"\"Add prefix for feature names out that includes the transformer names.\n+\n+    def _hstack(self, Xs):\n+        \"\"\"\n+        Stacks Xs horizontally.\n+\n+        This allows subclasses to control the stacking behavior, while reusing\n+        everything else from ColumnTransformer.\n \n         Parameters\n         ----------\n-        transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n-            The tuple consistent of the transformer's name and its feature names out.\n-\n-        Returns\n-        -------\n-        feature_names_out : ndarray of shape (n_features,), dtype=str\n-            Transformed feature names.\n+        Xs : list of {array-like, sparse matrix, dataframe}\n         \"\"\"\n-        if self.verbose_feature_names_out:\n-            # Prefix the feature names out with the transformers name\n-            names = list(\n-                chain.from_iterable(\n-                    (f\"{name}__{i}\" for i in feature_names_out)\n-                    for name, feature_names_out in transformer_with_feature_names_out\n-                )\n-            )\n-            return np.asarray(names, dtype=object)\n+        config = _get_output_config(\"transform\", self)\n+        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n+            pd = check_pandas_support(\"transform\")\n+            output = pd.concat(Xs, axis=1)\n+            # `pd.concat` adds a `0` suffix to columns with the same name;\n+            # we remove the suffix here.\n+            if len(Xs) > 1:\n+                output.columns = output.columns.str.removesuffix(\"_0\")\n+            output.index = Xs[0].index\n+            return output\n+\n+        if any(sparse.issparse(X) for X in Xs):\n+            return sparse.hstack(Xs).tocsr()\n+        else:\n+            return np.hstack(Xs)\n \n         # verbose_feature_names_out is False\n         # Check that names are all unique without a prefix\n@@ -854,18 +871,36 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 pd = check_pandas_support(\"transform\")\n                 output = pd.concat(Xs, axis=1)\n \n-                # If all transformers define `get_feature_names_out`, then transform\n-                # will adjust the column names to be consistent with\n-                # verbose_feature_names_out. Here we prefix the feature names if\n-                # verbose_feature_names_out=True.\n-\n                 if not self.verbose_feature_names_out:\n                     return output\n \n-                transformer_names = [\n-                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n-                ]\n+                # Get transformer names and outputs, filtering to match non-empty outputs\n+                transformer_info = list(self._iter(fitted=True, replace_strings=True))\n                 feature_names_outs = [X.columns for X in Xs]\n+                \n+                # Filter transformer names to match the actual outputs in Xs\n+                # by excluding transformers that produced empty outputs\n+                filtered_transformer_names = []\n+                for i, (name, transformer, columns) in enumerate(transformer_info):\n+                    if i < len(Xs) and len(Xs[i].columns) > 0:\n+                        filtered_transformer_names.append(name)\n+                \n+                # Ensure we have matching lengths\n+                if len(filtered_transformer_names) == len(feature_names_outs):\n+                    names_out = self._add_prefix_for_feature_names_out(\n+                        list(zip(filtered_transformer_names, feature_names_outs))\n+                    )\n+                    output.columns = names_out\n+                    return output\n+\n+\n+                transformer_names = []\n+                feature_names_outs = []\n+                for i, (name, transformer, columns) in enumerate(self._iter(fitted=True, replace_strings=True)):\n+                    if i < len(Xs) and hasattr(Xs[i], 'columns') and len(Xs[i].columns) > 0:\n+                        transformer_names.append(name)\n+                        feature_names_outs.append(Xs[i].columns)\n+                \n                 names_out = self._add_prefix_for_feature_names_out(\n                     list(zip(transformer_names, feature_names_outs))\n                 )\n@@ -904,6 +939,7 @@ def _check_X(X):\n     return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n \n \n+\n def _is_empty_column_selection(column):\n     \"\"\"\n     Return True if the column selection is empty (empty list or all-False\n@@ -915,11 +951,13 @@ def _is_empty_column_selection(column):\n     elif hasattr(column, \"__len__\"):\n         return (\n             len(column) == 0\n-            or all(isinstance(col, bool) for col in column)\n-            and not any(column)\n+            or (all(isinstance(col, bool) for col in column)\n+            and not any(column))\n         )\n     else:\n         return False\n+    else:\n+        return False\n \n \n def _get_transformer_list(estimators):\n",
    "variant_4": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..526a0303c 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -391,8 +391,23 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     ).set_output(transform=output_config[\"dense\"])\n                 elif trans == \"drop\":\n                     continue\n-                elif _is_empty_column_selection(columns):\n-                    continue\n+\n+                # Get transformer names that actually produced output\n+                transformer_names = []\n+                for (name, trans, columns), X in zip(\n+                    self._iter(fitted=True, replace_strings=True), Xs\n+                ):\n+                    if X.shape[1] > 0:  # Only include transformers with non-empty output\n+                        transformer_names.append(name)\n+                \n+                # Get feature names for transformers that produced output\n+                feature_names_outs = [\n+                    self._add_prefix_for_feature_names_out(\n+                        list(X.columns), transformer_names[i]\n+                    )\n+                    for i, X in enumerate(Xs)\n+                    if X.shape[1] > 0\n+                ]\n \n             if column_as_strings:\n                 # Convert all columns to using their string labels\n@@ -530,28 +545,39 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             transformer_with_feature_names_out\n         )\n \n-    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n-        \"\"\"Add prefix for feature names out that includes the transformer names.\n+\n+    def _hstack(self, Xs):\n+        \"\"\"Stacks Xs horizontally.\n+\n+        This allows subclasses to control the stacking behavior, while reusing\n+        everything else from ColumnTransformer.\n \n         Parameters\n         ----------\n-        transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n-            The tuple consistent of the transformer's name and its feature names out.\n-\n-        Returns\n-        -------\n-        feature_names_out : ndarray of shape (n_features,), dtype=str\n-            Transformed feature names.\n+        Xs : list of {array-like, sparse matrix, dataframe}\n         \"\"\"\n-        if self.verbose_feature_names_out:\n-            # Prefix the feature names out with the transformers name\n-            names = list(\n-                chain.from_iterable(\n-                    (f\"{name}__{i}\" for i in feature_names_out)\n-                    for name, feature_names_out in transformer_with_feature_names_out\n-                )\n-            )\n-            return np.asarray(names, dtype=object)\n+        if self._n_features == 0:\n+            # No columns were selected\n+            if hasattr(Xs[0], \"iloc\"):\n+                return Xs[0].iloc[:, :0]\n+            else:\n+                return np.empty((Xs[0].shape[0], 0))\n+\n+        config = _get_output_config(\"transform\", self)\n+        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n+            pd = check_pandas_support(\"transform\")\n+            output = pd.concat(Xs, axis=1)\n+\n+            # `pd.concat` adds a integer suffix when concat'ing transformers\n+            # with identical feature names\n+            if not output.columns.is_unique:\n+                output.columns = self.get_feature_names_out()\n+\n+        elif sparse.issparse(Xs[0]):\n+            output = sparse.hstack(Xs).tocsr()\n+        else:\n+            output = np.hstack(Xs)\n+        return output\n \n         # verbose_feature_names_out is False\n         # Check that names are all unique without a prefix\n@@ -854,18 +880,45 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 pd = check_pandas_support(\"transform\")\n                 output = pd.concat(Xs, axis=1)\n \n-                # If all transformers define `get_feature_names_out`, then transform\n-                # will adjust the column names to be consistent with\n-                # verbose_feature_names_out. Here we prefix the feature names if\n-                # verbose_feature_names_out=True.\n-\n                 if not self.verbose_feature_names_out:\n                     return output\n \n-                transformer_names = [\n-                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n-                ]\n-                feature_names_outs = [X.columns for X in Xs]\n+                # Get transformer names and feature names, but only for transformers\n+                # that actually produced output (non-empty Xs)\n+                all_transformers = list(self._iter(fitted=True, replace_strings=True))\n+                transformer_names = []\n+                feature_names_outs = []\n+                \n+                # Only include transformers that have corresponding non-empty outputs\n+                transformer_idx = 0\n+                for i, X in enumerate(Xs):\n+                    if X.shape[1] > 0:  # Only include transformers with actual output columns\n+                        # Find the corresponding transformer name\n+                        while transformer_idx < len(all_transformers):\n+                            transformer_name, transformer, columns = all_transformers[transformer_idx]\n+                            transformer_idx += 1\n+                            if not _is_empty_column_selection(columns):\n+                                transformer_names.append(transformer_name)\n+                                feature_names_outs.append(X.columns)\n+                                break\n+                \n+                names_out = self._add_prefix_for_feature_names_out(\n+                    list(zip(transformer_names, feature_names_outs))\n+                )\n+                output.columns = names_out\n+                    return output\n+\n+\n+                transformer_names = []\n+                feature_names_outs = []\n+                \n+                # Only include transformers that actually produced output\n+                transformer_iter = self._iter(fitted=True, replace_strings=True)\n+                for i, (name, transformer, columns) in enumerate(transformer_iter):\n+                    if i < len(Xs) and not Xs[i].empty:\n+                        transformer_names.append(name)\n+                        feature_names_outs.append(Xs[i].columns)\n+                \n                 names_out = self._add_prefix_for_feature_names_out(\n                     list(zip(transformer_names, feature_names_outs))\n                 )\n@@ -904,6 +957,7 @@ def _check_X(X):\n     return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n \n \n+\n def _is_empty_column_selection(column):\n     \"\"\"\n     Return True if the column selection is empty (empty list or all-False\n@@ -915,11 +969,13 @@ def _is_empty_column_selection(column):\n     elif hasattr(column, \"__len__\"):\n         return (\n             len(column) == 0\n-            or all(isinstance(col, bool) for col in column)\n-            and not any(column)\n+            or (all(isinstance(col, bool) for col in column)\n+            and not any(column))\n         )\n     else:\n         return False\n+    else:\n+        return False\n \n \n def _get_transformer_list(estimators):\n",
    "variant_5": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..4b10d7d62 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -391,8 +391,30 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     ).set_output(transform=output_config[\"dense\"])\n                 elif trans == \"drop\":\n                     continue\n-                elif _is_empty_column_selection(columns):\n-                    continue\n+\n+                # Get transformer names that actually produced output\n+                transformer_names = []\n+                for name, trans, columns in self._iter(fitted=True, replace_strings=True):\n+                    if trans == \"passthrough\":\n+                        trans = FunctionTransformer(\n+                            accept_sparse=True,\n+                            check_inverse=False,\n+                            feature_names_out=\"one-to-one\",\n+                        ).set_output(transform=output_config[\"dense\"])\n+                    elif trans == \"drop\":\n+                        continue\n+                    elif _is_empty_column_selection(columns):\n+                        continue\n+                    transformer_names.append(name)\n+                \n+                # Only proceed if we have matching transformers and outputs\n+                if len(transformer_names) == len(Xs):\n+                    feature_names_outs = [\n+                        X.columns if hasattr(X, \"columns\") else None for X in Xs\n+                    ]\n+                    feature_names_out = self._add_prefix_for_feature_names_out(\n+                        list(zip(transformer_names, feature_names_outs))\n+                    )\n \n             if column_as_strings:\n                 # Convert all columns to using their string labels\n@@ -530,28 +552,33 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             transformer_with_feature_names_out\n         )\n \n-    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n-        \"\"\"Add prefix for feature names out that includes the transformer names.\n+\n+    def _hstack(self, Xs):\n+        \"\"\"\n+        Stacks Xs horizontally.\n+\n+        This allows subclasses to control the stacking behavior, while reusing\n+        everything else from ColumnTransformer.\n \n         Parameters\n         ----------\n-        transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n-            The tuple consistent of the transformer's name and its feature names out.\n-\n-        Returns\n-        -------\n-        feature_names_out : ndarray of shape (n_features,), dtype=str\n-            Transformed feature names.\n+        Xs : list of {array-like, sparse matrix, dataframe}\n         \"\"\"\n-        if self.verbose_feature_names_out:\n-            # Prefix the feature names out with the transformers name\n-            names = list(\n-                chain.from_iterable(\n-                    (f\"{name}__{i}\" for i in feature_names_out)\n-                    for name, feature_names_out in transformer_with_feature_names_out\n-                )\n-            )\n-            return np.asarray(names, dtype=object)\n+        config = _get_output_config(\"transform\", self)\n+        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n+            pd = check_pandas_support(\"transform\")\n+            output = pd.concat(Xs, axis=1)\n+            # `pd.concat` adds a keys level to the columns, remove it\n+            if isinstance(output.columns, pd.MultiIndex):\n+                output.columns = output.columns.get_level_values(-1)\n+            output.index = Xs[0].index\n+            return output\n+\n+        if any(sparse.issparse(f) for f in Xs):\n+            Xs = sparse.hstack(Xs).tocsr()\n+        else:\n+            Xs = np.hstack(Xs)\n+        return Xs\n \n         # verbose_feature_names_out is False\n         # Check that names are all unique without a prefix\n@@ -854,18 +881,29 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 pd = check_pandas_support(\"transform\")\n                 output = pd.concat(Xs, axis=1)\n \n-                # If all transformers define `get_feature_names_out`, then transform\n-                # will adjust the column names to be consistent with\n-                # verbose_feature_names_out. Here we prefix the feature names if\n-                # verbose_feature_names_out=True.\n-\n                 if not self.verbose_feature_names_out:\n                     return output\n \n-                transformer_names = [\n-                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n+                # Get transformer names and feature names for non-empty outputs only\n+                transformer_info = [\n+                    (name, X.columns) for (name, _, _), X in zip(\n+                        self._iter(fitted=True, replace_strings=True), Xs\n+                    ) if len(X.columns) > 0\n                 ]\n-                feature_names_outs = [X.columns for X in Xs]\n+                \n+                if transformer_info:\n+                    names_out = self._add_prefix_for_feature_names_out(transformer_info)\n+                    output.columns = names_out\n+                    return output\n+\n+\n+                transformer_names = []\n+                feature_names_outs = []\n+                for i, (name, transformer, columns) in enumerate(self._iter(fitted=True, replace_strings=True)):\n+                    if i < len(Xs) and hasattr(Xs[i], 'columns') and len(Xs[i].columns) > 0:\n+                        transformer_names.append(name)\n+                        feature_names_outs.append(Xs[i].columns)\n+                \n                 names_out = self._add_prefix_for_feature_names_out(\n                     list(zip(transformer_names, feature_names_outs))\n                 )\n@@ -904,6 +942,7 @@ def _check_X(X):\n     return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n \n \n+\n def _is_empty_column_selection(column):\n     \"\"\"\n     Return True if the column selection is empty (empty list or all-False\n@@ -915,11 +954,13 @@ def _is_empty_column_selection(column):\n     elif hasattr(column, \"__len__\"):\n         return (\n             len(column) == 0\n-            or all(isinstance(col, bool) for col in column)\n-            and not any(column)\n+            or (all(isinstance(col, bool) for col in column)\n+            and not any(column))\n         )\n     else:\n         return False\n+    else:\n+        return False\n \n \n def _get_transformer_list(estimators):\n",
    "variant_6": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..76ea27a86 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -391,8 +391,25 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     ).set_output(transform=output_config[\"dense\"])\n                 elif trans == \"drop\":\n                     continue\n-                elif _is_empty_column_selection(columns):\n-                    continue\n+\n+                # List of feature names for each transformer.\n+                if hasattr(self, 'feature_names_in_'):\n+                    # Filter out transformers that produced empty outputs\n+                    # to align with the actual Xs list\n+                    non_empty_transformers = []\n+                    transformer_idx = 0\n+                    for name, trans, columns in self._iter(fitted=True, replace_strings=True):\n+                        if not _is_empty_column_selection(columns):\n+                            non_empty_transformers.append((name, trans, columns))\n+                            transformer_idx += 1\n+                    \n+                    feature_names_outs = [X.columns for name, trans, columns in non_empty_transformers]\n+                else:\n+                    feature_names_outs = [\n+                        _get_feature_names_out_with_prefix(name, trans)\n+                        for name, trans, columns in self._iter(fitted=True, replace_strings=True)\n+                        if not _is_empty_column_selection(columns)\n+                    ]\n \n             if column_as_strings:\n                 # Convert all columns to using their string labels\n@@ -530,28 +547,35 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             transformer_with_feature_names_out\n         )\n \n-    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n-        \"\"\"Add prefix for feature names out that includes the transformer names.\n+\n+    def _hstack(self, Xs):\n+        \"\"\"Stacks Xs horizontally.\n+\n+        This allows subclasses to control the stacking behavior, while reusing\n+        everything else from ColumnTransformer.\n \n         Parameters\n         ----------\n-        transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n-            The tuple consistent of the transformer's name and its feature names out.\n-\n-        Returns\n-        -------\n-        feature_names_out : ndarray of shape (n_features,), dtype=str\n-            Transformed feature names.\n+        Xs : list of {array-like, sparse matrix, dataframe}\n         \"\"\"\n-        if self.verbose_feature_names_out:\n-            # Prefix the feature names out with the transformers name\n-            names = list(\n-                chain.from_iterable(\n-                    (f\"{name}__{i}\" for i in feature_names_out)\n-                    for name, feature_names_out in transformer_with_feature_names_out\n-                )\n-            )\n-            return np.asarray(names, dtype=object)\n+        if self._n_features == 0:\n+            # No columns were selected\n+            if hasattr(Xs[0], \"iloc\"):\n+                return Xs[0].iloc[:, :0]\n+            else:\n+                return np.empty((Xs[0].shape[0], 0))\n+\n+        config = _get_output_config(\"transform\", self)\n+        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n+            pd = check_pandas_support(\"transform\")\n+            output = pd.concat(Xs, axis=1)\n+\n+            # `pd.concat` adds a `RangeIndex` for the columns, we want to\n+            # use the feature names that we generate.\n+            output.columns = self.get_feature_names_out()\n+            return output\n+\n+        return sparse.hstack(Xs).tocsr()\n \n         # verbose_feature_names_out is False\n         # Check that names are all unique without a prefix\n@@ -854,18 +878,34 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 pd = check_pandas_support(\"transform\")\n                 output = pd.concat(Xs, axis=1)\n \n-                # If all transformers define `get_feature_names_out`, then transform\n-                # will adjust the column names to be consistent with\n-                # verbose_feature_names_out. Here we prefix the feature names if\n-                # verbose_feature_names_out=True.\n-\n                 if not self.verbose_feature_names_out:\n                     return output\n \n-                transformer_names = [\n-                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n-                ]\n-                feature_names_outs = [X.columns for X in Xs]\n+                # Get transformer names and outputs, filtering to match actual outputs\n+                transformer_info = list(self._iter(fitted=True, replace_strings=True))\n+                transformer_names = []\n+                feature_names_outs = []\n+                \n+                # Only include transformers that produced non-empty outputs\n+                for i, (name, transformer, columns) in enumerate(transformer_info):\n+                    if i < len(Xs) and hasattr(Xs[i], 'columns') and len(Xs[i].columns) > 0:\n+                        transformer_names.append(name)\n+                        feature_names_outs.append(Xs[i].columns)\n+                \n+                names_out = self._add_prefix_for_feature_names_out(\n+                    list(zip(transformer_names, feature_names_outs))\n+                )\n+                output.columns = names_out\n+                    return output\n+\n+\n+                transformer_names = []\n+                feature_names_outs = []\n+                for i, (name, transformer, columns) in enumerate(self._iter(fitted=True, replace_strings=True)):\n+                    if i < len(Xs) and len(Xs[i].columns) > 0:\n+                        transformer_names.append(name)\n+                        feature_names_outs.append(Xs[i].columns)\n+                \n                 names_out = self._add_prefix_for_feature_names_out(\n                     list(zip(transformer_names, feature_names_outs))\n                 )\n@@ -904,6 +944,7 @@ def _check_X(X):\n     return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n \n \n+\n def _is_empty_column_selection(column):\n     \"\"\"\n     Return True if the column selection is empty (empty list or all-False\n@@ -915,11 +956,13 @@ def _is_empty_column_selection(column):\n     elif hasattr(column, \"__len__\"):\n         return (\n             len(column) == 0\n-            or all(isinstance(col, bool) for col in column)\n-            and not any(column)\n+            or (all(isinstance(col, bool) for col in column)\n+            and not any(column))\n         )\n     else:\n         return False\n+    else:\n+        return False\n \n \n def _get_transformer_list(estimators):\n",
    "variant_7": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..1fd48fa19 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -391,8 +391,21 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     ).set_output(transform=output_config[\"dense\"])\n                 elif trans == \"drop\":\n                     continue\n-                elif _is_empty_column_selection(columns):\n-                    continue\n+\n+                # Get transformer names and outputs, filtering out empty outputs\n+                transformer_names = []\n+                filtered_Xs = []\n+                \n+                for name, trans, columns, _ in self._iter(fitted=True, replace_strings=True):\n+                    # Find the corresponding output in Xs\n+                    transformer_idx = [t[0] for t in self.transformers_].index(name)\n+                    if transformer_idx < len(Xs) and Xs[transformer_idx].shape[1] > 0:\n+                        transformer_names.append(name)\n+                        filtered_Xs.append(Xs[transformer_idx])\n+                \n+                # Use filtered lists for feature naming\n+                Xs = filtered_Xs\n+                transformer_names = transformer_names\n \n             if column_as_strings:\n                 # Convert all columns to using their string labels\n@@ -530,28 +543,34 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             transformer_with_feature_names_out\n         )\n \n-    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n-        \"\"\"Add prefix for feature names out that includes the transformer names.\n+\n+    def _hstack(self, Xs):\n+        \"\"\"\n+        Stacks Xs horizontally.\n+\n+        This allows subclasses to control the stacking behavior, while reusing\n+        everything else from ColumnTransformer.\n \n         Parameters\n         ----------\n-        transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n-            The tuple consistent of the transformer's name and its feature names out.\n-\n-        Returns\n-        -------\n-        feature_names_out : ndarray of shape (n_features,), dtype=str\n-            Transformed feature names.\n+        Xs : list of {array-like, sparse matrix, dataframe}\n         \"\"\"\n-        if self.verbose_feature_names_out:\n-            # Prefix the feature names out with the transformers name\n-            names = list(\n-                chain.from_iterable(\n-                    (f\"{name}__{i}\" for i in feature_names_out)\n-                    for name, feature_names_out in transformer_with_feature_names_out\n-                )\n-            )\n-            return np.asarray(names, dtype=object)\n+        config = _get_output_config(\"transform\", self)\n+        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n+            pd = check_pandas_support(\"transform\")\n+            output = pd.concat(Xs, axis=1)\n+            # `pd.concat` adds a `RangeIndex` which is unused\n+            output.index = Xs[0].index\n+            return output\n+\n+        if any(sparse.issparse(X) for X in Xs):\n+            return sparse.hstack(Xs).tocsr()\n+        else:\n+            Xs = [X for X in Xs if X.shape[1] > 0]\n+            if not Xs:\n+                # All transformers produced empty outputs\n+                return np.zeros((self._n_features, 0))\n+            return np.hstack(Xs)\n \n         # verbose_feature_names_out is False\n         # Check that names are all unique without a prefix\n@@ -854,18 +873,37 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 pd = check_pandas_support(\"transform\")\n                 output = pd.concat(Xs, axis=1)\n \n-                # If all transformers define `get_feature_names_out`, then transform\n-                # will adjust the column names to be consistent with\n-                # verbose_feature_names_out. Here we prefix the feature names if\n-                # verbose_feature_names_out=True.\n-\n                 if not self.verbose_feature_names_out:\n                     return output\n \n-                transformer_names = [\n-                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n-                ]\n-                feature_names_outs = [X.columns for X in Xs]\n+                # Get transformer names and outputs, filtering to match actual outputs\n+                transformer_info = list(self._iter(fitted=True, replace_strings=True))\n+                transformer_names = []\n+                feature_names_outs = []\n+                \n+                # Only include transformers that produced non-empty outputs\n+                xs_index = 0\n+                for name, transformer, columns in transformer_info:\n+                    if not _is_empty_column_selection(columns):\n+                        if xs_index < len(Xs) and len(Xs[xs_index].columns) > 0:\n+                            transformer_names.append(name)\n+                            feature_names_outs.append(Xs[xs_index].columns)\n+                        xs_index += 1\n+                \n+                names_out = self._add_prefix_for_feature_names_out(\n+                    list(zip(transformer_names, feature_names_outs))\n+                )\n+                output.columns = names_out\n+                    return output\n+\n+\n+                transformer_names = []\n+                feature_names_outs = []\n+                for i, (name, transformer, columns) in enumerate(self._iter(fitted=True, replace_strings=True)):\n+                    if i < len(Xs) and hasattr(Xs[i], 'columns') and len(Xs[i].columns) > 0:\n+                        transformer_names.append(name)\n+                        feature_names_outs.append(Xs[i].columns)\n+                \n                 names_out = self._add_prefix_for_feature_names_out(\n                     list(zip(transformer_names, feature_names_outs))\n                 )\n@@ -904,6 +942,7 @@ def _check_X(X):\n     return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n \n \n+\n def _is_empty_column_selection(column):\n     \"\"\"\n     Return True if the column selection is empty (empty list or all-False\n@@ -915,11 +954,13 @@ def _is_empty_column_selection(column):\n     elif hasattr(column, \"__len__\"):\n         return (\n             len(column) == 0\n-            or all(isinstance(col, bool) for col in column)\n-            and not any(column)\n+            or (all(isinstance(col, bool) for col in column)\n+            and not any(column))\n         )\n     else:\n         return False\n+    else:\n+        return False\n \n \n def _get_transformer_list(estimators):\n",
    "variant_8": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..de53b2059 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -391,8 +391,17 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     ).set_output(transform=output_config[\"dense\"])\n                 elif trans == \"drop\":\n                     continue\n-                elif _is_empty_column_selection(columns):\n-                    continue\n+\n+                # List of tuples (name, fitted_transformer, column) for\n+                # transformers that actually produced output\n+                output_transformers = []\n+                for (name, fitted_transformer, column), X in zip(\n+                    self._iter(fitted=True, replace_strings=True), Xs\n+                ):\n+                    if X.shape[1] > 0:  # Only include transformers with non-empty output\n+                        output_transformers.append((name, fitted_transformer, column))\n+                \n+                transformer_names = [name for name, _, _ in output_transformers]\n \n             if column_as_strings:\n                 # Convert all columns to using their string labels\n@@ -530,28 +539,33 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             transformer_with_feature_names_out\n         )\n \n-    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n-        \"\"\"Add prefix for feature names out that includes the transformer names.\n+\n+    def _hstack(self, Xs):\n+        \"\"\"Stacks Xs horizontally.\n+\n+        This allows subclasses to control the stacking behavior, while reusing\n+        everything else from ColumnTransformer.\n \n         Parameters\n         ----------\n-        transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n-            The tuple consistent of the transformer's name and its feature names out.\n-\n-        Returns\n-        -------\n-        feature_names_out : ndarray of shape (n_features,), dtype=str\n-            Transformed feature names.\n+        Xs : list of {array-like, sparse matrix, dataframe}\n         \"\"\"\n-        if self.verbose_feature_names_out:\n-            # Prefix the feature names out with the transformers name\n-            names = list(\n-                chain.from_iterable(\n-                    (f\"{name}__{i}\" for i in feature_names_out)\n-                    for name, feature_names_out in transformer_with_feature_names_out\n-                )\n-            )\n-            return np.asarray(names, dtype=object)\n+        config = _get_output_config(\"transform\", self)\n+        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n+            pd = check_pandas_support(\"transform\")\n+            output = pd.concat(Xs, axis=1)\n+            # `pd.concat` adds a redundant level to the column MultiIndex\n+            output.columns = output.columns.droplevel(0)\n+            return output\n+\n+        if any(sparse.issparse(X) for X in Xs):\n+            return sparse.hstack(Xs).tocsr()\n+        else:\n+            Xs = [X for X in Xs if X.shape[1] > 0]\n+            if not Xs:\n+                # All transformers produced empty output\n+                return np.empty((self.n_features_in_, 0))\n+            return np.hstack(Xs)\n \n         # verbose_feature_names_out is False\n         # Check that names are all unique without a prefix\n@@ -854,18 +868,45 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 pd = check_pandas_support(\"transform\")\n                 output = pd.concat(Xs, axis=1)\n \n-                # If all transformers define `get_feature_names_out`, then transform\n-                # will adjust the column names to be consistent with\n-                # verbose_feature_names_out. Here we prefix the feature names if\n-                # verbose_feature_names_out=True.\n-\n                 if not self.verbose_feature_names_out:\n                     return output\n \n-                transformer_names = [\n-                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n+                # Get transformer names and feature names, but only for transformers\n+                # that actually produced output (non-empty Xs)\n+                all_transformers = [\n+                    t for t in self._iter(fitted=True, replace_strings=True)\n                 ]\n-                feature_names_outs = [X.columns for X in Xs]\n+                \n+                # Filter to only include transformers that produced non-empty output\n+                transformer_names = []\n+                feature_names_outs = []\n+                \n+                transformer_idx = 0\n+                for i, X in enumerate(Xs):\n+                    if X.shape[1] > 0:  # Only include transformers with actual output\n+                        # Find the corresponding transformer name\n+                        while transformer_idx < len(all_transformers):\n+                            transformer_name, transformer, columns = all_transformers[transformer_idx]\n+                            transformer_idx += 1\n+                            if not _is_empty_column_selection(columns):\n+                                transformer_names.append(transformer_name)\n+                                feature_names_outs.append(X.columns)\n+                                break\n+                \n+                names_out = self._add_prefix_for_feature_names_out(\n+                    list(zip(transformer_names, feature_names_outs))\n+                )\n+                output.columns = names_out\n+                    return output\n+\n+\n+                transformer_names = []\n+                feature_names_outs = []\n+                for i, (name, transformer, columns) in enumerate(self._iter(fitted=True, replace_strings=True)):\n+                    if i < len(Xs) and hasattr(Xs[i], 'columns') and len(Xs[i].columns) > 0:\n+                        transformer_names.append(name)\n+                        feature_names_outs.append(Xs[i].columns)\n+                \n                 names_out = self._add_prefix_for_feature_names_out(\n                     list(zip(transformer_names, feature_names_outs))\n                 )\n@@ -904,6 +945,7 @@ def _check_X(X):\n     return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n \n \n+\n def _is_empty_column_selection(column):\n     \"\"\"\n     Return True if the column selection is empty (empty list or all-False\n@@ -915,11 +957,13 @@ def _is_empty_column_selection(column):\n     elif hasattr(column, \"__len__\"):\n         return (\n             len(column) == 0\n-            or all(isinstance(col, bool) for col in column)\n-            and not any(column)\n+            or (all(isinstance(col, bool) for col in column)\n+            and not any(column))\n         )\n     else:\n         return False\n+    else:\n+        return False\n \n \n def _get_transformer_list(estimators):\n"
  }
}