{
  "zero_patches": {
    "Location 1 (/root/hy/projects_2/scikit-learn/sklearn/decomposition/kernel_pca.py lines 213-223)": "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n\n        return K\n",
    "Location 2 (/root/hy/projects_2/scikit-learn/sklearn/decomposition/kernel_pca.py lines 200-211)": "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
    "Location 3 (/root/hy/projects_2/scikit-learn/sklearn/decomposition/kernel_pca.py lines 276-283)": "\n        # Sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # Normalize eigenvectors\n        for i in range(self.n_components_):\n            self.alphas_[:, i] /= np.sqrt(self.lambdas_[i])\n",
    "Location 4 (/root/hy/projects_2/scikit-learn/sklearn/decomposition/kernel_pca.py lines 296-299)": "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n"
  },
  "variant_patches": {
    "Location 1 (/root/hy/projects_2/scikit-learn/sklearn/decomposition/kernel_pca.py lines 213-223)": [
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n\n        return K\n",
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n\n        return K\n",
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n\n        return K\n",
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n\n        return K\n",
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n\n        return K\n",
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n\n        return K\n",
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n\n        return K\n",
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n\n        return K\n"
    ],
    "Location 2 (/root/hy/projects_2/scikit-learn/sklearn/decomposition/kernel_pca.py lines 200-211)": [
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
      "\n        if eigen_solver == 'dense':\n            self.lambdas_, self.alphas_ = linalg.eigh(\n                K, eigvals=(K.shape[0] - n_components, K.shape[0] - 1))\n        elif eigen_solver == 'arpack':\n            random_state = check_random_state(self.random_state)\n            # initialize with [-1,1] as in ARPACK\n            v0 = random_state.uniform(-1, 1, K.shape[0])\n            self.lambdas_, self.alphas_ = eigsh(K, n_components,\n                                                which=\"LA\",\n                                                tol=self.tol,\n                                                maxiter=self.max_iter,\n                                                v0=v0)\n\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n"
    ],
    "Location 3 (/root/hy/projects_2/scikit-learn/sklearn/decomposition/kernel_pca.py lines 276-283)": [
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue (null space) if required\n        if self.remove_zero_eig or self.n_components is not None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue (null space) if required\n        if self.remove_zero_eig or self.n_components is not None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
      "\n        # Sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # Remove eigenvectors with a zero eigenvalue (null space) if required\n        if self.remove_zero_eig or self.n_components is not None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
      "\n        # Flip eigenvalues and eigenvectors for decreasing eigenvalues order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # Remove eigenvectors with a zero eigenvalue (null space) if required\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n"
    ],
    "Location 4 (/root/hy/projects_2/scikit-learn/sklearn/decomposition/kernel_pca.py lines 296-299)": [
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n\n        return self\n",
      "\n        # Sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # Remove eigenvectors with a zero eigenvalue (null space) if required\n        if self.remove_zero_eig or self.n_components is not None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
      "\n        # Sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # Remove eigenvectors with a zero eigenvalue (null space) if required\n        if self.remove_zero_eig or self.n_components is not None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
      "\n        # Sort eigenvectors in decreasing order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # Remove eigenvectors with a zero eigenvalue (null space) if required\n        if self.remove_zero_eig or self.n_components is not None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
      "\n        # sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # remove eigenvectors with a zero eigenvalue\n        if self.remove_zero_eig or self.n_components is None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
      "\n        # Sort eigenvectors in descending order\n        indices = self.lambdas_.argsort()[::-1]\n        self.lambdas_ = self.lambdas_[indices]\n        self.alphas_ = self.alphas_[:, indices]\n\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        # Remove eigenvectors with a zero eigenvalue (null space) if required\n        if self.remove_zero_eig or self.n_components is not None:\n            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n",
      "\n        # Standardize eigenvector signs to ensure reproducibility\n        # Make the component with largest absolute value positive\n        for i in range(self.alphas_.shape[1]):\n            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n            if self.alphas_[max_abs_idx, i] < 0:\n                self.alphas_[:, i] *= -1\n\n        return self\n"
    ]
  },
  "combined_diffs": {
    "raw_patch": "diff --git a/sklearn/decomposition/kernel_pca.py b/sklearn/decomposition/kernel_pca.py\nindex bb91d0cbb..89a9baff0 100644\n--- a/sklearn/decomposition/kernel_pca.py\n+++ b/sklearn/decomposition/kernel_pca.py\n@@ -197,6 +197,7 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         else:\n             eigen_solver = self.eigen_solver\n \n+\n         if eigen_solver == 'dense':\n             self.lambdas_, self.alphas_ = linalg.eigh(\n                 K, eigvals=(K.shape[0] - n_components, K.shape[0] - 1))\n@@ -210,6 +211,7 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n                                                 maxiter=self.max_iter,\n                                                 v0=v0)\n \n+\n         # sort eigenvectors in descending order\n         indices = self.lambdas_.argsort()[::-1]\n         self.lambdas_ = self.lambdas_[indices]\n@@ -220,6 +222,13 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n             self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n             self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n \n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n         return K\n \n     def _fit_inverse_transform(self, X_transformed, X):\n@@ -273,6 +282,7 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         -------\n         X_new : array-like, shape (n_samples, n_components)\n         \"\"\"\n+\n         self.fit(X, **params)\n \n         X_transformed = self.alphas_ * np.sqrt(self.lambdas_)\n@@ -293,6 +303,7 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         -------\n         X_new : array-like, shape (n_samples, n_components)\n         \"\"\"\n+\n         check_is_fitted(self, 'X_fit_')\n \n         K = self._centerer.transform(self._get_kernel(X, self.X_fit_))\n",
    "variant_0": "diff --git a/sklearn/decomposition/kernel_pca.py b/sklearn/decomposition/kernel_pca.py\nindex bb91d0cbb..46e2c0e66 100644\n--- a/sklearn/decomposition/kernel_pca.py\n+++ b/sklearn/decomposition/kernel_pca.py\n@@ -197,24 +197,37 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         else:\n             eigen_solver = self.eigen_solver\n \n-        if eigen_solver == 'dense':\n-            self.lambdas_, self.alphas_ = linalg.eigh(\n-                K, eigvals=(K.shape[0] - n_components, K.shape[0] - 1))\n-        elif eigen_solver == 'arpack':\n-            random_state = check_random_state(self.random_state)\n-            # initialize with [-1,1] as in ARPACK\n-            v0 = random_state.uniform(-1, 1, K.shape[0])\n-            self.lambdas_, self.alphas_ = eigsh(K, n_components,\n-                                                which=\"LA\",\n-                                                tol=self.tol,\n-                                                maxiter=self.max_iter,\n-                                                v0=v0)\n \n         # sort eigenvectors in descending order\n         indices = self.lambdas_.argsort()[::-1]\n         self.lambdas_ = self.lambdas_[indices]\n         self.alphas_ = self.alphas_[:, indices]\n \n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n+        # remove eigenvectors with a zero eigenvalue\n+        if self.remove_zero_eig or self.n_components is None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n+\n+\n+        # sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n+\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n         # remove eigenvectors with a zero eigenvalue\n         if self.remove_zero_eig or self.n_components is None:\n             self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n@@ -273,14 +286,22 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         -------\n         X_new : array-like, shape (n_samples, n_components)\n         \"\"\"\n-        self.fit(X, **params)\n \n-        X_transformed = self.alphas_ * np.sqrt(self.lambdas_)\n+        # Sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n \n-        if self.fit_inverse_transform:\n-            self._fit_inverse_transform(X_transformed, X)\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n \n-        return X_transformed\n+        # Normalize eigenvectors\n+        for i in range(self.n_components_):\n+            self.alphas_[:, i] /= np.sqrt(self.lambdas_[i])\n \n     def transform(self, X):\n         \"\"\"Transform X.\n@@ -293,10 +314,23 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         -------\n         X_new : array-like, shape (n_samples, n_components)\n         \"\"\"\n-        check_is_fitted(self, 'X_fit_')\n \n-        K = self._centerer.transform(self._get_kernel(X, self.X_fit_))\n-        return np.dot(K, self.alphas_ / np.sqrt(self.lambdas_))\n+        # sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n+\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n+        # remove eigenvectors with a zero eigenvalue\n+        if self.remove_zero_eig or self.n_components is None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n \n     def inverse_transform(self, X):\n         \"\"\"Transform X back to original space.\n",
    "variant_1": "diff --git a/sklearn/decomposition/kernel_pca.py b/sklearn/decomposition/kernel_pca.py\nindex bb91d0cbb..5ec1d0d88 100644\n--- a/sklearn/decomposition/kernel_pca.py\n+++ b/sklearn/decomposition/kernel_pca.py\n@@ -197,24 +197,37 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         else:\n             eigen_solver = self.eigen_solver\n \n-        if eigen_solver == 'dense':\n-            self.lambdas_, self.alphas_ = linalg.eigh(\n-                K, eigvals=(K.shape[0] - n_components, K.shape[0] - 1))\n-        elif eigen_solver == 'arpack':\n-            random_state = check_random_state(self.random_state)\n-            # initialize with [-1,1] as in ARPACK\n-            v0 = random_state.uniform(-1, 1, K.shape[0])\n-            self.lambdas_, self.alphas_ = eigsh(K, n_components,\n-                                                which=\"LA\",\n-                                                tol=self.tol,\n-                                                maxiter=self.max_iter,\n-                                                v0=v0)\n \n         # sort eigenvectors in descending order\n         indices = self.lambdas_.argsort()[::-1]\n         self.lambdas_ = self.lambdas_[indices]\n         self.alphas_ = self.alphas_[:, indices]\n \n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n+        # remove eigenvectors with a zero eigenvalue\n+        if self.remove_zero_eig or self.n_components is None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n+\n+\n+        # sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n+\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n         # remove eigenvectors with a zero eigenvalue\n         if self.remove_zero_eig or self.n_components is None:\n             self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n@@ -273,14 +286,23 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         -------\n         X_new : array-like, shape (n_samples, n_components)\n         \"\"\"\n-        self.fit(X, **params)\n \n-        X_transformed = self.alphas_ * np.sqrt(self.lambdas_)\n+        # sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n \n-        if self.fit_inverse_transform:\n-            self._fit_inverse_transform(X_transformed, X)\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n \n-        return X_transformed\n+        # remove eigenvectors with a zero eigenvalue\n+        if self.remove_zero_eig or self.n_components is None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n \n     def transform(self, X):\n         \"\"\"Transform X.\n@@ -293,10 +315,25 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         -------\n         X_new : array-like, shape (n_samples, n_components)\n         \"\"\"\n-        check_is_fitted(self, 'X_fit_')\n \n-        K = self._centerer.transform(self._get_kernel(X, self.X_fit_))\n-        return np.dot(K, self.alphas_ / np.sqrt(self.lambdas_))\n+        # sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n+\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n+        # remove eigenvectors with a zero eigenvalue\n+        if self.remove_zero_eig or self.n_components is None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n+\n+        return self\n \n     def inverse_transform(self, X):\n         \"\"\"Transform X back to original space.\n",
    "variant_2": "diff --git a/sklearn/decomposition/kernel_pca.py b/sklearn/decomposition/kernel_pca.py\nindex bb91d0cbb..be4c3d899 100644\n--- a/sklearn/decomposition/kernel_pca.py\n+++ b/sklearn/decomposition/kernel_pca.py\n@@ -197,24 +197,37 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         else:\n             eigen_solver = self.eigen_solver\n \n-        if eigen_solver == 'dense':\n-            self.lambdas_, self.alphas_ = linalg.eigh(\n-                K, eigvals=(K.shape[0] - n_components, K.shape[0] - 1))\n-        elif eigen_solver == 'arpack':\n-            random_state = check_random_state(self.random_state)\n-            # initialize with [-1,1] as in ARPACK\n-            v0 = random_state.uniform(-1, 1, K.shape[0])\n-            self.lambdas_, self.alphas_ = eigsh(K, n_components,\n-                                                which=\"LA\",\n-                                                tol=self.tol,\n-                                                maxiter=self.max_iter,\n-                                                v0=v0)\n \n         # sort eigenvectors in descending order\n         indices = self.lambdas_.argsort()[::-1]\n         self.lambdas_ = self.lambdas_[indices]\n         self.alphas_ = self.alphas_[:, indices]\n \n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n+        # remove eigenvectors with a zero eigenvalue\n+        if self.remove_zero_eig or self.n_components is None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n+\n+\n+        # sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n+\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n         # remove eigenvectors with a zero eigenvalue\n         if self.remove_zero_eig or self.n_components is None:\n             self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n@@ -273,14 +286,23 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         -------\n         X_new : array-like, shape (n_samples, n_components)\n         \"\"\"\n-        self.fit(X, **params)\n \n-        X_transformed = self.alphas_ * np.sqrt(self.lambdas_)\n+        # sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n \n-        if self.fit_inverse_transform:\n-            self._fit_inverse_transform(X_transformed, X)\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n \n-        return X_transformed\n+        # remove eigenvectors with a zero eigenvalue\n+        if self.remove_zero_eig or self.n_components is None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n \n     def transform(self, X):\n         \"\"\"Transform X.\n@@ -293,10 +315,23 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         -------\n         X_new : array-like, shape (n_samples, n_components)\n         \"\"\"\n-        check_is_fitted(self, 'X_fit_')\n \n-        K = self._centerer.transform(self._get_kernel(X, self.X_fit_))\n-        return np.dot(K, self.alphas_ / np.sqrt(self.lambdas_))\n+        # Sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n+\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n+        # Remove eigenvectors with a zero eigenvalue (null space) if required\n+        if self.remove_zero_eig or self.n_components is not None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n \n     def inverse_transform(self, X):\n         \"\"\"Transform X back to original space.\n",
    "variant_3": "diff --git a/sklearn/decomposition/kernel_pca.py b/sklearn/decomposition/kernel_pca.py\nindex bb91d0cbb..be4c3d899 100644\n--- a/sklearn/decomposition/kernel_pca.py\n+++ b/sklearn/decomposition/kernel_pca.py\n@@ -197,24 +197,37 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         else:\n             eigen_solver = self.eigen_solver\n \n-        if eigen_solver == 'dense':\n-            self.lambdas_, self.alphas_ = linalg.eigh(\n-                K, eigvals=(K.shape[0] - n_components, K.shape[0] - 1))\n-        elif eigen_solver == 'arpack':\n-            random_state = check_random_state(self.random_state)\n-            # initialize with [-1,1] as in ARPACK\n-            v0 = random_state.uniform(-1, 1, K.shape[0])\n-            self.lambdas_, self.alphas_ = eigsh(K, n_components,\n-                                                which=\"LA\",\n-                                                tol=self.tol,\n-                                                maxiter=self.max_iter,\n-                                                v0=v0)\n \n         # sort eigenvectors in descending order\n         indices = self.lambdas_.argsort()[::-1]\n         self.lambdas_ = self.lambdas_[indices]\n         self.alphas_ = self.alphas_[:, indices]\n \n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n+        # remove eigenvectors with a zero eigenvalue\n+        if self.remove_zero_eig or self.n_components is None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n+\n+\n+        # sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n+\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n         # remove eigenvectors with a zero eigenvalue\n         if self.remove_zero_eig or self.n_components is None:\n             self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n@@ -273,14 +286,23 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         -------\n         X_new : array-like, shape (n_samples, n_components)\n         \"\"\"\n-        self.fit(X, **params)\n \n-        X_transformed = self.alphas_ * np.sqrt(self.lambdas_)\n+        # sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n \n-        if self.fit_inverse_transform:\n-            self._fit_inverse_transform(X_transformed, X)\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n \n-        return X_transformed\n+        # remove eigenvectors with a zero eigenvalue\n+        if self.remove_zero_eig or self.n_components is None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n \n     def transform(self, X):\n         \"\"\"Transform X.\n@@ -293,10 +315,23 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         -------\n         X_new : array-like, shape (n_samples, n_components)\n         \"\"\"\n-        check_is_fitted(self, 'X_fit_')\n \n-        K = self._centerer.transform(self._get_kernel(X, self.X_fit_))\n-        return np.dot(K, self.alphas_ / np.sqrt(self.lambdas_))\n+        # Sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n+\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n+        # Remove eigenvectors with a zero eigenvalue (null space) if required\n+        if self.remove_zero_eig or self.n_components is not None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n \n     def inverse_transform(self, X):\n         \"\"\"Transform X back to original space.\n",
    "variant_4": "diff --git a/sklearn/decomposition/kernel_pca.py b/sklearn/decomposition/kernel_pca.py\nindex bb91d0cbb..127af97a5 100644\n--- a/sklearn/decomposition/kernel_pca.py\n+++ b/sklearn/decomposition/kernel_pca.py\n@@ -197,6 +197,7 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         else:\n             eigen_solver = self.eigen_solver\n \n+\n         if eigen_solver == 'dense':\n             self.lambdas_, self.alphas_ = linalg.eigh(\n                 K, eigvals=(K.shape[0] - n_components, K.shape[0] - 1))\n@@ -215,6 +216,31 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         self.lambdas_ = self.lambdas_[indices]\n         self.alphas_ = self.alphas_[:, indices]\n \n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n+        # remove eigenvectors with a zero eigenvalue\n+        if self.remove_zero_eig or self.n_components is None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n+\n+\n+        # sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n+\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n         # remove eigenvectors with a zero eigenvalue\n         if self.remove_zero_eig or self.n_components is None:\n             self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n@@ -273,14 +299,23 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         -------\n         X_new : array-like, shape (n_samples, n_components)\n         \"\"\"\n-        self.fit(X, **params)\n \n-        X_transformed = self.alphas_ * np.sqrt(self.lambdas_)\n+        # sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n \n-        if self.fit_inverse_transform:\n-            self._fit_inverse_transform(X_transformed, X)\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n \n-        return X_transformed\n+        # remove eigenvectors with a zero eigenvalue (null space) if required\n+        if self.remove_zero_eig or self.n_components is not None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n \n     def transform(self, X):\n         \"\"\"Transform X.\n@@ -293,10 +328,23 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         -------\n         X_new : array-like, shape (n_samples, n_components)\n         \"\"\"\n-        check_is_fitted(self, 'X_fit_')\n \n-        K = self._centerer.transform(self._get_kernel(X, self.X_fit_))\n-        return np.dot(K, self.alphas_ / np.sqrt(self.lambdas_))\n+        # sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n+\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n+        # remove eigenvectors with a zero eigenvalue\n+        if self.remove_zero_eig or self.n_components is None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n \n     def inverse_transform(self, X):\n         \"\"\"Transform X back to original space.\n",
    "variant_5": "diff --git a/sklearn/decomposition/kernel_pca.py b/sklearn/decomposition/kernel_pca.py\nindex bb91d0cbb..54f093895 100644\n--- a/sklearn/decomposition/kernel_pca.py\n+++ b/sklearn/decomposition/kernel_pca.py\n@@ -197,24 +197,37 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         else:\n             eigen_solver = self.eigen_solver\n \n-        if eigen_solver == 'dense':\n-            self.lambdas_, self.alphas_ = linalg.eigh(\n-                K, eigvals=(K.shape[0] - n_components, K.shape[0] - 1))\n-        elif eigen_solver == 'arpack':\n-            random_state = check_random_state(self.random_state)\n-            # initialize with [-1,1] as in ARPACK\n-            v0 = random_state.uniform(-1, 1, K.shape[0])\n-            self.lambdas_, self.alphas_ = eigsh(K, n_components,\n-                                                which=\"LA\",\n-                                                tol=self.tol,\n-                                                maxiter=self.max_iter,\n-                                                v0=v0)\n \n         # sort eigenvectors in descending order\n         indices = self.lambdas_.argsort()[::-1]\n         self.lambdas_ = self.lambdas_[indices]\n         self.alphas_ = self.alphas_[:, indices]\n \n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n+        # remove eigenvectors with a zero eigenvalue\n+        if self.remove_zero_eig or self.n_components is None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n+\n+\n+        # sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n+\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n         # remove eigenvectors with a zero eigenvalue\n         if self.remove_zero_eig or self.n_components is None:\n             self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n@@ -273,14 +286,23 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         -------\n         X_new : array-like, shape (n_samples, n_components)\n         \"\"\"\n-        self.fit(X, **params)\n \n-        X_transformed = self.alphas_ * np.sqrt(self.lambdas_)\n+        # sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n \n-        if self.fit_inverse_transform:\n-            self._fit_inverse_transform(X_transformed, X)\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n \n-        return X_transformed\n+        # remove eigenvectors with a zero eigenvalue (null space) if required\n+        if self.remove_zero_eig or self.n_components is not None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n \n     def transform(self, X):\n         \"\"\"Transform X.\n@@ -293,10 +315,23 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         -------\n         X_new : array-like, shape (n_samples, n_components)\n         \"\"\"\n-        check_is_fitted(self, 'X_fit_')\n \n-        K = self._centerer.transform(self._get_kernel(X, self.X_fit_))\n-        return np.dot(K, self.alphas_ / np.sqrt(self.lambdas_))\n+        # Sort eigenvectors in decreasing order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n+\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n+        # Remove eigenvectors with a zero eigenvalue (null space) if required\n+        if self.remove_zero_eig or self.n_components is not None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n \n     def inverse_transform(self, X):\n         \"\"\"Transform X back to original space.\n",
    "variant_6": "diff --git a/sklearn/decomposition/kernel_pca.py b/sklearn/decomposition/kernel_pca.py\nindex bb91d0cbb..3bb0887af 100644\n--- a/sklearn/decomposition/kernel_pca.py\n+++ b/sklearn/decomposition/kernel_pca.py\n@@ -197,24 +197,37 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         else:\n             eigen_solver = self.eigen_solver\n \n-        if eigen_solver == 'dense':\n-            self.lambdas_, self.alphas_ = linalg.eigh(\n-                K, eigvals=(K.shape[0] - n_components, K.shape[0] - 1))\n-        elif eigen_solver == 'arpack':\n-            random_state = check_random_state(self.random_state)\n-            # initialize with [-1,1] as in ARPACK\n-            v0 = random_state.uniform(-1, 1, K.shape[0])\n-            self.lambdas_, self.alphas_ = eigsh(K, n_components,\n-                                                which=\"LA\",\n-                                                tol=self.tol,\n-                                                maxiter=self.max_iter,\n-                                                v0=v0)\n \n         # sort eigenvectors in descending order\n         indices = self.lambdas_.argsort()[::-1]\n         self.lambdas_ = self.lambdas_[indices]\n         self.alphas_ = self.alphas_[:, indices]\n \n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n+        # remove eigenvectors with a zero eigenvalue\n+        if self.remove_zero_eig or self.n_components is None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n+\n+\n+        # sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n+\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n         # remove eigenvectors with a zero eigenvalue\n         if self.remove_zero_eig or self.n_components is None:\n             self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n@@ -273,14 +286,23 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         -------\n         X_new : array-like, shape (n_samples, n_components)\n         \"\"\"\n-        self.fit(X, **params)\n \n-        X_transformed = self.alphas_ * np.sqrt(self.lambdas_)\n+        # Sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n \n-        if self.fit_inverse_transform:\n-            self._fit_inverse_transform(X_transformed, X)\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n \n-        return X_transformed\n+        # Remove eigenvectors with a zero eigenvalue (null space) if required\n+        if self.remove_zero_eig or self.n_components is not None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n \n     def transform(self, X):\n         \"\"\"Transform X.\n@@ -293,10 +315,23 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         -------\n         X_new : array-like, shape (n_samples, n_components)\n         \"\"\"\n-        check_is_fitted(self, 'X_fit_')\n \n-        K = self._centerer.transform(self._get_kernel(X, self.X_fit_))\n-        return np.dot(K, self.alphas_ / np.sqrt(self.lambdas_))\n+        # sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n+\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n+        # remove eigenvectors with a zero eigenvalue\n+        if self.remove_zero_eig or self.n_components is None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n \n     def inverse_transform(self, X):\n         \"\"\"Transform X back to original space.\n",
    "variant_7": "diff --git a/sklearn/decomposition/kernel_pca.py b/sklearn/decomposition/kernel_pca.py\nindex bb91d0cbb..be4c3d899 100644\n--- a/sklearn/decomposition/kernel_pca.py\n+++ b/sklearn/decomposition/kernel_pca.py\n@@ -197,24 +197,37 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         else:\n             eigen_solver = self.eigen_solver\n \n-        if eigen_solver == 'dense':\n-            self.lambdas_, self.alphas_ = linalg.eigh(\n-                K, eigvals=(K.shape[0] - n_components, K.shape[0] - 1))\n-        elif eigen_solver == 'arpack':\n-            random_state = check_random_state(self.random_state)\n-            # initialize with [-1,1] as in ARPACK\n-            v0 = random_state.uniform(-1, 1, K.shape[0])\n-            self.lambdas_, self.alphas_ = eigsh(K, n_components,\n-                                                which=\"LA\",\n-                                                tol=self.tol,\n-                                                maxiter=self.max_iter,\n-                                                v0=v0)\n \n         # sort eigenvectors in descending order\n         indices = self.lambdas_.argsort()[::-1]\n         self.lambdas_ = self.lambdas_[indices]\n         self.alphas_ = self.alphas_[:, indices]\n \n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n+        # remove eigenvectors with a zero eigenvalue\n+        if self.remove_zero_eig or self.n_components is None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n+\n+\n+        # sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n+\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n         # remove eigenvectors with a zero eigenvalue\n         if self.remove_zero_eig or self.n_components is None:\n             self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n@@ -273,14 +286,23 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         -------\n         X_new : array-like, shape (n_samples, n_components)\n         \"\"\"\n-        self.fit(X, **params)\n \n-        X_transformed = self.alphas_ * np.sqrt(self.lambdas_)\n+        # sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n \n-        if self.fit_inverse_transform:\n-            self._fit_inverse_transform(X_transformed, X)\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n \n-        return X_transformed\n+        # remove eigenvectors with a zero eigenvalue\n+        if self.remove_zero_eig or self.n_components is None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n \n     def transform(self, X):\n         \"\"\"Transform X.\n@@ -293,10 +315,23 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         -------\n         X_new : array-like, shape (n_samples, n_components)\n         \"\"\"\n-        check_is_fitted(self, 'X_fit_')\n \n-        K = self._centerer.transform(self._get_kernel(X, self.X_fit_))\n-        return np.dot(K, self.alphas_ / np.sqrt(self.lambdas_))\n+        # Sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n+\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n+        # Remove eigenvectors with a zero eigenvalue (null space) if required\n+        if self.remove_zero_eig or self.n_components is not None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n \n     def inverse_transform(self, X):\n         \"\"\"Transform X back to original space.\n",
    "variant_8": "diff --git a/sklearn/decomposition/kernel_pca.py b/sklearn/decomposition/kernel_pca.py\nindex bb91d0cbb..166e46f00 100644\n--- a/sklearn/decomposition/kernel_pca.py\n+++ b/sklearn/decomposition/kernel_pca.py\n@@ -197,24 +197,37 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         else:\n             eigen_solver = self.eigen_solver\n \n-        if eigen_solver == 'dense':\n-            self.lambdas_, self.alphas_ = linalg.eigh(\n-                K, eigvals=(K.shape[0] - n_components, K.shape[0] - 1))\n-        elif eigen_solver == 'arpack':\n-            random_state = check_random_state(self.random_state)\n-            # initialize with [-1,1] as in ARPACK\n-            v0 = random_state.uniform(-1, 1, K.shape[0])\n-            self.lambdas_, self.alphas_ = eigsh(K, n_components,\n-                                                which=\"LA\",\n-                                                tol=self.tol,\n-                                                maxiter=self.max_iter,\n-                                                v0=v0)\n \n         # sort eigenvectors in descending order\n         indices = self.lambdas_.argsort()[::-1]\n         self.lambdas_ = self.lambdas_[indices]\n         self.alphas_ = self.alphas_[:, indices]\n \n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n+        # remove eigenvectors with a zero eigenvalue\n+        if self.remove_zero_eig or self.n_components is None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n+\n+\n+        # sort eigenvectors in descending order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n+\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n         # remove eigenvectors with a zero eigenvalue\n         if self.remove_zero_eig or self.n_components is None:\n             self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n@@ -273,14 +286,23 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         -------\n         X_new : array-like, shape (n_samples, n_components)\n         \"\"\"\n-        self.fit(X, **params)\n \n-        X_transformed = self.alphas_ * np.sqrt(self.lambdas_)\n+        # Flip eigenvalues and eigenvectors for decreasing eigenvalues order\n+        indices = self.lambdas_.argsort()[::-1]\n+        self.lambdas_ = self.lambdas_[indices]\n+        self.alphas_ = self.alphas_[:, indices]\n \n-        if self.fit_inverse_transform:\n-            self._fit_inverse_transform(X_transformed, X)\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n \n-        return X_transformed\n+        # Remove eigenvectors with a zero eigenvalue (null space) if required\n+        if self.remove_zero_eig or self.n_components is None:\n+            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n+            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n \n     def transform(self, X):\n         \"\"\"Transform X.\n@@ -293,10 +315,15 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         -------\n         X_new : array-like, shape (n_samples, n_components)\n         \"\"\"\n-        check_is_fitted(self, 'X_fit_')\n \n-        K = self._centerer.transform(self._get_kernel(X, self.X_fit_))\n-        return np.dot(K, self.alphas_ / np.sqrt(self.lambdas_))\n+        # Standardize eigenvector signs to ensure reproducibility\n+        # Make the component with largest absolute value positive\n+        for i in range(self.alphas_.shape[1]):\n+            max_abs_idx = np.argmax(np.abs(self.alphas_[:, i]))\n+            if self.alphas_[max_abs_idx, i] < 0:\n+                self.alphas_[:, i] *= -1\n+\n+        return self\n \n     def inverse_transform(self, X):\n         \"\"\"Transform X back to original space.\n"
  }
}