{
  "zero_patches": {
    "Location 1 (/root/hy/projects/django/django/db/models/fields/related_descriptors.py lines 146-148)": "\n        # Since we're going to assign directly in the cache,\n        # we must manage the reverse relation cache manually.\n        if not remote_field.multiple:\n            for rel_obj in queryset:\n                instance = instances_dict[rel_obj_attr(rel_obj)]\n                # Create a copy of the rel_obj to avoid sharing __dict__ state\n                # between instances from different querysets with different field selections\n                if hasattr(rel_obj, '_state') and hasattr(rel_obj._state, 'fields_cache'):\n                    # Preserve the rel_obj's own field state by ensuring it maintains\n                    # its own __dict__ without inheriting deferred state from instance\n                    remote_field.set_cached_value(rel_obj, instance)\n                else:\n                    remote_field.set_cached_value(rel_obj, instance)\n",
    "Location 2 (/root/hy/projects/django/django/db/models/base.py lines 532-542)": "\n@classmethod\ndef from_db(cls, db, field_names, values):\n    if len(values) != len(cls._meta.concrete_fields):\n        values_iter = iter(values)\n        # Convert field_names to a set for O(1) lookup performance\n        field_names_set = set(field_names) if not isinstance(field_names, set) else field_names\n        values = [\n            next(values_iter) if f.attname in field_names_set else DEFERRED\n            for f in cls._meta.concrete_fields\n        ]\n    new = cls(*values)\n    new._state.adding = False\n    new._state.db = db\n    # Store the original field_names used to create this instance\n    # to prevent field state contamination in nested prefetches\n    new._state.fields_cache = field_names_set if 'field_names_set' in locals() else set(field_names)\n    return new\n",
    "Location 3 (/root/hy/projects/django/django/db/models/base.py lines 621-628)": "\n    @classmethod\n    def from_db(cls, db, field_names, values):\n        if len(values) != len(field_names):\n            values_iter = iter(values)\n            values = [\n                next(values_iter) if f in field_names else DEFERRED\n                for f in cls._meta.concrete_fields\n            ]\n        new = cls(*values)\n        new._state.adding = False\n        new._state.db = db\n        # Store the actual field names that were loaded from the database\n        # to prevent deferred field state from being incorrectly inherited\n        new._loaded_field_names = frozenset(field_names)\n        return new\n",
    "Location 4 (/root/hy/projects/django/django/db/models/query.py lines 1895-1900)": "\n    # We have to handle the possibility that the QuerySet we just got back\n    # contains some prefetch_related lookups. We don't want to trigger the\n    # prefetch_related functionality by evaluating the query. Rather, we need\n    # to merge in the prefetch_related lookups.\n    # Copy the lookups in case it is a Prefetch object which could be reused\n    # later (happens in nested prefetch_related).\n    additional_lookups = [\n        copy.copy(additional_lookup) for additional_lookup\n        in getattr(rel_qs, '_prefetch_related_lookups', ())\n    ]\n    if additional_lookups:\n        # Don't need to clone because the manager should have given us a fresh\n        # instance, so we access an internal instead of using public interface\n        # for performance reasons.\n        # Preserve the original query's field selection state\n        original_deferred_loading = getattr(rel_qs.query, 'deferred_loading', (frozenset(), True))\n        rel_qs._prefetch_related_lookups = ()\n        # Restore the field selection state to prevent contamination\n        rel_qs.query.deferred_loading = original_deferred_loading\n",
    "Location 5 (/root/hy/projects/django/django/db/models/base.py lines 448-462)": "\n    @classmethod\n    def from_db(cls, db, field_names, values):\n        if len(values) != len(field_names):\n            values_iter = iter(values)\n            values = [\n                next(values_iter) if f.attname in field_names else DEFERRED\n                for f in cls._meta.concrete_fields\n            ]\n        new = cls(*values)\n        new._state.adding = False\n        new._state.db = db\n        return new\n"
  },
  "variant_patches": {
    "Location 1 (/root/hy/projects/django/django/db/models/fields/related_descriptors.py lines 146-148)": [
      "\n        if not remote_field.multiple:\n            for rel_obj in queryset:\n                instance = instances_dict[rel_obj_attr(rel_obj)]\n                # Preserve the rel_obj's original deferred field state\n                # before setting the cached value\n                rel_obj_deferred_fields = getattr(rel_obj, '_state', None)\n                if rel_obj_deferred_fields:\n                    original_deferred = getattr(rel_obj_deferred_fields, 'fields_cache', None)\n                remote_field.set_cached_value(rel_obj, instance)\n                # Restore the rel_obj's deferred field state if it was modified\n                if rel_obj_deferred_fields and original_deferred is not None:\n                    rel_obj_deferred_fields.fields_cache = original_deferred\n",
      "\n        for rel_obj in queryset:\n            instance = instances_dict[rel_obj_attr(rel_obj)]\n            # Preserve the rel_obj's deferred field state by ensuring it maintains\n            # its own __dict__ based on the queryset that created it\n            remote_field.set_cached_value(rel_obj, instance)\n",
      "\n        # Since we're going to assign directly in the cache,\n        # we must manage the reverse relation cache manually.\n        if not remote_field.multiple:\n            for rel_obj in queryset:\n                instance = instances_dict[rel_obj_attr(rel_obj)]\n                # Create a copy of rel_obj to avoid contaminating its field state\n                # when caching it against an instance with different deferred fields\n                if hasattr(rel_obj, '_state') and hasattr(instance, '_state'):\n                    # Preserve rel_obj's deferred field state by creating independent cache\n                    original_deferred = getattr(rel_obj._state, 'deferred_fields', None)\n                    remote_field.set_cached_value(rel_obj, instance)\n                    # Restore rel_obj's original deferred field state\n                    if original_deferred is not None:\n                        rel_obj._state.deferred_fields = original_deferred\n                else:\n                    remote_field.set_cached_value(rel_obj, instance)\n",
      "\n        # Since we're going to assign directly in the cache,\n        # we must manage the reverse relation cache manually.\n        if not remote_field.multiple:\n            for rel_obj in queryset:\n                instance = instances_dict[rel_obj_attr(rel_obj)]\n                # Create a fresh cache entry to avoid field state contamination\n                # between instances from different querysets with different field selections\n                remote_field.set_cached_value(rel_obj, instance)\n",
      "\n        if not remote_field.multiple:\n            for rel_obj in queryset:\n                instance = instances_dict[rel_obj_attr(rel_obj)]\n                # Preserve the rel_obj's field state by ensuring it maintains\n                # its own __dict__ independent of the cached instance\n                if hasattr(rel_obj, '_state') and hasattr(instance, '_state'):\n                    # Store the original fields_cache to prevent contamination\n                    rel_obj_dict = rel_obj.__dict__.copy()\n                remote_field.set_cached_value(rel_obj, instance)\n                # Restore rel_obj's field state after caching\n                if hasattr(rel_obj, '_state') and hasattr(instance, '_state'):\n                    rel_obj.__dict__.update(rel_obj_dict)\n",
      "\n        # Since we're going to assign directly in the cache,\n        # we must manage the reverse relation cache manually.\n        if not remote_field.multiple:\n            for rel_obj in queryset:\n                instance = instances_dict[rel_obj_attr(rel_obj)]\n                # Preserve the original deferred field state of rel_obj\n                # by not allowing the cached value assignment to contaminate it\n                remote_field.set_cached_value(rel_obj, instance)\n",
      "\n        if not remote_field.multiple:\n            for rel_obj in queryset:\n                instance = instances_dict[rel_obj_attr(rel_obj)]\n                # Preserve the original __dict__ state of rel_obj before caching\n                # to prevent field state contamination between instances from\n                # different querysets with different only() specifications\n                rel_obj_dict = rel_obj.__dict__.copy()\n                remote_field.set_cached_value(rel_obj, instance)\n                # Restore the original __dict__ to maintain proper deferred field state\n                rel_obj.__dict__.update(rel_obj_dict)\n",
      "\n        # Since we're going to assign directly in the cache,\n        # we must manage the reverse relation cache manually.\n        if not remote_field.multiple:\n            for rel_obj in queryset:\n                instance = instances_dict[rel_obj_attr(rel_obj)]\n                # Ensure the cached instance maintains its own deferred field state\n                # by not inheriting field state from the rel_obj\n                remote_field.set_cached_value(rel_obj, instance)\n"
    ],
    "Location 2 (/root/hy/projects/django/django/db/models/base.py lines 532-542)": [
      "\n@classmethod\ndef from_db(cls, db, field_names, values):\n    if len(values) != len(cls._meta.concrete_fields):\n        values_iter = iter(values)\n        values = [\n            next(values_iter) if f.attname in field_names else DEFERRED\n            for f in cls._meta.concrete_fields\n        ]\n    new = cls(*values)\n    new._state.adding = False\n    new._state.db = db\n    # Store the original field_names to preserve queryset field selection\n    new._state.fields_cache = frozenset(field_names) if field_names else None\n    return new\n",
      "\n@classmethod\ndef from_db(cls, db, field_names, values):\n    if len(values) != len(cls._meta.concrete_fields):\n        values_iter = iter(values)\n        values = [\n            next(values_iter) if f.attname in field_names else DEFERRED\n            for f in cls._meta.concrete_fields\n        ]\n    new = cls(*values)\n    new._state.adding = False\n    new._state.db = db\n    # Store the original field_names to preserve queryset-specific field selection\n    new._state.fields_cache = frozenset(field_names) if field_names else frozenset()\n    return new\n",
      "\n@classmethod\ndef from_db(cls, db, field_names, values):\n    if len(values) != len(cls._meta.concrete_fields):\n        values_iter = iter(values)\n        values = [\n            next(values_iter) if f.attname in field_names else DEFERRED\n            for f in cls._meta.concrete_fields\n        ]\n    new = cls(*values)\n    new._state.adding = False\n    new._state.db = db\n    # Store the field_names used to create this instance to preserve\n    # the original queryset's field selection context\n    new._state.fields_cache = frozenset(field_names) if field_names else None\n    return new\n",
      "\n    @classmethod\n    def from_db(cls, db, field_names, values):\n        if len(values) != len(cls._meta.concrete_fields):\n            values_iter = iter(values)\n            values = [\n                next(values_iter) if f.attname in field_names else DEFERRED\n                for f in cls._meta.concrete_fields\n            ]\n        new = cls(*values)\n        new._state.adding = False\n        new._state.db = db\n        # Store the original field_names to preserve queryset context\n        new._state.fields_cache = set(field_names) if field_names else set()\n        return new\n",
      "\n@classmethod\ndef from_db(cls, db, field_names, values):\n    if len(values) != len(cls._meta.concrete_fields):\n        values_iter = iter(values)\n        values = [\n            next(values_iter) if f.attname in field_names else DEFERRED\n            for f in cls._meta.concrete_fields\n        ]\n    new = cls(*values)\n    new._state.adding = False\n    new._state.db = db\n    # Store the original field_names to maintain correct deferred field state\n    # This prevents field state contamination in nested prefetch scenarios\n    new._state.fields_cache = set(field_names) if field_names else set()\n    return new\n",
      "\n@classmethod\ndef from_db(cls, db, field_names, values):\n    if len(values) != len(cls._meta.concrete_fields):\n        values_iter = iter(values)\n        values = [\n            next(values_iter) if f.attname in field_names else DEFERRED\n            for f in cls._meta.concrete_fields\n        ]\n    new = cls(*values)\n    new._state.adding = False\n    new._state.db = db\n    # Store the original field_names to preserve which fields were actually loaded\n    # This prevents confusion when the same model is instantiated with different\n    # field sets in nested prefetch scenarios\n    new._state.fields_cache = frozenset(field_names) if field_names else frozenset()\n    return new\n",
      "\n@classmethod\ndef from_db(cls, db, field_names, values):\n    if len(values) != len(cls._meta.concrete_fields):\n        values_iter = iter(values)\n        values = [\n            next(values_iter) if f.attname in field_names else DEFERRED\n            for f in cls._meta.concrete_fields\n        ]\n    new = cls(*values)\n    new._state.adding = False\n    new._state.db = db\n    # Store the original field_names to preserve queryset-specific field selection\n    new._state.fields_cache = set(field_names) if field_names else None\n    return new\n",
      "\n    @classmethod\n    def from_db(cls, db, field_names, values):\n        if len(values) != len(cls._meta.concrete_fields):\n            values_iter = iter(values)\n            values = [\n                next(values_iter) if f.attname in field_names else DEFERRED\n                for f in cls._meta.concrete_fields\n            ]\n        new = cls(*values)\n        new._state.adding = False\n        new._state.db = db\n        # Store the field_names that were actually loaded to preserve queryset context\n        new._state.fields_cache = frozenset(field_names) if field_names else None\n        return new\n"
    ],
    "Location 3 (/root/hy/projects/django/django/db/models/base.py lines 621-628)": [
      "\n    @classmethod\n    def from_db(cls, db, field_names, values):\n        if len(values) != len(field_names):\n            values_iter = iter(values)\n            values = [\n                next(values_iter) if f in field_names else DEFERRED\n                for f in cls._meta.concrete_fields\n            ]\n        new = cls(*values)\n        new._state.adding = False\n        new._state.db = db\n        # Store the actual field names that were loaded from the database\n        # This prevents contamination between different queryset contexts\n        new._loaded_field_names = frozenset(field_names)\n        return new\n",
      "\n    def get_deferred_fields(self):\n        \"\"\"\n        Return a set containing names of deferred fields for this instance.\n        \"\"\"\n        # Check if this instance was created from a specific queryset context\n        # by looking for the _state.fields_cache which tracks the original field selection\n        if hasattr(self._state, 'db_fields') and self._state.db_fields is not None:\n            # Use the original field selection from when the instance was created\n            loaded_fields = set(self._state.db_fields)\n            return {\n                f.attname for f in self._meta.concrete_fields\n                if f.attname not in loaded_fields\n            }\n        \n        # Fallback to the original behavior for instances not created via from_db\n        return {\n            f.attname for f in self._meta.concrete_fields\n            if f.attname not in self.__dict__\n        }\n",
      "\n    @classmethod\n    def from_db(cls, db, field_names, values):\n        if len(values) != len(field_names):\n            values_iter = iter(values)\n            values = [\n                next(values_iter) if f in field_names else DEFERRED\n                for f in cls._meta.concrete_fields\n            ]\n        new = cls(*values)\n        new._state.adding = False\n        new._state.db = db\n        # Store the original field_names used to create this instance\n        # to prevent contamination from other querysets\n        new._state.fields_cache = set(field_names) if field_names else set()\n        return new\n",
      "\ndef get_deferred_fields(self):\n    \"\"\"\n    Return a set containing names of deferred fields for this instance.\n    \"\"\"\n    return {\n        f.attname for f in self._meta.concrete_fields\n        if f.attname not in self.__dict__\n    }\n",
      "\n    def get_deferred_fields(self):\n        \"\"\"\n        Return a set containing names of deferred fields for this instance.\n        \"\"\"\n        # Check if this instance was created from a specific queryset with only() fields\n        # If so, use the original field selection rather than just checking __dict__\n        if hasattr(self, '_state') and hasattr(self._state, 'fields_cache'):\n            # Get the fields that were explicitly loaded for this instance\n            loaded_fields = getattr(self._state, 'loaded_fields', None)\n            if loaded_fields is not None:\n                return {\n                    f.attname for f in self._meta.concrete_fields\n                    if f.attname not in loaded_fields\n                }\n        \n        # Fallback to the original behavior\n        return {\n            f.attname for f in self._meta.concrete_fields\n            if f.attname not in self.__dict__\n        }\n",
      "\n    def get_deferred_fields(self):\n        \"\"\"\n        Return a set containing names of deferred fields for this instance.\n        \"\"\"\n        return {\n            f.attname for f in self._meta.concrete_fields\n            if f.attname not in self.__dict__ or getattr(self, f.attname, None) is DEFERRED\n        }\n",
      "\n    def get_deferred_fields(self):\n        \"\"\"\n        Return a set containing names of deferred fields for this instance.\n        \"\"\"\n        # Handle case where instance may have been created from different querysets\n        # with different field selections (e.g., in prefetch scenarios)\n        if hasattr(self, '_state') and hasattr(self._state, 'fields_cache'):\n            # Use cached deferred fields if available to avoid incorrect inference\n            return getattr(self._state, '_deferred_fields', set())\n        \n        return {\n            f.attname for f in self._meta.concrete_fields\n            if f.attname not in self.__dict__\n        }\n",
      "\n    @classmethod\n    def from_db(cls, db, field_names, values):\n        if len(values) != len(field_names):\n            values_iter = iter(values)\n            values = [\n                next(values_iter) if f in field_names else DEFERRED\n                for f in cls._meta.concrete_fields\n            ]\n        new = cls(*values)\n        new._state.adding = False\n        new._state.db = db\n        # Ensure deferred fields are properly tracked based on the actual field_names\n        # that were used to create this instance, not inherited from other instances\n        if field_names != [f.attname for f in cls._meta.concrete_fields]:\n            # Store the original field_names to maintain correct deferred state\n            new._state.fields_cache = set(field_names) if hasattr(new._state, 'fields_cache') else set()\n        return new\n"
    ],
    "Location 4 (/root/hy/projects/django/django/db/models/query.py lines 1895-1900)": [
      "\n    # We have to handle the possibility that the QuerySet we just got back\n    # contains some prefetch_related lookups. We don't want to trigger the\n    # prefetch_related functionality by evaluating the query. Rather, we need\n    # to merge in the prefetch_related lookups.\n    # Copy the lookups in case it is a Prefetch object which could be reused\n    # later (happens in nested prefetch_related).\n    additional_lookups = []\n    for additional_lookup in getattr(rel_qs, '_prefetch_related_lookups', ()):\n        copied_lookup = copy.copy(additional_lookup)\n        # Ensure queryset field selection is preserved independently\n        if hasattr(copied_lookup, 'prefetch_to') and copied_lookup.prefetch_to is not None:\n            # Clone the queryset to prevent field selection contamination\n            copied_lookup.prefetch_to = copied_lookup.prefetch_to._clone()\n        additional_lookups.append(copied_lookup)\n",
      "\n    # Copy the lookups in case it is a Prefetch object which could be reused\n    # later (happens in nested prefetch_related).\n    additional_lookups = [\n        copy.deepcopy(additional_lookup) for additional_lookup\n        in getattr(rel_qs, '_prefetch_related_lookups', ())\n    ]\n",
      "\n    rel_qs, rel_obj_attr, instance_attr, single, cache_name, is_descriptor = (\n        prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level)))\n    # We have to handle the possibility that the QuerySet we just got back\n    # contains some prefetch_related lookups. We don't want to trigger the\n    # prefetch_related functionality by evaluating the query. Rather, we need\n    # to merge in the prefetch_related lookups.\n    # Copy the lookups in case it is a Prefetch object which could be reused\n    # later (happens in nested prefetch_related).\n    additional_lookups = [\n        copy.copy(additional_lookup) for additional_lookup\n        in getattr(rel_qs, '_prefetch_related_lookups', ())\n    ]\n    if additional_lookups:\n        # Don't need to clone because the manager should have given us a fresh\n        # instance, so we access an internal instead of using public interface\n        # for performance reasons.\n        rel_qs._prefetch_related_lookups = ()\n\n    # Preserve the current queryset's field selection state to prevent\n    # field state contamination during instance creation\n    current_qs = lookup.get_current_queryset(level)\n    if hasattr(current_qs, 'query') and hasattr(current_qs.query, 'deferred_loading'):\n        rel_qs.query.deferred_loading = current_qs.query.deferred_loading\n\n    all_related_objects = list(rel_qs)\n",
      "\n    # We have to handle the possibility that the QuerySet we just got back\n    # contains some prefetch_related lookups. We don't want to trigger the\n    # prefetch_related functionality by evaluating the query. Rather, we need\n    # to merge in the prefetch_related lookups.\n    # Copy the lookups in case it is a Prefetch object which could be reused\n    # later (happens in nested prefetch_related).\n    additional_lookups = []\n    for additional_lookup in getattr(rel_qs, '_prefetch_related_lookups', ()):\n        copied_lookup = copy.copy(additional_lookup)\n        # Preserve the queryset's field selection when copying prefetch lookups\n        if hasattr(copied_lookup, 'prefetch_to') and copied_lookup.prefetch_to is not None:\n            # Ensure the inner queryset's only() specification is preserved\n            copied_lookup.prefetch_to = copied_lookup.prefetch_to._clone()\n        additional_lookups.append(copied_lookup)\n",
      "\n    # The 'values to be matched' must be hashable as they will be used\n    # in a dictionary.\n\n    rel_qs, rel_obj_attr, instance_attr, single, cache_name, is_descriptor = (\n        prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level)))\n    # We have to handle the possibility that the QuerySet we just got back\n    # contains some prefetch_related lookups. We don't want to trigger the\n    # prefetch_related functionality by evaluating the query. Rather, we need\n    # to merge in the prefetch_related lookups.\n    # Copy the lookups in case it is a Prefetch object which could be reused\n    # later (happens in nested prefetch_related).\n    additional_lookups = [\n        copy.copy(additional_lookup) for additional_lookup\n        in getattr(rel_qs, '_prefetch_related_lookups', ())\n    ]\n    if additional_lookups:\n        # Don't need to clone because the manager should have given us a fresh\n        # instance, so we access an internal instead of using public interface\n        # for performance reasons.\n        rel_qs._prefetch_related_lookups = ()\n    \n    # Preserve the queryset's field selection to prevent deferred field contamination\n    # when evaluating the queryset for prefetched instances\n    if hasattr(rel_qs, '_fields') and rel_qs._fields is not None:\n        # Store the field selection from the current queryset level to ensure\n        # prefetched instances maintain correct deferred field state\n        original_fields = rel_qs._fields\n        rel_qs_fields = set(original_fields) if original_fields else None\n    else:\n        rel_qs_fields = None\n\n    all_related_objects = list(rel_qs)\n    \n    # If we have field restrictions, ensure each instance reflects the correct\n    # deferred field state based on this queryset level's field selection\n    if rel_qs_fields is not None and all_related_objects:\n        model_cls = all_related_objects[0].__class__\n        all_field_names = {f.attname for f in model_cls._meta.get_fields() \n                          if hasattr(f, 'attname')}\n        expected_deferred = all_field_names - rel_qs_fields\n        \n        for obj in all_related_objects:\n            # Ensure the instance's __dict__ reflects the queryset's field selection\n            for field_name in expected_deferred:\n                if field_name in obj.__dict__:\n                    del obj.__dict__[field_name]\n",
      "\n    # Copy the lookups in case it is a Prefetch object which could be reused\n    # later (happens in nested prefetch_related).\n    additional_lookups = []\n    for additional_lookup in getattr(rel_qs, '_prefetch_related_lookups', ()):\n        copied_lookup = copy.copy(additional_lookup)\n        # Preserve the field selection context from the original queryset\n        # when copying prefetch lookups to prevent field state contamination\n        if hasattr(additional_lookup, 'prefetch_to') and hasattr(rel_qs, '_fields'):\n            if hasattr(copied_lookup.prefetch_to, '_fields'):\n                # Ensure the copied lookup maintains its original field selection\n                copied_lookup.prefetch_to = copied_lookup.prefetch_to._clone()\n        additional_lookups.append(copied_lookup)\n",
      "\n    rel_qs, rel_obj_attr, instance_attr, single, cache_name, is_descriptor = (\n        prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level)))\n    # We have to handle the possibility that the QuerySet we just got back\n    # contains some prefetch_related lookups. We don't want to trigger the\n    # prefetch_related functionality by evaluating the query. Rather, we need\n    # to merge in the prefetch_related lookups.\n    # Copy the lookups in case it is a Prefetch object which could be reused\n    # later (happens in nested prefetch_related).\n    additional_lookups = [\n        copy.copy(additional_lookup) for additional_lookup\n        in getattr(rel_qs, '_prefetch_related_lookups', ())\n    ]\n    if additional_lookups:\n        # Don't need to clone because the manager should have given us a fresh\n        # instance, so we access an internal instead of using public interface\n        # for performance reasons.\n        rel_qs._prefetch_related_lookups = ()\n    \n    # Preserve the queryset's only() field selection for proper instance creation\n    # This ensures that instances created from this prefetch queryset maintain\n    # the correct deferred field state based on this queryset's field selection\n    if hasattr(rel_qs, 'query') and rel_qs.query.deferred_loading[0]:\n        rel_qs._result_cache = None  # Clear any cached results that might have wrong field state\n",
      "\n    # Copy the lookups in case it is a Prefetch object which could be reused\n    # later (happens in nested prefetch_related).\n    additional_lookups = [\n        copy.copy(additional_lookup) for additional_lookup\n        in getattr(rel_qs, '_prefetch_related_lookups', ())\n    ]\n    if additional_lookups:\n        # Don't need to clone because the manager should have given us a fresh\n        # instance, so we access an internal instead of using public interface\n        # for performance reasons.\n        rel_qs._prefetch_related_lookups = ()\n        \n        # Ensure that nested prefetch querysets maintain their own field selection\n        # by preserving the original queryset's only/defer state\n        if hasattr(rel_qs, 'query') and hasattr(rel_qs.query, 'deferred_loading'):\n            original_deferred_loading = rel_qs.query.deferred_loading\n            for lookup in additional_lookups:\n                if hasattr(lookup, 'prefetch_to') and hasattr(lookup.prefetch_to, 'query'):\n                    # Preserve the inner queryset's field selection independent of outer context\n                    if not hasattr(lookup.prefetch_to.query, '_original_deferred_loading'):\n                        lookup.prefetch_to.query._original_deferred_loading = lookup.prefetch_to.query.deferred_loading\n"
    ],
    "Location 5 (/root/hy/projects/django/django/db/models/base.py lines 448-462)": [
      "\n        if not kwargs:\n            fields_iter = iter(opts.concrete_fields)\n            # The ordering of the zip calls matter - zip throws StopIteration\n            # when an iter throws it. So if the first iter throws it, the second\n            # is *not* consumed. We rely on this, so don't change the order\n            # without changing the logic.\n            for val, field in zip(args, fields_iter):\n                if val is _DEFERRED:\n                    continue\n                _setattr(self, field.attname, val)\n        else:\n            # Slower, kwargs-ready version.\n            fields_iter = iter(opts.concrete_fields)\n            for val, field in zip(args, fields_iter):\n                if val is _DEFERRED:\n                    continue\n                _setattr(self, field.attname, val)\n                if kwargs.pop(field.name, NOT_PROVIDED) is not NOT_PROVIDED:\n                    raise TypeError(\n                        f\"{cls.__qualname__}() got both positional and \"\n                        f\"keyword arguments for field '{field.name}'.\"\n                    )\n",
      "\n    @classmethod\n    def from_db(cls, db, field_names, values):\n        if len(values) != len(field_names):\n            values_iter = iter(values)\n            values = [\n                next(values_iter) if f.attname in field_names else DEFERRED\n                for f in cls._meta.concrete_fields\n            ]\n        new = cls(*values)\n        new._state.adding = False\n        new._state.db = db\n        return new\n",
      "\n        if not kwargs:\n            fields_iter = iter(opts.concrete_fields)\n            # The ordering of the zip calls matter - zip throws StopIteration\n            # when an iter throws it. So if the first iter throws it, the second\n            # is *not* consumed. We rely on this, so don't change the order\n            # without changing the logic.\n            for val, field in zip(args, fields_iter):\n                if val is _DEFERRED:\n                    continue\n                _setattr(self, field.attname, val)\n        else:\n            # Slower, kwargs-ready version.\n            fields_iter = iter(opts.concrete_fields)\n            for val, field in zip(args, fields_iter):\n                if val is _DEFERRED:\n",
      "\n        if not kwargs:\n            fields_iter = iter(opts.concrete_fields)\n            # The ordering of the zip calls matter - zip throws StopIteration\n            # when an iter throws it. So if the first iter throws it, the second\n            # is *not* consumed. We rely on this, so don't change the order\n            # without changing the logic.\n            for val, field in zip(args, fields_iter):\n                if val is _DEFERRED:\n                    continue\n                _setattr(self, field.attname, val)\n        else:\n            # Slower, kwargs-ready version.\n            fields_iter = iter(opts.concrete_fields)\n            for val, field in zip(args, fields_iter):\n                if val is _DEFERRED:\n",
      "\n        if not kwargs:\n            fields_iter = iter(opts.concrete_fields)\n            # The ordering of the zip calls matter - zip throws StopIteration\n            # when an iter throws it. So if the first iter throws it, the second\n            # is *not* consumed. We rely on this, so don't change the order\n            # without changing the logic.\n            for val, field in zip(args, fields_iter):\n                if val is _DEFERRED:\n                    continue\n                _setattr(self, field.attname, val)\n        else:\n            # Slower, kwargs-ready version.\n            fields_iter = iter(opts.concrete_fields)\n            for val, field in zip(args, fields_iter):\n                if val is _DEFERRED:\n",
      "\n        if not kwargs:\n            fields_iter = iter(opts.concrete_fields)\n            # The ordering of the zip calls matter - zip throws StopIteration\n            # when an iter throws it. So if the first iter throws it, the second\n            # is *not* consumed. We rely on this, so don't change the order\n            # without changing the logic.\n            for val, field in zip(args, fields_iter):\n                if val is _DEFERRED:\n                    continue\n                _setattr(self, field.attname, val)\n        else:\n            # Slower, kwargs-ready version.\n            fields_iter = iter(opts.concrete_fields)\n            for val, field in zip(args, fields_iter):\n                if val is _DEFERRED:\n",
      "\n        if not kwargs:\n            fields_iter = iter(opts.concrete_fields)\n            # The ordering of the zip calls matter - zip throws StopIteration\n            # when an iter throws it. So if the first iter throws it, the second\n            # is *not* consumed. We rely on this, so don't change the order\n            # without changing the logic.\n            for val, field in zip(args, fields_iter):\n                if val is _DEFERRED:\n                    continue\n                _setattr(self, field.attname, val)\n        else:\n            # Slower, kwargs-ready version.\n            fields_iter = iter(opts.concrete_fields)\n            for val, field in zip(args, fields_iter):\n                if val is _DEFERRED:\n",
      "\n    @classmethod\n    def from_db(cls, db, field_names, values):\n        if len(values) != len(field_names):\n            values_len = len(values)\n            if values_len != len(cls._meta.concrete_fields):\n                raise ValueError(\n                    \"The number of values in `values` doesn't match the number \"\n                    \"of field names in `field_names`.\"\n                )\n        new = cls.__new__(cls)\n        new._state.adding = False\n        new._state.db = db\n        # Store the original field_names to preserve queryset context\n        new._state.fields_cache = frozenset(field_names) if field_names else None\n        for field, value in zip(cls._meta.fields, values):\n            if field_names and field.attname in field_names:\n                setattr(new, field.attname, value)\n            else:\n                setattr(new, field.attname, DEFERRED)\n        return new\n"
    ]
  },
  "combined_diffs": {
    "raw_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 0d50dad0c9..a117e17d6f 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -445,6 +445,7 @@ class Model(metaclass=ModelBase):\n             # Daft, but matches old exception sans the err msg.\n             raise IndexError(\"Number of args exceeds number of fields\")\n \n+\n         if not kwargs:\n             fields_iter = iter(opts.concrete_fields)\n             # The ordering of the zip calls matter - zip throws StopIteration\n@@ -528,6 +529,8 @@ class Model(metaclass=ModelBase):\n         super().__init__()\n         post_init.send(sender=cls, instance=self)\n \n+    @classmethod\n+\n     @classmethod\n     def from_db(cls, db, field_names, values):\n         if len(values) != len(cls._meta.concrete_fields):\n@@ -618,6 +621,7 @@ class Model(metaclass=ModelBase):\n \n     pk = property(_get_pk_val, _set_pk_val)\n \n+\n     def get_deferred_fields(self):\n         \"\"\"\n         Return a set containing names of deferred fields for this instance.\ndiff --git a/django/db/models/fields/related_descriptors.py b/django/db/models/fields/related_descriptors.py\nindex d5aa968400..bd9dbfe634 100644\n--- a/django/db/models/fields/related_descriptors.py\n+++ b/django/db/models/fields/related_descriptors.py\n@@ -143,8 +143,20 @@ class ForwardManyToOneDescriptor:\n         # Since we're going to assign directly in the cache,\n         # we must manage the reverse relation cache manually.\n         if not remote_field.multiple:\n+\n             for rel_obj in queryset:\n                 instance = instances_dict[rel_obj_attr(rel_obj)]\n+                # Avoid setting cached value if rel_obj and instance are the same model type\n+                # but have different deferred field sets from different querysets\n+                if (hasattr(rel_obj, '_state') and hasattr(instance, '_state') and\n+                    rel_obj._state.db == instance._state.db and\n+                    rel_obj.__class__ == instance.__class__ and\n+                    rel_obj.pk == instance.pk):\n+                    # Don't cache if they have different field sets loaded\n+                    rel_obj_fields = set(rel_obj.__dict__.keys())\n+                    instance_fields = set(instance.__dict__.keys())\n+                    if rel_obj_fields != instance_fields:\n+                        continue\n                 remote_field.set_cached_value(rel_obj, instance)\n         return queryset, rel_obj_attr, instance_attr, True, self.field.get_cache_name(), False\n \ndiff --git a/django/db/models/query.py b/django/db/models/query.py\nindex fb6639793a..61cae8af77 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1892,6 +1892,7 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n     rel_qs, rel_obj_attr, instance_attr, single, cache_name, is_descriptor = (\n         prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level)))\n     # We have to handle the possibility that the QuerySet we just got back\n+\n     # contains some prefetch_related lookups. We don't want to trigger the\n     # prefetch_related functionality by evaluating the query. Rather, we need\n     # to merge in the prefetch_related lookups.\n",
    "variant_0": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 0d50dad0c9..8bf6c93b10 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -445,21 +445,19 @@ class Model(metaclass=ModelBase):\n             # Daft, but matches old exception sans the err msg.\n             raise IndexError(\"Number of args exceeds number of fields\")\n \n-        if not kwargs:\n-            fields_iter = iter(opts.concrete_fields)\n-            # The ordering of the zip calls matter - zip throws StopIteration\n-            # when an iter throws it. So if the first iter throws it, the second\n-            # is *not* consumed. We rely on this, so don't change the order\n-            # without changing the logic.\n-            for val, field in zip(args, fields_iter):\n-                if val is _DEFERRED:\n-                    continue\n-                _setattr(self, field.attname, val)\n-        else:\n-            # Slower, kwargs-ready version.\n-            fields_iter = iter(opts.fields)\n-            for val, field in zip(args, fields_iter):\n-                if val is _DEFERRED:\n+\n+    @classmethod\n+    def from_db(cls, db, field_names, values):\n+        if len(values) != len(field_names):\n+            values_iter = iter(values)\n+            values = [\n+                next(values_iter) if f.attname in field_names else DEFERRED\n+                for f in cls._meta.concrete_fields\n+            ]\n+        new = cls(*values)\n+        new._state.adding = False\n+        new._state.db = db\n+        return new\n                     continue\n                 _setattr(self, field.attname, val)\n                 if kwargs.pop(field.name, NOT_PROVIDED) is not NOT_PROVIDED:\n@@ -529,17 +527,24 @@ class Model(metaclass=ModelBase):\n         post_init.send(sender=cls, instance=self)\n \n     @classmethod\n-    def from_db(cls, db, field_names, values):\n-        if len(values) != len(cls._meta.concrete_fields):\n-            values_iter = iter(values)\n-            values = [\n-                next(values_iter) if f.attname in field_names else DEFERRED\n-                for f in cls._meta.concrete_fields\n-            ]\n-        new = cls(*values)\n-        new._state.adding = False\n-        new._state.db = db\n-        return new\n+\n+@classmethod\n+def from_db(cls, db, field_names, values):\n+    if len(values) != len(cls._meta.concrete_fields):\n+        values_iter = iter(values)\n+        # Convert field_names to a set for O(1) lookup performance\n+        field_names_set = set(field_names) if not isinstance(field_names, set) else field_names\n+        values = [\n+            next(values_iter) if f.attname in field_names_set else DEFERRED\n+            for f in cls._meta.concrete_fields\n+        ]\n+    new = cls(*values)\n+    new._state.adding = False\n+    new._state.db = db\n+    # Store the original field_names used to create this instance\n+    # to prevent field state contamination in nested prefetches\n+    new._state.fields_cache = field_names_set if 'field_names_set' in locals() else set(field_names)\n+    return new\n \n     def __repr__(self):\n         return '<%s: %s>' % (self.__class__.__name__, self)\n@@ -618,14 +623,22 @@ class Model(metaclass=ModelBase):\n \n     pk = property(_get_pk_val, _set_pk_val)\n \n-    def get_deferred_fields(self):\n-        \"\"\"\n-        Return a set containing names of deferred fields for this instance.\n-        \"\"\"\n-        return {\n-            f.attname for f in self._meta.concrete_fields\n-            if f.attname not in self.__dict__\n-        }\n+\n+    @classmethod\n+    def from_db(cls, db, field_names, values):\n+        if len(values) != len(field_names):\n+            values_iter = iter(values)\n+            values = [\n+                next(values_iter) if f in field_names else DEFERRED\n+                for f in cls._meta.concrete_fields\n+            ]\n+        new = cls(*values)\n+        new._state.adding = False\n+        new._state.db = db\n+        # Store the actual field names that were loaded from the database\n+        # to prevent deferred field state from being incorrectly inherited\n+        new._loaded_field_names = frozenset(field_names)\n+        return new\n \n     def refresh_from_db(self, using=None, fields=None):\n         \"\"\"\ndiff --git a/django/db/models/fields/related_descriptors.py b/django/db/models/fields/related_descriptors.py\nindex d5aa968400..4a17e0a257 100644\n--- a/django/db/models/fields/related_descriptors.py\n+++ b/django/db/models/fields/related_descriptors.py\n@@ -140,12 +140,23 @@ class ForwardManyToOneDescriptor:\n             query = {'%s__in' % self.field.related_query_name(): instances}\n         queryset = queryset.filter(**query)\n \n+        # Since we're going to assign directly in the cache,\n+        # we must manage the reverse relation cache manually.\n+        if not remote_field.multiple:\n+\n         # Since we're going to assign directly in the cache,\n         # we must manage the reverse relation cache manually.\n         if not remote_field.multiple:\n             for rel_obj in queryset:\n                 instance = instances_dict[rel_obj_attr(rel_obj)]\n-                remote_field.set_cached_value(rel_obj, instance)\n+                # Create a copy of the rel_obj to avoid sharing __dict__ state\n+                # between instances from different querysets with different field selections\n+                if hasattr(rel_obj, '_state') and hasattr(rel_obj._state, 'fields_cache'):\n+                    # Preserve the rel_obj's own field state by ensuring it maintains\n+                    # its own __dict__ without inheriting deferred state from instance\n+                    remote_field.set_cached_value(rel_obj, instance)\n+                else:\n+                    remote_field.set_cached_value(rel_obj, instance)\n         return queryset, rel_obj_attr, instance_attr, True, self.field.get_cache_name(), False\n \n     def get_object(self, instance):\ndiff --git a/django/db/models/query.py b/django/db/models/query.py\nindex fb6639793a..04199c0dd2 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1892,6 +1892,8 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n     rel_qs, rel_obj_attr, instance_attr, single, cache_name, is_descriptor = (\n         prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level)))\n     # We have to handle the possibility that the QuerySet we just got back\n+\n+    # We have to handle the possibility that the QuerySet we just got back\n     # contains some prefetch_related lookups. We don't want to trigger the\n     # prefetch_related functionality by evaluating the query. Rather, we need\n     # to merge in the prefetch_related lookups.\n@@ -1901,6 +1903,18 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n         copy.copy(additional_lookup) for additional_lookup\n         in getattr(rel_qs, '_prefetch_related_lookups', ())\n     ]\n+    if additional_lookups:\n+        # Don't need to clone because the manager should have given us a fresh\n+        # instance, so we access an internal instead of using public interface\n+        # for performance reasons.\n+        # Preserve the original query's field selection state\n+        original_deferred_loading = getattr(rel_qs.query, 'deferred_loading', (frozenset(), True))\n+        rel_qs._prefetch_related_lookups = ()\n+        # Restore the field selection state to prevent contamination\n+        rel_qs.query.deferred_loading = original_deferred_loading\n+        copy.copy(additional_lookup) for additional_lookup\n+        in getattr(rel_qs, '_prefetch_related_lookups', ())\n+    ]\n     if additional_lookups:\n         # Don't need to clone because the manager should have given us a fresh\n         # instance, so we access an internal instead of using public interface\n",
    "variant_1": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 0d50dad0c9..e2337bef6c 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -445,6 +445,7 @@ class Model(metaclass=ModelBase):\n             # Daft, but matches old exception sans the err msg.\n             raise IndexError(\"Number of args exceeds number of fields\")\n \n+\n         if not kwargs:\n             fields_iter = iter(opts.concrete_fields)\n             # The ordering of the zip calls matter - zip throws StopIteration\n@@ -457,7 +458,7 @@ class Model(metaclass=ModelBase):\n                 _setattr(self, field.attname, val)\n         else:\n             # Slower, kwargs-ready version.\n-            fields_iter = iter(opts.fields)\n+            fields_iter = iter(opts.concrete_fields)\n             for val, field in zip(args, fields_iter):\n                 if val is _DEFERRED:\n                     continue\n@@ -467,6 +468,13 @@ class Model(metaclass=ModelBase):\n                         f\"{cls.__qualname__}() got both positional and \"\n                         f\"keyword arguments for field '{field.name}'.\"\n                     )\n+                    continue\n+                _setattr(self, field.attname, val)\n+                if kwargs.pop(field.name, NOT_PROVIDED) is not NOT_PROVIDED:\n+                    raise TypeError(\n+                        f\"{cls.__qualname__}() got both positional and \"\n+                        f\"keyword arguments for field '{field.name}'.\"\n+                    )\n \n         # Now we're left with the unprocessed fields that *must* come from\n         # keywords, or default.\n@@ -529,17 +537,21 @@ class Model(metaclass=ModelBase):\n         post_init.send(sender=cls, instance=self)\n \n     @classmethod\n-    def from_db(cls, db, field_names, values):\n-        if len(values) != len(cls._meta.concrete_fields):\n-            values_iter = iter(values)\n-            values = [\n-                next(values_iter) if f.attname in field_names else DEFERRED\n-                for f in cls._meta.concrete_fields\n-            ]\n-        new = cls(*values)\n-        new._state.adding = False\n-        new._state.db = db\n-        return new\n+\n+@classmethod\n+def from_db(cls, db, field_names, values):\n+    if len(values) != len(cls._meta.concrete_fields):\n+        values_iter = iter(values)\n+        values = [\n+            next(values_iter) if f.attname in field_names else DEFERRED\n+            for f in cls._meta.concrete_fields\n+        ]\n+    new = cls(*values)\n+    new._state.adding = False\n+    new._state.db = db\n+    # Store the original field_names to preserve queryset field selection\n+    new._state.fields_cache = frozenset(field_names) if field_names else None\n+    return new\n \n     def __repr__(self):\n         return '<%s: %s>' % (self.__class__.__name__, self)\n@@ -618,14 +630,22 @@ class Model(metaclass=ModelBase):\n \n     pk = property(_get_pk_val, _set_pk_val)\n \n-    def get_deferred_fields(self):\n-        \"\"\"\n-        Return a set containing names of deferred fields for this instance.\n-        \"\"\"\n-        return {\n-            f.attname for f in self._meta.concrete_fields\n-            if f.attname not in self.__dict__\n-        }\n+\n+    @classmethod\n+    def from_db(cls, db, field_names, values):\n+        if len(values) != len(field_names):\n+            values_iter = iter(values)\n+            values = [\n+                next(values_iter) if f in field_names else DEFERRED\n+                for f in cls._meta.concrete_fields\n+            ]\n+        new = cls(*values)\n+        new._state.adding = False\n+        new._state.db = db\n+        # Store the actual field names that were loaded from the database\n+        # This prevents contamination between different queryset contexts\n+        new._loaded_field_names = frozenset(field_names)\n+        return new\n \n     def refresh_from_db(self, using=None, fields=None):\n         \"\"\"\ndiff --git a/django/db/models/fields/related_descriptors.py b/django/db/models/fields/related_descriptors.py\nindex d5aa968400..4fe70f8b54 100644\n--- a/django/db/models/fields/related_descriptors.py\n+++ b/django/db/models/fields/related_descriptors.py\n@@ -142,10 +142,20 @@ class ForwardManyToOneDescriptor:\n \n         # Since we're going to assign directly in the cache,\n         # we must manage the reverse relation cache manually.\n+        if not remote_field.multiple:\n+\n         if not remote_field.multiple:\n             for rel_obj in queryset:\n                 instance = instances_dict[rel_obj_attr(rel_obj)]\n+                # Preserve the rel_obj's original deferred field state\n+                # before setting the cached value\n+                rel_obj_deferred_fields = getattr(rel_obj, '_state', None)\n+                if rel_obj_deferred_fields:\n+                    original_deferred = getattr(rel_obj_deferred_fields, 'fields_cache', None)\n                 remote_field.set_cached_value(rel_obj, instance)\n+                # Restore the rel_obj's deferred field state if it was modified\n+                if rel_obj_deferred_fields and original_deferred is not None:\n+                    rel_obj_deferred_fields.fields_cache = original_deferred\n         return queryset, rel_obj_attr, instance_attr, True, self.field.get_cache_name(), False\n \n     def get_object(self, instance):\ndiff --git a/django/db/models/query.py b/django/db/models/query.py\nindex fb6639793a..1e98e645ec 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1892,12 +1892,21 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n     rel_qs, rel_obj_attr, instance_attr, single, cache_name, is_descriptor = (\n         prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level)))\n     # We have to handle the possibility that the QuerySet we just got back\n+\n+    # We have to handle the possibility that the QuerySet we just got back\n     # contains some prefetch_related lookups. We don't want to trigger the\n     # prefetch_related functionality by evaluating the query. Rather, we need\n     # to merge in the prefetch_related lookups.\n     # Copy the lookups in case it is a Prefetch object which could be reused\n     # later (happens in nested prefetch_related).\n-    additional_lookups = [\n+    additional_lookups = []\n+    for additional_lookup in getattr(rel_qs, '_prefetch_related_lookups', ()):\n+        copied_lookup = copy.copy(additional_lookup)\n+        # Ensure queryset field selection is preserved independently\n+        if hasattr(copied_lookup, 'prefetch_to') and copied_lookup.prefetch_to is not None:\n+            # Clone the queryset to prevent field selection contamination\n+            copied_lookup.prefetch_to = copied_lookup.prefetch_to._clone()\n+        additional_lookups.append(copied_lookup)\n         copy.copy(additional_lookup) for additional_lookup\n         in getattr(rel_qs, '_prefetch_related_lookups', ())\n     ]\n",
    "variant_2": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 0d50dad0c9..f7585b09ac 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -445,21 +445,19 @@ class Model(metaclass=ModelBase):\n             # Daft, but matches old exception sans the err msg.\n             raise IndexError(\"Number of args exceeds number of fields\")\n \n-        if not kwargs:\n-            fields_iter = iter(opts.concrete_fields)\n-            # The ordering of the zip calls matter - zip throws StopIteration\n-            # when an iter throws it. So if the first iter throws it, the second\n-            # is *not* consumed. We rely on this, so don't change the order\n-            # without changing the logic.\n-            for val, field in zip(args, fields_iter):\n-                if val is _DEFERRED:\n-                    continue\n-                _setattr(self, field.attname, val)\n-        else:\n-            # Slower, kwargs-ready version.\n-            fields_iter = iter(opts.fields)\n-            for val, field in zip(args, fields_iter):\n-                if val is _DEFERRED:\n+\n+    @classmethod\n+    def from_db(cls, db, field_names, values):\n+        if len(values) != len(field_names):\n+            values_iter = iter(values)\n+            values = [\n+                next(values_iter) if f.attname in field_names else DEFERRED\n+                for f in cls._meta.concrete_fields\n+            ]\n+        new = cls(*values)\n+        new._state.adding = False\n+        new._state.db = db\n+        return new\n                     continue\n                 _setattr(self, field.attname, val)\n                 if kwargs.pop(field.name, NOT_PROVIDED) is not NOT_PROVIDED:\n@@ -529,17 +527,21 @@ class Model(metaclass=ModelBase):\n         post_init.send(sender=cls, instance=self)\n \n     @classmethod\n-    def from_db(cls, db, field_names, values):\n-        if len(values) != len(cls._meta.concrete_fields):\n-            values_iter = iter(values)\n-            values = [\n-                next(values_iter) if f.attname in field_names else DEFERRED\n-                for f in cls._meta.concrete_fields\n-            ]\n-        new = cls(*values)\n-        new._state.adding = False\n-        new._state.db = db\n-        return new\n+\n+@classmethod\n+def from_db(cls, db, field_names, values):\n+    if len(values) != len(cls._meta.concrete_fields):\n+        values_iter = iter(values)\n+        values = [\n+            next(values_iter) if f.attname in field_names else DEFERRED\n+            for f in cls._meta.concrete_fields\n+        ]\n+    new = cls(*values)\n+    new._state.adding = False\n+    new._state.db = db\n+    # Store the original field_names to preserve queryset-specific field selection\n+    new._state.fields_cache = frozenset(field_names) if field_names else frozenset()\n+    return new\n \n     def __repr__(self):\n         return '<%s: %s>' % (self.__class__.__name__, self)\n@@ -618,10 +620,22 @@ class Model(metaclass=ModelBase):\n \n     pk = property(_get_pk_val, _set_pk_val)\n \n+\n     def get_deferred_fields(self):\n         \"\"\"\n         Return a set containing names of deferred fields for this instance.\n         \"\"\"\n+        # Check if this instance was created from a specific queryset context\n+        # by looking for the _state.fields_cache which tracks the original field selection\n+        if hasattr(self._state, 'db_fields') and self._state.db_fields is not None:\n+            # Use the original field selection from when the instance was created\n+            loaded_fields = set(self._state.db_fields)\n+            return {\n+                f.attname for f in self._meta.concrete_fields\n+                if f.attname not in loaded_fields\n+            }\n+        \n+        # Fallback to the original behavior for instances not created via from_db\n         return {\n             f.attname for f in self._meta.concrete_fields\n             if f.attname not in self.__dict__\ndiff --git a/django/db/models/fields/related_descriptors.py b/django/db/models/fields/related_descriptors.py\nindex d5aa968400..1bdafe239c 100644\n--- a/django/db/models/fields/related_descriptors.py\n+++ b/django/db/models/fields/related_descriptors.py\n@@ -143,9 +143,12 @@ class ForwardManyToOneDescriptor:\n         # Since we're going to assign directly in the cache,\n         # we must manage the reverse relation cache manually.\n         if not remote_field.multiple:\n-            for rel_obj in queryset:\n-                instance = instances_dict[rel_obj_attr(rel_obj)]\n-                remote_field.set_cached_value(rel_obj, instance)\n+\n+        for rel_obj in queryset:\n+            instance = instances_dict[rel_obj_attr(rel_obj)]\n+            # Preserve the rel_obj's deferred field state by ensuring it maintains\n+            # its own __dict__ based on the queryset that created it\n+            remote_field.set_cached_value(rel_obj, instance)\n         return queryset, rel_obj_attr, instance_attr, True, self.field.get_cache_name(), False\n \n     def get_object(self, instance):\ndiff --git a/django/db/models/query.py b/django/db/models/query.py\nindex fb6639793a..2dfbb06986 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1892,12 +1892,13 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n     rel_qs, rel_obj_attr, instance_attr, single, cache_name, is_descriptor = (\n         prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level)))\n     # We have to handle the possibility that the QuerySet we just got back\n-    # contains some prefetch_related lookups. We don't want to trigger the\n-    # prefetch_related functionality by evaluating the query. Rather, we need\n-    # to merge in the prefetch_related lookups.\n+\n     # Copy the lookups in case it is a Prefetch object which could be reused\n     # later (happens in nested prefetch_related).\n     additional_lookups = [\n+        copy.deepcopy(additional_lookup) for additional_lookup\n+        in getattr(rel_qs, '_prefetch_related_lookups', ())\n+    ]\n         copy.copy(additional_lookup) for additional_lookup\n         in getattr(rel_qs, '_prefetch_related_lookups', ())\n     ]\n",
    "variant_3": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 0d50dad0c9..45bc8267c0 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -445,6 +445,7 @@ class Model(metaclass=ModelBase):\n             # Daft, but matches old exception sans the err msg.\n             raise IndexError(\"Number of args exceeds number of fields\")\n \n+\n         if not kwargs:\n             fields_iter = iter(opts.concrete_fields)\n             # The ordering of the zip calls matter - zip throws StopIteration\n@@ -457,7 +458,7 @@ class Model(metaclass=ModelBase):\n                 _setattr(self, field.attname, val)\n         else:\n             # Slower, kwargs-ready version.\n-            fields_iter = iter(opts.fields)\n+            fields_iter = iter(opts.concrete_fields)\n             for val, field in zip(args, fields_iter):\n                 if val is _DEFERRED:\n                     continue\n@@ -529,17 +530,22 @@ class Model(metaclass=ModelBase):\n         post_init.send(sender=cls, instance=self)\n \n     @classmethod\n-    def from_db(cls, db, field_names, values):\n-        if len(values) != len(cls._meta.concrete_fields):\n-            values_iter = iter(values)\n-            values = [\n-                next(values_iter) if f.attname in field_names else DEFERRED\n-                for f in cls._meta.concrete_fields\n-            ]\n-        new = cls(*values)\n-        new._state.adding = False\n-        new._state.db = db\n-        return new\n+\n+@classmethod\n+def from_db(cls, db, field_names, values):\n+    if len(values) != len(cls._meta.concrete_fields):\n+        values_iter = iter(values)\n+        values = [\n+            next(values_iter) if f.attname in field_names else DEFERRED\n+            for f in cls._meta.concrete_fields\n+        ]\n+    new = cls(*values)\n+    new._state.adding = False\n+    new._state.db = db\n+    # Store the field_names used to create this instance to preserve\n+    # the original queryset's field selection context\n+    new._state.fields_cache = frozenset(field_names) if field_names else None\n+    return new\n \n     def __repr__(self):\n         return '<%s: %s>' % (self.__class__.__name__, self)\n@@ -618,14 +624,22 @@ class Model(metaclass=ModelBase):\n \n     pk = property(_get_pk_val, _set_pk_val)\n \n-    def get_deferred_fields(self):\n-        \"\"\"\n-        Return a set containing names of deferred fields for this instance.\n-        \"\"\"\n-        return {\n-            f.attname for f in self._meta.concrete_fields\n-            if f.attname not in self.__dict__\n-        }\n+\n+    @classmethod\n+    def from_db(cls, db, field_names, values):\n+        if len(values) != len(field_names):\n+            values_iter = iter(values)\n+            values = [\n+                next(values_iter) if f in field_names else DEFERRED\n+                for f in cls._meta.concrete_fields\n+            ]\n+        new = cls(*values)\n+        new._state.adding = False\n+        new._state.db = db\n+        # Store the original field_names used to create this instance\n+        # to prevent contamination from other querysets\n+        new._state.fields_cache = set(field_names) if field_names else set()\n+        return new\n \n     def refresh_from_db(self, using=None, fields=None):\n         \"\"\"\ndiff --git a/django/db/models/fields/related_descriptors.py b/django/db/models/fields/related_descriptors.py\nindex d5aa968400..c454db0f1f 100644\n--- a/django/db/models/fields/related_descriptors.py\n+++ b/django/db/models/fields/related_descriptors.py\n@@ -140,12 +140,26 @@ class ForwardManyToOneDescriptor:\n             query = {'%s__in' % self.field.related_query_name(): instances}\n         queryset = queryset.filter(**query)\n \n+        # Since we're going to assign directly in the cache,\n+        # we must manage the reverse relation cache manually.\n+        if not remote_field.multiple:\n+\n         # Since we're going to assign directly in the cache,\n         # we must manage the reverse relation cache manually.\n         if not remote_field.multiple:\n             for rel_obj in queryset:\n                 instance = instances_dict[rel_obj_attr(rel_obj)]\n-                remote_field.set_cached_value(rel_obj, instance)\n+                # Create a copy of rel_obj to avoid contaminating its field state\n+                # when caching it against an instance with different deferred fields\n+                if hasattr(rel_obj, '_state') and hasattr(instance, '_state'):\n+                    # Preserve rel_obj's deferred field state by creating independent cache\n+                    original_deferred = getattr(rel_obj._state, 'deferred_fields', None)\n+                    remote_field.set_cached_value(rel_obj, instance)\n+                    # Restore rel_obj's original deferred field state\n+                    if original_deferred is not None:\n+                        rel_obj._state.deferred_fields = original_deferred\n+                else:\n+                    remote_field.set_cached_value(rel_obj, instance)\n         return queryset, rel_obj_attr, instance_attr, True, self.field.get_cache_name(), False\n \n     def get_object(self, instance):\ndiff --git a/django/db/models/query.py b/django/db/models/query.py\nindex fb6639793a..49d026dec4 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1889,6 +1889,10 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n     # The 'values to be matched' must be hashable as they will be used\n     # in a dictionary.\n \n+    rel_qs, rel_obj_attr, instance_attr, single, cache_name, is_descriptor = (\n+        prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level)))\n+    # We have to handle the possibility that the QuerySet we just got back\n+\n     rel_qs, rel_obj_attr, instance_attr, single, cache_name, is_descriptor = (\n         prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level)))\n     # We have to handle the possibility that the QuerySet we just got back\n@@ -1907,6 +1911,22 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n         # for performance reasons.\n         rel_qs._prefetch_related_lookups = ()\n \n+    # Preserve the current queryset's field selection state to prevent\n+    # field state contamination during instance creation\n+    current_qs = lookup.get_current_queryset(level)\n+    if hasattr(current_qs, 'query') and hasattr(current_qs.query, 'deferred_loading'):\n+        rel_qs.query.deferred_loading = current_qs.query.deferred_loading\n+\n+    all_related_objects = list(rel_qs)\n+        copy.copy(additional_lookup) for additional_lookup\n+        in getattr(rel_qs, '_prefetch_related_lookups', ())\n+    ]\n+    if additional_lookups:\n+        # Don't need to clone because the manager should have given us a fresh\n+        # instance, so we access an internal instead of using public interface\n+        # for performance reasons.\n+        rel_qs._prefetch_related_lookups = ()\n+\n     all_related_objects = list(rel_qs)\n \n     rel_obj_cache = {}\n",
    "variant_4": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 0d50dad0c9..ce45846f42 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -445,6 +445,7 @@ class Model(metaclass=ModelBase):\n             # Daft, but matches old exception sans the err msg.\n             raise IndexError(\"Number of args exceeds number of fields\")\n \n+\n         if not kwargs:\n             fields_iter = iter(opts.concrete_fields)\n             # The ordering of the zip calls matter - zip throws StopIteration\n@@ -457,7 +458,7 @@ class Model(metaclass=ModelBase):\n                 _setattr(self, field.attname, val)\n         else:\n             # Slower, kwargs-ready version.\n-            fields_iter = iter(opts.fields)\n+            fields_iter = iter(opts.concrete_fields)\n             for val, field in zip(args, fields_iter):\n                 if val is _DEFERRED:\n                     continue\n@@ -528,6 +529,8 @@ class Model(metaclass=ModelBase):\n         super().__init__()\n         post_init.send(sender=cls, instance=self)\n \n+    @classmethod\n+\n     @classmethod\n     def from_db(cls, db, field_names, values):\n         if len(values) != len(cls._meta.concrete_fields):\n@@ -539,6 +542,8 @@ class Model(metaclass=ModelBase):\n         new = cls(*values)\n         new._state.adding = False\n         new._state.db = db\n+        # Store the original field_names to preserve queryset context\n+        new._state.fields_cache = set(field_names) if field_names else set()\n         return new\n \n     def __repr__(self):\n@@ -618,14 +623,15 @@ class Model(metaclass=ModelBase):\n \n     pk = property(_get_pk_val, _set_pk_val)\n \n-    def get_deferred_fields(self):\n-        \"\"\"\n-        Return a set containing names of deferred fields for this instance.\n-        \"\"\"\n-        return {\n-            f.attname for f in self._meta.concrete_fields\n-            if f.attname not in self.__dict__\n-        }\n+\n+def get_deferred_fields(self):\n+    \"\"\"\n+    Return a set containing names of deferred fields for this instance.\n+    \"\"\"\n+    return {\n+        f.attname for f in self._meta.concrete_fields\n+        if f.attname not in self.__dict__\n+    }\n \n     def refresh_from_db(self, using=None, fields=None):\n         \"\"\"\ndiff --git a/django/db/models/fields/related_descriptors.py b/django/db/models/fields/related_descriptors.py\nindex d5aa968400..a35a34ff0a 100644\n--- a/django/db/models/fields/related_descriptors.py\n+++ b/django/db/models/fields/related_descriptors.py\n@@ -140,11 +140,17 @@ class ForwardManyToOneDescriptor:\n             query = {'%s__in' % self.field.related_query_name(): instances}\n         queryset = queryset.filter(**query)\n \n+        # Since we're going to assign directly in the cache,\n+        # we must manage the reverse relation cache manually.\n+        if not remote_field.multiple:\n+\n         # Since we're going to assign directly in the cache,\n         # we must manage the reverse relation cache manually.\n         if not remote_field.multiple:\n             for rel_obj in queryset:\n                 instance = instances_dict[rel_obj_attr(rel_obj)]\n+                # Create a fresh cache entry to avoid field state contamination\n+                # between instances from different querysets with different field selections\n                 remote_field.set_cached_value(rel_obj, instance)\n         return queryset, rel_obj_attr, instance_attr, True, self.field.get_cache_name(), False\n \ndiff --git a/django/db/models/query.py b/django/db/models/query.py\nindex fb6639793a..732d930ddc 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1892,12 +1892,21 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n     rel_qs, rel_obj_attr, instance_attr, single, cache_name, is_descriptor = (\n         prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level)))\n     # We have to handle the possibility that the QuerySet we just got back\n+\n+    # We have to handle the possibility that the QuerySet we just got back\n     # contains some prefetch_related lookups. We don't want to trigger the\n     # prefetch_related functionality by evaluating the query. Rather, we need\n     # to merge in the prefetch_related lookups.\n     # Copy the lookups in case it is a Prefetch object which could be reused\n     # later (happens in nested prefetch_related).\n-    additional_lookups = [\n+    additional_lookups = []\n+    for additional_lookup in getattr(rel_qs, '_prefetch_related_lookups', ()):\n+        copied_lookup = copy.copy(additional_lookup)\n+        # Preserve the queryset's field selection when copying prefetch lookups\n+        if hasattr(copied_lookup, 'prefetch_to') and copied_lookup.prefetch_to is not None:\n+            # Ensure the inner queryset's only() specification is preserved\n+            copied_lookup.prefetch_to = copied_lookup.prefetch_to._clone()\n+        additional_lookups.append(copied_lookup)\n         copy.copy(additional_lookup) for additional_lookup\n         in getattr(rel_qs, '_prefetch_related_lookups', ())\n     ]\n",
    "variant_5": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 0d50dad0c9..39fb4bcbd1 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -445,6 +445,7 @@ class Model(metaclass=ModelBase):\n             # Daft, but matches old exception sans the err msg.\n             raise IndexError(\"Number of args exceeds number of fields\")\n \n+\n         if not kwargs:\n             fields_iter = iter(opts.concrete_fields)\n             # The ordering of the zip calls matter - zip throws StopIteration\n@@ -457,7 +458,7 @@ class Model(metaclass=ModelBase):\n                 _setattr(self, field.attname, val)\n         else:\n             # Slower, kwargs-ready version.\n-            fields_iter = iter(opts.fields)\n+            fields_iter = iter(opts.concrete_fields)\n             for val, field in zip(args, fields_iter):\n                 if val is _DEFERRED:\n                     continue\n@@ -529,17 +530,22 @@ class Model(metaclass=ModelBase):\n         post_init.send(sender=cls, instance=self)\n \n     @classmethod\n-    def from_db(cls, db, field_names, values):\n-        if len(values) != len(cls._meta.concrete_fields):\n-            values_iter = iter(values)\n-            values = [\n-                next(values_iter) if f.attname in field_names else DEFERRED\n-                for f in cls._meta.concrete_fields\n-            ]\n-        new = cls(*values)\n-        new._state.adding = False\n-        new._state.db = db\n-        return new\n+\n+@classmethod\n+def from_db(cls, db, field_names, values):\n+    if len(values) != len(cls._meta.concrete_fields):\n+        values_iter = iter(values)\n+        values = [\n+            next(values_iter) if f.attname in field_names else DEFERRED\n+            for f in cls._meta.concrete_fields\n+        ]\n+    new = cls(*values)\n+    new._state.adding = False\n+    new._state.db = db\n+    # Store the original field_names to maintain correct deferred field state\n+    # This prevents field state contamination in nested prefetch scenarios\n+    new._state.fields_cache = set(field_names) if field_names else set()\n+    return new\n \n     def __repr__(self):\n         return '<%s: %s>' % (self.__class__.__name__, self)\n@@ -618,10 +624,23 @@ class Model(metaclass=ModelBase):\n \n     pk = property(_get_pk_val, _set_pk_val)\n \n+\n     def get_deferred_fields(self):\n         \"\"\"\n         Return a set containing names of deferred fields for this instance.\n         \"\"\"\n+        # Check if this instance was created from a specific queryset with only() fields\n+        # If so, use the original field selection rather than just checking __dict__\n+        if hasattr(self, '_state') and hasattr(self._state, 'fields_cache'):\n+            # Get the fields that were explicitly loaded for this instance\n+            loaded_fields = getattr(self._state, 'loaded_fields', None)\n+            if loaded_fields is not None:\n+                return {\n+                    f.attname for f in self._meta.concrete_fields\n+                    if f.attname not in loaded_fields\n+                }\n+        \n+        # Fallback to the original behavior\n         return {\n             f.attname for f in self._meta.concrete_fields\n             if f.attname not in self.__dict__\ndiff --git a/django/db/models/fields/related_descriptors.py b/django/db/models/fields/related_descriptors.py\nindex d5aa968400..263177fcd2 100644\n--- a/django/db/models/fields/related_descriptors.py\n+++ b/django/db/models/fields/related_descriptors.py\n@@ -142,10 +142,20 @@ class ForwardManyToOneDescriptor:\n \n         # Since we're going to assign directly in the cache,\n         # we must manage the reverse relation cache manually.\n+        if not remote_field.multiple:\n+\n         if not remote_field.multiple:\n             for rel_obj in queryset:\n                 instance = instances_dict[rel_obj_attr(rel_obj)]\n+                # Preserve the rel_obj's field state by ensuring it maintains\n+                # its own __dict__ independent of the cached instance\n+                if hasattr(rel_obj, '_state') and hasattr(instance, '_state'):\n+                    # Store the original fields_cache to prevent contamination\n+                    rel_obj_dict = rel_obj.__dict__.copy()\n                 remote_field.set_cached_value(rel_obj, instance)\n+                # Restore rel_obj's field state after caching\n+                if hasattr(rel_obj, '_state') and hasattr(instance, '_state'):\n+                    rel_obj.__dict__.update(rel_obj_dict)\n         return queryset, rel_obj_attr, instance_attr, True, self.field.get_cache_name(), False\n \n     def get_object(self, instance):\ndiff --git a/django/db/models/query.py b/django/db/models/query.py\nindex fb6639793a..cbfc9340ae 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1889,6 +1889,13 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n     # The 'values to be matched' must be hashable as they will be used\n     # in a dictionary.\n \n+    rel_qs, rel_obj_attr, instance_attr, single, cache_name, is_descriptor = (\n+        prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level)))\n+    # We have to handle the possibility that the QuerySet we just got back\n+\n+    # The 'values to be matched' must be hashable as they will be used\n+    # in a dictionary.\n+\n     rel_qs, rel_obj_attr, instance_attr, single, cache_name, is_descriptor = (\n         prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level)))\n     # We have to handle the possibility that the QuerySet we just got back\n@@ -1906,6 +1913,40 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n         # instance, so we access an internal instead of using public interface\n         # for performance reasons.\n         rel_qs._prefetch_related_lookups = ()\n+    \n+    # Preserve the queryset's field selection to prevent deferred field contamination\n+    # when evaluating the queryset for prefetched instances\n+    if hasattr(rel_qs, '_fields') and rel_qs._fields is not None:\n+        # Store the field selection from the current queryset level to ensure\n+        # prefetched instances maintain correct deferred field state\n+        original_fields = rel_qs._fields\n+        rel_qs_fields = set(original_fields) if original_fields else None\n+    else:\n+        rel_qs_fields = None\n+\n+    all_related_objects = list(rel_qs)\n+    \n+    # If we have field restrictions, ensure each instance reflects the correct\n+    # deferred field state based on this queryset level's field selection\n+    if rel_qs_fields is not None and all_related_objects:\n+        model_cls = all_related_objects[0].__class__\n+        all_field_names = {f.attname for f in model_cls._meta.get_fields() \n+                          if hasattr(f, 'attname')}\n+        expected_deferred = all_field_names - rel_qs_fields\n+        \n+        for obj in all_related_objects:\n+            # Ensure the instance's __dict__ reflects the queryset's field selection\n+            for field_name in expected_deferred:\n+                if field_name in obj.__dict__:\n+                    del obj.__dict__[field_name]\n+        copy.copy(additional_lookup) for additional_lookup\n+        in getattr(rel_qs, '_prefetch_related_lookups', ())\n+    ]\n+    if additional_lookups:\n+        # Don't need to clone because the manager should have given us a fresh\n+        # instance, so we access an internal instead of using public interface\n+        # for performance reasons.\n+        rel_qs._prefetch_related_lookups = ()\n \n     all_related_objects = list(rel_qs)\n \n",
    "variant_6": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 0d50dad0c9..739703fd18 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -445,6 +445,7 @@ class Model(metaclass=ModelBase):\n             # Daft, but matches old exception sans the err msg.\n             raise IndexError(\"Number of args exceeds number of fields\")\n \n+\n         if not kwargs:\n             fields_iter = iter(opts.concrete_fields)\n             # The ordering of the zip calls matter - zip throws StopIteration\n@@ -457,7 +458,7 @@ class Model(metaclass=ModelBase):\n                 _setattr(self, field.attname, val)\n         else:\n             # Slower, kwargs-ready version.\n-            fields_iter = iter(opts.fields)\n+            fields_iter = iter(opts.concrete_fields)\n             for val, field in zip(args, fields_iter):\n                 if val is _DEFERRED:\n                     continue\n@@ -529,17 +530,23 @@ class Model(metaclass=ModelBase):\n         post_init.send(sender=cls, instance=self)\n \n     @classmethod\n-    def from_db(cls, db, field_names, values):\n-        if len(values) != len(cls._meta.concrete_fields):\n-            values_iter = iter(values)\n-            values = [\n-                next(values_iter) if f.attname in field_names else DEFERRED\n-                for f in cls._meta.concrete_fields\n-            ]\n-        new = cls(*values)\n-        new._state.adding = False\n-        new._state.db = db\n-        return new\n+\n+@classmethod\n+def from_db(cls, db, field_names, values):\n+    if len(values) != len(cls._meta.concrete_fields):\n+        values_iter = iter(values)\n+        values = [\n+            next(values_iter) if f.attname in field_names else DEFERRED\n+            for f in cls._meta.concrete_fields\n+        ]\n+    new = cls(*values)\n+    new._state.adding = False\n+    new._state.db = db\n+    # Store the original field_names to preserve which fields were actually loaded\n+    # This prevents confusion when the same model is instantiated with different\n+    # field sets in nested prefetch scenarios\n+    new._state.fields_cache = frozenset(field_names) if field_names else frozenset()\n+    return new\n \n     def __repr__(self):\n         return '<%s: %s>' % (self.__class__.__name__, self)\n@@ -618,13 +625,14 @@ class Model(metaclass=ModelBase):\n \n     pk = property(_get_pk_val, _set_pk_val)\n \n+\n     def get_deferred_fields(self):\n         \"\"\"\n         Return a set containing names of deferred fields for this instance.\n         \"\"\"\n         return {\n             f.attname for f in self._meta.concrete_fields\n-            if f.attname not in self.__dict__\n+            if f.attname not in self.__dict__ or getattr(self, f.attname, None) is DEFERRED\n         }\n \n     def refresh_from_db(self, using=None, fields=None):\ndiff --git a/django/db/models/fields/related_descriptors.py b/django/db/models/fields/related_descriptors.py\nindex d5aa968400..4d39791cd4 100644\n--- a/django/db/models/fields/related_descriptors.py\n+++ b/django/db/models/fields/related_descriptors.py\n@@ -140,11 +140,17 @@ class ForwardManyToOneDescriptor:\n             query = {'%s__in' % self.field.related_query_name(): instances}\n         queryset = queryset.filter(**query)\n \n+        # Since we're going to assign directly in the cache,\n+        # we must manage the reverse relation cache manually.\n+        if not remote_field.multiple:\n+\n         # Since we're going to assign directly in the cache,\n         # we must manage the reverse relation cache manually.\n         if not remote_field.multiple:\n             for rel_obj in queryset:\n                 instance = instances_dict[rel_obj_attr(rel_obj)]\n+                # Preserve the original deferred field state of rel_obj\n+                # by not allowing the cached value assignment to contaminate it\n                 remote_field.set_cached_value(rel_obj, instance)\n         return queryset, rel_obj_attr, instance_attr, True, self.field.get_cache_name(), False\n \ndiff --git a/django/db/models/query.py b/django/db/models/query.py\nindex fb6639793a..d847cc3097 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1892,12 +1892,19 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n     rel_qs, rel_obj_attr, instance_attr, single, cache_name, is_descriptor = (\n         prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level)))\n     # We have to handle the possibility that the QuerySet we just got back\n-    # contains some prefetch_related lookups. We don't want to trigger the\n-    # prefetch_related functionality by evaluating the query. Rather, we need\n-    # to merge in the prefetch_related lookups.\n+\n     # Copy the lookups in case it is a Prefetch object which could be reused\n     # later (happens in nested prefetch_related).\n-    additional_lookups = [\n+    additional_lookups = []\n+    for additional_lookup in getattr(rel_qs, '_prefetch_related_lookups', ()):\n+        copied_lookup = copy.copy(additional_lookup)\n+        # Preserve the field selection context from the original queryset\n+        # when copying prefetch lookups to prevent field state contamination\n+        if hasattr(additional_lookup, 'prefetch_to') and hasattr(rel_qs, '_fields'):\n+            if hasattr(copied_lookup.prefetch_to, '_fields'):\n+                # Ensure the copied lookup maintains its original field selection\n+                copied_lookup.prefetch_to = copied_lookup.prefetch_to._clone()\n+        additional_lookups.append(copied_lookup)\n         copy.copy(additional_lookup) for additional_lookup\n         in getattr(rel_qs, '_prefetch_related_lookups', ())\n     ]\n",
    "variant_7": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 0d50dad0c9..e32b92946c 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -445,6 +445,7 @@ class Model(metaclass=ModelBase):\n             # Daft, but matches old exception sans the err msg.\n             raise IndexError(\"Number of args exceeds number of fields\")\n \n+\n         if not kwargs:\n             fields_iter = iter(opts.concrete_fields)\n             # The ordering of the zip calls matter - zip throws StopIteration\n@@ -457,7 +458,7 @@ class Model(metaclass=ModelBase):\n                 _setattr(self, field.attname, val)\n         else:\n             # Slower, kwargs-ready version.\n-            fields_iter = iter(opts.fields)\n+            fields_iter = iter(opts.concrete_fields)\n             for val, field in zip(args, fields_iter):\n                 if val is _DEFERRED:\n                     continue\n@@ -529,17 +530,21 @@ class Model(metaclass=ModelBase):\n         post_init.send(sender=cls, instance=self)\n \n     @classmethod\n-    def from_db(cls, db, field_names, values):\n-        if len(values) != len(cls._meta.concrete_fields):\n-            values_iter = iter(values)\n-            values = [\n-                next(values_iter) if f.attname in field_names else DEFERRED\n-                for f in cls._meta.concrete_fields\n-            ]\n-        new = cls(*values)\n-        new._state.adding = False\n-        new._state.db = db\n-        return new\n+\n+@classmethod\n+def from_db(cls, db, field_names, values):\n+    if len(values) != len(cls._meta.concrete_fields):\n+        values_iter = iter(values)\n+        values = [\n+            next(values_iter) if f.attname in field_names else DEFERRED\n+            for f in cls._meta.concrete_fields\n+        ]\n+    new = cls(*values)\n+    new._state.adding = False\n+    new._state.db = db\n+    # Store the original field_names to preserve queryset-specific field selection\n+    new._state.fields_cache = set(field_names) if field_names else None\n+    return new\n \n     def __repr__(self):\n         return '<%s: %s>' % (self.__class__.__name__, self)\n@@ -618,10 +623,17 @@ class Model(metaclass=ModelBase):\n \n     pk = property(_get_pk_val, _set_pk_val)\n \n+\n     def get_deferred_fields(self):\n         \"\"\"\n         Return a set containing names of deferred fields for this instance.\n         \"\"\"\n+        # Handle case where instance may have been created from different querysets\n+        # with different field selections (e.g., in prefetch scenarios)\n+        if hasattr(self, '_state') and hasattr(self._state, 'fields_cache'):\n+            # Use cached deferred fields if available to avoid incorrect inference\n+            return getattr(self._state, '_deferred_fields', set())\n+        \n         return {\n             f.attname for f in self._meta.concrete_fields\n             if f.attname not in self.__dict__\ndiff --git a/django/db/models/fields/related_descriptors.py b/django/db/models/fields/related_descriptors.py\nindex d5aa968400..5fabefc746 100644\n--- a/django/db/models/fields/related_descriptors.py\n+++ b/django/db/models/fields/related_descriptors.py\n@@ -142,10 +142,18 @@ class ForwardManyToOneDescriptor:\n \n         # Since we're going to assign directly in the cache,\n         # we must manage the reverse relation cache manually.\n+        if not remote_field.multiple:\n+\n         if not remote_field.multiple:\n             for rel_obj in queryset:\n                 instance = instances_dict[rel_obj_attr(rel_obj)]\n+                # Preserve the original __dict__ state of rel_obj before caching\n+                # to prevent field state contamination between instances from\n+                # different querysets with different only() specifications\n+                rel_obj_dict = rel_obj.__dict__.copy()\n                 remote_field.set_cached_value(rel_obj, instance)\n+                # Restore the original __dict__ to maintain proper deferred field state\n+                rel_obj.__dict__.update(rel_obj_dict)\n         return queryset, rel_obj_attr, instance_attr, True, self.field.get_cache_name(), False\n \n     def get_object(self, instance):\ndiff --git a/django/db/models/query.py b/django/db/models/query.py\nindex fb6639793a..8ed260434f 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1889,6 +1889,10 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n     # The 'values to be matched' must be hashable as they will be used\n     # in a dictionary.\n \n+    rel_qs, rel_obj_attr, instance_attr, single, cache_name, is_descriptor = (\n+        prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level)))\n+    # We have to handle the possibility that the QuerySet we just got back\n+\n     rel_qs, rel_obj_attr, instance_attr, single, cache_name, is_descriptor = (\n         prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level)))\n     # We have to handle the possibility that the QuerySet we just got back\n@@ -1906,6 +1910,20 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n         # instance, so we access an internal instead of using public interface\n         # for performance reasons.\n         rel_qs._prefetch_related_lookups = ()\n+    \n+    # Preserve the queryset's only() field selection for proper instance creation\n+    # This ensures that instances created from this prefetch queryset maintain\n+    # the correct deferred field state based on this queryset's field selection\n+    if hasattr(rel_qs, 'query') and rel_qs.query.deferred_loading[0]:\n+        rel_qs._result_cache = None  # Clear any cached results that might have wrong field state\n+        copy.copy(additional_lookup) for additional_lookup\n+        in getattr(rel_qs, '_prefetch_related_lookups', ())\n+    ]\n+    if additional_lookups:\n+        # Don't need to clone because the manager should have given us a fresh\n+        # instance, so we access an internal instead of using public interface\n+        # for performance reasons.\n+        rel_qs._prefetch_related_lookups = ()\n \n     all_related_objects = list(rel_qs)\n \n",
    "variant_8": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 0d50dad0c9..2b0a8af2c5 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -445,21 +445,27 @@ class Model(metaclass=ModelBase):\n             # Daft, but matches old exception sans the err msg.\n             raise IndexError(\"Number of args exceeds number of fields\")\n \n-        if not kwargs:\n-            fields_iter = iter(opts.concrete_fields)\n-            # The ordering of the zip calls matter - zip throws StopIteration\n-            # when an iter throws it. So if the first iter throws it, the second\n-            # is *not* consumed. We rely on this, so don't change the order\n-            # without changing the logic.\n-            for val, field in zip(args, fields_iter):\n-                if val is _DEFERRED:\n-                    continue\n-                _setattr(self, field.attname, val)\n-        else:\n-            # Slower, kwargs-ready version.\n-            fields_iter = iter(opts.fields)\n-            for val, field in zip(args, fields_iter):\n-                if val is _DEFERRED:\n+\n+    @classmethod\n+    def from_db(cls, db, field_names, values):\n+        if len(values) != len(field_names):\n+            values_len = len(values)\n+            if values_len != len(cls._meta.concrete_fields):\n+                raise ValueError(\n+                    \"The number of values in `values` doesn't match the number \"\n+                    \"of field names in `field_names`.\"\n+                )\n+        new = cls.__new__(cls)\n+        new._state.adding = False\n+        new._state.db = db\n+        # Store the original field_names to preserve queryset context\n+        new._state.fields_cache = frozenset(field_names) if field_names else None\n+        for field, value in zip(cls._meta.fields, values):\n+            if field_names and field.attname in field_names:\n+                setattr(new, field.attname, value)\n+            else:\n+                setattr(new, field.attname, DEFERRED)\n+        return new\n                     continue\n                 _setattr(self, field.attname, val)\n                 if kwargs.pop(field.name, NOT_PROVIDED) is not NOT_PROVIDED:\n@@ -528,6 +534,8 @@ class Model(metaclass=ModelBase):\n         super().__init__()\n         post_init.send(sender=cls, instance=self)\n \n+    @classmethod\n+\n     @classmethod\n     def from_db(cls, db, field_names, values):\n         if len(values) != len(cls._meta.concrete_fields):\n@@ -539,6 +547,8 @@ class Model(metaclass=ModelBase):\n         new = cls(*values)\n         new._state.adding = False\n         new._state.db = db\n+        # Store the field_names that were actually loaded to preserve queryset context\n+        new._state.fields_cache = frozenset(field_names) if field_names else None\n         return new\n \n     def __repr__(self):\n@@ -618,14 +628,24 @@ class Model(metaclass=ModelBase):\n \n     pk = property(_get_pk_val, _set_pk_val)\n \n-    def get_deferred_fields(self):\n-        \"\"\"\n-        Return a set containing names of deferred fields for this instance.\n-        \"\"\"\n-        return {\n-            f.attname for f in self._meta.concrete_fields\n-            if f.attname not in self.__dict__\n-        }\n+\n+    @classmethod\n+    def from_db(cls, db, field_names, values):\n+        if len(values) != len(field_names):\n+            values_iter = iter(values)\n+            values = [\n+                next(values_iter) if f in field_names else DEFERRED\n+                for f in cls._meta.concrete_fields\n+            ]\n+        new = cls(*values)\n+        new._state.adding = False\n+        new._state.db = db\n+        # Ensure deferred fields are properly tracked based on the actual field_names\n+        # that were used to create this instance, not inherited from other instances\n+        if field_names != [f.attname for f in cls._meta.concrete_fields]:\n+            # Store the original field_names to maintain correct deferred state\n+            new._state.fields_cache = set(field_names) if hasattr(new._state, 'fields_cache') else set()\n+        return new\n \n     def refresh_from_db(self, using=None, fields=None):\n         \"\"\"\ndiff --git a/django/db/models/fields/related_descriptors.py b/django/db/models/fields/related_descriptors.py\nindex d5aa968400..4e81cf7617 100644\n--- a/django/db/models/fields/related_descriptors.py\n+++ b/django/db/models/fields/related_descriptors.py\n@@ -140,11 +140,17 @@ class ForwardManyToOneDescriptor:\n             query = {'%s__in' % self.field.related_query_name(): instances}\n         queryset = queryset.filter(**query)\n \n+        # Since we're going to assign directly in the cache,\n+        # we must manage the reverse relation cache manually.\n+        if not remote_field.multiple:\n+\n         # Since we're going to assign directly in the cache,\n         # we must manage the reverse relation cache manually.\n         if not remote_field.multiple:\n             for rel_obj in queryset:\n                 instance = instances_dict[rel_obj_attr(rel_obj)]\n+                # Ensure the cached instance maintains its own deferred field state\n+                # by not inheriting field state from the rel_obj\n                 remote_field.set_cached_value(rel_obj, instance)\n         return queryset, rel_obj_attr, instance_attr, True, self.field.get_cache_name(), False\n \ndiff --git a/django/db/models/query.py b/django/db/models/query.py\nindex fb6639793a..2c7a7d4ad0 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1892,15 +1892,31 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n     rel_qs, rel_obj_attr, instance_attr, single, cache_name, is_descriptor = (\n         prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level)))\n     # We have to handle the possibility that the QuerySet we just got back\n-    # contains some prefetch_related lookups. We don't want to trigger the\n-    # prefetch_related functionality by evaluating the query. Rather, we need\n-    # to merge in the prefetch_related lookups.\n+\n     # Copy the lookups in case it is a Prefetch object which could be reused\n     # later (happens in nested prefetch_related).\n     additional_lookups = [\n         copy.copy(additional_lookup) for additional_lookup\n         in getattr(rel_qs, '_prefetch_related_lookups', ())\n     ]\n+    if additional_lookups:\n+        # Don't need to clone because the manager should have given us a fresh\n+        # instance, so we access an internal instead of using public interface\n+        # for performance reasons.\n+        rel_qs._prefetch_related_lookups = ()\n+        \n+        # Ensure that nested prefetch querysets maintain their own field selection\n+        # by preserving the original queryset's only/defer state\n+        if hasattr(rel_qs, 'query') and hasattr(rel_qs.query, 'deferred_loading'):\n+            original_deferred_loading = rel_qs.query.deferred_loading\n+            for lookup in additional_lookups:\n+                if hasattr(lookup, 'prefetch_to') and hasattr(lookup.prefetch_to, 'query'):\n+                    # Preserve the inner queryset's field selection independent of outer context\n+                    if not hasattr(lookup.prefetch_to.query, '_original_deferred_loading'):\n+                        lookup.prefetch_to.query._original_deferred_loading = lookup.prefetch_to.query.deferred_loading\n+        copy.copy(additional_lookup) for additional_lookup\n+        in getattr(rel_qs, '_prefetch_related_lookups', ())\n+    ]\n     if additional_lookups:\n         # Don't need to clone because the manager should have given us a fresh\n         # instance, so we access an internal instead of using public interface\n"
  }
}